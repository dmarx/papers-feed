---
File: .github/workflows/1_update_and_enrich.yml
---
name: 1) Process Updates + Enrichments

on:
  workflow_dispatch:
  issues:
    types: [reopened]
    
  schedule:
    - cron: '0 0 * * *'

jobs:
  hydrate-arxiv:
    runs-on: ubuntu-latest
    if: >
      contains(join(github.event.issue.labels.*.name, ','), 'TODO:hydrate-metadata') ||
      github.event_name == 'workflow_dispatch'
    permissions:
      issues: write
    steps:
      - uses: actions/checkout@v4
      
      - uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'
          
      - name: Install dependencies
        run: pip install gh-store>=0.11.2 arxiv

      - name: Process Updates
        run: |
          python scripts/hydrate_metadata.py \
            hydrate_all_open_issues \
            --repo ${{ github.repository }} \
            --token ${{ secrets.GITHUB_TOKEN }}

  process-updates:
    runs-on: ubuntu-latest
    if: "!contains(github.event.issue.labels.*.name, 'TODO:hydrate-metadata') && contains(github.event.issue.labels.*.name, 'stored-object')"
    permissions:
      issues: write
    steps:
      - uses: actions/checkout@v4
      
      - uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'
          
      - name: Install dependencies
        run: pip install gh-store>=0.11.2
          
      - name: Process Updates
        run: |
          python -m gh_store process-updates \
            --issue ${{ github.event.issue.number }} \
            --token ${{ secrets.GITHUB_TOKEN }} \
            --repo ${{ github.repository }}

  notify-deploy-after-process:
    needs: [process-updates]
    if: contains(join(github.event.issue.labels.*.name, ','), 'stored-object')
    runs-on: ubuntu-latest
    steps:
          
      - name: Trigger frontend deploy
        run: |
          curl -L \
            -X POST \
            -H "Accept: application/vnd.github+json" \
            -H "Authorization: Bearer ${{ secrets.GITHUB_TOKEN }}" \
            -H "X-GitHub-Api-Version: 2022-11-28" \
            https://api.github.com/repos/${{ github.repository }}/actions/workflows/2_deploy-frontend.yml/dispatches \
            -d "{\"ref\":\"${{ github.ref }}\"}"

  notify-deploy-after-enrichment:
    needs: [hydrate-arxiv]
    if: contains(join(github.event.issue.labels.*.name, ','), 'stored-object')
    runs-on: ubuntu-latest
    steps:
          
      - name: Trigger frontend deploy
        run: |
          curl -L \
            -X POST \
            -H "Accept: application/vnd.github+json" \
            -H "Authorization: Bearer ${{ secrets.GITHUB_TOKEN }}" \
            -H "X-GitHub-Api-Version: 2022-11-28" \
            https://api.github.com/repos/${{ github.repository }}/actions/workflows/2_deploy-frontend.yml/dispatches \
            -d "{\"ref\":\"${{ github.ref }}\"}"



---
File: .github/workflows/2_deploy-frontend.yml
---
name: Deploy Frontend

on:
  workflow_dispatch:
  push:
    branches: [ main ]
    paths:
      - 'data/papers/gh-store-snapshot.json'
      - 'frontend/*'
      - '.github/workflows/2_deploy-frontend.yml'

concurrency:
  group: store-deploy
  cancel-in-progress: false

permissions:
  contents: write
  pages: write
  id-token: write
  actions: read

jobs:
  update-snapshot:
    runs-on: ubuntu-latest
    outputs:
      changes_detected: ${{ steps.commit-changes.outputs.changes_detected }}
    steps:
      - name: Wait for updates
        uses: actions/github-script@v7
        with:
          script: |
            while (true) {
              const runs = await github.rest.actions.listWorkflowRuns({
                owner: context.repo.owner,
                repo: context.repo.repo,
                workflow_id: '1_store-sync.yml',
              });
              
              const activeUpdates = runs.data.workflow_runs.filter(run => 
                (run.status === 'in_progress' || run.status === 'queued')
              );
              
              if (activeUpdates.length === 0) break;
              console.log(`Waiting for ${activeUpdates.length} active updates to complete...`);
              await new Promise(r => setTimeout(r, 10000));
            }

      - uses: actions/checkout@v4
      
      - uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'
          
      - name: Install dependencies
        run: pip install gh-store

      - name: Update snapshot
        env:
          SNAPSHOT_PATH: data/papers/gh-store-snapshot.json
        run: |
          mkdir -p $(dirname ${{ env.SNAPSHOT_PATH }})
          python -m gh_store update-snapshot \
            --token ${{ secrets.GITHUB_TOKEN }} \
            --repo ${{ github.repository }} \
            --snapshot-path ${{ env.SNAPSHOT_PATH }}
      
      # - name: Convert data
      #   run: |
      #     python frontend/scripts/convert_store.py \
      #       --snapshot_path data/papers/gh-store-snapshot.json \
      #       --output_path data/papers/papers.json \
      #       --archive_path data/papers/papers-archive.json \
      #       --features_base data/papers

      - name: Upload papers data
        uses: actions/upload-artifact@v4
        with:
          name: papers-json
          path: data/papers/gh-store-snapshot.json

      - name: Commit changes
        id: commit-changes
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "chore: Update store snapshot [${{ github.run_id }}]"
          # file_pattern: 'data/papers/**'
      
  deploy:
    needs: update-snapshot
    if: github.event_name == 'workflow_dispatch' || needs.update-snapshot.outputs.changes_detected == 'true'
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: true

      - name: Download papers.json
        uses: actions/download-artifact@v4
        with:
          name: papers-json
          path: web/

      - name: Build web directory
        run: |
          cp frontend/* web/
          
          # Copy paper features maintaining directory structure
          cd data
          if [ -d "papers" ]; then
            # Create papers directory in web/data
            mkdir -p ../web/data/papers
            
            # Find all markdown files under papers/*/features
            # and copy them maintaining directory structure
            find papers -type f -name "*.md" -path "*/features/*" -exec cp --parents {} ../web/data/ \;
          fi
          cd ..

      - name: Get git info
        id: git-info
        run: |
          echo "branch=${GITHUB_REF#refs/heads/}" >> $GITHUB_OUTPUT
          echo "commit=$(git rev-parse --short HEAD)" >> $GITHUB_OUTPUT
          echo "repo=${GITHUB_REPOSITORY}" >> $GITHUB_OUTPUT

      - name: Create git info JSON
        run: |
          echo "{\"branch\": \"${{ steps.git-info.outputs.branch }}\", \"commit\": \"${{ steps.git-info.outputs.commit }}\", \"repo\": \"${{ steps.git-info.outputs.repo }}\"}" > web/data/git-info.json

      - name: Deploy to GitHub Pages
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./web
          force_orphan: true



---
File: .github/workflows/ATTIC/1_store-sync.yml
---
name: Store Sync

on:
  workflow_dispatch:
  # issues:
  #   types: [reopened]
  # schedule:
  #   - cron: '0 0 * * *'

jobs:
  process-updates:
    runs-on: ubuntu-latest
    if: contains(github.event.issue.labels.*.name, 'stored-object')
    permissions:
      issues: write
    steps:
      - uses: actions/checkout@v4
      
      - uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'
          
      - name: Install dependencies
        run: pip install gh-store
          
      - name: Process Updates
        run: |
          python -m gh_store process-updates \
            --issue ${{ github.event.issue.number }} \
            --token ${{ secrets.GITHUB_TOKEN }} \
            --repo ${{ github.repository }}

  notify-deploy:
    needs: process-updates
    runs-on: ubuntu-latest
    steps:
      - name: Trigger frontend deploy
        run: |
          curl -L \
            -X POST \
            -H "Accept: application/vnd.github+json" \
            -H "Authorization: Bearer ${{ secrets.GITHUB_TOKEN }}" \
            -H "X-GitHub-Api-Version: 2022-11-28" \
            https://api.github.com/repos/${{ github.repository }}/actions/workflows/2_deploy-frontend.yml/dispatches \
            -d "{\"ref\":\"${{ github.ref }}\"}"



---
File: .github/workflows/ATTIC/DEPRECATED_pandoc_convert-markdown.yml
---
# .github/workflows/convert-markdown.yml
name: Convert Papers to Markdown

on:
  # schedule:
  #   - cron: '0 */12 * * *'  # Run every 12 hours
  workflow_dispatch:
  
concurrency:
  group: ${{ github.repository }}-event-processing
  cancel-in-progress: false
  
jobs:

  convert-markdown:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: true
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y pandoc texlive-base
          pandoc --version  # Verify installation
      
      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install papers_feed
      
      - name: Convert to markdown
        run: |
          python -m papers_feed.asset_manager convert-markdown
          python -m papers_feed.asset_manager retry-failures
      
      - name: Commit changes
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "chore: Convert papers to markdown"
          file_pattern: |
            data/papers/**



---
File: .github/workflows/ATTIC/arxiv-metadata-hydration-ts.yml
---
name: Fetch arXiv Metadata

on:
  issues:
    types: [opened, reopened]

jobs:
  fetch-arxiv-metadata:
    runs-on: ubuntu-latest
    if: contains(github.event.issue.labels.*.name, 'stored-object')
    steps:
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          
      - name: Install gh-store-client
        run: npm install gh-store-client
        
      - name: Fetch and post arXiv metadata
        uses: actions/github-script@v7
        with:
          script: |
            
            function findObjectId(labels) {
              if (!labels || !Array.isArray(labels)) {
                return null;
              }
              
              for (const label of labels) {
                if (label.name && label.name.startsWith('UID:')) {
                  return label.name.substring(4).trim();
                }
              }
              
              return null;
            }
            
            function removePrefix(string, prefix, sep = ':') {
              if (string.startsWith(prefix + sep)) {
                return string.slice(prefix.length + sep.length);
              }
              return null; // Return null to indicate no match
            }
            
            function extractPaperId(string, prefix) {
              // Case 1: Format is "prefix:id"
              let result = removePrefix(string, prefix, ':');
              if (result !== null) return result;
              
              // Case 2: Format is "prefix.id"
              result = removePrefix(string, prefix, '.');
              if (result !== null) return result;
              
              // Case 3: Format is "prefix:prefix:id"
              result = removePrefix(string, prefix + ':' + prefix, ':');
              if (result !== null) return result;
              
              // Case 3 alternate: Format is "prefix.prefix.id"
              result = removePrefix(string, prefix + '.' + prefix, '.');
              if (result !== null) return result;
              
              // Case 4: If none of the above, return the original string
              return string;
            }

            ///////////////////////////////////////////////////////////

            const issue = context.payload.issue;
            const issueNumber = issue.number;
            const issueBody = issue.body.trim();            
            console.log(`Processing issue #${issueNumber} with body: ${issueBody}`);

            const objectId = findObjectId(issue.labels);            
            if (!objectId) {
              throw new Error(`Unable to identify a gh-store UID among labels: ${issue.labels}`);
            }
            console.log(`Found objectId: ${objectId}`);

            if (!objectId.startsWith('paper:')) {
              throw new Error(`Exiting: ${objectId} is not a paper.`);
            }
            const paperId = objectId.slice(6);
            const arxivId = extractPaperId(paperId, 'arxiv');

            // Validate arXiv ID format (basic validation)
            const arxivIdRegex = /\d{4}\.\d{4,5}(v\d+)?|\w+\/\d{7}(v\d+)?/;
            if (!arxivIdRegex.test(arxivId)) {
              throw new Error(`Invalid arXiv ID format: ${arxivId}`);
            }
            
            //let store = GitHubStoreClient(token=${{ secrets.GITHUB_TOKEN }}, repo=${{ github.repository }});
            const { GitHubStoreClient } = require('gh-store-client');
            const store = new GitHubStoreClient(
              process.env.GITHUB_TOKEN,
              `${context.repo.owner}/${context.repo.repo}`
            );
            let obj = store.getObject(objectId);
            console.log("Got stored object:", obj);
            
            console.log(`Fetching metadata for arXiv ID: ${arxivId}`);
            
            try {
              // Fetch metadata from arXiv API using native fetch
              const response = await fetch(`http://export.arxiv.org/api/query?id_list=${arxivId}`);
              
              if (!response.ok) {
                throw new Error(`arXiv API responded with status: ${response.status}`);
              }
              
              const xmlData = await response.text();
              
              // Parse XML response using DOMParser
              const parseXML = (xmlString) => {
                // Simple XML parser for arXiv API response
                // This extracts specific elements we need
                const getTagContent = (tag, xml) => {
                  const regex = new RegExp(`<${tag}[^>]*>(.*?)</${tag}>`, 'gs');
                  const matches = [...xml.matchAll(regex)];
                  return matches.map(m => m[1].trim());
                };
                
                const getAttributes = (tag, xml) => {
                  const regex = new RegExp(`<${tag}([^>]*)>`, 'g');
                  const matches = [...xml.matchAll(regex)];
                  return matches.map(m => {
                    const attrs = {};
                    const attrMatches = [...m[1].matchAll(/(\w+)="([^"]*)"/g)];
                    attrMatches.forEach(attr => {
                      attrs[attr[1]] = attr[2];
                    });
                    return attrs;
                  });
                };
                
                const authors = getTagContent('author', xmlString).map(author => {
                  const name = getTagContent('name', author)[0];
                  return name;
                });
                
                const categories = getAttributes('category', xmlString).map(attr => attr.term);
                
                const links = getAttributes('link', xmlString).map(attr => ({
                  rel: attr.rel,
                  href: attr.href,
                  type: attr.type
                }));
                
                return {
                  id: getTagContent('id', xmlString)[0],
                  title: getTagContent('title', xmlString)[0],
                  authors: authors,
                  published: getTagContent('published', xmlString)[0],
                  updated: getTagContent('updated', xmlString)[0],
                  summary: getTagContent('summary', xmlString)[0],
                  categories: categories,
                  links: links
                };
              };
              
              // Extract relevant metadata
              const metadata = parseXML(xmlData);
              
              if (!metadata.id) {
                throw new Error(`No metadata found for arXiv ID: ${arxivId}`);
              }
              
              console.log(`Successfully fetched metadata for arXiv ID: ${arxivId}`);
              
              // Post metadata as comment
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: issueNumber,
                body: `\`\`\`json\n${JSON.stringify(metadata, null, 2)}\n\`\`\``
              });
              
              console.log('Posted metadata comment to issue');
              
            } catch (error) {
              console.error(`Error: ${error.message}`);
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: issueNumber,
                body: `Error fetching arXiv metadata: ${error.message}`
              });
            }



---
File: .github/workflows/ATTIC/convert-markdown.yaml
---
name: Generate Missing Markdown Conversions (grobid)

on:
  schedule:
    - cron: '0 */12 * * *'  # Run every 12 hours
  workflow_dispatch:
  
concurrency:
  group: ${{ github.repository }}-event-processing
  cancel-in-progress: false

jobs:
  convert:
    runs-on: ubuntu-latest
    services:
      grobid:
        image: lfoppiano/grobid:latest-crf
        ports:
          - 8070:8070
        env:
          JAVA_OPTS: "-Xmx4g"
        volumes:
          - ${{ github.workspace }}:/opt/grobid/input
        options: "--init"
        
    steps:
      - uses: actions/checkout@v4
    
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
    
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install llamero lxml requests
    
      - name: Process PDF
        env:
          GROBID_HOST: localhost  # Use localhost since the service is mapped to that port
        run: |
          # Wait until Grobid is ready
          for i in {1..30}; do
            if curl -sSf http://localhost:8070/api/isalive > /dev/null; then
              echo "Grobid is ready!"
              break
            fi
            echo "Attempt $i: Service not ready yet, waiting..."
            sleep 10
          done
          python scripts/process_pdf.py generate_missing_conversions

      # Commit and push the generated output back to the repository.
      - name: Commit and Push Remaining Outputs (xml)
        uses: EndBug/add-and-commit@v9
        with:
          # The 'add' value here could be the folder or file pattern where the output is created.
          # For example, if the PDF is in a subdirectory, you might want to commit changes in that folder.
          add: '.'
          message: "Add tei xml's"
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}



---
File: .github/workflows/ATTIC/deploy_frontend.yaml
---
name: Deploy Paper Feed to GitHub Pages

on:
  push:
    paths:
      - 'data/papers/gh-store-snapshot.json'
      - '.github/workflows/deploy_frontend.yaml'
      - 'frontend/scripts/convert_store.py'
  workflow_dispatch:
  schedule:
    - cron: '0 0 * * *'  # Run daily at midnight UTC

concurrency:
  group: ${{ github.repository }}-event-processing
  cancel-in-progress: false

permissions:
  contents: write
  pages: write
  id-token: write

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: true

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install fire loguru

      - name: Prepare web directory
        run: |
          mkdir -p web/{styles,js,data}
          cp frontend/src/styles/*.css web/styles/
          cp frontend/src/js/*.js web/js/
          cp frontend/src/templates/index.html web/index.html
          
      - name: Convert data
        run: |
          python frontend/scripts/convert_store.py \
            --snapshot_path data/papers/gh-store-snapshot.json \
            --output_path web/data/papers.json

      - name: Ensure presence of .nojekyll file
        run: touch web/.nojekyll

      - name: Get git info
        id: git-info
        run: |
          echo "branch=${GITHUB_REF#refs/heads/}" >> $GITHUB_OUTPUT
          echo "commit=$(git rev-parse --short HEAD)" >> $GITHUB_OUTPUT
          echo "repo=${GITHUB_REPOSITORY}" >> $GITHUB_OUTPUT

      - name: Create git info JSON
        run: |
          echo "{\"branch\": \"${{ steps.git-info.outputs.branch }}\", \"commit\": \"${{ steps.git-info.outputs.commit }}\", \"repo\": \"${{ steps.git-info.outputs.repo }}\"}" > web/data/git-info.json

      - name: Setup Pages
        uses: actions/configure-pages@v4

      - name: Upload artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: web
  
      - name: Deploy to GitHub Pages
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./web
          force_orphan: true



---
File: .github/workflows/ATTIC/download-papers.yml
---
# .github/workflows/download-papers.yml
name: Download Paper Files

on:
  # schedule:
  #   - cron: '0 */6 * * *'  # Run every 6 hours
  workflow_dispatch:
  
concurrency:
  group: ${{ github.repository }}-event-processing
  cancel-in-progress: false
  
jobs:
  download-files:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: true
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install papers_feed
      
      - name: Download PDFs (uncomment to download source)
        run: |
          python -m papers_feed.asset_manager download-pdfs
          #python -m papers_feed.asset_manager download-source
      
      - name: Commit changes
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "chore: Download paper files"
          file_pattern: |
            data/papers/**



---
File: .github/workflows/ATTIC/gh-store-snapshot.yml
---
# gh-store-snapshot.yml
name: Gh-Store Snapshot Management

on:
  issues:
    types: [reopened]
  # schedule:
  #   # Run daily at midnight UTC
  #   - cron: '0 0 * * *'
  workflow_dispatch:
    # Allow manual triggering
    inputs:
      force_new:
        description: 'Force creation of new snapshot'
        required: false
        type: boolean
        default: false

env:
  SNAPSHOT_PATH: data/papers/gh-store-snapshot.json

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: false

jobs:
  process-updates:
    if: contains(github.event.issue.labels.*.name, 'stored-object')
    uses: "dmarx/papers-feed/.github/workflows/ghstore-process-updates.yml@673d20a8da9003fa5f437ac66f613a2b869badc4"
  snapshot:
    needs: process-updates
    runs-on: ubuntu-latest
    permissions:
      contents: write  # Needed for pushing snapshot changes

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install gh-store

      - name: Check for existing snapshot
        id: check_snapshot
        run: |
          if [ -f "${{ env.SNAPSHOT_PATH }}" ] && [ "${{ github.event.inputs.force_new }}" != "true" ]; then
            echo "exists=true" >> $GITHUB_OUTPUT
          else
            echo "exists=false" >> $GITHUB_OUTPUT
          fi

      - name: Create new snapshot
        if: steps.check_snapshot.outputs.exists == 'false'
        run: |
          # Ensure directory exists
          mkdir -p $(dirname ${{ env.SNAPSHOT_PATH }})
          
          # Create snapshot using CLI
          python -m gh_store snapshot \
            --token ${{ secrets.GITHUB_TOKEN }} \
            --repo ${{ github.repository }} \
            --output ${{ env.SNAPSHOT_PATH }}

      - name: Update existing snapshot
        if: steps.check_snapshot.outputs.exists == 'true'
        run: |
          python -m gh_store update-snapshot \
            --token ${{ secrets.GITHUB_TOKEN }} \
            --repo ${{ github.repository }} \
            --snapshot-path ${{ env.SNAPSHOT_PATH }}
            
      - name: Commit changes
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "${{ steps.check_snapshot.outputs.exists == 'true' && 'chore: Update data store snapshot' || 'chore: Create initial data store snapshot' }}"
          file_pattern: "${{ env.SNAPSHOT_PATH }}"



---
File: .github/workflows/ATTIC/ghstore-process-updates.yml
---
# .github/workflows/ghstore-process-updates.yml

name: Process Object Updates

on:
  #issues:
  #  types: [reopened]
  workflow_call:

jobs:
  process-updates:
    runs-on: ubuntu-latest
    if: contains(github.event.issue.labels.*.name, 'stored-object')
    permissions:
      issues: write 
    steps:
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install gh-store
          
      - name: Process Updates
        run: |
          python -m gh_store process-updates \
            --issue ${{ github.event.issue.number }} \
            --token ${{ secrets.GITHUB_TOKEN }} \
            --repo ${{ github.repository }}



---
File: .github/workflows/ATTIC/hard-refresh.yml
---
# .github/workflows/hard-refresh.yml
name: Hard Refresh

on:
  workflow_dispatch:  # Manual trigger only
  
permissions:
  contents: write
  issues: write

jobs:

  refresh:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
      with:
        submodules: true
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'
      
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install PyGithub
        pip install papers_feed
    
    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y pandoc texlive-base
    
    - name: Clear data directory and reopen issues
      run: |
        python - <<EOF
        import os
        import shutil
        from github import Github
        
        # Clear data directory
        data_dir = "data"
        if os.path.exists(data_dir):
            print(f"Removing {data_dir} directory...")
            shutil.rmtree(data_dir)
            os.makedirs(data_dir)
        
        # Reopen closed paper/reading issues
        g = Github(os.environ["GITHUB_TOKEN"])
        repo = g.get_repo(os.environ["GITHUB_REPOSITORY"])
        
        for issue in repo.get_issues(state="closed"):
            labels = [label.name for label in issue.labels]
            if "wontfix" in labels:
                continue
            if "paper" in labels or "reading-session" in labels:
                print(f"Reopening issue #{issue.number}")
                issue.edit(state="open")
        EOF
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Process events
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      run: python -m papers_feed.process_events
  
    - name: Download PDFs and Source
      run: |
        python -m papers_feed.asset_manager download-pdfs
        python -m papers_feed.asset_manager download-source

    - name: Convert to markdown
      run: |
        python -m papers_feed.asset_manager convert-markdown
        python -m papers_feed.asset_manager retry-failures
    
    - name: Commit and push if there are changes
      uses: stefanzweifel/git-auto-commit-action@v5
      with:
        commit_message: "chore: Hard refresh"
        file_pattern: |
          data/**



---
File: .github/workflows/ATTIC/process-events.yml
---
# .github/workflows/process-events.yml
name: Process Paper Events
on:
  push:
    paths:
      - ".github/workflows/process-events.yml"
  issues:
    types: [opened]
    labels:
      - 'paper'
      - 'reading-session'
  # schedule:
  #   - cron: '0 * * * *'  # Run every hour
  workflow_call:
  workflow_dispatch:
  
concurrency:
  group: ${{ github.repository }}-event-processing
  cancel-in-progress: false
  
jobs:
  process-papers:
    runs-on: ubuntu-latest
    permissions:
      actions: write
      contents: write
      issues: write
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: true
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install papers_feed
      
      - name: Process Events
        id: process
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          OUTPUT=$(python -m papers_feed.process_events)
          echo "Debug: Script output: $OUTPUT"
          if [[ "$OUTPUT" == *"Events processed."* ]]; then
            echo "SHOULD_TRIGGER=true" >> "$GITHUB_OUTPUT"
          else
            echo "SHOULD_TRIGGER=false" >> "$GITHUB_OUTPUT"
          fi

      - name: Conditionally trigger frontend deploy
        if: ${{ steps.process.outputs.SHOULD_TRIGGER == 'true' }}
        run: |
          curl -L \
            -X POST \
            -H "Accept: application/vnd.github+json" \
            -H "Authorization: Bearer ${{ secrets.GITHUB_TOKEN }}" \
            -H "X-GitHub-Api-Version: 2022-11-28" \
            https://api.github.com/repos/${{ github.repository }}/actions/workflows/deploy_frontend.yaml/dispatches \
            -d '{"ref":"${{ github.ref }}"}'



---
File: .github/workflows/ATTIC/process_enrichments.yaml
---
name: Process Enrichments

on:
  issues:
    types: [opened, reopened]
  workflow_dispatch:  # Allow manual triggering
  schedule:
    - cron: '0 0 * * *'  # Run daily at midnight UTC

jobs:
  process-features:
    runs-on: ubuntu-latest
    
    # Only check for feature-node label if triggered by an issue event
    if: |
      github.event_name != 'issues' || 
      (github.event_name == 'issues' && contains(github.event.issue.labels.*.name, 'feature-node'))
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.12'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install llamero PyGithub duckduckgo-search
        
    - name: Process feature requests
      run: python scripts/process_enrichments.py
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}



---
File: .github/workflows/ATTIC/process_pdf.yml
---
name: Process PDF with Grobid

on:
  workflow_dispatch:
    inputs:
      pdf_path:
        description: 'Path to PDF file relative to repository root'
        required: true
        type: string
      output_format:
        description: 'Output format (markdown/tei)'
        required: true
        type: choice
        options:
          - markdown
          - tei
        default: 'markdown'
      tag:
        description: 'Optional tag to append to the output filename'
        required: false
        default: ''

jobs:
  convert:
    runs-on: ubuntu-latest
    services:
      grobid:
        image: lfoppiano/grobid:latest-crf
        ports:
          - 8070:8070
        env:
          JAVA_OPTS: "-Xmx4g"
        volumes:
          - ${{ github.workspace }}:/opt/grobid/input
        options: "--init"
        
    steps:
      - uses: actions/checkout@v4
    
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
    
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests loguru fire lxml
    
      - name: Process PDF
        env:
          GROBID_HOST: localhost  # Use localhost since the service is mapped to that port
        run: |
          # Wait until Grobid is ready
          for i in {1..30}; do
            if curl -sSf http://localhost:8070/api/isalive > /dev/null; then
              echo "Grobid is ready!"
              break
            fi
            echo "Attempt $i: Service not ready yet, waiting..."
            sleep 10
          done
          python scripts/process_pdf.py ${{ github.event.inputs.pdf_path }} --format ${{ github.event.inputs.output_format }} --tag "${{ github.event.inputs.tag }}"
    
      # Commit and push the generated output back to the repository.
      - name: Commit and Push Output
        uses: EndBug/add-and-commit@v9
        with:
          # The 'add' value here could be the folder or file pattern where the output is created.
          # For example, if the PDF is in a subdirectory, you might want to commit changes in that folder.
          add: '.'
          message: "Add processed output for ${{ github.event.inputs.pdf_path }}"
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}



---
File: .github/workflows/ATTIC/refresh_pdfs.yaml
---
name: REFRESH ALL Markdown Conversions (grobid)

on:
  workflow_dispatch:
      # tag:
      #   description: 'Optional tag to append to the output filename'
      #   required: false
      #   default: ''

jobs:
  convert:
    runs-on: ubuntu-latest
    services:
      grobid:
        image: lfoppiano/grobid:latest-crf
        ports:
          - 8070:8070
        env:
          JAVA_OPTS: "-Xmx4g"
        volumes:
          - ${{ github.workspace }}:/opt/grobid/input
        options: "--init"
        
    steps:
      - uses: actions/checkout@v4
    
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
    
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install llamero lxml requests
    
      - name: Process PDF
        env:
          GROBID_HOST: localhost  # Use localhost since the service is mapped to that port
        run: |
          # Wait until Grobid is ready
          for i in {1..30}; do
            if curl -sSf http://localhost:8070/api/isalive > /dev/null; then
              echo "Grobid is ready!"
              break
            fi
            echo "Attempt $i: Service not ready yet, waiting..."
            sleep 10
          done
          python scripts/process_pdf.py flush_old_conversions --tag=""
          python scripts/process_pdf.py flush_old_conversions --tag="grobid"
          python scripts/process_pdf.py generate_missing_conversions
    
      # Commit and push the generated output back to the repository.
      - name: Commit and Push Output
        uses: EndBug/add-and-commit@v9
        with:
          # The 'add' value here could be the folder or file pattern where the output is created.
          # For example, if the PDF is in a subdirectory, you might want to commit changes in that folder.
          add: '.'
          message: "Add processed output for ${{ github.event.inputs.pdf_path }}"
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}



---
File: .github/workflows/ATTIC/refresh_pdfs_via_tei.yaml
---
name: REFRESH ALL Markdown Conversions (grobid) - WITH TEI

on:
  workflow_dispatch:

jobs:
  convert:
    runs-on: ubuntu-latest
        
    steps:
      - uses: actions/checkout@v4
    
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
    
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install llamero lxml requests
    
      - name: Process PDF
        run: |
          python scripts/process_pdf.py flush_old_conversions --tag="grobid"
          python scripts/process_pdf.py generate_missing_conversions --regenerate-tei=False
    
      # Commit and push the generated output back to the repository.
      - name: Commit and Push Output
        uses: EndBug/add-and-commit@v9
        with:
          # The 'add' value here could be the folder or file pattern where the output is created.
          # For example, if the PDF is in a subdirectory, you might want to commit changes in that folder.
          add: '.'
          message: "Add processed output for ${{ github.event.inputs.pdf_path }}"
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}



---
File: .github/workflows/build-extension.yml
---
# .github/workflows/build-extension.yml
name: Build Extension

on:
  push:
    paths:
      - 'extension/**'
      - '.github/workflows/build-extension.yml'
    branches: [ main, ext-use-gh-store ]
  workflow_dispatch:

jobs:
  build:
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: extension

    steps:
    - uses: actions/checkout@v4
    
    # Generate package-lock.json if it doesn't exist
    # - name: Initialize npm
    #   run: |
    #     if [ ! -f "package-lock.json" ]; then
    #       npm install --package-lock-only --no-audit
    #     else
    #       echo "package-lock.json exists"
    #     fi
    
    # Regenerate package-lock.json to ensure it matches package.json
    - name: Regenerate package-lock.json
      run: |
        if [ -f "package-lock.json" ]; then
          rm -f package-lock.json
        fi
        npm install --package-lock-only --no-audit

    - name: Flush old build
      run: rm -rf dist/
    
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '20'
        #cache: 'npm'
        #cache-dependency-path: './extension/package-lock.json'
        
    - name: Install dependencies
      #run: npm ci --prefer-offline
      run: npm install --prefer-offline
        
      
    - name: Show environment info
      run: |
        echo "Node version:"
        node --version
        echo "NPM version:"
        npm --version
        echo "Directory structure:"
        ls -R
        echo "package.json contents:"
        cat package.json
        
    - name: Type check
      run: npm run type-check
        
    - name: Build extension
      run: |
        set -ex
        npm run build
        echo "Build output:"
        ls -la dist/

    # Debug output
    - name: Show build results
      if: always()
      run: |
        echo "Current directory:"
        pwd
        echo "Directory contents:"
        ls -lha
        echo "Dist directory contents (if exists):"
        ls -lha dist/ || echo "No dist directory"
        echo "Error logs (if any):"
        find . -name "*.log" -exec cat {} \;

    # Commit the built files
    - name: Commit bundled files
      uses: stefanzweifel/git-auto-commit-action@v5
      with:
        commit_message: "chore: Update extension bundles"
        file_pattern: "extension/dist/*"
        #branch: ${{ github.ref }}



---
File: .github/workflows/deduplicate-ghstore.yml
---
# .github/workflows/deduplicate.yml
# Workflow to automatically find and deduplicate objects in gh-store


name: Deduplicate GH-Store Objects

on:
  # schedule:
  #   - cron: '0 2 * * *' # Run daily at 2:00 UTC
  # push:
  #   branches: [ canonicalizer-newlabels ]
  #   paths: [ ".github/workflows/deduplicate.yml" ]
  # Allow manual triggering
  workflow_dispatch:
    inputs:
      dry_run:
        description: 'Dry run (no changes)'
        type: boolean
        default: true
      specific_object:
        description: 'Process specific object ID only (leave blank for all)'
        type: string
        required: false

jobs:
  deduplicate:
    runs-on: ubuntu-latest
    permissions:
      issues: write  # Needed to modify issues
      contents: read  # Needed to read code
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install gh-store
      
      - name: Run deduplication tool
        id: deduplicate
        run: |
          echo "Running deduplication process..."
          
          # Set up basic command
          CMD="python -m gh_store.tools.canonicalize --token ${{ secrets.GITHUB_TOKEN }} --repo ${{ github.repository }}"
          
          # Check if dry run
          if [[ "${{ github.event.inputs.dry_run }}" == "true" ]]; then
            CMD="$CMD --dry-run"
            echo "::notice::Running in dry-run mode - no changes will be made"
          fi
          
          # Check if specific object requested
          if [[ "${{ github.event.inputs.specific_object }}" != "" ]]; then
            OBJECT_ID="${{ github.event.inputs.specific_object }}"
            CMD="$CMD --object-id $OBJECT_ID"
            echo "::notice::Processing specific object: $OBJECT_ID"
          fi
          
          # First find duplicates and capture output
          echo "Finding duplicates..."
          FIND_OUTPUT=$(eval "$CMD --find-duplicates" 2>&1)
          echo "$FIND_OUTPUT"
          
          # Check if duplicates found
          if [[ "$FIND_OUTPUT" == *"No duplicate objects found"* ]]; then
            echo "::notice::No duplicate objects found!"
            echo "duplicates_found=false" >> $GITHUB_OUTPUT
            exit 0
          else
            echo "duplicates_found=true" >> $GITHUB_OUTPUT
          fi
          
          # Process duplicates
          echo "Processing duplicates..."
          DEDUP_OUTPUT=$(eval "$CMD --deduplicate" 2>&1)
          echo "$DEDUP_OUTPUT"
          
          # Extract metrics
          OBJECTS_PROCESSED=$(echo "$DEDUP_OUTPUT" | grep -o "Processed [0-9]* objects" | grep -o "[0-9]*")
          if [[ -z "$OBJECTS_PROCESSED" ]]; then
            OBJECTS_PROCESSED=0
          fi
          
          echo "objects_processed=$OBJECTS_PROCESSED" >> $GITHUB_OUTPUT
      
      - name: Create summary
        if: steps.deduplicate.outputs.duplicates_found == 'true'
        run: |
          echo "# Deduplication Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [[ "${{ github.event.inputs.dry_run }}" == "true" ]]; then
            echo "**DRY RUN** - No changes were made" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "Found duplicates for ${{ steps.deduplicate.outputs.objects_processed }} objects" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "The deduplication process:" >> $GITHUB_STEP_SUMMARY
          echo "1. Identified objects with multiple issues" >> $GITHUB_STEP_SUMMARY
          echo "2. Selected the oldest issue as canonical for each object" >> $GITHUB_STEP_SUMMARY
          echo "3. Marked other issues as deprecated duplicates" >> $GITHUB_STEP_SUMMARY
          echo "4. Processed virtual merges to ensure data consistency" >> $GITHUB_STEP_SUMMARY
      
      - name: Handle no duplicates
        if: steps.deduplicate.outputs.duplicates_found == 'false'
        run: |
          echo "# Deduplication Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "âœ… No duplicate objects found in the repository." >> $GITHUB_STEP_SUMMARY



---
File: .github/workflows/ghstore-process-bulk.yml
---
# .github/workflows/ghstore-process-bulk.yml
name: Process Bulk Object Updates

on:
  workflow_dispatch:
    inputs:
      label:
        description: 'Label to process (default: stored-object)'
        required: true
        type: string
        default: 'stored-object'

jobs:
  process-updates:
    runs-on: ubuntu-latest
    permissions:
      issues: write 
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install gh-store rich loguru

      - name: Process Updates
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          REPO: ${{ github.repository }}
          LABEL: ${{ inputs.label }}
        run: |
          python - << 'EOF'
          import os
          from github import Github
          from gh_store.__main__ import CLI
          from loguru import logger
          from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn

          # Initialize GitHub client
          g = Github(os.environ["GITHUB_TOKEN"])
          repo = g.get_repo(os.environ["REPO"])
          label = os.environ["LABEL"]

          # Get all open issues with the specified label
          logger.info(f"Finding open issues with label: {label}")
          open_issues = list(repo.get_issues(state="open", labels=[label]))

          if not open_issues:
              logger.warning("No open issues found with specified label")
              exit(0)

          logger.info(f"Found {len(open_issues)} issues to process")

          # Initialize CLI
          cli = CLI()

          # Create progress bar
          with Progress(
              SpinnerColumn(),
              TextColumn("[bold blue]{task.description}"),
              BarColumn(),
              TextColumn("[progress.percentage]{task.percentage:>3.0f}%"),
          ) as progress:
              process_task = progress.add_task(
                  "Processing issues...",
                  total=len(open_issues)
              )

              for issue in open_issues:
                  logger.info(f"Processing issue #{issue.number}")
                  cli.process_updates(
                      issue=issue.number,
                      token=os.environ["GITHUB_TOKEN"],
                      repo=os.environ["REPO"]
                  )
                  progress.update(process_task, advance=1)

          logger.info("Bulk processing completed")
          EOF



---
File: .github/workflows/llamero-summarize.yaml
---
name: Llamero Summarization

on:
  push:
    branches: [ main ]
  workflow_dispatch:

jobs:
  generate-summaries:
    runs-on: ubuntu-latest
    permissions:
      contents: write
      pull-requests: write

    steps:
    - uses: actions/checkout@v4
      with:
        fetch-depth: 1

    - name: Install llamero
      run: touch requirements.txt

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        #cache: 'pip'

    - name: Install llamero
      run: pip install llamero

    - name: Generate summaries
      run: |
        llamero summarize all
        #llamero tree --output summaries/tree.md



---
File: .github/workflows/mirror-issues.yaml
---
# .github/workflows/mirror_repository.yml
name: Mirror GitHub Repository

on:
  workflow_dispatch:
    inputs:
      source_repo:
        description: 'Source repository (format: owner/repo)'
        required: true
        default: 'dmarx/papers-feed'
      target_repo:
        description: 'Target repository (format: owner/repo)'
        required: true
        default: 'dmarx/papers-feed-dev'
      clear_target_labels:
        description: 'Clear all labels from issues in target repository'
        required: true
        type: boolean
        default: false
      issue_range_start:
        description: 'Starting issue number to copy (optional)'
        required: false
      issue_range_end:
        description: 'Ending issue number to copy (optional)'
        required: false

jobs:
  mirror-repo:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
        with:
          fetch-depth: 1  # Shallow clone - only get the latest commit

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          python -m pip install PyGithub fire loguru

      - name: Run mirroring script
        env:
          DEV_REPO_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          python scripts/github_repo_mirror.py mirror \
            --source-repo=${{ github.event.inputs.source_repo }} \
            --target-repo=${{ github.event.inputs.target_repo }} \
            --clear-target-labels=${{ github.event.inputs.clear_target_labels }} \
            ${{ github.event.inputs.issue_range_start != '' && format('--issue-range-start={0}', github.event.inputs.issue_range_start) || '' }} \
            ${{ github.event.inputs.issue_range_end != '' && format('--issue-range-end={0}', github.event.inputs.issue_range_end) || '' }}



---
File: .github/workflows/ops-misc.yml
---
# .github/workflows/ops-misc.yml
# General purpose utility operator for one-off operations
# Executes misc.sh and clears it after successful run

name: Miscellaneous Operations

on:
  # push:
  #   paths:
  #     - 'ops/misc.sh'
  #     - '.github/workflows/ops-misc.yml'
  workflow_dispatch:

permissions:
  contents: write

jobs:
  execute-misc:
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Execute and clear misc script
        run: |
          cat ops/misc.sh
          . ops/misc.sh
          echo '#!/bin/bash' > ops/misc.sh

      - uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "chore: executed miscellaneous operation"



---
File: .github/workflows/paper-enrichment.yml
---
# .github/workflows/paper-enrichment.yml

name: PDF Download and Enrichment

on:
  issues:
    types: [opened, reopened]
  # schedule:
  #   - cron: '0 */6 * * *'
  workflow_dispatch:
  

concurrency:
  group: ${{ github.repository }}-event-processing
  cancel-in-progress: false

jobs:
  download-pdfs:
    runs-on: ubuntu-latest
    if: |
      github.event_name != 'issues' || 
      (github.event_name == 'issues' && contains(github.event.issue.labels.*.name, 'feature-node'))
    permissions:
      contents: write
    outputs:
      has_changes: ${{ steps.commit.outputs.changes_detected }}
      
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: true
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install papers_feed
      
      - name: Download PDFs
        run: |
          python -m papers_feed.asset_manager download-pdfs
      
      - name: Commit changes
        id: commit
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "chore: Download paper files"
          file_pattern: |
            data/papers/**

  convert-pdfs-to-markdown:
    runs-on: ubuntu-latest
    needs: download-pdfs
    if: github.event_name != 'issues' || needs.download-pdfs.outputs.has_changes == 'true'
    outputs:
      has_changes: ${{ steps.commit.outputs.changes_detected }}
    
    services:
      grobid:
        image: lfoppiano/grobid:latest-crf
        ports:
          - 8070:8070
        env:
          JAVA_OPTS: "-Xmx4g"
        volumes:
          - ${{ github.workspace }}:/opt/grobid/input
        options: "--init"
        
    steps:
      - uses: actions/checkout@v4
    
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
    
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install llamero lxml requests
    
      - name: Process PDF
        env:
          GROBID_HOST: localhost
        run: |
          for i in {1..30}; do
            if curl -sSf http://localhost:8070/api/isalive > /dev/null; then
              echo "Grobid is ready!"
              break
            fi
            echo "Attempt $i: Service not ready yet, waiting..."
            sleep 10
          done
          python scripts/process_pdf.py generate_missing_conversions

      - name: Commit and Push Conversions
        id: commit
        uses: EndBug/add-and-commit@v9
        with:
          add: '.'
          message: "Add tei xml's"
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

  process-enrichments:
    needs: convert-pdfs-to-markdown
    if: github.event_name != 'issues' || needs.convert-pdfs-to-markdown.outputs.has_changes == 'true'
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v4
        with:
          ref: ${{ github.ref }}
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install llamero PyGithub duckduckgo-search
          
      - name: Process enrichments
        run: python scripts/process_enrichments.py
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}



---
File: .github/workflows/process-issue-task.yaml
---
name: Process Task From Issue Trigger
on:
  issues:
    types: [opened, reopened]

jobs:
  process-search:
    if: contains(github.event.issue.labels.*.name, 'task')
    runs-on: ubuntu-latest
    permissions:
      issues: write
      contents: write
    steps:
      - uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install gh-store duckduckgo_search
          if [ -f requirements.txt ]; then
            pip install -r requirements.txt
          fi
          
      - name: Process Task
        run: |
          RESULT=$(python scripts/process_task.py --issue-id "$ISSUE_NUMBER")
          gh issue comment "$ISSUE_NUMBER" --body "$RESULT" --repo "$GITHUB_REPOSITORY"

          # TODO: use gh-store to update the issue state and be responsible for closing it
          gh issue close "$ISSUE_NUMBER" --repo "$GITHUB_REPOSITORY"
          
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          ISSUE_NUMBER: ${{ github.event.issue.number }}



---
File: .github/workflows/relabel-issues.yml
---
# .github/workflows/relabel-issues.yml
# GitHub Action to relabel issues based on criteria

name: Relabel Issues

on:
  workflow_dispatch:
    inputs:
      source_label:
        description: 'Source label (Y)'
        required: true
        type: string
      target_label:
        description: 'Target label to apply (X)'
        required: true
        type: string
      min_issue_number:
        description: 'Minimum issue number (k)'
        required: true
        type: number
  
jobs:
  relabel-issues:
    name: Relabel Issues
    runs-on: ubuntu-latest
    
    steps:
      - name: Apply labels to matching issues
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const sourceLabel = '${{ inputs.source_label }}';
            const targetLabel = '${{ inputs.target_label }}';
            const minIssueNumber = ${{ inputs.min_issue_number }};
            
            console.log(`Finding issues with label "${sourceLabel}" and number > ${minIssueNumber}`);
            
            // Get all issues (open and closed) with the source label
            const query = `label:"${sourceLabel}" repo:${context.repo.owner}/${context.repo.repo}`;
            
            // Process issues in batches due to pagination
            let processedCount = 0;
            let labeledCount = 0;
            
            for await (const response of github.paginate.iterator(
              github.rest.search.issuesAndPullRequests,
              { q: query }
            )) {
              for (const issue of response.data) {
                processedCount++;
                
                // Check if issue number meets the criteria
                if (issue.number > minIssueNumber) {
                  // Check if target label already exists
                  const hasLabel = issue.labels.some(label => label.name === targetLabel);
                  
                  if (!hasLabel) {
                    // Add the target label
                    await github.rest.issues.addLabels({
                      owner: context.repo.owner,
                      repo: context.repo.repo,
                      issue_number: issue.number,
                      labels: [targetLabel]
                    });
                    
                    console.log(`Applied label "${targetLabel}" to issue #${issue.number}: ${issue.title}`);
                    labeledCount++;
                  } else {
                    console.log(`Issue #${issue.number} already has label "${targetLabel}"`);
                  }
                }
              }
            }
            
            // Report summary
            console.log(`\nRelabeling complete!`);
            console.log(`- Total processed: ${processedCount} issues`);
            console.log(`- Newly labeled: ${labeledCount} issues`);



---
File: .github/workflows/toggle-issues.yml
---
# .github/workflows/toggle-issues.yaml
name: Toggle Issues

on:
  workflow_dispatch:
    inputs:
      label:
        description: 'toggle issues matching this label'
        required: true
        type: string
        default: 'gh-store'
      perform_close:
        description: 'Close matching open issues'
        required: true
        type: boolean
        default: true
      perform_reopen:
        description: 'Reopen issues closed during the `perform_close` step'
        required: true
        type: boolean
        default: true
      reopen_all_matching:
        description: 'Reopen all labeled issues (not just those closed in this run)'
        required: true
        type: boolean
        default: false

permissions:
  issues: write

jobs:
  toggle-issues:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Install Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install fire loguru PyGithub requests rich

      - name: Run issue toggle script
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          REPO: ${{ github.repository }}
          LABEL: ${{ inputs.label }}
          PERFORM_CLOSE: ${{ inputs.perform_close }}
          PERFORM_REOPEN: ${{ inputs.perform_reopen }}
          REOPEN_ALL_MATCHING: ${{ inputs.reopen_all_matching }}
        run: python scripts/toggle_issues.py



---
File: extension/background.ts
---
// background.ts
// Background script with icon management integration

import { GitHubStoreClient } from 'gh-store-client';
import { PaperManager } from './papers/manager';
import { SessionService } from './utils/session-service';
import { PopupManager } from './utils/popup-manager';
import { SourceIntegrationManager } from './source-integration/source-manager';
import { IconManager, IconState } from './utils/icon-manager';
import { loguru } from './utils/logger';
import { PaperMetadata } from './papers/types';

// Import from central registry instead of individual integrations
import { sourceIntegrations } from './source-integration/registry';
import { Message } from './source-integration/types';

const logger = loguru.getLogger('background');

// Global state
let githubToken = '';
let githubRepo = '';
let paperManager: PaperManager | null = null;
let sessionService: SessionService | null = null;
let popupManager: PopupManager | null = null;
let sourceManager: SourceIntegrationManager | null = null;
let iconManager: IconManager | null = null;

// Initialize sources
function initializeSources() {
  sourceManager = new SourceIntegrationManager();
  
  // Register all sources from the central registry
  for (const integration of sourceIntegrations) {
    sourceManager.registerSource(integration);
  }
  
  logger.info('Source manager initialized with integrations:', 
    sourceIntegrations.map(int => int.id).join(', '));
  
  return sourceManager;
}

// Initialize everything
async function initialize() {
  try {
    // Initialize sources first
    initializeSources();
    
    // Initialize icon manager
    iconManager = new IconManager();
    logger.info('Icon manager initialized');
    
    // Load GitHub credentials
    const items = await chrome.storage.sync.get(['githubToken', 'githubRepo']);
    githubToken = items.githubToken || '';
    githubRepo = items.githubRepo || '';
    logger.info('Credentials loaded', { hasToken: !!githubToken, hasRepo: !!githubRepo });
    
    // Initialize paper manager if we have credentials
    if (githubToken && githubRepo) {
      const githubClient = new GitHubStoreClient(githubToken, githubRepo);
      
      // Pass the source manager to the paper manager
      paperManager = new PaperManager(githubClient, sourceManager!);
      logger.info('Paper manager initialized');
      
      // Initialize session service with paper manager
      sessionService = new SessionService(paperManager);
    } else {
      // Initialize session service without paper manager
      sessionService = new SessionService(null);
    }
    
    logger.info('Session service initialized');
    
    // Initialize popup manager
    popupManager = new PopupManager(
      () => sourceManager,
      () => paperManager
    );
    logger.info('Popup manager initialized');
    
    // Set up message listeners
    setupMessageListeners();
    
    // Initialize debug objects
    initializeDebugObjects();
  } catch (error) {
    logger.error('Initialization error', error);
  }
}

// Set up message listeners
function setupMessageListeners() {
  chrome.runtime.onMessage.addListener((message: any, sender, sendResponse) => {
    if (message.type === 'contentScriptReady' && sender.tab?.id) {
      logger.debug('Content script ready:', sender.tab.url);
      sendResponse({ success: true });
      return true;
    }
    
    if (message.type === 'paperMetadata' && message.metadata && sender.tab?.id) {
      // Store metadata received from content script and update icon
      handlePaperMetadata(message.metadata, sender.tab.id);
      sendResponse({ success: true });
      return true;
    }
    
    if (message.type === 'paperDetected' && sender.tab?.id) {
      // Paper detected but not yet stored - show detected state
      handlePaperDetected(sender.tab.id, message.sourceId, message.paperId);
      sendResponse({ success: true });
      return true;
    }
    
    if (message.type === 'noPaperDetected' && sender.tab?.id) {
      // No paper detected - reset to default icon
      handleNoPaperDetected(sender.tab.id);
      sendResponse({ success: true });
      return true;
    }
    
    if (message.type === 'getCurrentPaper') {
      const session = sessionService?.getCurrentSession();
      const paperMetadata = session 
        ? sessionService?.getPaperMetadata(session.sourceId, session.paperId)
        : null;
      
      logger.debug('Popup requested current paper', paperMetadata);
      sendResponse(paperMetadata);
      return true;
    }
    
    if (message.type === 'updateRating') {
      logger.debug('Rating update requested:', message.rating);
      handleUpdateRating(message.rating, sendResponse);
      return true; // Will respond asynchronously
    }
    
    if (message.type === 'startSession') {
      handleStartSession(message.sourceId, message.paperId);
      sendResponse({ success: true });
      return true;
    }
    
    if (message.type === 'sessionHeartbeat') {
      handleSessionHeartbeat();
      sendResponse({ success: true });
      return true;
    }
    
    if (message.type === 'endSession') {
      handleEndSession(message.reason || 'user_action');
      sendResponse({ success: true });
      return true;
    }

    // New handler for manual paper logging from popup
    if (message.type === 'manualPaperLog' && message.metadata && sender.tab?.id) {
      handleManualPaperLog(message.metadata, sender.tab.id)
        .then(() => sendResponse({ success: true }))
        .catch(error => {
          logger.error('Error handling manual paper log', error);
          sendResponse({ 
            success: false, 
            error: error instanceof Error ? error.message : 'Unknown error' 
          });
        });
      return true; // Will respond asynchronously
    }
    
    // Other message handlers are managed by PopupManager
    
    return false; // Not handled
  });
}

// Handle paper detected (before storage)
async function handlePaperDetected(tabId: number, sourceId: string, paperId: string) {
  if (!iconManager) return;
  
  try {
    await iconManager.setPaperDetected(tabId);
    logger.debug(`Set detected icon for ${sourceId}:${paperId} in tab ${tabId}`);
  } catch (error) {
    logger.error('Error setting detected icon', error);
  }
}

// Handle no paper detected
async function handleNoPaperDetected(tabId: number) {
  if (!iconManager) return;
  
  try {
    await iconManager.resetIcon(tabId);
    logger.debug(`Reset icon for tab ${tabId}`);
  } catch (error) {
    logger.error('Error resetting icon', error);
  }
}

// Handle paper metadata from content script
async function handlePaperMetadata(metadata: PaperMetadata, tabId: number) {
  logger.info(`Received metadata for ${metadata.sourceId}:${metadata.paperId}`);
  
  try {
    // Store metadata in session service
    if (sessionService) {
      sessionService.storePaperMetadata(metadata);
    }
    
    // Store in GitHub if we have a paper manager
    if (paperManager) {
      await paperManager.getOrCreatePaper(metadata);
      logger.debug('Paper metadata stored in GitHub');
      
      // Update icon to tracked state
      if (iconManager) {
        await iconManager.setPaperTracked(tabId);
        logger.debug(`Set tracked icon for ${metadata.sourceId}:${metadata.paperId} in tab ${tabId}`);
      }
    } else {
      // No paper manager - just show detected state
      if (iconManager) {
        await iconManager.setPaperDetected(tabId);
      }
    }
  } catch (error) {
    logger.error('Error handling paper metadata', error);
    
    // On error, show detected state instead of tracked
    if (iconManager) {
      await iconManager.setPaperDetected(tabId);
    }
  }
}

// Handle rating update
async function handleUpdateRating(rating: string, sendResponse: (response: any) => void) {
  if (!paperManager || !sessionService) {
    sendResponse({ success: false, error: 'Services not initialized' });
    return;
  }

  const session = sessionService.getCurrentSession();
  if (!session) {
    sendResponse({ success: false, error: 'No current session' });
    return;
  }

  const metadata = sessionService.getPaperMetadata();
  if (!metadata) {
    sendResponse({ success: false, error: 'No paper metadata available' });
    return;
  }

  try {
    await paperManager.updateRating(
      session.sourceId,
      session.paperId, 
      rating,
      metadata
    );
    
    // Update stored metadata with new rating
    metadata.rating = rating;
    
    sendResponse({ success: true });
  } catch (error) {
    logger.error('Error updating rating:', error);
    sendResponse({ success: false, error: error instanceof Error ? error.message : 'Unknown error' });
  }
}

// Handle session start request
function handleStartSession(sourceId: string, paperId: string) {
  if (!sessionService) {
    logger.error('Session service not initialized');
    return;
  }
  
  // Get metadata if available
  const existingMetadata = sessionService.getPaperMetadata(sourceId, paperId);
  
  // Start the session
  sessionService.startSession(sourceId, paperId, existingMetadata);
  logger.info(`Started session for ${sourceId}:${paperId}`);
}

// Handle session heartbeat
function handleSessionHeartbeat() {
  if (!sessionService) {
    logger.error('Session service not initialized');
    return;
  }
  
  sessionService.recordHeartbeat();
}

// Handle session end request
function handleEndSession(reason: string) {
  if (!sessionService) {
    logger.error('Session service not initialized');
    return;
  }
  
  const session = sessionService.getCurrentSession();
  if (session) {
    logger.info(`Ending session: ${reason}`);
    sessionService.endSession();
  }
}

async function handleManualPaperLog(metadata: PaperMetadata, tabId: number): Promise<void> {
  logger.info(`Received manual paper log: ${metadata.sourceId}:${metadata.paperId}`);
  
  try {
    // Store metadata in session service
    if (sessionService) {
      sessionService.storePaperMetadata(metadata);
    }
    
    // Store in GitHub if we have a paper manager
    if (paperManager) {
      await paperManager.getOrCreatePaper(metadata);
      logger.debug('Manually logged paper stored in GitHub');
      
      // Update icon to tracked state
      if (iconManager) {
        await iconManager.setPaperTracked(tabId);
        logger.debug(`Set tracked icon for manually logged paper in tab ${tabId}`);
      }
    }
  } catch (error) {
    logger.error('Error handling manual paper log', error);
    throw error;
  }
}

// Listen for credential changes
chrome.storage.onChanged.addListener(async (changes) => {
  logger.debug('Storage changes detected', Object.keys(changes));
  
  if (changes.githubToken) {
    githubToken = changes.githubToken.newValue;
  }
  if (changes.githubRepo) {
    githubRepo = changes.githubRepo.newValue;
  }
  
  // Reinitialize paper manager if credentials changed
  if (changes.githubToken || changes.githubRepo) {
    if (githubToken && githubRepo) {
      const githubClient = new GitHubStoreClient(githubToken, githubRepo);
      
      // Pass the source manager to the paper manager
      paperManager = new PaperManager(githubClient, sourceManager!);
      logger.info('Paper manager reinitialized');
      
      // Reinitialize session service with new paper manager
      sessionService = new SessionService(paperManager);
      logger.info('Session service reinitialized');
    }
  }
});

// Initialize debug objects in service worker scope
function initializeDebugObjects() {
  // @ts-ignore
  self.__DEBUG__ = {
    get paperManager() { return paperManager; },
    get sessionService() { return sessionService; },
    get popupManager() { return popupManager; },
    get sourceManager() { return sourceManager; },
    get iconManager() { return iconManager; },
    getGithubClient: () => paperManager ? paperManager.getClient() : null,
    getCurrentPaper: () => {
      const session = sessionService?.getCurrentSession();
      return session ? sessionService?.getPaperMetadata(session.sourceId, session.paperId) : null;
    },
    getSessionStats: () => sessionService?.getSessionStats(),
    getSources: () => sourceManager?.getAllSources(),
    forceEndSession: () => sessionService?.endSession(),
    setIconState: (tabId: number, state: IconState) => iconManager?.setIconState(tabId, state)
  };

  logger.info('Debug objects registered');
}

// Initialize extension
initialize();



---
File: extension/config/session.ts
---
// config/session.ts
// Session configuration management

import { RawSessionConfig, SessionConfig } from './types';
import { loguru } from '../utils/logger';

const logger = loguru.getLogger('session-config');

// Default configuration values
export const DEFAULT_CONFIG: RawSessionConfig = {
    idleThresholdMinutes: 5,
    minSessionDurationSeconds: 30,
    requireContinuousActivity: true,  // If true, resets timer on idle
    logPartialSessions: false,        // If true, logs sessions even if under minimum duration
    activityUpdateIntervalSeconds: 1  // How often to update active time
};

/**
 * Load session configuration from storage
 */
export async function loadSessionConfig(): Promise<RawSessionConfig> {
    try {
        const items = await chrome.storage.sync.get('sessionConfig');
        const config = { ...DEFAULT_CONFIG, ...items.sessionConfig };
        logger.debug('Loaded session config', config);
        return config;
    } catch (error) {
        logger.error('Error loading session config', error);
        return DEFAULT_CONFIG;
    }
}

/**
 * Save session configuration to storage
 */
export async function saveSessionConfig(config: RawSessionConfig): Promise<void> {
    try {
        // Ensure values are the correct type
        const sanitizedConfig: RawSessionConfig = {
            idleThresholdMinutes: Number(config.idleThresholdMinutes),
            minSessionDurationSeconds: Number(config.minSessionDurationSeconds),
            requireContinuousActivity: Boolean(config.requireContinuousActivity),
            logPartialSessions: Boolean(config.logPartialSessions),
            activityUpdateIntervalSeconds: Number(config.activityUpdateIntervalSeconds)
        };
        
        await chrome.storage.sync.set({ sessionConfig: sanitizedConfig });
        logger.debug('Saved session config', sanitizedConfig);
    } catch (error) {
        logger.error('Error saving session config', error);
        throw error;
    }
}

/**
 * Convert configuration to milliseconds for internal use
 */
export function getConfigurationInMs(config: RawSessionConfig): SessionConfig {
    return {
        idleThreshold: config.idleThresholdMinutes * 60 * 1000,
        minSessionDuration: config.minSessionDurationSeconds * 1000,
        activityUpdateInterval: config.activityUpdateIntervalSeconds * 1000,
        requireContinuousActivity: config.requireContinuousActivity,
        logPartialSessions: config.logPartialSessions
    };
}



---
File: extension/config/types.ts
---
// config/types.ts
// Type definitions for configuration

export interface RawSessionConfig {
  // Time in minutes before considering user idle
  idleThresholdMinutes: number;
  
  // Minimum session duration in seconds to log
  minSessionDurationSeconds: number;
  
  // Whether to reset timer on idle
  requireContinuousActivity: boolean;
  
  // Whether to log sessions shorter than minimum duration
  logPartialSessions: boolean;
  
  // How often to update active time in seconds
  activityUpdateIntervalSeconds: number;
}

export interface SessionConfig {
  // Time in milliseconds before considering user idle
  idleThreshold: number;
  
  // Minimum session duration in milliseconds to log
  minSessionDuration: number;
  
  // Whether to reset timer on idle
  requireContinuousActivity: boolean;
  
  // Whether to log sessions shorter than minimum duration
  logPartialSessions: boolean;
  
  // How often to update active time in milliseconds
  activityUpdateInterval: number;
}

export interface StorageConfig {
  // GitHub access token
  githubToken: string;
  
  // GitHub repository (owner/repo)
  githubRepo: string;
  
  // Session tracking configuration
  sessionConfig: RawSessionConfig;
}



---
File: extension/content.ts
---
// content.ts
// Content script with icon state management

import { LinkProcessor } from './source-integration/link-processor';
import { SourceIntegration, Message } from './source-integration/types';
import { PaperMetadata } from './papers/types';
import { loguru } from './utils/logger';
import { BaseSourceIntegration } from './source-integration/base-source';
import { generatePaperIdFromUrl } from './source-integration/metadata-extractor';

// Import from registry instead of individual sources
import { sourceIntegrations } from './source-integration/registry';

const logger = loguru.getLogger('content-script');

logger.info('Paper Tracker content script loaded');

// Base source for fallback processing
const baseSource = new BaseSourceIntegration();

// Track active popup
let activePopup: HTMLElement | null = null;

// Heartbeat interval
let heartbeatInterval: number | null = null;
const HEARTBEAT_INTERVAL = 5000; // 5 seconds

// Track tab visibility
let isTabVisible = true;

// Track current session
let currentSession: { sourceId: string; paperId: string } | null = null;

// Track current paper detection state
let currentPaperState: 'none' | 'detected' | 'tracked' = 'none';

// Create link processor
const linkProcessor = new LinkProcessor((sourceId, paperId, link) => {
  // Callback when link is found
  injectAnnotationButton(link, sourceId, paperId);
});

// Initialize sources
function initializeSources() {
  // Register each source with the link processor
  for (const source of sourceIntegrations) {
    logger.debug(`Initializing source: ${source.id}`);
    
    // Register patterns with link processor
    source.urlPatterns.forEach(pattern => {
      linkProcessor.registerPattern({
        sourceId: source.id,
        pattern,
        extractPaperId: (url: string) => source.extractPaperId(url)
      });
    });
  }
}

// Inject common styles
function injectStyles() {
  if (document.getElementById('paper-tracker-styles')) {
    return; // Already injected
  }
  
  const styles = `
  .paper-annotator {
    display: inline-block;
    margin-left: 4px;
    cursor: pointer;
    font-size: 0.9em;
    opacity: 0.7;
    transition: opacity 0.2s;
    vertical-align: baseline;
  }

  .paper-annotator:hover {
    opacity: 1;
  }

  .paper-popup-wrapper {
    position: fixed;
    z-index: 10000;
  }

  .paper-popup {
    position: relative;
    background: white;
    border: 1px solid #ddd;
    border-radius: 6px;
    padding: 12px;
    box-shadow: 0 4px 12px rgba(0,0,0,0.15);
    width: 300px;
    box-sizing: border-box;
  }

  .paper-popup-header {
    font-weight: bold;
    margin-bottom: 8px;
    line-height: 1.4;
    font-size: 1em;
  }

  .paper-popup-meta {
    color: #666;
    font-size: 0.85em;
    margin-bottom: 12px;
    line-height: 1.4;
  }

  .paper-popup-buttons {
    display: flex;
    gap: 8px;
    margin: 8px 0;
  }

  .paper-popup button {
    padding: 6px 12px;
    border: 1px solid #ddd;
    border-radius: 4px;
    background: #f5f5f5;
    cursor: pointer;
    transition: all 0.2s ease;
    font-size: 0.9em;
  }

  .paper-popup button:hover {
    background: #e8e8e8;
    border-color: #ccc;
  }

  .paper-popup button.active {
    background: #e0e0e0;
    border-color: #aaa;
  }

  .paper-popup textarea {
    width: calc(100% - 16px);
    min-height: 80px;
    margin: 8px 0;
    padding: 8px;
    border: 1px solid #ddd;
    border-radius: 4px;
    resize: vertical;
    font-family: inherit;
    font-size: 0.9em;
    line-height: 1.4;
    box-sizing: border-box;
  }

  .paper-popup textarea:focus {
    outline: none;
    border-color: #aaa;
  }

  .paper-popup-actions {
    display: flex;
    justify-content: flex-end;
    gap: 8px;
    margin-top: 12px;
  }

  .paper-popup .save-button {
    background: #2563eb;
    color: white;
    border-color: #2563eb;
  }

  .paper-popup .save-button:hover {
    background: #1d4ed8;
    border-color: #1d4ed8;
  }
  `;
  
  const styleSheet = document.createElement('style');
  styleSheet.id = 'paper-tracker-styles';
  styleSheet.textContent = styles;
  document.head.appendChild(styleSheet);
  
  logger.debug('Injected styles');
}

// Add annotation button to link
function injectAnnotationButton(link: HTMLAnchorElement, sourceId: string, paperId: string): void {
  // Skip if already processed
  if (link.nextSibling && 
      link.nextSibling.nodeType === Node.ELEMENT_NODE &&
      (link.nextSibling as Element).classList.contains('paper-annotator')) {
    return;
  }
  
  // Create annotator button
  const annotator = document.createElement('span');
  annotator.className = 'paper-annotator';
  annotator.textContent = 'ðŸ“';
  annotator.title = 'Add annotation';
  
  // Store data attributes
  annotator.dataset.sourceId = sourceId;
  annotator.dataset.paperId = paperId;
  
  // Add click handler
  annotator.addEventListener('click', (e) => {
    e.preventDefault();
    e.stopPropagation();
    
    // Send message to background script to show popup
    chrome.runtime.sendMessage({
      type: 'showAnnotationPopup',
      sourceId,
      paperId,
      position: {
        x: e.clientX,
        y: e.clientY
      }
    });
  });
  
  // Add to page next to link
  link.parentNode?.insertBefore(annotator, link.nextSibling);
}

// Get source that can handle a URL
function getSourceForUrl(url: string): SourceIntegration | null {
  for (const source of sourceIntegrations) {
    if (source.canHandleUrl(url)) {
      return source;
    }
  }
  return null;
}

// Send icon state update to background
function updateIconState(state: 'none' | 'detected' | 'tracked', sourceId?: string, paperId?: string) {
  if (state === currentPaperState) return; // No change needed
  
  currentPaperState = state;
  
  switch (state) {
    case 'none':
      chrome.runtime.sendMessage({ type: 'noPaperDetected' });
      break;
    case 'detected':
      chrome.runtime.sendMessage({ 
        type: 'paperDetected', 
        sourceId, 
        paperId 
      });
      break;
    case 'tracked':
      // Icon will be updated when metadata is sent
      break;
  }
  
  logger.debug(`Updated icon state to: ${state}`, { sourceId, paperId });
}

// Set up click-outside handler for popups
document.addEventListener('click', (e) => {
  if (activePopup && 
      !activePopup.contains(e.target as Node) && 
      !(e.target as Element).classList.contains('paper-annotator')) {
    activePopup.parentElement?.remove();
    activePopup = null;
  }
});

// Start session tracking
function startSessionTracking(sourceId: string, paperId: string) {
  // Stop any existing heartbeat
  stopHeartbeat();
  
  // Only start tracking if tab is visible
  if (!isTabVisible) {
    logger.debug(`Not starting session for ${sourceId}:${paperId} because tab is not visible`);
    return;
  }
  
  // Update current session
  currentSession = { sourceId, paperId };
  
  // Tell background script to start a new session
  chrome.runtime.sendMessage({
    type: 'startSession',
    sourceId,
    paperId
  }, response => {
    if (response?.success) {
      logger.debug(`Started session for ${sourceId}:${paperId}`);
      
      // Start sending heartbeats
      startHeartbeat();
    } else {
      logger.error(`Failed to start session for ${sourceId}:${paperId}`, response?.error);
    }
  });
}

// Start sending heartbeats to background script
function startHeartbeat() {
  if (!currentSession) return;
  
  // Clear any existing interval
  stopHeartbeat();
  
  // Set new interval
  heartbeatInterval = window.setInterval(() => {
    if (!currentSession) return;
    
    chrome.runtime.sendMessage({
      type: 'sessionHeartbeat',
      sourceId: currentSession.sourceId,
      paperId: currentSession.paperId,
      timestamp: Date.now()
    });
  }, HEARTBEAT_INTERVAL);
  
  logger.debug(`Started heartbeat for ${currentSession.sourceId}:${currentSession.paperId}`);
}

// Stop sending heartbeats
function stopHeartbeat() {
  if (heartbeatInterval !== null) {
    clearInterval(heartbeatInterval);
    heartbeatInterval = null;
    logger.debug('Stopped heartbeat');
  }
}

// End the current session
function endCurrentSession(reason: string) {
  if (!currentSession) return;
  
  const { sourceId, paperId } = currentSession;
  
  // Stop heartbeat
  stopHeartbeat();
  
  // Send end session message
  chrome.runtime.sendMessage({
    type: 'endSession',
    sourceId,
    paperId,
    reason
  }, response => {
    logger.debug(`Ended session for ${sourceId}:${paperId}`, { reason });
  });
  
  // Clear current session
  currentSession = null;
}

// Process the current page
async function processCurrentPage(force: boolean = false): Promise<PaperMetadata | null> {
  const url = window.location.href;
  
  // Find a source that can handle this URL
  let source = getSourceForUrl(url);
  
  // If no source was found and force parameter is set, use base source
  if (!source && force) {
    logger.info(`No matching source found, but force parameter set. Using base source for: ${url}`);
    source = baseSource;
  }

  // If we still don't have a source, mark as no paper detected
  if (!source) {
    logger.debug(`No source found for URL: ${url}`);
    updateIconState('none');
    return null;
  }

  // Now that we have a source, extract the paperId
  const paperId = source.extractPaperId(url);
  if (!paperId) {
    logger.info(`Unable to determine a paperId for url: ${url}`);
    updateIconState('none');
    return null;
  }
  
  // Update icon to detected state
  updateIconState('detected', source.id, paperId);
  
  try {
    // Use source-specific extraction
    const metadata = await source.extractMetadata(document, paperId);
    
    if (metadata) {
      // Send metadata to background script (this will trigger tracked state)
      chrome.runtime.sendMessage({
        type: 'paperMetadata',
        metadata
      });
      
      logger.debug(`Sent extracted metadata to background script for ${metadata.sourceId}:${metadata.paperId}`);
      
      // Update to tracked state
      updateIconState('tracked', metadata.sourceId, metadata.paperId);
      
      // Start session tracking if tab is visible
      if (isTabVisible) {
        startSessionTracking(metadata.sourceId, metadata.paperId);
      }
      
      return metadata;
    }
  } catch (error) {
    logger.error(`Error extracting metadata for ${source.id}:${paperId}`, error);
    // Keep detected state even on error
  }
  
  return null;
}

// Visibility change listener
document.addEventListener('visibilitychange', () => {
  const wasVisible = isTabVisible;
  isTabVisible = document.visibilityState === 'visible';
  
  if (isTabVisible && !wasVisible) {
    // Tab has become visible again - restart session
    logger.info('Tab became visible again');
    
    // If we have a current session, restart it
    if (currentSession) {
      startSessionTracking(currentSession.sourceId, currentSession.paperId);
    } else {
      // Otherwise, try to process the page
      processCurrentPage();
    }
  } else if (!isTabVisible && wasVisible) {
    // Tab has become hidden - end current session
    logger.info('Tab hidden');
    if (currentSession) {
      endCurrentSession('tab_hidden');
    }
  }
});

// Focus/blur listeners
window.addEventListener('focus', () => {
  if (!isTabVisible) return; // Don't restart if tab is hidden
  
  logger.info('Window gained focus');
  
  // If we have a current session, restart it
  if (currentSession) {
    startSessionTracking(currentSession.sourceId, currentSession.paperId);
  } else {
    // Otherwise, try to process the page
    processCurrentPage();
  }
});

window.addEventListener('blur', () => {
  logger.info('Window lost focus');
  
  // End the current session
  if (currentSession) {
    endCurrentSession('window_blur');
  }
});

// Inform background when page is unloaded
window.addEventListener('beforeunload', () => {
  if (currentSession) {
    logger.info('Page unloading');
    endCurrentSession('page_unload');
  }
});

// Message handler for background script
chrome.runtime.onMessage.addListener((message: any, sender, sendResponse) => {
  logger.debug('Received message', message);

  if (message.type === 'extractPaperMetadata') {
    logger.debug('Received request to force paper metadata extraction');
    
    // Use processCurrentPage with force=true to enable fallback extraction
    processCurrentPage(true)
      .then(metadata => {
        if (metadata) {
          sendResponse({ success: true, metadata });
        } else {
          sendResponse({ success: false, error: 'Failed to extract metadata' });
        }
      })
      .catch(error => {
        logger.error('Error extracting metadata', error);
        sendResponse({ 
          success: false, 
          error: error instanceof Error ? error.message : 'Unknown error' 
        });
      });
    return true; // Will respond asynchronously
  }
  
  if (message.type === 'showPopup') {
    // Remove existing popup
    if (activePopup) {
      activePopup.parentElement?.remove();
      activePopup = null;
    }
    
    // Create popup wrapper
    const wrapper = document.createElement('div');
    wrapper.className = 'paper-popup-wrapper';
    
    // Position near click or element
    if (message.position) {
      wrapper.style.left = `${message.position.x}px`;
      wrapper.style.top = `${message.position.y}px`;
    }
    
    // Create popup
    const popup = document.createElement('div');
    popup.className = 'paper-popup';
    popup.innerHTML = message.html;
    
    // Add to page
    wrapper.appendChild(popup);
    document.body.appendChild(wrapper);
    
    // Set up event handlers
    if (message.handlers) {
      for (const handler of message.handlers) {
        const elements = popup.querySelectorAll(handler.selector);
        elements.forEach(element => {
          element.addEventListener(handler.event, () => {
            chrome.runtime.sendMessage({
              type: 'popupAction',
              action: handler.action,
              sourceId: message.sourceId,
              paperId: message.paperId,
              data: {
                value: element.tagName === 'TEXTAREA' ? 
                  (element as HTMLTextAreaElement).value : 
                  (element as HTMLElement).getAttribute('data-vote'),
                checked: element.tagName === 'INPUT' ? 
                  (element as HTMLInputElement).checked : undefined,
                id: (element as HTMLElement).id
              }
            });
          });
        });
      }
    }
    
    // Save reference
    activePopup = popup;
    
    sendResponse({ success: true });
    return true;
  }
  
  if (message.type === 'processPage') {
    // Re-process the entire page
    linkProcessor.processLinks(document);
    processCurrentPage();
    sendResponse({ success: true });
    return true;
  }
});

// Initialize
(async function initialize() {
  // Inject styles
  injectStyles();
  
  // Initialize sources
  initializeSources();
  
  // Process links
  linkProcessor.processLinks(document);
  
  // Start observing for new links
  linkProcessor.startObserving(document);
  
  // Set initial tab visibility
  isTabVisible = document.visibilityState === 'visible';
  
  // Process current page
  processCurrentPage();
  
  // Tell background script we're ready and what page we're on
  chrome.runtime.sendMessage(
    { 
      type: 'contentScriptReady', 
      url: window.location.href 
    },
    (response) => {
      if (response?.success) {
        logger.debug('Background script acknowledged ready status');
      }
    }
  );
})();

// Set up observer for URL changes (single page apps)
let lastUrl = location.href;
new MutationObserver(() => {
  const url = location.href;
  if (url !== lastUrl) {
    // End any current session
    if (currentSession) {
      endCurrentSession('url_change');
    }
    
    // Reset icon state
    updateIconState('none');
    
    // Update URL and process new page
    lastUrl = url;
    processCurrentPage();
  }
}).observe(document, { subtree: true, childList: true });



---
File: extension/dist/background.bundle.js
---
var f=(i=>(i.GH_STORE="gh-store",i.STORED_OBJECT="stored-object",i.DEPRECATED="deprecated-object",i.UID_PREFIX="UID:",i.ALIAS_TO_PREFIX="ALIAS-TO:",i))(f||{});var m=class{constructor(e={}){this.cache=new Map,this.maxSize=e.maxSize??1e3,this.ttl=e.ttl??1e3*60*60,this.accessOrder=[];}get(e){let t=this.cache.get(e);if(t){if(Date.now()-t.lastAccessed>this.ttl){this.cache.delete(e),this.removeFromAccessOrder(e);return}return t.lastAccessed=Date.now(),this.updateAccessOrder(e),t.issueNumber}}set(e,t,r){if(this.cache.size>=this.maxSize&&!this.cache.has(e)){let s=this.accessOrder[this.accessOrder.length-1];s&&(this.cache.delete(s),this.removeFromAccessOrder(s));}this.cache.set(e,{issueNumber:t,lastAccessed:Date.now(),createdAt:r.createdAt,updatedAt:r.updatedAt}),this.updateAccessOrder(e);}remove(e){this.cache.delete(e),this.removeFromAccessOrder(e);}clear(){this.cache.clear(),this.accessOrder=[];}getStats(){return {size:this.cache.size,maxSize:this.maxSize,ttl:this.ttl}}shouldRefresh(e,t){let r=this.cache.get(e);return r?t>r.updatedAt:!0}updateAccessOrder(e){this.removeFromAccessOrder(e),this.accessOrder.unshift(e);}removeFromAccessOrder(e){let t=this.accessOrder.indexOf(e);t>-1&&this.accessOrder.splice(t,1);}};var y="0.11.1";var d=class{constructor(e,t,r={}){if(this.token=e,this.repo=t,!this.repo)throw new Error("Repository is required");this.config={baseLabel:r.baseLabel??"stored-object",uidPrefix:r.uidPrefix??"UID:",reactions:{processed:r.reactions?.processed??"+1",initialState:r.reactions?.initialState??"rocket"}},this.cache=new m(r.cache);}isPublic(){return this.token===null}async fetchFromGitHub(e,t={}){let r=new URL(`https://api.github.com/repos/${this.repo}${e}`);t.params&&(Object.entries(t.params).forEach(([a,n])=>{r.searchParams.append(a,n);}),delete t.params);let s={Accept:"application/vnd.github.v3+json"};if(t.headers){let a=t.headers;Object.keys(a).forEach(n=>{s[n]=a[n];});}this.token&&(s.Authorization=`token ${this.token}`);let i=await fetch(r.toString(),{...t,headers:s});if(!i.ok)throw new Error(`GitHub API error: ${i.status}`);return i.json()}createCommentPayload(e,t,r){let s={_data:e,_meta:{client_version:y,timestamp:new Date().toISOString(),update_mode:"append",issue_number:t}};return r&&(s.type=r),s}async getObject(e){let t=this.cache.get(e),r;if(t)try{r=await this.fetchFromGitHub(`/issues/${t}`),this._verifyIssueLabels(r,e)||(this.cache.remove(e),r=void 0);}catch{this.cache.remove(e);}if(!r){let c=await this.fetchFromGitHub("/issues",{method:"GET",params:{labels:["gh-store",this.config.baseLabel,`${this.config.uidPrefix}${e}`].join(","),state:"closed"}});if(!c||c.length===0)throw new Error(`No object found with ID: ${e}`);r=c[0];}if(!r?.body)throw new Error(`Invalid issue data received for ID: ${e}`);let s=JSON.parse(r.body),i=new Date(r.created_at),a=new Date(r.updated_at);return this.cache.set(e,r.number,{createdAt:i,updatedAt:a}),{meta:{objectId:e,label:`${this.config.uidPrefix}${e}`,issueNumber:r.number,createdAt:i,updatedAt:a,version:await this._getVersion(r.number)},data:s}}async createObject(e,t,r=[]){if(!this.token)throw new Error("Authentication required for creating objects");let s=`${this.config.uidPrefix}${e}`,i=["gh-store",this.config.baseLabel,s,...r],a=await this.fetchFromGitHub("/issues",{method:"POST",body:JSON.stringify({title:`Stored Object: ${e}`,body:JSON.stringify(t,null,2),labels:i})});this.cache.set(e,a.number,{createdAt:new Date(a.created_at),updatedAt:new Date(a.updated_at)});let n=this.createCommentPayload(t,a.number,"initial_state"),c=await this.fetchFromGitHub(`/issues/${a.number}/comments`,{method:"POST",body:JSON.stringify({body:JSON.stringify(n,null,2)})});return await this.fetchFromGitHub(`/issues/comments/${c.id}/reactions`,{method:"POST",body:JSON.stringify({content:this.config.reactions.processed})}),await this.fetchFromGitHub(`/issues/comments/${c.id}/reactions`,{method:"POST",body:JSON.stringify({content:this.config.reactions.initialState})}),await this.fetchFromGitHub(`/issues/${a.number}`,{method:"PATCH",body:JSON.stringify({state:"closed"})}),{meta:{objectId:e,label:s,issueNumber:a.number,createdAt:new Date(a.created_at),updatedAt:new Date(a.updated_at),version:1},data:t}}_verifyIssueLabels(e,t){let r=new Set([this.config.baseLabel,`${this.config.uidPrefix}${t}`]);return e.labels.some(s=>r.has(s.name))}async updateObject(e,t){if(!this.token)throw new Error("Authentication required for updating objects");let r=await this.fetchFromGitHub("/issues",{method:"GET",params:{labels:[this.config.baseLabel,`${this.config.uidPrefix}${e}`].join(","),state:"all"}});if(!r||r.length===0)throw new Error(`No object found with ID: ${e}`);let s=r[0],i=this.createCommentPayload(t,s.number);return await this.fetchFromGitHub(`/issues/${s.number}/comments`,{method:"POST",body:JSON.stringify({body:JSON.stringify(i,null,2)})}),await this.fetchFromGitHub(`/issues/${s.number}`,{method:"PATCH",body:JSON.stringify({state:"open"})}),this.getObject(e)}async listAll(){let e=await this.fetchFromGitHub("/issues",{method:"GET",params:{labels:this.config.baseLabel,state:"closed"}}),t={};for(let r of e)if(!r.labels.some(s=>s.name==="archived"))try{let s=this._getObjectIdFromLabels(r),i=JSON.parse(r.body),a={objectId:s,label:s,issueNumber:r.number,createdAt:new Date(r.created_at),updatedAt:new Date(r.updated_at),version:await this._getVersion(r.number)};t[s]={meta:a,data:i};}catch{continue}return t}async listUpdatedSince(e){let t=await this.fetchFromGitHub("/issues",{method:"GET",params:{labels:this.config.baseLabel,state:"closed",since:e.toISOString()}}),r={};for(let s of t)if(!s.labels.some(i=>i.name==="archived"))try{let i=this._getObjectIdFromLabels(s),a=JSON.parse(s.body),n=new Date(s.updated_at);if(n>e){let c={objectId:i,label:i,issueNumber:s.number,createdAt:new Date(s.created_at),updatedAt:n,version:await this._getVersion(s.number)};r[i]={meta:c,data:a};}}catch{continue}return r}async getObjectHistory(e){let t=await this.fetchFromGitHub("/issues",{method:"GET",params:{labels:[this.config.baseLabel,`${this.config.uidPrefix}${e}`].join(","),state:"all"}});if(!t||t.length===0)throw new Error(`No object found with ID: ${e}`);let r=t[0],s=await this.fetchFromGitHub(`/issues/${r.number}/comments`),i=[];for(let a of s)try{let n=JSON.parse(a.body),c="update",u,p={client_version:"legacy",timestamp:a.created_at,update_mode:"append"};typeof n=="object"?"_data"in n?(c=n.type||"update",u=n._data,p=n._meta||p):"type"in n&&n.type==="initial_state"?(c="initial_state",u=n.data):u=n:u=n,i.push({timestamp:a.created_at,type:c,data:u,commentId:a.id});}catch{continue}return i}async _getVersion(e){return (await this.fetchFromGitHub(`/issues/${e}/comments`)).length+1}_getObjectIdFromLabels(e){for(let t of e.labels)if(t.name!==this.config.baseLabel&&t.name.startsWith(this.config.uidPrefix))return t.name.slice(this.config.uidPrefix.length);throw new Error(`No UID label found with prefix ${this.config.uidPrefix}`)}};var E={level:"info",silent:!1},A={error:3,warn:2,info:1,debug:0},b=class{constructor(e,t={}){this.entries=[];this.moduleName=e,this.config={...E,...t};}debug(e,t){this.log("debug",e,t);}info(e,t){this.log("info",e,t);}warn(e,t){this.log("warn",e,t);}error(e,t){this.log("error",e,t);}log(e,t,r){if(A[e]<A[this.config.level])return;let s={timestamp:new Date().toISOString(),level:e,module:this.moduleName,message:t,metadata:r};this.entries.push(s);}getEntries(){return [...this.entries]}clearEntries(){this.entries=[];}configure(e){this.config={...this.config,...e};}getConfig(){return {...this.config}}};new b("CanonicalStore");

// extension/papers/types.ts
// Updated for heartbeat-based session tracking
/**
 * Type guard for interaction log
 */
function isInteractionLog(data) {
    const log = data;
    return (typeof log === 'object' &&
        log !== null &&
        typeof log.sourceId === 'string' &&
        typeof log.paperId === 'string' &&
        Array.isArray(log.interactions));
}

// utils/logger.ts
// Logging utility wrapping loguru
/**
 * Logger class for consistent logging throughout the extension
 */
class Logger {
    constructor(module) {
        this.module = module;
    }
    /**
     * Log debug message
     */
    debug(message, data) {
        console.debug(`[${this.module}] ${message}`, data !== undefined ? data : '');
    }
    /**
     * Log info message
     */
    info(message, data) {
        console.info(`[${this.module}] ${message}`, data !== undefined ? data : '');
    }
    /**
     * Log warning message
     */
    warning(message, data) {
        console.warn(`[${this.module}] ${message}`, data !== undefined ? data : '');
    }
    /**
     * Alias for warning method (to match loguru API)
     */
    warn(message, data) {
        this.warning(message, data);
    }
    /**
     * Log error message
     */
    error(message, data) {
        console.error(`[${this.module}] ${message}`, data !== undefined ? data : '');
    }
}
/**
 * Loguru mock for browser extension use
 */
class LoguruMock {
    /**
     * Get logger for a module
     */
    getLogger(module) {
        return new Logger(module);
    }
}
// Export singleton instance
const loguru = new LoguruMock();

const logger$9 = loguru.getLogger('paper-manager');
class PaperManager {
    constructor(client, sourceManager) {
        this.client = client;
        this.sourceManager = sourceManager;
        logger$9.debug('Paper manager initialized');
    }
    /**
     * Get paper by source and ID
     */
    async getPaper(sourceId, paperId) {
        const objectId = this.sourceManager.formatObjectId('paper', sourceId, paperId);
        try {
            const obj = await this.client.getObject(objectId);
            return obj.data;
        }
        catch (error) {
            if (error instanceof Error && error.message.includes('No object found')) {
                return null;
            }
            throw error;
        }
    }
    /**
     * Get or create paper metadata
     */
    async getOrCreatePaper(paperData) {
        const { sourceId, paperId } = paperData;
        const objectId = this.sourceManager.formatObjectId('paper', sourceId, paperId);
        const paperIdentifier = this.sourceManager.formatPaperId(sourceId, paperId);
        try {
            const obj = await this.client.getObject(objectId);
            const data = obj.data;
            logger$9.debug(`Retrieved existing paper: ${paperIdentifier}`);
            return data;
        }
        catch (error) {
            if (error instanceof Error && error.message.includes('No object found')) {
                // Create new paper
                const defaultPaperData = {
                    ...paperData,
                    timestamp: new Date().toISOString(),
                    rating: paperData.rating || 'novote'
                };
                const newobj = await this.client.createObject(objectId, defaultPaperData);
                logger$9.debug(`Created new paper: ${paperIdentifier}`);
                // reopen to trigger metadata hydration
                await this.client.fetchFromGitHub(`/issues/${newobj.meta.issueNumber}`, {
                    method: "PATCH",
                    body: JSON.stringify({ state: "open" })
                });
                return defaultPaperData;
            }
            throw error;
        }
    }
    /**
     * Get or create interaction log for a paper
     */
    async getOrCreateInteractionLog(sourceId, paperId) {
        const objectId = this.sourceManager.formatObjectId('interactions', sourceId, paperId);
        const paperIdentifier = this.sourceManager.formatPaperId(sourceId, paperId);
        try {
            const obj = await this.client.getObject(objectId);
            const data = obj.data;
            if (isInteractionLog(data)) {
                return data;
            }
            throw new Error('Invalid interaction log format');
        }
        catch (error) {
            if (error instanceof Error && error.message.includes('No object found')) {
                const newLog = {
                    sourceId,
                    paperId,
                    interactions: []
                };
                await this.client.createObject(objectId, newLog);
                logger$9.debug(`Created new interaction log: ${paperIdentifier}`);
                return newLog;
            }
            throw error;
        }
    }
    /**
     * Get GitHub client instance
     */
    getClient() {
        return this.client;
    }
    /**
     * Log a reading session
     */
    async logReadingSession(sourceId, paperId, session, paperData) {
        // Ensure paper exists
        if (paperData) {
            await this.getOrCreatePaper({
                sourceId,
                paperId,
                url: paperData.url || this.sourceManager.formatPaperId(sourceId, paperId),
                title: paperData.title || paperId,
                authors: paperData.authors || '',
                abstract: paperData.abstract || '',
                timestamp: new Date().toISOString(),
                rating: 'novote',
                publishedDate: paperData.publishedDate || '',
                tags: paperData.tags || []
            });
        }
        // Log the session as an interaction
        await this.addInteraction(sourceId, paperId, {
            type: 'reading_session',
            timestamp: new Date().toISOString(),
            data: session
        });
        const paperIdentifier = this.sourceManager.formatPaperId(sourceId, paperId);
        logger$9.info(`Logged reading session for ${paperIdentifier}`, { duration: session.duration_seconds });
    }
    /**
     * Log an annotation
     */
    async logAnnotation(sourceId, paperId, key, value, paperData) {
        // Ensure paper exists
        if (paperData) {
            await this.getOrCreatePaper({
                sourceId,
                paperId,
                url: paperData.url || this.sourceManager.formatPaperId(sourceId, paperId),
                title: paperData.title || paperId,
                authors: paperData.authors || '',
                abstract: paperData.abstract || '',
                timestamp: new Date().toISOString(),
                rating: 'novote',
                publishedDate: paperData.publishedDate || '',
                tags: paperData.tags || []
            });
        }
        // Log the annotation as an interaction
        await this.addInteraction(sourceId, paperId, {
            type: 'annotation',
            timestamp: new Date().toISOString(),
            data: { key, value }
        });
        const paperIdentifier = this.sourceManager.formatPaperId(sourceId, paperId);
        logger$9.info(`Logged annotation for ${paperIdentifier}`, { key });
    }
    /**
     * Update paper rating
     */
    async updateRating(sourceId, paperId, rating, paperData) {
        // Ensure paper exists and get current data
        const paper = await this.getOrCreatePaper({
            sourceId,
            paperId,
            url: paperData?.url || this.sourceManager.formatPaperId(sourceId, paperId),
            title: paperData?.title || paperId,
            authors: paperData?.authors || '',
            abstract: paperData?.abstract || '',
            timestamp: new Date().toISOString(),
            rating: 'novote',
            publishedDate: paperData?.publishedDate || '',
            tags: paperData?.tags || []
        });
        const objectId = this.sourceManager.formatObjectId('paper', sourceId, paperId);
        // Update paper metadata with new rating
        await this.client.updateObject(objectId, {
            ...paper,
            rating
        });
        // Log rating change as an interaction
        await this.addInteraction(sourceId, paperId, {
            type: 'rating',
            timestamp: new Date().toISOString(),
            data: { rating }
        });
        const paperIdentifier = this.sourceManager.formatPaperId(sourceId, paperId);
        logger$9.info(`Updated rating for ${paperIdentifier} to ${rating}`);
    }
    /**
     * Add interaction to log
     */
    async addInteraction(sourceId, paperId, interaction) {
        const log = await this.getOrCreateInteractionLog(sourceId, paperId);
        log.interactions.push(interaction);
        const objectId = this.sourceManager.formatObjectId('interactions', sourceId, paperId);
        await this.client.updateObject(objectId, log);
    }
}

// session-service.ts
const logger$8 = loguru.getLogger('session-service');
/**
 * Session tracking service for paper reading sessions
 *
 * Manages session state, heartbeats, and persistence
 * Designed for use in the background script (Service Worker)
 */
class SessionService {
    /**
     * Create a new session service
     */
    constructor(paperManager) {
        this.paperManager = paperManager;
        this.activeSession = null;
        this.timeoutId = null;
        this.paperMetadata = new Map();
        // Configuration
        this.HEARTBEAT_TIMEOUT = 15000; // 15 seconds
        logger$8.debug('Session service initialized');
    }
    /**
     * Start a new session for a paper
     */
    startSession(sourceId, paperId, metadata) {
        // End any existing session
        this.endSession();
        // Create new session
        this.activeSession = {
            sourceId,
            paperId,
            startTime: new Date(),
            heartbeatCount: 0,
            lastHeartbeatTime: new Date()
        };
        // Store metadata if provided
        if (metadata) {
            const key = `${sourceId}:${paperId}`;
            this.paperMetadata.set(key, metadata);
            logger$8.debug(`Stored metadata for ${key}`);
        }
        // Start timeout check
        this.scheduleTimeoutCheck();
        logger$8.info(`Started session for ${sourceId}:${paperId}`);
    }
    /**
     * Record a heartbeat for the current session
     */
    recordHeartbeat() {
        if (!this.activeSession) {
            return false;
        }
        this.activeSession.heartbeatCount++;
        this.activeSession.lastHeartbeatTime = new Date();
        // Reschedule timeout
        this.scheduleTimeoutCheck();
        if (this.activeSession.heartbeatCount % 12 === 0) { // Log every minute (12 x 5sec heartbeats)
            logger$8.debug(`Session received ${this.activeSession.heartbeatCount} heartbeats`);
        }
        return true;
    }
    /**
     * Schedule a check for heartbeat timeout
     */
    scheduleTimeoutCheck() {
        // Clear existing timeout
        if (this.timeoutId !== null) {
            clearTimeout(this.timeoutId);
        }
        // Set new timeout
        this.timeoutId = self.setTimeout(() => {
            this.checkTimeout();
        }, this.HEARTBEAT_TIMEOUT);
    }
    /**
     * Check if the session has timed out due to missing heartbeats
     */
    checkTimeout() {
        if (!this.activeSession)
            return;
        const now = Date.now();
        const lastTime = this.activeSession.lastHeartbeatTime.getTime();
        if ((now - lastTime) > this.HEARTBEAT_TIMEOUT) {
            logger$8.info('Session timeout detected');
            this.endSession();
        }
        else {
            this.scheduleTimeoutCheck();
        }
    }
    /**
     * End the current session and get the data
     */
    endSession() {
        if (!this.activeSession)
            return null;
        // Clear timeout
        if (this.timeoutId !== null) {
            clearTimeout(this.timeoutId);
            this.timeoutId = null;
        }
        const { sourceId, paperId, startTime, heartbeatCount } = this.activeSession;
        const endTime = new Date();
        // Calculate duration (5 seconds per heartbeat)
        const duration = heartbeatCount * 5;
        // Calculate total elapsed time
        const totalElapsed = endTime.getTime() - startTime.getTime();
        const totalElapsedSeconds = Math.round(totalElapsed / 1000);
        // Set idle seconds to the difference (for backward compatibility)
        const idleSeconds = Math.max(0, totalElapsedSeconds - duration);
        // Create session data
        const sessionData = {
            session_id: `session_${Date.now()}_${Math.random().toString(36).substring(2, 9)}`,
            source_id: sourceId,
            paper_id: paperId,
            start_time: startTime.toISOString(),
            end_time: endTime.toISOString(),
            heartbeat_count: heartbeatCount,
            duration_seconds: duration,
            // Legacy fields
            idle_seconds: idleSeconds,
            total_elapsed_seconds: totalElapsedSeconds
        };
        // Store session if it was meaningful and we have a paper manager
        if (this.paperManager && heartbeatCount > 0) {
            const metadata = this.getPaperMetadata(sourceId, paperId);
            this.paperManager.logReadingSession(sourceId, paperId, sessionData, metadata)
                .catch(err => logger$8.error('Failed to store session', err));
        }
        logger$8.info(`Ended session for ${sourceId}:${paperId}`, {
            duration,
            heartbeats: heartbeatCount
        });
        // Clear active session
        this.activeSession = null;
        return sessionData;
    }
    /**
     * Check if a session is currently active
     */
    hasActiveSession() {
        return this.activeSession !== null;
    }
    /**
     * Get information about the current session
     */
    getCurrentSession() {
        if (!this.activeSession)
            return null;
        return {
            sourceId: this.activeSession.sourceId,
            paperId: this.activeSession.paperId
        };
    }
    /**
     * Get paper metadata for the current or specified session
     */
    getPaperMetadata(sourceId, paperId) {
        if (!sourceId || !paperId) {
            if (!this.activeSession)
                return undefined;
            sourceId = this.activeSession.sourceId;
            paperId = this.activeSession.paperId;
        }
        return this.paperMetadata.get(`${sourceId}:${paperId}`);
    }
    /**
     * Store paper metadata
     */
    storePaperMetadata(metadata) {
        const key = `${metadata.sourceId}:${metadata.paperId}`;
        this.paperMetadata.set(key, metadata);
    }
    /**
     * Get time since last heartbeat in milliseconds
     */
    getTimeSinceLastHeartbeat() {
        if (!this.activeSession) {
            return null;
        }
        return Date.now() - this.activeSession.lastHeartbeatTime.getTime();
    }
    /**
     * Get session statistics for debugging
     */
    getSessionStats() {
        if (!this.activeSession) {
            return { active: false };
        }
        return {
            active: true,
            sourceId: this.activeSession.sourceId,
            paperId: this.activeSession.paperId,
            startTime: this.activeSession.startTime.toISOString(),
            heartbeatCount: this.activeSession.heartbeatCount,
            lastHeartbeatTime: this.activeSession.lastHeartbeatTime.toISOString(),
            elapsedTime: Math.round((Date.now() - this.activeSession.startTime.getTime()) / 1000)
        };
    }
}

// extension/utils/popup-manager.ts
const logger$7 = loguru.getLogger('popup-manager');
/**
 * Manages all popup-related functionality
 */
class PopupManager {
    /**
     * Create a new popup manager
     */
    constructor(sourceManagerProvider, paperManagerProvider) {
        this.sourceManagerProvider = sourceManagerProvider;
        this.paperManagerProvider = paperManagerProvider;
        this.setupMessageListeners();
        logger$7.debug('Popup manager initialized');
    }
    /**
     * Set up message listeners for popup-related messages
     */
    setupMessageListeners() {
        chrome.runtime.onMessage.addListener((message, sender, sendResponse) => {
            // Handle popup actions (ratings, notes, etc.)
            if (message.type === 'popupAction') {
                this.handlePopupAction(message.sourceId, message.paperId, message.action, message.data).then(() => {
                    sendResponse({ success: true });
                }).catch(error => {
                    logger$7.error('Error handling popup action', error);
                    sendResponse({
                        success: false,
                        error: error instanceof Error ? error.message : 'Unknown error'
                    });
                });
                return true; // Will respond asynchronously
            }
            // Handle request to show annotation popup
            if (message.type === 'showAnnotationPopup' && sender.tab?.id) {
                this.handleShowAnnotationPopup(sender.tab.id, message.sourceId, message.paperId, message.position).then(() => {
                    sendResponse({ success: true });
                }).catch(error => {
                    logger$7.error('Error showing popup', error);
                    sendResponse({
                        success: false,
                        error: error instanceof Error ? error.message : 'Unknown error'
                    });
                });
                return true; // Will respond asynchronously
            }
            return false; // Not handled
        });
    }
    /**
     * Handle a request to show an annotation popup
     */
    async handleShowAnnotationPopup(tabId, sourceId, paperId, position) {
        logger$7.debug(`Showing annotation popup for ${sourceId}:${paperId}`);
        // Check if we have source and paper manager
        const sourceManager = this.sourceManagerProvider();
        const paperManager = this.paperManagerProvider();
        if (!sourceManager) {
            throw new Error('Source manager not initialized');
        }
        if (!paperManager) {
            throw new Error('Paper manager not initialized');
        }
        try {
            // Get paper data
            const paper = await paperManager.getPaper(sourceId, paperId);
            // Create popup HTML
            const html = this.createPopupHtml(paper || {
                sourceId,
                paperId,
                title: paperId,
                authors: '',
                abstract: '',
                url: '',
                timestamp: new Date().toISOString(),
                publishedDate: '',
                tags: [],
                rating: 'novote'
            });
            // Get handlers
            const handlers = this.getStandardPopupHandlers();
            // Send message to content script to show popup
            const message = {
                type: 'showPopup',
                sourceId,
                paperId,
                html,
                handlers,
                position
            };
            await chrome.tabs.sendMessage(tabId, message);
            logger$7.debug(`Sent popup to content script for ${sourceId}:${paperId}`);
        }
        catch (error) {
            logger$7.error(`Error showing popup for ${sourceId}:${paperId}`, error);
            throw error;
        }
    }
    /**
     * Handle popup actions (ratings, notes, etc.)
     */
    async handlePopupAction(sourceId, paperId, action, data) {
        const paperManager = this.paperManagerProvider();
        if (!paperManager) {
            throw new Error('Paper manager not initialized');
        }
        logger$7.debug(`Handling popup action: ${action}`, { sourceId, paperId });
        try {
            if (action === 'rate') {
                await paperManager.updateRating(sourceId, paperId, data.value);
                logger$7.info(`Updated rating for ${sourceId}:${paperId} to ${data.value}`);
            }
            else if (action === 'saveNotes') {
                if (data.value) {
                    await paperManager.logAnnotation(sourceId, paperId, 'notes', data.value);
                    logger$7.info(`Saved notes for ${sourceId}:${paperId}`);
                }
            }
        }
        catch (error) {
            logger$7.error(`Error handling action ${action} for ${sourceId}:${paperId}`, error);
            throw error;
        }
    }
    /**
     * Create HTML for paper popup
     */
    createPopupHtml(paper) {
        return `
      <div class="paper-popup-header">${paper.title || paper.paperId}</div>
      <div class="paper-popup-meta">${paper.authors || ''}</div>
      
      <div class="paper-popup-buttons">
        <button class="vote-button" data-vote="thumbsup" id="btn-thumbsup" ${paper.rating === 'thumbsup' ? 'class="active"' : ''}>ðŸ‘ Interesting</button>
        <button class="vote-button" data-vote="thumbsdown" id="btn-thumbsdown" ${paper.rating === 'thumbsdown' ? 'class="active"' : ''}>ðŸ‘Ž Not Relevant</button>
      </div>
      
      <textarea placeholder="Add notes about this paper..." id="paper-notes"></textarea>
      
      <div class="paper-popup-actions">
        <button class="save-button" id="btn-save">Save</button>
      </div>
    `;
    }
    /**
     * Get standard popup event handlers
     */
    getStandardPopupHandlers() {
        return [
            { selector: '#btn-thumbsup', event: 'click', action: 'rate' },
            { selector: '#btn-thumbsdown', event: 'click', action: 'rate' },
            { selector: '#btn-save', event: 'click', action: 'saveNotes' }
        ];
    }
}

// extension/source-integration/source-manager.ts
const logger$6 = loguru.getLogger('source-manager');
/**
 * Manages source integrations
 */
class SourceIntegrationManager {
    constructor() {
        this.sources = new Map();
        logger$6.info('Source integration manager initialized');
    }
    /**
     * Register a source integration
     */
    registerSource(source) {
        if (this.sources.has(source.id)) {
            logger$6.warning(`Source with ID '${source.id}' already registered, overwriting`);
        }
        this.sources.set(source.id, source);
        logger$6.info(`Registered source: ${source.name} (${source.id})`);
    }
    /**
     * Get all registered sources
     */
    getAllSources() {
        return Array.from(this.sources.values());
    }
    /**
     * Get source that can handle a URL
     */
    getSourceForUrl(url) {
        for (const source of this.sources.values()) {
            if (source.canHandleUrl(url)) {
                logger$6.debug(`Found source for URL '${url}': ${source.id}`);
                return source;
            }
        }
        logger$6.debug(`No source found for URL: ${url}`);
        return null;
    }
    /**
     * Get source by ID
     */
    getSourceById(sourceId) {
        const source = this.sources.get(sourceId);
        return source || null;
    }
    /**
     * Extract paper ID from URL using appropriate source
     */
    extractPaperId(url) {
        for (const source of this.sources.values()) {
            if (source.canHandleUrl(url)) {
                const paperId = source.extractPaperId(url);
                if (paperId) {
                    logger$6.debug(`Extracted paper ID '${paperId}' from URL using ${source.id}`);
                    return { sourceId: source.id, paperId };
                }
            }
        }
        logger$6.debug(`Could not extract paper ID from URL: ${url}`);
        return null;
    }
    /**
     * Format a paper identifier using the appropriate source
     */
    formatPaperId(sourceId, paperId) {
        const source = this.sources.get(sourceId);
        if (source) {
            return source.formatPaperId(paperId);
        }
        // Fallback if source not found
        logger$6.warning(`Source '${sourceId}' not found, using default format for paper ID`);
        return `${sourceId}.${paperId}`;
    }
    /**
     * Format an object ID using the appropriate source
     */
    formatObjectId(type, sourceId, paperId) {
        const source = this.sources.get(sourceId);
        if (source) {
            return source.formatObjectId(type, paperId);
        }
        // Fallback if source not found
        logger$6.warning(`Source '${sourceId}' not found, using default format for object ID`);
        return `${type}:${sourceId}.${paperId}`;
    }
    /**
     * Get all content script match patterns
     */
    getAllContentScriptMatches() {
        const patterns = [];
        for (const source of this.sources.values()) {
            patterns.push(...source.contentScriptMatches);
        }
        return patterns;
    }
}

// extension/utils/icon-manager.ts
const logger$5 = loguru.getLogger('icon-manager');
var IconState;
(function (IconState) {
    IconState["DEFAULT"] = "default";
    IconState["DETECTED"] = "detected";
    IconState["TRACKED"] = "tracked";
})(IconState || (IconState = {}));
// Your excellent SVG definitions (keeping them as-is)
// Accessible color schemes for each state
const ICON_COLORS = {
    [IconState.DEFAULT]: {
        background: '#fef2f2',
        paper: '#fecaca',
        bookmark: '#dc2626',
    },
    [IconState.DETECTED]: {
        background: '#eff6ff',
        paper: '#93c5fd',
        bookmark: '#2563eb',
    },
    [IconState.TRACKED]: {
        background: '#ecfdf5',
        paper: '#86efac',
        bookmark: '#059669',
    },
};
const ICON_CONFIGS = {
    [IconState.DEFAULT]: {
        colors: ICON_COLORS[IconState.DEFAULT],
        title: 'Academic Paper Tracker',
    },
    [IconState.DETECTED]: {
        colors: ICON_COLORS[IconState.DETECTED],
        title: 'Paper Detected - Academic Paper Tracker',
    },
    [IconState.TRACKED]: {
        colors: ICON_COLORS[IconState.TRACKED],
        title: 'Paper Tracked - Academic Paper Tracker',
    },
};
const ICON_SIZES = [16, 32, 48, 128];
class IconManager {
    constructor() {
        this.tabStates = new Map();
        this.pendingUpdates = new Map(); // NEW: Prevent race conditions
        this.iconCache = new Map(); // NEW: Cache rasterized icons
        this.setupTabListeners();
        this.preloadIcons(); // NEW: Pre-rasterize all icons at startup
        logger$5.debug('Icon manager initialized');
    }
    setupTabListeners() {
        chrome.tabs.onRemoved.addListener((tabId) => {
            this.tabStates.delete(tabId);
            this.pendingUpdates.delete(tabId);
            logger$5.debug(`Cleaned up icon state for closed tab ${tabId}`);
        });
        chrome.tabs.onUpdated.addListener((tabId, changeInfo) => {
            if (changeInfo.status === 'loading' && changeInfo.url) {
                this.setIconState(tabId, IconState.DEFAULT);
                logger$5.debug(`Reset icon for tab ${tabId} navigating to ${changeInfo.url}`);
            }
        });
    }
    // NEW: Pre-generate all icons for better performance
    async preloadIcons() {
        try {
            for (const state of Object.values(IconState)) {
                const config = ICON_CONFIGS[state];
                const imageDataMap = {};
                for (const px of ICON_SIZES) {
                    const imgData = this.createCanvasIcon(config.colors, px, px);
                    imageDataMap[px.toString()] = imgData;
                }
                this.iconCache.set(state, imageDataMap);
            }
            logger$5.debug('Pre-loaded all icon states');
        }
        catch (error) {
            logger$5.error('Failed to preload icons:', error);
        }
    }
    async setIconState(tabId, state) {
        // NEW: Check if already in this state (deduplication)
        const currentState = this.tabStates.get(tabId);
        if (currentState === state) {
            logger$5.debug(`Icon already in ${state} state for tab ${tabId}, skipping`);
            return;
        }
        // NEW: Wait for any pending updates to avoid race conditions
        const pending = this.pendingUpdates.get(tabId);
        if (pending) {
            try {
                await pending;
            }
            catch (error) {
                logger$5.warn(`Previous icon update failed for tab ${tabId}:`, error);
            }
        }
        // Create update promise
        const updatePromise = this.performIconUpdate(tabId, state);
        this.pendingUpdates.set(tabId, updatePromise);
        try {
            await updatePromise;
            this.tabStates.set(tabId, state);
            logger$5.debug(`Set icon state to ${state} for tab ${tabId}`);
        }
        catch (error) {
            logger$5.error(`Failed to set icon state for tab ${tabId}:`, error);
            throw error;
        }
        finally {
            this.pendingUpdates.delete(tabId);
        }
    }
    async performIconUpdate(tabId, state) {
        const config = ICON_CONFIGS[state];
        // Check if tab still exists
        try {
            await chrome.tabs.get(tabId);
        }
        catch (error) {
            logger$5.debug(`Tab ${tabId} no longer exists, skipping icon update`);
            return;
        }
        try {
            // NEW: Use cached icons if available, otherwise generate on demand
            let imageDataMap = this.iconCache.get(state);
            if (!imageDataMap) {
                logger$5.debug(`Cache miss for ${state}, generating on demand`);
                imageDataMap = {};
                for (const px of ICON_SIZES) {
                    const imgData = this.createCanvasIcon(config.colors, px, px);
                    imageDataMap[px.toString()] = imgData;
                }
                this.iconCache.set(state, imageDataMap);
            }
            await chrome.action.setIcon({
                tabId,
                imageData: imageDataMap,
            });
            await chrome.action.setTitle({
                tabId,
                title: config.title,
            });
        }
        catch (error) {
            // Handle specific Chrome API errors gracefully
            const errorMessage = error instanceof Error ? error.message : String(error);
            if (errorMessage.includes('No tab with id') ||
                errorMessage.includes('Cannot access')) {
                logger$5.debug(`Cannot update icon for tab ${tabId}: ${errorMessage}`);
                return;
            }
            throw error;
        }
    }
    // NEW: Create icon using improved Canvas drawing (no borders, larger bookmark)
    createCanvasIcon(colors, widthPx, heightPx) {
        const offscreen = new OffscreenCanvas(widthPx, heightPx);
        const ctx = offscreen.getContext('2d');
        if (!ctx) {
            throw new Error('Failed to get 2D context from OffscreenCanvas');
        }
        // Use full canvas - no padding for maximum space utilization
        const paperWidth = widthPx;
        const paperHeight = heightPx;
        // Draw background (full canvas)
        ctx.fillStyle = colors.background;
        ctx.fillRect(0, 0, widthPx, heightPx);
        // Draw paper (no rounded corners for cleaner look at small sizes)
        ctx.fillStyle = colors.paper;
        ctx.fillRect(0, 0, paperWidth, paperHeight);
        // Draw larger, more prominent bookmark (35% of width)
        const bookmarkWidth = Math.floor(widthPx * 0.35);
        const bookmarkHeight = Math.floor(heightPx * 0.8);
        const bookmarkX = widthPx - bookmarkWidth;
        const bookmarkY = 0;
        ctx.fillStyle = colors.bookmark;
        ctx.fillRect(bookmarkX, bookmarkY, bookmarkWidth, bookmarkHeight);
        // Draw prominent notch (60% of bookmark width for better visibility)
        const notchSize = Math.floor(bookmarkWidth * 0.6);
        ctx.fillStyle = colors.paper;
        ctx.beginPath();
        ctx.moveTo(bookmarkX, bookmarkY + bookmarkHeight);
        ctx.lineTo(bookmarkX + bookmarkWidth, bookmarkY + bookmarkHeight);
        ctx.lineTo(bookmarkX + bookmarkWidth / 2, bookmarkY + bookmarkHeight - notchSize);
        ctx.closePath();
        ctx.fill();
        return ctx.getImageData(0, 0, widthPx, heightPx);
    }
    getIconState(tabId) {
        return this.tabStates.get(tabId) || IconState.DEFAULT;
    }
    async setPaperDetected(tabId) {
        await this.setIconState(tabId, IconState.DETECTED);
    }
    async setPaperTracked(tabId) {
        await this.setIconState(tabId, IconState.TRACKED);
    }
    async resetIcon(tabId) {
        await this.setIconState(tabId, IconState.DEFAULT);
    }
    async setBadgeText(tabId, text, color) {
        try {
            await chrome.action.setBadgeText({ tabId, text });
            if (color) {
                await chrome.action.setBadgeBackgroundColor({ tabId, color });
            }
            logger$5.debug(`Set badge text "${text}" for tab ${tabId}`);
        }
        catch (error) {
            logger$5.error(`Failed to set badge text for tab ${tabId}:`, error);
        }
    }
    async clearBadge(tabId) {
        await this.setBadgeText(tabId, '');
    }
    // NEW: Utility method to add dynamic badges/indicators
    async setPaperCount(tabId, count) {
        if (count > 0) {
            await this.setBadgeText(tabId, count.toString(), '#FF4444');
        }
        else {
            await this.clearBadge(tabId);
        }
    }
    // NEW: Reset all tabs to default (useful for extension restart)
    async resetAllIcons() {
        try {
            const tabs = await chrome.tabs.query({});
            await Promise.allSettled(tabs.map(tab => tab.id ? this.resetIcon(tab.id) : Promise.resolve()));
            logger$5.info('Reset all tab icons');
        }
        catch (error) {
            logger$5.error('Failed to reset all icons:', error);
        }
    }
    // NEW: Get cache statistics for debugging
    getCacheStats() {
        let totalSize = 0;
        for (const imageDataMap of this.iconCache.values()) {
            for (const imageData of Object.values(imageDataMap)) {
                totalSize += imageData.data.length;
            }
        }
        return {
            states: this.iconCache.size,
            totalSize
        };
    }
}

// extension/source-integration/metadata-extractor.ts
const logger$4 = loguru.getLogger('metadata-extractor');
// Constants for standard source types
const SOURCE_TYPES = {
    PDF: 'pdf',
    URL: 'url',
};
/**
 * Base class for metadata extraction with customizable extraction methods
 * Each method can be overridden to provide source-specific extraction
 */
class MetadataExtractor {
    /**
     * Create a new metadata extractor for a document
     */
    constructor(document) {
        this.document = document;
        this.url = document.location.href;
        logger$4.debug('Initialized metadata extractor for:', this.url);
    }
    /**
     * Helper method to get content from meta tags
     */
    getMetaContent(selector) {
        const element = this.document.querySelector(selector);
        return element ? element.getAttribute('content') || '' : '';
    }
    /**
     * Extract and return all metadata fields
     */
    extract() {
        logger$4.debug('Extracting metadata from page:', this.url);
        const metadata = {
            title: this.extractTitle(),
            authors: this.extractAuthors(),
            description: this.extractDescription(),
            publishedDate: this.extractPublishedDate(),
            doi: this.extractDoi(),
            journalName: this.extractJournalName(),
            tags: this.extractTags(),
            url: this.url
        };
        logger$4.debug('Metadata extraction complete:', metadata);
        return metadata;
    }
    /**
     * Extract title from document
     * Considers multiple metadata standards with priority order
     */
    extractTitle() {
        // Title extraction - priority order
        return (
        // Dublin Core
        this.getMetaContent('meta[name="DC.Title"]') || this.getMetaContent('meta[name="dc.title"]') ||
            // Citation
            this.getMetaContent('meta[name="citation_title"]') ||
            // Open Graph
            this.getMetaContent('meta[property="og:title"]') ||
            // Standard meta
            this.getMetaContent('meta[name="title"]') ||
            // Fallback to document title
            this.document.title);
    }
    /**
     * Extract authors from document
     * Handles multiple author formats and sources
     */
    extractAuthors() {
        // Get all citation authors (some pages have multiple citation_author tags)
        const citationAuthors = [];
        this.document.querySelectorAll('meta[name="citation_author"]').forEach(el => {
            const content = el.getAttribute('content');
            if (content)
                citationAuthors.push(content);
        });
        // Get all DC creators
        const dcCreators = [];
        this.document.querySelectorAll('meta[name="DC.Creator.PersonalName"]').forEach(el => {
            const content = el.getAttribute('content');
            if (content)
                dcCreators.push(content);
        });
        // Individual author elements
        const dcCreator = this.getMetaContent('meta[name="DC.Creator.PersonalName"]') || this.getMetaContent('meta[name="dc.creator.personalname"]');
        const citationAuthor = this.getMetaContent('meta[name="citation_author"]');
        const ogAuthor = this.getMetaContent('meta[property="og:article:author"]') ||
            this.getMetaContent('meta[name="author"]');
        // Set authors with priority
        if (dcCreators.length > 0) {
            return dcCreators.join(', ');
        }
        else if (citationAuthors.length > 0) {
            return citationAuthors.join(', ');
        }
        else if (dcCreator) {
            return dcCreator;
        }
        else if (citationAuthor) {
            return citationAuthor;
        }
        else if (ogAuthor) {
            return ogAuthor;
        }
        return '';
    }
    /**
     * Extract description/abstract from document
     */
    extractDescription() {
        return (this.getMetaContent('meta[name="DC.Description"]') || this.getMetaContent('meta[name="dc.description"]') ||
            this.getMetaContent('meta[name="citation_abstract"]') ||
            this.getMetaContent('meta[property="og:description"]') ||
            this.getMetaContent('meta[name="description"]'));
    }
    /**
     * Extract publication date from document
     */
    extractPublishedDate() {
        return (this.getMetaContent('meta[name="DC.Date.issued"]') || this.getMetaContent('meta[name="dc.date.issued"]') || this.getMetaContent('meta[name="dc.date"]') || this.getMetaContent('meta[name="dc.Date"]') || this.getMetaContent('meta[name="DC.Date"]') ||
            this.getMetaContent('meta[name="citation_date"]') ||
            this.getMetaContent('meta[property="article:published_time"]'));
    }
    /**
     * Extract DOI (Digital Object Identifier) from document
     */
    extractDoi() {
        return (this.getMetaContent('meta[name="DC.Identifier.DOI"]') || this.getMetaContent('meta[name="dc.identifier.doi"]') ||
            this.getMetaContent('meta[name="citation_doi"]'));
    }
    /**
     * Extract journal name from document
     */
    extractJournalName() {
        return (this.getMetaContent('meta[name="DC.Source"]') || this.getMetaContent('meta[name="dc.source"]') ||
            this.getMetaContent('meta[name="citation_journal_title"]'));
    }
    /**
     * Extract keywords/tags from document
     */
    extractTags() {
        const keywords = this.getMetaContent('meta[name="keywords"]') ||
            this.getMetaContent('meta[name="DC.Subject"]') || this.getMetaContent('meta[name="dc.subject"]');
        if (keywords) {
            return keywords.split(',').map(tag => tag.trim());
        }
        return [];
    }
    /**
     * Determine if the current URL is a PDF
     */
    isPdf() {
        return isPdfUrl(this.url);
    }
    /**
     * Get the source type (PDF or URL)
     */
    getSourceType() {
        return this.isPdf() ? SOURCE_TYPES.PDF : SOURCE_TYPES.URL;
    }
    /**
     * Generate a paper ID for the current URL
     */
    generatePaperId() {
        return generatePaperIdFromUrl(this.url);
    }
}
/**
 * Create a common metadata extractor for a document
 * Factory function for creating the default extractor
 */
function createMetadataExtractor(document) {
    return new MetadataExtractor(document);
}
/**
 * Generate a paper ID from a URL
 * Creates a consistent hash-based identifier
 */
function generatePaperIdFromUrl(url) {
    // Use a basic hash function to create an ID from the URL
    let hash = 0;
    for (let i = 0; i < url.length; i++) {
        const char = url.charCodeAt(i);
        hash = ((hash << 5) - hash) + char;
        hash = hash & hash; // Convert to 32bit integer
    }
    // Create a positive hexadecimal string
    const positiveHash = Math.abs(hash).toString(16).toUpperCase();
    // Use the first 8 characters as the ID
    return positiveHash.substring(0, 8);
}
/**
 * Determine if a URL is a PDF
 */
function isPdfUrl(url) {
    return url.toLowerCase().endsWith('.pdf');
}

// extension/source-integration/base-source.ts
const logger$3 = loguru.getLogger('base-source');
/**
 * Base class for source integrations
 * Provides default implementations for all methods
 * Specific sources can override as needed
 */
class BaseSourceIntegration {
    constructor() {
        // Default properties - set for generic web pages
        this.id = 'url';
        this.name = 'Web Page';
        this.urlPatterns = [
            /^https?:\/\/(?!.*\.pdf($|\?|#)).*$/i // Match HTTP/HTTPS URLs that aren't PDFs
        ];
        this.contentScriptMatches = [];
    }
    /**
     * Check if this integration can handle the given URL
     * Default implementation checks against urlPatterns
     */
    canHandleUrl(url) {
        return this.urlPatterns.some(pattern => pattern.test(url));
    }
    /**
     * Extract paper ID from URL
     * Default implementation creates a hash from the URL
     */
    extractPaperId(url) {
        return generatePaperIdFromUrl(url);
    }
    /**
     * Create a metadata extractor for the given document
     * Override this method to provide a custom extractor for your source
     */
    createMetadataExtractor(document) {
        return createMetadataExtractor(document);
    }
    /**
     * Extract metadata from a page
     * Default implementation uses common metadata extraction
     */
    async extractMetadata(document, paperId) {
        try {
            logger$3.debug(`Extracting metadata using base extractor for ID: ${paperId}`);
            // Create a metadata extractor for this document
            const extractor = this.createMetadataExtractor(document);
            // Extract metadata
            const extracted = extractor.extract();
            const url = document.location.href;
            // Determine source type (PDF or URL)
            const sourceType = extractor.getSourceType();
            // Create PaperMetadata object
            return {
                sourceId: this.id,
                //paperId: this.formatPaperId(paperId),
                paperId: paperId,
                url: url,
                title: extracted.title || document.title || paperId,
                authors: extracted.authors || '',
                abstract: extracted.description || '',
                timestamp: new Date().toISOString(),
                rating: 'novote',
                publishedDate: extracted.publishedDate || '',
                tags: extracted.tags || [],
                doi: extracted.doi,
                journalName: extracted.journalName,
                sourceType: sourceType // Store the source type for reference
            };
        }
        catch (error) {
            logger$3.error('Error extracting metadata with base extractor', error);
            return null;
        }
    }
    /**
     * Format a paper identifier for this source
     * Default implementation uses the format: sourceId.paperId
     */
    formatPaperId(paperId) {
        return `${this.id}.${paperId}`;
    }
    /**
     * Parse a paper identifier specific to this source
     * Default implementation handles source.paperId format and extracts paperId
     */
    parsePaperId(identifier) {
        const prefix = `${this.id}.`;
        if (identifier.startsWith(prefix)) {
            return identifier.substring(prefix.length);
        }
        // Try legacy format (sourceId:paperId)
        const legacyPrefix = `${this.id}:`;
        if (identifier.startsWith(legacyPrefix)) {
            logger$3.debug(`Parsed legacy format identifier: ${identifier}`);
            return identifier.substring(legacyPrefix.length);
        }
        return null;
    }
    /**
     * Format a storage object ID for this source
     * Default implementation uses the format: type:sourceId.paperId
     */
    formatObjectId(type, paperId) {
        return `${type}:${this.formatPaperId(paperId)}`;
    }
}

// extension/source-integration/arxiv/index.ts
const logger$2 = loguru.getLogger('arxiv-integration');
/**
 * Custom metadata extractor for arXiv pages
 */
class ArxivMetadataExtractor extends MetadataExtractor {
    constructor(document, apiMetadata) {
        super(document);
        this.apiMetadata = apiMetadata;
    }
    /**
     * Override title extraction to use API data if available
     */
    extractTitle() {
        if (this.apiMetadata?.title) {
            return this.apiMetadata.title;
        }
        // arXiv-specific selectors
        //const arxivTitle = this.document.querySelector('.title.mathjax')?.textContent?.trim();
        //return arxivTitle || super.extractTitle();
        return super.extractTitle();
    }
    /**
     * Override authors extraction to use API data if available
     */
    extractAuthors() {
        if (this.apiMetadata?.authors) {
            return this.apiMetadata.authors;
        }
        // arXiv-specific selectors
        const authorLinks = this.document.querySelectorAll('.authors a');
        if (authorLinks.length > 0) {
            return Array.from(authorLinks)
                .map(link => link.textContent?.trim())
                .filter(Boolean)
                .join(', ');
        }
        return super.extractAuthors();
    }
    /**
     * Override description extraction to use API data if available
     */
    extractDescription() {
        if (this.apiMetadata?.description) {
            return this.apiMetadata.description;
        }
        // arXiv-specific selectors
        const abstract = this.document.querySelector('.abstract')?.textContent?.trim();
        if (abstract) {
            // Remove "Abstract:" prefix if present
            return abstract.replace(/^Abstract:\s*/i, '');
        }
        return super.extractDescription();
    }
    /**
     * Override published date extraction to use API data if available
     */
    extractPublishedDate() {
        if (this.apiMetadata?.publishedDate) {
            return this.apiMetadata.publishedDate;
        }
        // arXiv-specific date extraction
        const datelineElement = this.document.querySelector('.dateline');
        if (datelineElement) {
            const dateText = datelineElement.textContent;
            const dateMatch = dateText?.match(/\(Submitted on ([^)]+)\)/);
            if (dateMatch) {
                return dateMatch[1];
            }
        }
        return super.extractPublishedDate();
    }
    /**
     * Override DOI extraction to use API data if available
     */
    extractDoi() {
        return this.apiMetadata?.doi || super.extractDoi();
    }
    /**
     * Override journal extraction to use API data if available
     */
    extractJournalName() {
        return this.apiMetadata?.journalName || super.extractJournalName();
    }
    /**
     * Override tags extraction to use API data if available
     */
    extractTags() {
        if (this.apiMetadata?.tags) {
            return this.apiMetadata.tags;
        }
        // arXiv-specific category extraction
        const subjects = this.document.querySelector('.subjects')?.textContent?.trim();
        if (subjects) {
            return subjects.split(/[;,]/).map(tag => tag.trim()).filter(Boolean);
        }
        return super.extractTags();
    }
}
/**
 * ArXiv integration with custom metadata extraction
 */
class ArXivIntegration extends BaseSourceIntegration {
    constructor() {
        super(...arguments);
        this.id = 'arxiv';
        this.name = 'arXiv.org';
        // URL patterns for papers
        this.urlPatterns = [
            /arxiv\.org\/(abs|pdf|html)\/([0-9.]+)/,
            /arxiv\.org\/\w+\/([0-9.]+)/
        ];
        // Content script matches
        // readonly contentScriptMatches = [
        //   "*://*.arxiv.org/*"
        // ];
        // ArXiv API endpoint
        this.API_BASE_URL = 'https://export.arxiv.org/api/query';
    }
    /**
     * Extract paper ID from URL
     */
    extractPaperId(url) {
        for (const pattern of this.urlPatterns) {
            const match = url.match(pattern);
            if (match) {
                return match[2] || match[1]; // The capture group with the paper ID
            }
        }
        return null;
    }
    /**
     * Create a custom metadata extractor for arXiv
     */
    createMetadataExtractor(document) {
        return new ArxivMetadataExtractor(document);
    }
    /**
     * Fetch metadata from ArXiv API
     */
    async fetchFromApi(paperId) {
        try {
            const apiUrl = `${this.API_BASE_URL}?id_list=${paperId}`;
            logger$2.debug(`Fetching from ArXiv API: ${apiUrl}`);
            const response = await fetch(apiUrl);
            if (!response.ok) {
                logger$2.error(`ArXiv API request failed with status: ${response.status}`);
                return null;
            }
            const xmlText = await response.text();
            // Parse XML to JSON
            const parser = new DOMParser();
            const xmlDoc = parser.parseFromString(xmlText, 'text/xml');
            // Convert XML to a more manageable format
            const entry = xmlDoc.querySelector('entry');
            if (!entry) {
                logger$2.warn('No entry found in ArXiv API response');
                return null;
            }
            // Extract metadata from XML
            const title = entry.querySelector('title')?.textContent?.trim() || '';
            const summary = entry.querySelector('summary')?.textContent?.trim() || '';
            const published = entry.querySelector('published')?.textContent?.trim() || '';
            // Extract authors
            const authorElements = entry.querySelectorAll('author name');
            const authors = Array.from(authorElements)
                .map(el => el.textContent?.trim())
                .filter(Boolean)
                .join(', ');
            // Extract DOI if available
            const doi = entry.querySelector('arxiv\\:doi, doi')?.textContent?.trim();
            // Extract journal reference if available
            const journalRef = entry.querySelector('arxiv\\:journal_ref, journal_ref')?.textContent?.trim();
            // Extract categories
            const categoryElements = entry.querySelectorAll('category');
            const categories = Array.from(categoryElements)
                .map(el => el.getAttribute('term'))
                .filter(Boolean);
            return {
                title,
                authors,
                description: summary,
                publishedDate: published,
                doi,
                journalName: journalRef,
                tags: categories
            };
        }
        catch (error) {
            logger$2.error('Error fetching from ArXiv API', error);
            return null;
        }
    }
    /**
     * Extract metadata from page or fetch from API
     * Override parent method to handle the API fallback
     */
    async extractMetadata(document, paperId) {
        try {
            logger$2.info(`Extracting metadata for arXiv ID: ${paperId}`);
            // Try to extract from page first
            const extractor = this.createMetadataExtractor(document);
            const pageMetadata = extractor.extract();
            // Check if we have the essential fields
            const hasTitle = pageMetadata.title && pageMetadata.title !== document.title;
            const hasAuthors = pageMetadata.authors && pageMetadata.authors.length > 0;
            const hasAbstract = pageMetadata.description && pageMetadata.description.length > 0;
            if (hasTitle && hasAuthors && hasAbstract) {
                logger$2.debug('Successfully extracted complete metadata from page');
                return this.convertToPageMetadata(pageMetadata, paperId, extractor.getSourceType());
            }
            // If page extraction is incomplete, fetch from API
            logger$2.info('Page metadata incomplete, fetching from ArXiv API');
            const apiMetadata = await this.fetchFromApi(paperId);
            if (!apiMetadata) {
                logger$2.warn('Failed to fetch metadata from ArXiv API, using partial page data');
                return this.convertToPageMetadata(pageMetadata, paperId, extractor.getSourceType());
            }
            // Create a new extractor with API data
            const enhancedExtractor = new ArxivMetadataExtractor(document, apiMetadata);
            const mergedMetadata = enhancedExtractor.extract();
            logger$2.debug('Merged metadata from page and API', mergedMetadata);
            return this.convertToPageMetadata(mergedMetadata, paperId, enhancedExtractor.getSourceType());
        }
        catch (error) {
            logger$2.error('Error extracting metadata for arXiv', error);
            return null;
        }
    }
    /**
     * Convert ExtractedMetadata to PaperMetadata
     */
    convertToPageMetadata(extracted, paperId, sourceType) {
        return {
            sourceId: this.id,
            paperId: paperId,
            url: extracted.url || '',
            title: extracted.title,
            authors: extracted.authors,
            abstract: extracted.description,
            timestamp: new Date().toISOString(),
            rating: 'novote',
            publishedDate: extracted.publishedDate,
            tags: extracted.tags || [],
            doi: extracted.doi,
            journalName: extracted.journalName,
            sourceType: sourceType
        };
    }
}
// Export a singleton instance that can be used by both background and content scripts
const arxivIntegration = new ArXivIntegration();

// extension/source-integration/openreview/index.ts
const logger$1 = loguru.getLogger('openreview-integration');
/**
 * Custom metadata extractor for OpenReview pages
 */
class OpenReviewMetadataExtractor extends MetadataExtractor {
    /**
     * Extract metadata from OpenReview pages
     */
    extract() {
        // First try to extract using standard methods
        const baseMetadata = super.extract();
        try {
            // Get title from OpenReview-specific elements
            const title = this.document.querySelector('.citation_title')?.textContent ||
                this.document.querySelector('.forum-title h2')?.textContent;
            // Get authors
            const authorElements = Array.from(this.document.querySelectorAll('.forum-authors a'));
            const authors = authorElements
                .map(el => el.textContent)
                .filter(Boolean)
                .join(', ');
            // Get abstract
            const abstract = this.document.querySelector('meta[name="citation_abstract"]')?.getAttribute('content') ||
                Array.from(this.document.querySelectorAll('.note-content-field'))
                    .find(el => el.textContent?.includes('Abstract'))
                    ?.nextElementSibling?.textContent;
            // Get publication date
            const dateText = this.document.querySelector('.date.item')?.textContent;
            let publishedDate = '';
            if (dateText) {
                const dateMatch = dateText.match(/Published: ([^,]+)/);
                if (dateMatch) {
                    publishedDate = dateMatch[1];
                }
            }
            // Get DOI if available
            const doi = this.document.querySelector('meta[name="citation_doi"]')?.getAttribute('content') || '';
            // Get conference/journal name
            const venueElements = this.document.querySelectorAll('.forum-meta .item');
            let venue = '';
            for (let i = 0; i < venueElements.length; i++) {
                const el = venueElements[i];
                if (el.querySelector('.glyphicon-folder-open')) {
                    venue = el.textContent?.trim() || '';
                    break;
                }
            }
            // Get tags/keywords
            const keywordsElement = Array.from(this.document.querySelectorAll('.note-content-field'))
                .find(el => el.textContent?.includes('Keywords'));
            let tags = [];
            if (keywordsElement) {
                const keywordsValue = keywordsElement.nextElementSibling?.textContent;
                if (keywordsValue) {
                    tags = keywordsValue.split(',').map(tag => tag.trim());
                }
            }
            return {
                title: title || baseMetadata.title,
                authors: authors || baseMetadata.authors,
                description: abstract || baseMetadata.description,
                publishedDate: publishedDate || baseMetadata.publishedDate,
                doi: doi || baseMetadata.doi,
                journalName: venue || baseMetadata.journalName,
                tags: tags.length ? tags : baseMetadata.tags,
                url: this.url
            };
        }
        catch (error) {
            logger$1.error('Error during OpenReview-specific extraction', error);
            return baseMetadata;
        }
    }
}
/**
 * OpenReview integration with custom metadata extraction
 */
class OpenReviewIntegration extends BaseSourceIntegration {
    constructor() {
        super(...arguments);
        this.id = 'openreview';
        this.name = 'OpenReview';
        // URL patterns for papers
        this.urlPatterns = [
            /openreview\.net\/forum\?id=([a-zA-Z0-9]+)/,
            /openreview\.net\/pdf\?id=([a-zA-Z0-9]+)/
        ];
    }
    // Content script matches
    // readonly contentScriptMatches = [
    //   "*://*.openreview.net/*"
    // ];
    /**
     * Extract paper ID from URL
     */
    extractPaperId(url) {
        for (const pattern of this.urlPatterns) {
            const match = url.match(pattern);
            if (match) {
                return match[1]; // The capture group with the paper ID
            }
        }
        return null;
    }
    /**
     * Create a custom metadata extractor for OpenReview
     */
    createMetadataExtractor(document) {
        return new OpenReviewMetadataExtractor(document);
    }
    /**
     * Extract metadata from page
     * Override parent method to handle OpenReview-specific extraction
     */
    async extractMetadata(document, paperId) {
        logger$1.info(`Extracting metadata for OpenReview ID: ${paperId}`);
        // Extract metadata using our custom extractor
        const metadata = await super.extractMetadata(document, paperId);
        if (metadata) {
            // Add any OpenReview-specific metadata processing here
            logger$1.debug('Extracted metadata from OpenReview page');
            // Check if we're on a PDF page and adjust metadata accordingly
            if (document.location.href.includes('/pdf?id=')) {
                metadata.sourceType = 'pdf';
            }
        }
        return metadata;
    }
}
// Export a singleton instance that can be used by both background and content scripts
const openReviewIntegration = new OpenReviewIntegration();

// extension/source-integration/nature/index.ts
loguru.getLogger('nature-integration');
/**
 * Custom metadata extractor for Nature.com pages
 */
class NatureMetadataExtractor extends MetadataExtractor {
    /**
     * Override title extraction to use meta tag first
     */
    extractTitle() {
        const metaTitle = this.getMetaContent('meta[name="citation_title"]') ||
            this.getMetaContent('meta[property="og:title"]');
        return metaTitle || super.extractTitle();
    }
    /**
     * Override authors extraction to use meta tag first
     */
    extractAuthors() {
        const metaAuthors = this.getMetaContent('meta[name="citation_author"]');
        if (metaAuthors) {
            return metaAuthors;
        }
        // Fallback to HTML extraction
        const authorElements = this.document.querySelectorAll('.c-article-author-list__item');
        if (authorElements.length > 0) {
            return Array.from(authorElements)
                .map(el => el.textContent?.trim())
                .filter(Boolean)
                .join(', ');
        }
        return super.extractAuthors();
    }
    /**
     * Extract keywords/tags from document
     */
    extractTags() {
        const keywords = this.getMetaContent('meta[name="dc.subject"]');
        if (keywords) {
            return keywords.split(',').map(tag => tag.trim());
        }
        return [];
    }
    /**
     * Override description extraction to use meta tag first
     */
    extractDescription() {
        const metaDescription = this.getMetaContent('meta[name="description"]') ||
            this.getMetaContent('meta[property="og:description"]');
        return metaDescription || super.extractDescription();
    }
    /**
     * Override published date extraction to use meta tag
     */
    extractPublishedDate() {
        return this.getMetaContent('meta[name="citation_publication_date"]') || super.extractPublishedDate();
    }
    /**
     * Override DOI extraction to use meta tag
     */
    extractDoi() {
        return this.getMetaContent('meta[name="citation_doi"]') || super.extractDoi();
    }
}
/**
 * Nature.com integration with custom metadata extraction
 */
class NatureIntegration extends BaseSourceIntegration {
    constructor() {
        super(...arguments);
        this.id = 'nature';
        this.name = 'Nature';
        // URL pattern for Nature articles with capture group for ID
        this.urlPatterns = [
            /nature\.com\/articles\/([^?]+)/,
        ];
    }
    // Content script matches  
    // readonly contentScriptMatches = [
    //   "*://*.nature.com/articles/*"
    // ];
    /**
     * Extract paper ID from URL
     */
    extractPaperId(url) {
        const match = url.match(this.urlPatterns[0]);
        return match ? match[1] : null;
    }
    /**
     * Create a custom metadata extractor for Nature.com
     */
    createMetadataExtractor(document) {
        return new NatureMetadataExtractor(document);
    }
}
// Export a singleton instance 
const natureIntegration = new NatureIntegration();

// extension/source-integration/pnas/index.ts
class PnasIntegration extends BaseSourceIntegration {
    constructor() {
        super(...arguments);
        this.id = 'pnas';
        this.name = 'PNAS';
        this.urlPatterns = [
            /pnas\.org\/doi\/10\.1073\/pnas\.([0-9]+)/
        ];
    }
    // readonly contentScriptMatches = [
    //   "*://*.pnas.org/doi/*"
    // ];
    // upstream BaseSourceIntegration.extractPaperId should default to this behavior when able
    extractPaperId(url) {
        const match = url.match(this.urlPatterns[0]);
        return match ? match[1] : null;
    }
}
const pnasIntegration = new PnasIntegration();

// extension/source-integration/misc/index.ts
class MiscIntegration extends BaseSourceIntegration {
    constructor() {
        super(...arguments);
        this.id = 'url-misc';
        this.name = 'misc tracked url';
        this.urlPatterns = []; // set this empty to disable attaching the content injection icon thing
        // add URLs here to track
        this.contentScriptMatches = [
            "sciencedirect.com/science/article/",
            "philpapers.org/rec/",
            "proceedings.neurips.cc/paper_files/paper/",
            "journals.sagepub.com/doi/",
            "link.springer.com/article/",
            ".science.org/doi/",
            "journals.aps.org/prx/abstract/",
            "onlinelibrary.wiley.com/doi/",
            "cell.com/trends/cognitive-sciences/fulltext/",
            "researchgate.net/publication/",
            "psycnet.apa.org/record/",
            "biorxiv.org/content/",
            "osf.io/preprints/",
            "frontiersin.org/journals/",
            "jstor.org/",
            "proceedings.mlr.press/",
            "journals.plos.org/plosone/article",
            "ieeexplore.ieee.org/document/",
            "royalsocietypublishing.org/doi/",
            "papers.nips.cc/paper_files/paper/",
            "philarchive.org/archive/",
            "tandfonline.com/doi/",
            "iopscience.iop.org/article/",
            "academic.oup.com/brain/article/",
            "elifesciences.org/articles/",
            "escholarship.org/content/",
            "pmc.ncbi.nlm.nih.gov/articles/",
            "pubmed.ncbi.nlm.nih.gov/",
            "openaccess.thecvf.com/content/",
            "zenodo.org/records/",
            "journals.asm.org/doi/full/",
            "physoc.onlinelibrary.wiley.com/doi/full/",
            "storage.courtlistener.com/recap/",
            "bmj.com/content/",
            "ntsb.gov/investigations/pages",
            "ntsb.gov/investigations/AccidentReports",
            "aclanthology.org/",
            "journals.ametsoc.org/view/journals/",
            "substack.com/p/",
            "citeseerx.",
            "/doi/",
            "/pdf/",
        ];
    }
    canHandleUrl(url) {
        return this.contentScriptMatches.some(pattern => url.includes(pattern));
    }
}
const miscIntegration = new MiscIntegration();

// extension/source-integration/registry.ts
const sourceIntegrations = [
    arxivIntegration,
    openReviewIntegration,
    natureIntegration,
    pnasIntegration,
    miscIntegration,
];

// background.ts
const logger = loguru.getLogger('background');
// Global state
let githubToken = '';
let githubRepo = '';
let paperManager = null;
let sessionService = null;
let popupManager = null;
let sourceManager = null;
let iconManager = null;
// Initialize sources
function initializeSources() {
    sourceManager = new SourceIntegrationManager();
    // Register all sources from the central registry
    for (const integration of sourceIntegrations) {
        sourceManager.registerSource(integration);
    }
    logger.info('Source manager initialized with integrations:', sourceIntegrations.map(int => int.id).join(', '));
    return sourceManager;
}
// Initialize everything
async function initialize() {
    try {
        // Initialize sources first
        initializeSources();
        // Initialize icon manager
        iconManager = new IconManager();
        logger.info('Icon manager initialized');
        // Load GitHub credentials
        const items = await chrome.storage.sync.get(['githubToken', 'githubRepo']);
        githubToken = items.githubToken || '';
        githubRepo = items.githubRepo || '';
        logger.info('Credentials loaded', { hasToken: !!githubToken, hasRepo: !!githubRepo });
        // Initialize paper manager if we have credentials
        if (githubToken && githubRepo) {
            const githubClient = new d(githubToken, githubRepo);
            // Pass the source manager to the paper manager
            paperManager = new PaperManager(githubClient, sourceManager);
            logger.info('Paper manager initialized');
            // Initialize session service with paper manager
            sessionService = new SessionService(paperManager);
        }
        else {
            // Initialize session service without paper manager
            sessionService = new SessionService(null);
        }
        logger.info('Session service initialized');
        // Initialize popup manager
        popupManager = new PopupManager(() => sourceManager, () => paperManager);
        logger.info('Popup manager initialized');
        // Set up message listeners
        setupMessageListeners();
        // Initialize debug objects
        initializeDebugObjects();
    }
    catch (error) {
        logger.error('Initialization error', error);
    }
}
// Set up message listeners
function setupMessageListeners() {
    chrome.runtime.onMessage.addListener((message, sender, sendResponse) => {
        if (message.type === 'contentScriptReady' && sender.tab?.id) {
            logger.debug('Content script ready:', sender.tab.url);
            sendResponse({ success: true });
            return true;
        }
        if (message.type === 'paperMetadata' && message.metadata && sender.tab?.id) {
            // Store metadata received from content script and update icon
            handlePaperMetadata(message.metadata, sender.tab.id);
            sendResponse({ success: true });
            return true;
        }
        if (message.type === 'paperDetected' && sender.tab?.id) {
            // Paper detected but not yet stored - show detected state
            handlePaperDetected(sender.tab.id, message.sourceId, message.paperId);
            sendResponse({ success: true });
            return true;
        }
        if (message.type === 'noPaperDetected' && sender.tab?.id) {
            // No paper detected - reset to default icon
            handleNoPaperDetected(sender.tab.id);
            sendResponse({ success: true });
            return true;
        }
        if (message.type === 'getCurrentPaper') {
            const session = sessionService?.getCurrentSession();
            const paperMetadata = session
                ? sessionService?.getPaperMetadata(session.sourceId, session.paperId)
                : null;
            logger.debug('Popup requested current paper', paperMetadata);
            sendResponse(paperMetadata);
            return true;
        }
        if (message.type === 'updateRating') {
            logger.debug('Rating update requested:', message.rating);
            handleUpdateRating(message.rating, sendResponse);
            return true; // Will respond asynchronously
        }
        if (message.type === 'startSession') {
            handleStartSession(message.sourceId, message.paperId);
            sendResponse({ success: true });
            return true;
        }
        if (message.type === 'sessionHeartbeat') {
            handleSessionHeartbeat();
            sendResponse({ success: true });
            return true;
        }
        if (message.type === 'endSession') {
            handleEndSession(message.reason || 'user_action');
            sendResponse({ success: true });
            return true;
        }
        // New handler for manual paper logging from popup
        if (message.type === 'manualPaperLog' && message.metadata && sender.tab?.id) {
            handleManualPaperLog(message.metadata, sender.tab.id)
                .then(() => sendResponse({ success: true }))
                .catch(error => {
                logger.error('Error handling manual paper log', error);
                sendResponse({
                    success: false,
                    error: error instanceof Error ? error.message : 'Unknown error'
                });
            });
            return true; // Will respond asynchronously
        }
        // Other message handlers are managed by PopupManager
        return false; // Not handled
    });
}
// Handle paper detected (before storage)
async function handlePaperDetected(tabId, sourceId, paperId) {
    if (!iconManager)
        return;
    try {
        await iconManager.setPaperDetected(tabId);
        logger.debug(`Set detected icon for ${sourceId}:${paperId} in tab ${tabId}`);
    }
    catch (error) {
        logger.error('Error setting detected icon', error);
    }
}
// Handle no paper detected
async function handleNoPaperDetected(tabId) {
    if (!iconManager)
        return;
    try {
        await iconManager.resetIcon(tabId);
        logger.debug(`Reset icon for tab ${tabId}`);
    }
    catch (error) {
        logger.error('Error resetting icon', error);
    }
}
// Handle paper metadata from content script
async function handlePaperMetadata(metadata, tabId) {
    logger.info(`Received metadata for ${metadata.sourceId}:${metadata.paperId}`);
    try {
        // Store metadata in session service
        if (sessionService) {
            sessionService.storePaperMetadata(metadata);
        }
        // Store in GitHub if we have a paper manager
        if (paperManager) {
            await paperManager.getOrCreatePaper(metadata);
            logger.debug('Paper metadata stored in GitHub');
            // Update icon to tracked state
            if (iconManager) {
                await iconManager.setPaperTracked(tabId);
                logger.debug(`Set tracked icon for ${metadata.sourceId}:${metadata.paperId} in tab ${tabId}`);
            }
        }
        else {
            // No paper manager - just show detected state
            if (iconManager) {
                await iconManager.setPaperDetected(tabId);
            }
        }
    }
    catch (error) {
        logger.error('Error handling paper metadata', error);
        // On error, show detected state instead of tracked
        if (iconManager) {
            await iconManager.setPaperDetected(tabId);
        }
    }
}
// Handle rating update
async function handleUpdateRating(rating, sendResponse) {
    if (!paperManager || !sessionService) {
        sendResponse({ success: false, error: 'Services not initialized' });
        return;
    }
    const session = sessionService.getCurrentSession();
    if (!session) {
        sendResponse({ success: false, error: 'No current session' });
        return;
    }
    const metadata = sessionService.getPaperMetadata();
    if (!metadata) {
        sendResponse({ success: false, error: 'No paper metadata available' });
        return;
    }
    try {
        await paperManager.updateRating(session.sourceId, session.paperId, rating, metadata);
        // Update stored metadata with new rating
        metadata.rating = rating;
        sendResponse({ success: true });
    }
    catch (error) {
        logger.error('Error updating rating:', error);
        sendResponse({ success: false, error: error instanceof Error ? error.message : 'Unknown error' });
    }
}
// Handle session start request
function handleStartSession(sourceId, paperId) {
    if (!sessionService) {
        logger.error('Session service not initialized');
        return;
    }
    // Get metadata if available
    const existingMetadata = sessionService.getPaperMetadata(sourceId, paperId);
    // Start the session
    sessionService.startSession(sourceId, paperId, existingMetadata);
    logger.info(`Started session for ${sourceId}:${paperId}`);
}
// Handle session heartbeat
function handleSessionHeartbeat() {
    if (!sessionService) {
        logger.error('Session service not initialized');
        return;
    }
    sessionService.recordHeartbeat();
}
// Handle session end request
function handleEndSession(reason) {
    if (!sessionService) {
        logger.error('Session service not initialized');
        return;
    }
    const session = sessionService.getCurrentSession();
    if (session) {
        logger.info(`Ending session: ${reason}`);
        sessionService.endSession();
    }
}
async function handleManualPaperLog(metadata, tabId) {
    logger.info(`Received manual paper log: ${metadata.sourceId}:${metadata.paperId}`);
    try {
        // Store metadata in session service
        if (sessionService) {
            sessionService.storePaperMetadata(metadata);
        }
        // Store in GitHub if we have a paper manager
        if (paperManager) {
            await paperManager.getOrCreatePaper(metadata);
            logger.debug('Manually logged paper stored in GitHub');
            // Update icon to tracked state
            if (iconManager) {
                await iconManager.setPaperTracked(tabId);
                logger.debug(`Set tracked icon for manually logged paper in tab ${tabId}`);
            }
        }
    }
    catch (error) {
        logger.error('Error handling manual paper log', error);
        throw error;
    }
}
// Listen for credential changes
chrome.storage.onChanged.addListener(async (changes) => {
    logger.debug('Storage changes detected', Object.keys(changes));
    if (changes.githubToken) {
        githubToken = changes.githubToken.newValue;
    }
    if (changes.githubRepo) {
        githubRepo = changes.githubRepo.newValue;
    }
    // Reinitialize paper manager if credentials changed
    if (changes.githubToken || changes.githubRepo) {
        if (githubToken && githubRepo) {
            const githubClient = new d(githubToken, githubRepo);
            // Pass the source manager to the paper manager
            paperManager = new PaperManager(githubClient, sourceManager);
            logger.info('Paper manager reinitialized');
            // Reinitialize session service with new paper manager
            sessionService = new SessionService(paperManager);
            logger.info('Session service reinitialized');
        }
    }
});
// Initialize debug objects in service worker scope
function initializeDebugObjects() {
    // @ts-ignore
    self.__DEBUG__ = {
        get paperManager() { return paperManager; },
        get sessionService() { return sessionService; },
        get popupManager() { return popupManager; },
        get sourceManager() { return sourceManager; },
        get iconManager() { return iconManager; },
        getGithubClient: () => paperManager ? paperManager.getClient() : null,
        getCurrentPaper: () => {
            const session = sessionService?.getCurrentSession();
            return session ? sessionService?.getPaperMetadata(session.sourceId, session.paperId) : null;
        },
        getSessionStats: () => sessionService?.getSessionStats(),
        getSources: () => sourceManager?.getAllSources(),
        forceEndSession: () => sessionService?.endSession(),
        setIconState: (tabId, state) => iconManager?.setIconState(tabId, state)
    };
    logger.info('Debug objects registered');
}
// Initialize extension
initialize();
//# sourceMappingURL=background.bundle.js.map



---
File: extension/dist/content-script.js
---
!function(){"use strict";class t{constructor(t){this.module=t}debug(t,e){console.debug(`[${this.module}] ${t}`,void 0!==e?e:"")}info(t,e){console.info(`[${this.module}] ${t}`,void 0!==e?e:"")}warning(t,e){console.warn(`[${this.module}] ${t}`,void 0!==e?e:"")}warn(t,e){this.warning(t,e)}error(t,e){console.error(`[${this.module}] ${t}`,void 0!==e?e:"")}}const e=new class{getLogger(e){return new t(e)}},r=e.getLogger("link-processor");const n=e.getLogger("metadata-extractor"),a="pdf",o="url";class i{constructor(t){this.document=t,this.url=t.location.href,n.debug("Initialized metadata extractor for:",this.url)}getMetaContent(t){const e=this.document.querySelector(t);return e&&e.getAttribute("content")||""}extract(){n.debug("Extracting metadata from page:",this.url);const t={title:this.extractTitle(),authors:this.extractAuthors(),description:this.extractDescription(),publishedDate:this.extractPublishedDate(),doi:this.extractDoi(),journalName:this.extractJournalName(),tags:this.extractTags(),url:this.url};return n.debug("Metadata extraction complete:",t),t}extractTitle(){return this.getMetaContent('meta[name="DC.Title"]')||this.getMetaContent('meta[name="dc.title"]')||this.getMetaContent('meta[name="citation_title"]')||this.getMetaContent('meta[property="og:title"]')||this.getMetaContent('meta[name="title"]')||this.document.title}extractAuthors(){const t=[];this.document.querySelectorAll('meta[name="citation_author"]').forEach((e=>{const r=e.getAttribute("content");r&&t.push(r)}));const e=[];this.document.querySelectorAll('meta[name="DC.Creator.PersonalName"]').forEach((t=>{const r=t.getAttribute("content");r&&e.push(r)}));const r=this.getMetaContent('meta[name="DC.Creator.PersonalName"]')||this.getMetaContent('meta[name="dc.creator.personalname"]'),n=this.getMetaContent('meta[name="citation_author"]'),a=this.getMetaContent('meta[property="og:article:author"]')||this.getMetaContent('meta[name="author"]');return e.length>0?e.join(", "):t.length>0?t.join(", "):r||(n||(a||""))}extractDescription(){return this.getMetaContent('meta[name="DC.Description"]')||this.getMetaContent('meta[name="dc.description"]')||this.getMetaContent('meta[name="citation_abstract"]')||this.getMetaContent('meta[property="og:description"]')||this.getMetaContent('meta[name="description"]')}extractPublishedDate(){return this.getMetaContent('meta[name="DC.Date.issued"]')||this.getMetaContent('meta[name="dc.date.issued"]')||this.getMetaContent('meta[name="dc.date"]')||this.getMetaContent('meta[name="dc.Date"]')||this.getMetaContent('meta[name="DC.Date"]')||this.getMetaContent('meta[name="citation_date"]')||this.getMetaContent('meta[property="article:published_time"]')}extractDoi(){return this.getMetaContent('meta[name="DC.Identifier.DOI"]')||this.getMetaContent('meta[name="dc.identifier.doi"]')||this.getMetaContent('meta[name="citation_doi"]')}extractJournalName(){return this.getMetaContent('meta[name="DC.Source"]')||this.getMetaContent('meta[name="dc.source"]')||this.getMetaContent('meta[name="citation_journal_title"]')}extractTags(){const t=this.getMetaContent('meta[name="keywords"]')||this.getMetaContent('meta[name="DC.Subject"]')||this.getMetaContent('meta[name="dc.subject"]');return t?t.split(",").map((t=>t.trim())):[]}isPdf(){return this.url.toLowerCase().endsWith(".pdf")}getSourceType(){return this.isPdf()?a:o}generatePaperId(){return s(this.url)}}function s(t){let e=0;for(let r=0;r<t.length;r++){e=(e<<5)-e+t.charCodeAt(r),e&=e}return Math.abs(e).toString(16).toUpperCase().substring(0,8)}const c=e.getLogger("base-source");class d{constructor(){this.id="url",this.name="Web Page",this.urlPatterns=[/^https?:\/\/(?!.*\.pdf($|\?|#)).*$/i],this.contentScriptMatches=[]}canHandleUrl(t){return this.urlPatterns.some((e=>e.test(t)))}extractPaperId(t){return s(t)}createMetadataExtractor(t){return function(t){return new i(t)}(t)}async extractMetadata(t,e){try{c.debug(`Extracting metadata using base extractor for ID: ${e}`);const r=this.createMetadataExtractor(t),n=r.extract(),a=t.location.href,o=r.getSourceType();return{sourceId:this.id,paperId:e,url:a,title:n.title||t.title||e,authors:n.authors||"",abstract:n.description||"",timestamp:(new Date).toISOString(),rating:"novote",publishedDate:n.publishedDate||"",tags:n.tags||[],doi:n.doi,journalName:n.journalName,sourceType:o}}catch(t){return c.error("Error extracting metadata with base extractor",t),null}}formatPaperId(t){return`${this.id}.${t}`}parsePaperId(t){const e=`${this.id}.`;if(t.startsWith(e))return t.substring(e.length);const r=`${this.id}:`;return t.startsWith(r)?(c.debug(`Parsed legacy format identifier: ${t}`),t.substring(r.length)):null}formatObjectId(t,e){return`${t}:${this.formatPaperId(e)}`}}const u=e.getLogger("arxiv-integration");class l extends i{constructor(t,e){super(t),this.apiMetadata=e}extractTitle(){return this.apiMetadata?.title?this.apiMetadata.title:super.extractTitle()}extractAuthors(){if(this.apiMetadata?.authors)return this.apiMetadata.authors;const t=this.document.querySelectorAll(".authors a");return t.length>0?Array.from(t).map((t=>t.textContent?.trim())).filter(Boolean).join(", "):super.extractAuthors()}extractDescription(){if(this.apiMetadata?.description)return this.apiMetadata.description;const t=this.document.querySelector(".abstract")?.textContent?.trim();return t?t.replace(/^Abstract:\s*/i,""):super.extractDescription()}extractPublishedDate(){if(this.apiMetadata?.publishedDate)return this.apiMetadata.publishedDate;const t=this.document.querySelector(".dateline");if(t){const e=t.textContent,r=e?.match(/\(Submitted on ([^)]+)\)/);if(r)return r[1]}return super.extractPublishedDate()}extractDoi(){return this.apiMetadata?.doi||super.extractDoi()}extractJournalName(){return this.apiMetadata?.journalName||super.extractJournalName()}extractTags(){if(this.apiMetadata?.tags)return this.apiMetadata.tags;const t=this.document.querySelector(".subjects")?.textContent?.trim();return t?t.split(/[;,]/).map((t=>t.trim())).filter(Boolean):super.extractTags()}}const p=new class extends d{constructor(){super(...arguments),this.id="arxiv",this.name="arXiv.org",this.urlPatterns=[/arxiv\.org\/(abs|pdf|html)\/([0-9.]+)/,/arxiv\.org\/\w+\/([0-9.]+)/],this.API_BASE_URL="https://export.arxiv.org/api/query"}extractPaperId(t){for(const e of this.urlPatterns){const r=t.match(e);if(r)return r[2]||r[1]}return null}createMetadataExtractor(t){return new l(t)}async fetchFromApi(t){try{const e=`${this.API_BASE_URL}?id_list=${t}`;u.debug(`Fetching from ArXiv API: ${e}`);const r=await fetch(e);if(!r.ok)return u.error(`ArXiv API request failed with status: ${r.status}`),null;const n=await r.text(),a=new DOMParser,o=a.parseFromString(n,"text/xml").querySelector("entry");if(!o)return u.warn("No entry found in ArXiv API response"),null;const i=o.querySelector("title")?.textContent?.trim()||"",s=o.querySelector("summary")?.textContent?.trim()||"",c=o.querySelector("published")?.textContent?.trim()||"",d=o.querySelectorAll("author name"),l=Array.from(d).map((t=>t.textContent?.trim())).filter(Boolean).join(", "),p=o.querySelector("arxiv\\:doi, doi")?.textContent?.trim(),h=o.querySelector("arxiv\\:journal_ref, journal_ref")?.textContent?.trim(),m=o.querySelectorAll("category");return{title:i,authors:l,description:s,publishedDate:c,doi:p,journalName:h,tags:Array.from(m).map((t=>t.getAttribute("term"))).filter(Boolean)}}catch(t){return u.error("Error fetching from ArXiv API",t),null}}async extractMetadata(t,e){try{u.info(`Extracting metadata for arXiv ID: ${e}`);const r=this.createMetadataExtractor(t),n=r.extract(),a=n.title&&n.title!==t.title,o=n.authors&&n.authors.length>0,i=n.description&&n.description.length>0;if(a&&o&&i)return u.debug("Successfully extracted complete metadata from page"),this.convertToPageMetadata(n,e,r.getSourceType());u.info("Page metadata incomplete, fetching from ArXiv API");const s=await this.fetchFromApi(e);if(!s)return u.warn("Failed to fetch metadata from ArXiv API, using partial page data"),this.convertToPageMetadata(n,e,r.getSourceType());const c=new l(t,s),d=c.extract();return u.debug("Merged metadata from page and API",d),this.convertToPageMetadata(d,e,c.getSourceType())}catch(t){return u.error("Error extracting metadata for arXiv",t),null}}convertToPageMetadata(t,e,r){return{sourceId:this.id,paperId:e,url:t.url||"",title:t.title,authors:t.authors,abstract:t.description,timestamp:(new Date).toISOString(),rating:"novote",publishedDate:t.publishedDate,tags:t.tags||[],doi:t.doi,journalName:t.journalName,sourceType:r}}},h=e.getLogger("openreview-integration");class m extends i{extract(){const t=super.extract();try{const e=this.document.querySelector(".citation_title")?.textContent||this.document.querySelector(".forum-title h2")?.textContent,r=Array.from(this.document.querySelectorAll(".forum-authors a")).map((t=>t.textContent)).filter(Boolean).join(", "),n=this.document.querySelector('meta[name="citation_abstract"]')?.getAttribute("content")||Array.from(this.document.querySelectorAll(".note-content-field")).find((t=>t.textContent?.includes("Abstract")))?.nextElementSibling?.textContent,a=this.document.querySelector(".date.item")?.textContent;let o="";if(a){const t=a.match(/Published: ([^,]+)/);t&&(o=t[1])}const i=this.document.querySelector('meta[name="citation_doi"]')?.getAttribute("content")||"",s=this.document.querySelectorAll(".forum-meta .item");let c="";for(let t=0;t<s.length;t++){const e=s[t];if(e.querySelector(".glyphicon-folder-open")){c=e.textContent?.trim()||"";break}}const d=Array.from(this.document.querySelectorAll(".note-content-field")).find((t=>t.textContent?.includes("Keywords")));let u=[];if(d){const t=d.nextElementSibling?.textContent;t&&(u=t.split(",").map((t=>t.trim())))}return{title:e||t.title,authors:r||t.authors,description:n||t.description,publishedDate:o||t.publishedDate,doi:i||t.doi,journalName:c||t.journalName,tags:u.length?u:t.tags,url:this.url}}catch(e){return h.error("Error during OpenReview-specific extraction",e),t}}}const g=new class extends d{constructor(){super(...arguments),this.id="openreview",this.name="OpenReview",this.urlPatterns=[/openreview\.net\/forum\?id=([a-zA-Z0-9]+)/,/openreview\.net\/pdf\?id=([a-zA-Z0-9]+)/]}extractPaperId(t){for(const e of this.urlPatterns){const r=t.match(e);if(r)return r[1]}return null}createMetadataExtractor(t){return new m(t)}async extractMetadata(t,e){h.info(`Extracting metadata for OpenReview ID: ${e}`);const r=await super.extractMetadata(t,e);return r&&(h.debug("Extracted metadata from OpenReview page"),t.location.href.includes("/pdf?id=")&&(r.sourceType="pdf")),r}};e.getLogger("nature-integration");class f extends i{extractTitle(){return this.getMetaContent('meta[name="citation_title"]')||this.getMetaContent('meta[property="og:title"]')||super.extractTitle()}extractAuthors(){const t=this.getMetaContent('meta[name="citation_author"]');if(t)return t;const e=this.document.querySelectorAll(".c-article-author-list__item");return e.length>0?Array.from(e).map((t=>t.textContent?.trim())).filter(Boolean).join(", "):super.extractAuthors()}extractTags(){const t=this.getMetaContent('meta[name="dc.subject"]');return t?t.split(",").map((t=>t.trim())):[]}extractDescription(){return this.getMetaContent('meta[name="description"]')||this.getMetaContent('meta[property="og:description"]')||super.extractDescription()}extractPublishedDate(){return this.getMetaContent('meta[name="citation_publication_date"]')||super.extractPublishedDate()}extractDoi(){return this.getMetaContent('meta[name="citation_doi"]')||super.extractDoi()}}const b=new class extends d{constructor(){super(...arguments),this.id="nature",this.name="Nature",this.urlPatterns=[/nature\.com\/articles\/([^?]+)/]}extractPaperId(t){const e=t.match(this.urlPatterns[0]);return e?e[1]:null}createMetadataExtractor(t){return new f(t)}};const x=new class extends d{constructor(){super(...arguments),this.id="pnas",this.name="PNAS",this.urlPatterns=[/pnas\.org\/doi\/10\.1073\/pnas\.([0-9]+)/]}extractPaperId(t){const e=t.match(this.urlPatterns[0]);return e?e[1]:null}};const y=new class extends d{constructor(){super(...arguments),this.id="url-misc",this.name="misc tracked url",this.urlPatterns=[],this.contentScriptMatches=["sciencedirect.com/science/article/","philpapers.org/rec/","proceedings.neurips.cc/paper_files/paper/","journals.sagepub.com/doi/","link.springer.com/article/",".science.org/doi/","journals.aps.org/prx/abstract/","onlinelibrary.wiley.com/doi/","cell.com/trends/cognitive-sciences/fulltext/","researchgate.net/publication/","psycnet.apa.org/record/","biorxiv.org/content/","osf.io/preprints/","frontiersin.org/journals/","jstor.org/","proceedings.mlr.press/","journals.plos.org/plosone/article","ieeexplore.ieee.org/document/","royalsocietypublishing.org/doi/","papers.nips.cc/paper_files/paper/","philarchive.org/archive/","tandfonline.com/doi/","iopscience.iop.org/article/","academic.oup.com/brain/article/","elifesciences.org/articles/","escholarship.org/content/","pmc.ncbi.nlm.nih.gov/articles/","pubmed.ncbi.nlm.nih.gov/","openaccess.thecvf.com/content/","zenodo.org/records/","journals.asm.org/doi/full/","physoc.onlinelibrary.wiley.com/doi/full/","storage.courtlistener.com/recap/","bmj.com/content/","ntsb.gov/investigations/pages","ntsb.gov/investigations/AccidentReports","aclanthology.org/","journals.ametsoc.org/view/journals/","substack.com/p/","citeseerx.","/doi/","/pdf/"]}canHandleUrl(t){return this.contentScriptMatches.some((e=>t.includes(e)))}},v=[p,g,b,x,y],M=e.getLogger("content-script");M.info("Paper Tracker content script loaded");const I=new d;let C=null,w=null;let S=!0,P=null,A="none";const E=new class{constructor(t){this.patterns=[],this.observer=null,this.processedLinks=new Set,this.onLinkFound=t,r.debug("Link processor initialized")}registerPattern(t){this.patterns.push(t),r.debug(`Registered pattern for ${t.sourceId}`)}processLinks(t){t.querySelectorAll("a[href]").forEach((t=>{const e=this.getLinkId(t);if(!this.processedLinks.has(e)){this.processedLinks.add(e);for(const e of this.patterns)if(e.pattern.test(t.href)){const r=e.extractPaperId(t.href);if(r){this.onLinkFound(e.sourceId,r,t);break}}}}))}startObserving(t){this.observer&&this.observer.disconnect(),this.observer=new MutationObserver((e=>{let r=!1;e.forEach((t=>{t.addedNodes.forEach((t=>{if(t.nodeType===Node.ELEMENT_NODE){"A"===t.tagName&&(r=!0);t.querySelectorAll("a[href]").length>0&&(r=!0)}}))})),r&&this.processLinks(t)})),this.observer.observe(t.body,{childList:!0,subtree:!0}),r.debug("Started observing for DOM changes")}getLinkId(t){const e=this.getElementPath(t);return`${t.href}|${e}`}getElementPath(t){const e=[];let r=t;for(;r&&r!==document.body;){let t=r.tagName.toLowerCase();if(r.id)t+=`#${r.id}`;else{const e=Array.from(r.parentElement?.children||[]),n=e.indexOf(r)+1;e.length>1&&(t+=`:nth-child(${n})`)}e.unshift(t),r=r.parentElement}return e.join(" > ")}stopObserving(){this.observer&&(this.observer.disconnect(),this.observer=null,r.debug("Stopped observing DOM changes"))}}(((t,e,r)=>{!function(t,e,r){if(t.nextSibling&&t.nextSibling.nodeType===Node.ELEMENT_NODE&&t.nextSibling.classList.contains("paper-annotator"))return;const n=document.createElement("span");n.className="paper-annotator",n.textContent="ðŸ“",n.title="Add annotation",n.dataset.sourceId=e,n.dataset.paperId=r,n.addEventListener("click",(t=>{t.preventDefault(),t.stopPropagation(),chrome.runtime.sendMessage({type:"showAnnotationPopup",sourceId:e,paperId:r,position:{x:t.clientX,y:t.clientY}})})),t.parentNode?.insertBefore(n,t.nextSibling)}(r,t,e)}));function D(t,e,r){if(t!==A){switch(A=t,t){case"none":chrome.runtime.sendMessage({type:"noPaperDetected"});break;case"detected":chrome.runtime.sendMessage({type:"paperDetected",sourceId:e,paperId:r})}M.debug(`Updated icon state to: ${t}`,{sourceId:e,paperId:r})}}function $(t,e){k(),S?(P={sourceId:t,paperId:e},chrome.runtime.sendMessage({type:"startSession",sourceId:t,paperId:e},(r=>{r?.success?(M.debug(`Started session for ${t}:${e}`),function(){if(!P)return;k(),w=window.setInterval((()=>{P&&chrome.runtime.sendMessage({type:"sessionHeartbeat",sourceId:P.sourceId,paperId:P.paperId,timestamp:Date.now()})}),5e3),M.debug(`Started heartbeat for ${P.sourceId}:${P.paperId}`)}()):M.error(`Failed to start session for ${t}:${e}`,r?.error)}))):M.debug(`Not starting session for ${t}:${e} because tab is not visible`)}function k(){null!==w&&(clearInterval(w),w=null,M.debug("Stopped heartbeat"))}function L(t){if(!P)return;const{sourceId:e,paperId:r}=P;k(),chrome.runtime.sendMessage({type:"endSession",sourceId:e,paperId:r,reason:t},(n=>{M.debug(`Ended session for ${e}:${r}`,{reason:t})})),P=null}async function N(t=!1){const e=window.location.href;let r=function(t){for(const e of v)if(e.canHandleUrl(t))return e;return null}(e);if(!r&&t&&(M.info(`No matching source found, but force parameter set. Using base source for: ${e}`),r=I),!r)return M.debug(`No source found for URL: ${e}`),D("none"),null;const n=r.extractPaperId(e);if(!n)return M.info(`Unable to determine a paperId for url: ${e}`),D("none"),null;D("detected",r.id,n);try{const t=await r.extractMetadata(document,n);if(t)return chrome.runtime.sendMessage({type:"paperMetadata",metadata:t}),M.debug(`Sent extracted metadata to background script for ${t.sourceId}:${t.paperId}`),D("tracked",t.sourceId,t.paperId),S&&$(t.sourceId,t.paperId),t}catch(t){M.error(`Error extracting metadata for ${r.id}:${n}`,t)}return null}document.addEventListener("click",(t=>{!C||C.contains(t.target)||t.target.classList.contains("paper-annotator")||(C.parentElement?.remove(),C=null)})),document.addEventListener("visibilitychange",(()=>{const t=S;S="visible"===document.visibilityState,S&&!t?(M.info("Tab became visible again"),P?$(P.sourceId,P.paperId):N()):!S&&t&&(M.info("Tab hidden"),P&&L("tab_hidden"))})),window.addEventListener("focus",(()=>{S&&(M.info("Window gained focus"),P?$(P.sourceId,P.paperId):N())})),window.addEventListener("blur",(()=>{M.info("Window lost focus"),P&&L("window_blur")})),window.addEventListener("beforeunload",(()=>{P&&(M.info("Page unloading"),L("page_unload"))})),chrome.runtime.onMessage.addListener(((t,e,r)=>{if(M.debug("Received message",t),"extractPaperMetadata"===t.type)return M.debug("Received request to force paper metadata extraction"),N(!0).then((t=>{r(t?{success:!0,metadata:t}:{success:!1,error:"Failed to extract metadata"})})).catch((t=>{M.error("Error extracting metadata",t),r({success:!1,error:t instanceof Error?t.message:"Unknown error"})})),!0;if("showPopup"===t.type){C&&(C.parentElement?.remove(),C=null);const e=document.createElement("div");e.className="paper-popup-wrapper",t.position&&(e.style.left=`${t.position.x}px`,e.style.top=`${t.position.y}px`);const n=document.createElement("div");if(n.className="paper-popup",n.innerHTML=t.html,e.appendChild(n),document.body.appendChild(e),t.handlers)for(const e of t.handlers){n.querySelectorAll(e.selector).forEach((r=>{r.addEventListener(e.event,(()=>{chrome.runtime.sendMessage({type:"popupAction",action:e.action,sourceId:t.sourceId,paperId:t.paperId,data:{value:"TEXTAREA"===r.tagName?r.value:r.getAttribute("data-vote"),checked:"INPUT"===r.tagName?r.checked:void 0,id:r.id}})}))}))}return C=n,r({success:!0}),!0}return"processPage"===t.type?(E.processLinks(document),N(),r({success:!0}),!0):void 0})),async function(){!function(){if(document.getElementById("paper-tracker-styles"))return;const t=document.createElement("style");t.id="paper-tracker-styles",t.textContent="\n  .paper-annotator {\n    display: inline-block;\n    margin-left: 4px;\n    cursor: pointer;\n    font-size: 0.9em;\n    opacity: 0.7;\n    transition: opacity 0.2s;\n    vertical-align: baseline;\n  }\n\n  .paper-annotator:hover {\n    opacity: 1;\n  }\n\n  .paper-popup-wrapper {\n    position: fixed;\n    z-index: 10000;\n  }\n\n  .paper-popup {\n    position: relative;\n    background: white;\n    border: 1px solid #ddd;\n    border-radius: 6px;\n    padding: 12px;\n    box-shadow: 0 4px 12px rgba(0,0,0,0.15);\n    width: 300px;\n    box-sizing: border-box;\n  }\n\n  .paper-popup-header {\n    font-weight: bold;\n    margin-bottom: 8px;\n    line-height: 1.4;\n    font-size: 1em;\n  }\n\n  .paper-popup-meta {\n    color: #666;\n    font-size: 0.85em;\n    margin-bottom: 12px;\n    line-height: 1.4;\n  }\n\n  .paper-popup-buttons {\n    display: flex;\n    gap: 8px;\n    margin: 8px 0;\n  }\n\n  .paper-popup button {\n    padding: 6px 12px;\n    border: 1px solid #ddd;\n    border-radius: 4px;\n    background: #f5f5f5;\n    cursor: pointer;\n    transition: all 0.2s ease;\n    font-size: 0.9em;\n  }\n\n  .paper-popup button:hover {\n    background: #e8e8e8;\n    border-color: #ccc;\n  }\n\n  .paper-popup button.active {\n    background: #e0e0e0;\n    border-color: #aaa;\n  }\n\n  .paper-popup textarea {\n    width: calc(100% - 16px);\n    min-height: 80px;\n    margin: 8px 0;\n    padding: 8px;\n    border: 1px solid #ddd;\n    border-radius: 4px;\n    resize: vertical;\n    font-family: inherit;\n    font-size: 0.9em;\n    line-height: 1.4;\n    box-sizing: border-box;\n  }\n\n  .paper-popup textarea:focus {\n    outline: none;\n    border-color: #aaa;\n  }\n\n  .paper-popup-actions {\n    display: flex;\n    justify-content: flex-end;\n    gap: 8px;\n    margin-top: 12px;\n  }\n\n  .paper-popup .save-button {\n    background: #2563eb;\n    color: white;\n    border-color: #2563eb;\n  }\n\n  .paper-popup .save-button:hover {\n    background: #1d4ed8;\n    border-color: #1d4ed8;\n  }\n  ",document.head.appendChild(t),M.debug("Injected styles")}(),function(){for(const t of v)M.debug(`Initializing source: ${t.id}`),t.urlPatterns.forEach((e=>{E.registerPattern({sourceId:t.id,pattern:e,extractPaperId:e=>t.extractPaperId(e)})}))}(),E.processLinks(document),E.startObserving(document),S="visible"===document.visibilityState,N(),chrome.runtime.sendMessage({type:"contentScriptReady",url:window.location.href},(t=>{t?.success&&M.debug("Background script acknowledged ready status")}))}();let j=location.href;new MutationObserver((()=>{const t=location.href;t!==j&&(P&&L("url_change"),D("none"),j=t,N())})).observe(document,{subtree:!0,childList:!0})}();
//# sourceMappingURL=content-script.js.map



---
File: extension/dist/options.bundle.js
---
// utils/logger.ts
// Logging utility wrapping loguru
/**
 * Logger class for consistent logging throughout the extension
 */
class Logger {
    constructor(module) {
        this.module = module;
    }
    /**
     * Log debug message
     */
    debug(message, data) {
        console.debug(`[${this.module}] ${message}`, data !== undefined ? data : '');
    }
    /**
     * Log info message
     */
    info(message, data) {
        console.info(`[${this.module}] ${message}`, data !== undefined ? data : '');
    }
    /**
     * Log warning message
     */
    warning(message, data) {
        console.warn(`[${this.module}] ${message}`, data !== undefined ? data : '');
    }
    /**
     * Alias for warning method (to match loguru API)
     */
    warn(message, data) {
        this.warning(message, data);
    }
    /**
     * Log error message
     */
    error(message, data) {
        console.error(`[${this.module}] ${message}`, data !== undefined ? data : '');
    }
}
/**
 * Loguru mock for browser extension use
 */
class LoguruMock {
    /**
     * Get logger for a module
     */
    getLogger(module) {
        return new Logger(module);
    }
}
// Export singleton instance
const loguru = new LoguruMock();

// config/session.ts
const logger = loguru.getLogger('session-config');
// Default configuration values
const DEFAULT_CONFIG = {
    idleThresholdMinutes: 5,
    minSessionDurationSeconds: 30,
    requireContinuousActivity: true, // If true, resets timer on idle
    logPartialSessions: false, // If true, logs sessions even if under minimum duration
    activityUpdateIntervalSeconds: 1 // How often to update active time
};
/**
 * Load session configuration from storage
 */
async function loadSessionConfig() {
    try {
        const items = await chrome.storage.sync.get('sessionConfig');
        const config = { ...DEFAULT_CONFIG, ...items.sessionConfig };
        logger.debug('Loaded session config', config);
        return config;
    }
    catch (error) {
        logger.error('Error loading session config', error);
        return DEFAULT_CONFIG;
    }
}
/**
 * Save session configuration to storage
 */
async function saveSessionConfig(config) {
    try {
        // Ensure values are the correct type
        const sanitizedConfig = {
            idleThresholdMinutes: Number(config.idleThresholdMinutes),
            minSessionDurationSeconds: Number(config.minSessionDurationSeconds),
            requireContinuousActivity: Boolean(config.requireContinuousActivity),
            logPartialSessions: Boolean(config.logPartialSessions),
            activityUpdateIntervalSeconds: Number(config.activityUpdateIntervalSeconds)
        };
        await chrome.storage.sync.set({ sessionConfig: sanitizedConfig });
        logger.debug('Saved session config', sanitizedConfig);
    }
    catch (error) {
        logger.error('Error saving session config', error);
        throw error;
    }
}

// options.ts
// Helper to set form values
function setFormValues(settings) {
    // GitHub settings
    if (settings.githubRepo) {
        document.getElementById('repo').value = settings.githubRepo;
    }
    if (settings.githubToken) {
        // Don't show the actual token, just indicate it's set
        document.getElementById('token').placeholder = 'â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢';
    }
    // Session settings
    document.getElementById('idleThreshold').value =
        String(settings.sessionConfig?.idleThresholdMinutes ?? DEFAULT_CONFIG.idleThresholdMinutes);
    document.getElementById('minDuration').value =
        String(settings.sessionConfig?.minSessionDurationSeconds ?? DEFAULT_CONFIG.minSessionDurationSeconds);
    document.getElementById('requireContinuous').checked =
        settings.sessionConfig?.requireContinuousActivity ?? DEFAULT_CONFIG.requireContinuousActivity;
    document.getElementById('logPartial').checked =
        settings.sessionConfig?.logPartialSessions ?? DEFAULT_CONFIG.logPartialSessions;
}
// Helper to get form values
function getFormValues() {
    return {
        githubRepo: document.getElementById('repo').value.trim(),
        githubToken: document.getElementById('token').value.trim(),
        sessionConfig: {
            idleThresholdMinutes: Number(document.getElementById('idleThreshold').value),
            minSessionDurationSeconds: Number(document.getElementById('minDuration').value),
            requireContinuousActivity: document.getElementById('requireContinuous').checked,
            logPartialSessions: document.getElementById('logPartial').checked,
            activityUpdateIntervalSeconds: DEFAULT_CONFIG.activityUpdateIntervalSeconds // Keep default
        }
    };
}
// Display status message
function showStatus(message, isError = false) {
    const status = document.getElementById('status');
    if (!status)
        return;
    status.textContent = message;
    status.className = `status ${isError ? 'error' : 'success'}`;
    // Clear status after 3 seconds if it's a success message
    if (!isError) {
        setTimeout(() => {
            if (status) {
                status.textContent = '';
                status.className = 'status';
            }
        }, 3000);
    }
}
// Validate settings before saving
async function validateSettings(settings) {
    // Validate repository format
    if (!/^[\w-]+\/[\w-]+$/.test(settings.githubRepo)) {
        throw new Error('Invalid repository format. Use username/repository');
    }
    // Validate the token by making a test API call
    const response = await fetch(`https://api.github.com/repos/${settings.githubRepo}`, {
        headers: {
            'Authorization': `token ${settings.githubToken}`,
            'Accept': 'application/vnd.github.v3+json'
        }
    });
    if (!response.ok) {
        throw new Error('Invalid token or repository. Please check your credentials.');
    }
    // Validate session settings
    const { sessionConfig } = settings;
    if (sessionConfig.idleThresholdMinutes < 1 || sessionConfig.idleThresholdMinutes > 60) {
        throw new Error('Idle threshold must be between 1 and 60 minutes');
    }
    if (sessionConfig.minSessionDurationSeconds < 1 || sessionConfig.minSessionDurationSeconds > 300) {
        throw new Error('Minimum session duration must be between 10 and 300 seconds');
    }
}
// Save settings
async function saveSettings(settings) {
    await chrome.storage.sync.set({
        githubRepo: settings.githubRepo,
        githubToken: settings.githubToken
    });
    await saveSessionConfig(settings.sessionConfig);
}
// Initialize options page
document.addEventListener('DOMContentLoaded', async () => {
    try {
        // Load current settings
        const [storageItems, sessionConfig] = await Promise.all([
            chrome.storage.sync.get(['githubRepo', 'githubToken']),
            loadSessionConfig()
        ]);
        // Combine settings and display them
        setFormValues({
            ...storageItems,
            sessionConfig
        });
        // Add save button handler
        const saveButton = document.getElementById('save');
        if (saveButton) {
            saveButton.addEventListener('click', async () => {
                try {
                    const settings = getFormValues();
                    await validateSettings(settings);
                    await saveSettings(settings);
                    showStatus('Settings saved successfully!');
                }
                catch (error) {
                    showStatus(`Error: ${error instanceof Error ? error.message : 'Unknown error'}`, true);
                }
            });
        }
    }
    catch (error) {
        showStatus(`Error loading settings: ${error instanceof Error ? error.message : 'Unknown error'}`, true);
    }
});
//# sourceMappingURL=options.bundle.js.map



---
File: extension/dist/popup.bundle.js
---
// extension/popup.ts
// Popup script with refactored manual paper tracking
console.log('Popup script starting...');
// Function to get paper data from background script
async function getCurrentPaper() {
    return new Promise((resolve) => {
        chrome.runtime.sendMessage({ type: 'getCurrentPaper' }, (response) => {
            console.log('Got paper data from background:', response);
            resolve(response);
        });
    });
}
// Function to update UI with paper data
function updateUI(paperData) {
    const titleElement = document.getElementById('paperTitle');
    const authorsElement = document.getElementById('paperAuthors');
    const statusElement = document.getElementById('status');
    const manualLogSection = document.getElementById('manualLogSection');
    if (!titleElement || !authorsElement || !statusElement || !manualLogSection) {
        console.error('Required DOM elements not found');
        return;
    }
    if (paperData) {
        // Show detected paper data
        titleElement.textContent = paperData.title || paperData.paperId;
        authorsElement.textContent = paperData.authors;
        statusElement.textContent = 'Paper tracked! Issue created on GitHub.';
        // Enable rating buttons
        const thumbsUpButton = document.getElementById('thumbsUp');
        const thumbsDownButton = document.getElementById('thumbsDown');
        if (thumbsUpButton && thumbsDownButton) {
            thumbsUpButton.disabled = false;
            thumbsDownButton.disabled = false;
            // Set active state on rating buttons
            thumbsUpButton.classList.toggle('active', paperData.rating === 'thumbsup');
            thumbsDownButton.classList.toggle('active', paperData.rating === 'thumbsdown');
        }
        // Hide manual log section
        manualLogSection.style.display = 'none';
    }
    else {
        // No paper detected - show manual log option
        titleElement.textContent = 'No paper detected';
        authorsElement.textContent = '';
        statusElement.textContent = 'Current page not recognized as a paper';
        // Disable rating buttons
        const thumbsUpButton = document.getElementById('thumbsUp');
        const thumbsDownButton = document.getElementById('thumbsDown');
        if (thumbsUpButton && thumbsDownButton) {
            thumbsUpButton.disabled = true;
            thumbsDownButton.disabled = true;
        }
        // Show manual log section
        manualLogSection.style.display = 'block';
    }
}
// Function to log current page as a paper (using content script extraction)
async function logCurrentPage() {
    console.log("attempting to log paper");
    // Get the active tab
    const tabs = await chrome.tabs.query({ active: true, currentWindow: true });
    if (!tabs[0] || !tabs[0].id) {
        const statusElement = document.getElementById('status');
        if (statusElement) {
            statusElement.textContent = 'Error: Could not access current tab';
        }
        return;
    }
    // Show loading state
    const statusElement = document.getElementById('status');
    if (statusElement) {
        statusElement.textContent = 'Extracting paper metadata...';
    }
    // Send message to content script requesting extraction
    chrome.tabs.sendMessage(tabs[0].id, {
        type: 'extractPaperMetadata'
    }, (response) => {
        if (chrome.runtime.lastError) {
            // Handle error
            if (statusElement) {
                statusElement.textContent = 'Error: ' + chrome.runtime.lastError.message;
            }
            return;
        }
        if (!response || !response.success || !response.metadata) {
            // Handle extraction failure
            if (statusElement) {
                statusElement.textContent = 'Error: ' + (response?.error || 'Failed to extract metadata');
            }
            return;
        }
        // Success - update UI
        updateUI(response.metadata);
        if (statusElement) {
            statusElement.textContent = 'Paper tracked successfully!';
        }
        // The content script has already:
        // 1. Sent metadata to background script
        // 2. Started a session if the tab is visible
        // Hide manual log section
        const manualLogSection = document.getElementById('manualLogSection');
        if (manualLogSection) {
            manualLogSection.style.display = 'none';
        }
        // Enable rating buttons
        const thumbsUpButton = document.getElementById('thumbsUp');
        const thumbsDownButton = document.getElementById('thumbsDown');
        if (thumbsUpButton && thumbsDownButton) {
            thumbsUpButton.disabled = false;
            thumbsDownButton.disabled = false;
        }
    });
}
// Initialize popup
document.addEventListener('DOMContentLoaded', async () => {
    console.log('Popup opened');
    // Get paper from the session tracker
    let paperData = null;
    let retries = 3;
    while (retries > 0 && !paperData) {
        paperData = await getCurrentPaper();
        if (!paperData) {
            await new Promise(resolve => setTimeout(resolve, 500)); // Wait 500ms before retry
            retries--;
        }
    }
    updateUI(paperData);
    // Set up rating handlers
    const thumbsUpButton = document.getElementById('thumbsUp');
    if (thumbsUpButton) {
        thumbsUpButton.addEventListener('click', () => {
            chrome.runtime.sendMessage({
                type: 'updateRating',
                rating: 'thumbsup'
            }, (response) => {
                const statusElement = document.getElementById('status');
                const thumbsUpButton = document.getElementById('thumbsUp');
                const thumbsDownButton = document.getElementById('thumbsDown');
                if (!statusElement || !thumbsUpButton || !thumbsDownButton)
                    return;
                if (response && response.success) {
                    statusElement.textContent = 'Rating updated to: thumbs up';
                    thumbsUpButton.classList.add('active');
                    thumbsDownButton.classList.remove('active');
                    setTimeout(() => window.close(), 1500);
                }
                else {
                    statusElement.textContent = 'Error: ' + (response?.error || 'Unknown error');
                }
            });
        });
    }
    const thumbsDownButton = document.getElementById('thumbsDown');
    if (thumbsDownButton) {
        thumbsDownButton.addEventListener('click', () => {
            chrome.runtime.sendMessage({
                type: 'updateRating',
                rating: 'thumbsdown'
            }, (response) => {
                const statusElement = document.getElementById('status');
                const thumbsUpButton = document.getElementById('thumbsUp');
                const thumbsDownButton = document.getElementById('thumbsDown');
                if (!statusElement || !thumbsUpButton || !thumbsDownButton)
                    return;
                if (response && response.success) {
                    statusElement.textContent = 'Rating updated to: thumbs down';
                    thumbsDownButton.classList.add('active');
                    thumbsUpButton.classList.remove('active');
                    setTimeout(() => window.close(), 1500);
                }
                else {
                    statusElement.textContent = 'Error: ' + (response?.error || 'Unknown error');
                }
            });
        });
    }
    // Set up one-click logging button
    const logPageButton = document.getElementById('logPageButton');
    if (logPageButton) {
        console.log("Attaching logPageButton event listener...");
        logPageButton.addEventListener('click', () => {
            console.log("logPageButton clicked...");
            logCurrentPage();
        });
    }
});
//# sourceMappingURL=popup.bundle.js.map



---
File: extension/favicon_io/about.txt
---
This favicon was generated using the following graphics from Twitter Twemoji:

- Graphics Title: 1f516.svg
- Graphics Author: Copyright 2020 Twitter, Inc and other contributors (https://github.com/twitter/twemoji)
- Graphics Source: https://github.com/twitter/twemoji/blob/master/assets/svg/1f516.svg
- Graphics License: CC-BY 4.0 (https://creativecommons.org/licenses/by/4.0/)



---
File: extension/manifest.json
---
{
  "manifest_version": 3,
  "name": "Academic Paper Tracker",
  "version": "2.0",
  "description": "Track and annotate academic papers from various sources",
  "permissions": [
    "tabs",
    "storage",
    "webNavigation",
    "scripting",
    "activeTab"
  ],
  "host_permissions": [
    "*://*.arxiv.org/*", 
    "*://export.arxiv.org/*",
    "*://*.openreview.net/*",
    "*://api.github.com/*",
    "<all_urls>"
  ],
  "background": {
    "service_worker": "dist/background.bundle.js",
    "type": "module"
  },
  "content_scripts": [{
    "matches": ["<all_urls>"],
    "js": ["dist/content-script.js"],
    "run_at": "document_end",
    "type": "module"
  }],
  "action": {
    "default_popup": "popup.html",
    "default_icon": "icons/bookmark/red/apple-touch-icon.png"
  },
  "options_ui": {
    "page": "options.html",
    "open_in_tab": false
  }
}



---
File: extension/options.html
---
<!DOCTYPE html>
<html>
<head>
  <title>ArXiv Tracker Settings</title>
  <style>
    body {
      padding: 20px;
      font-family: system-ui, -apple-system, sans-serif;
    }
    .container {
      max-width: 500px;
      margin: 0 auto;
    }
    .field {
      margin-bottom: 20px;
    }
    label {
      display: block;
      margin-bottom: 5px;
      font-weight: 500;
    }
    input[type="text"],
    input[type="password"],
    input[type="number"] {
      width: 100%;
      padding: 8px;
      border: 1px solid #ddd;
      border-radius: 4px;
      font-family: monospace;
    }
    input[type="number"] {
      width: 100px;
    }
    .help-text {
      font-size: 0.9em;
      color: #666;
      margin-top: 4px;
    }
    .status {
      margin-top: 16px;
      padding: 8px;
      border-radius: 4px;
    }
    .success {
      background: #e6ffe6;
      color: #006600;
    }
    .error {
      background: #ffe6e6;
      color: #660000;
    }
    button {
      background: #0366d6;
      color: white;
      border: none;
      padding: 8px 16px;
      border-radius: 4px;
      cursor: pointer;
      margin-top: 16px;
    }
    button:hover {
      background: #0255b3;
    }
    .section {
      margin-bottom: 32px;
    }
    .section-title {
      font-size: 1.2em;
      font-weight: 600;
      margin-bottom: 16px;
      padding-bottom: 8px;
      border-bottom: 1px solid #eee;
    }
    .checkbox-field {
      margin-top: 12px;
    }
    .checkbox-field label {
      display: flex;
      align-items: center;
      font-weight: normal;
    }
    .checkbox-field input[type="checkbox"] {
      margin-right: 8px;
    }
  </style>
</head>
<body>
  <div class="container">
    <h2>ArXiv Tracker Settings</h2>
    
    <div class="section">
      <div class="section-title">GitHub Integration</div>
      <div class="field">
        <label for="repo">GitHub Repository</label>
        <input type="text" id="repo" placeholder="username/repository">
        <div class="help-text">Format: username/repository (e.g., johndoe/arxiv-tracker)</div>
      </div>

      <div class="field">
        <label for="token">GitHub Personal Access Token</label>
        <input type="password" id="token" placeholder="ghp_xxxxxxxxxxxxxxxxxxxx">
        <div class="help-text">
          Token needs 'repo' scope for private repositories.<br>
          Never share this token with anyone.
        </div>
      </div>
    </div>

    <div class="section">
      <div class="section-title">Reading Session Settings</div>
      
      <div class="field">
        <label for="idleThreshold">Idle Threshold (minutes)</label>
        <input type="number" id="idleThreshold" min="1" max="60" value="5">
        <div class="help-text">
          Time of inactivity before session is paused (1-60 minutes).<br>
          Default: 5 minutes
        </div>
      </div>

      <div class="field">
        <label for="minDuration">Minimum Session Duration (seconds)</label>
        <input type="number" id="minDuration" min="10" max="300" value="30">
        <div class="help-text">
          Minimum time required to log a reading session (10-300 seconds).<br>
          Default: 30 seconds
        </div>
      </div>

      <div class="checkbox-field">
        <label>
          <input type="checkbox" id="requireContinuous">
          Require Continuous Activity
        </label>
        <div class="help-text">
          When enabled, resets the session timer if you're idle for too long.<br>
          Default: Enabled
        </div>
      </div>

      <div class="checkbox-field">
        <label>
          <input type="checkbox" id="logPartial">
          Log Partial Sessions
        </label>
        <div class="help-text">
          When enabled, logs sessions even if they're shorter than the minimum duration.<br>
          Default: Disabled
        </div>
      </div>
    </div>

    <button id="save">Save Settings</button>
    <div id="status" class="status"></div>
  </div>
  <script type="module" src="dist/options.bundle.js"></script>
</body>
</html>



---
File: extension/options.ts
---
// options.ts
import { loadSessionConfig, DEFAULT_CONFIG, saveSessionConfig } from './config/session';
import { RawSessionConfig } from './config/types';

// Helper to set form values
function setFormValues(settings: {
  githubRepo?: string;
  githubToken?: string;
  sessionConfig?: RawSessionConfig;
}): void {
  // GitHub settings
  if (settings.githubRepo) {
    (document.getElementById('repo') as HTMLInputElement).value = settings.githubRepo;
  }
  if (settings.githubToken) {
    // Don't show the actual token, just indicate it's set
    (document.getElementById('token') as HTMLInputElement).placeholder = 'â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢';
  }

  // Session settings
  (document.getElementById('idleThreshold') as HTMLInputElement).value = 
    String(settings.sessionConfig?.idleThresholdMinutes ?? DEFAULT_CONFIG.idleThresholdMinutes);
    
  (document.getElementById('minDuration') as HTMLInputElement).value = 
    String(settings.sessionConfig?.minSessionDurationSeconds ?? DEFAULT_CONFIG.minSessionDurationSeconds);
    
  (document.getElementById('requireContinuous') as HTMLInputElement).checked = 
    settings.sessionConfig?.requireContinuousActivity ?? DEFAULT_CONFIG.requireContinuousActivity;
    
  (document.getElementById('logPartial') as HTMLInputElement).checked = 
    settings.sessionConfig?.logPartialSessions ?? DEFAULT_CONFIG.logPartialSessions;
}

// Helper to get form values
function getFormValues(): {
  githubRepo: string;
  githubToken: string;
  sessionConfig: RawSessionConfig;
} {
  return {
    githubRepo: (document.getElementById('repo') as HTMLInputElement).value.trim(),
    githubToken: (document.getElementById('token') as HTMLInputElement).value.trim(),
    sessionConfig: {
      idleThresholdMinutes: Number((document.getElementById('idleThreshold') as HTMLInputElement).value),
      minSessionDurationSeconds: Number((document.getElementById('minDuration') as HTMLInputElement).value),
      requireContinuousActivity: (document.getElementById('requireContinuous') as HTMLInputElement).checked,
      logPartialSessions: (document.getElementById('logPartial') as HTMLInputElement).checked,
      activityUpdateIntervalSeconds: DEFAULT_CONFIG.activityUpdateIntervalSeconds // Keep default
    }
  };
}

// Display status message
function showStatus(message: string, isError = false): void {
  const status = document.getElementById('status');
  if (!status) return;
  
  status.textContent = message;
  status.className = `status ${isError ? 'error' : 'success'}`;

  // Clear status after 3 seconds if it's a success message
  if (!isError) {
    setTimeout(() => {
      if (status) {
        status.textContent = '';
        status.className = 'status';
      }
    }, 3000);
  }
}

// Validate settings before saving
async function validateSettings(settings: {
  githubRepo: string;
  githubToken: string;
  sessionConfig: RawSessionConfig;
}): Promise<void> {
  // Validate repository format
  if (!/^[\w-]+\/[\w-]+$/.test(settings.githubRepo)) {
    throw new Error('Invalid repository format. Use username/repository');
  }

  // Validate the token by making a test API call
  const response = await fetch(`https://api.github.com/repos/${settings.githubRepo}`, {
    headers: {
      'Authorization': `token ${settings.githubToken}`,
      'Accept': 'application/vnd.github.v3+json'
    }
  });

  if (!response.ok) {
    throw new Error('Invalid token or repository. Please check your credentials.');
  }

  // Validate session settings
  const { sessionConfig } = settings;
  if (sessionConfig.idleThresholdMinutes < 1 || sessionConfig.idleThresholdMinutes > 60) {
    throw new Error('Idle threshold must be between 1 and 60 minutes');
  }
  if (sessionConfig.minSessionDurationSeconds < 1 || sessionConfig.minSessionDurationSeconds > 300) {
    throw new Error('Minimum session duration must be between 10 and 300 seconds');
  }
}

// Save settings
async function saveSettings(settings: {
  githubRepo: string;
  githubToken: string;
  sessionConfig: RawSessionConfig;
}): Promise<void> {
  await chrome.storage.sync.set({
    githubRepo: settings.githubRepo,
    githubToken: settings.githubToken
  });

  await saveSessionConfig(settings.sessionConfig);
}

// Initialize options page
document.addEventListener('DOMContentLoaded', async () => {
  try {
    // Load current settings
    const [storageItems, sessionConfig] = await Promise.all([
      chrome.storage.sync.get(['githubRepo', 'githubToken']),
      loadSessionConfig()
    ]);

    // Combine settings and display them
    setFormValues({
      ...(storageItems as {
        githubRepo?: string;
        githubToken?: string;
      }),
      sessionConfig
    });

    // Add save button handler
    const saveButton = document.getElementById('save');
    if (saveButton) {
      saveButton.addEventListener('click', async () => {
        try {
          const settings = getFormValues();
          await validateSettings(settings);
          await saveSettings(settings);
          showStatus('Settings saved successfully!');
        } catch (error) {
          showStatus(`Error: ${error instanceof Error ? error.message : 'Unknown error'}`, true);
        }
      });
    }

  } catch (error) {
    showStatus(`Error loading settings: ${error instanceof Error ? error.message : 'Unknown error'}`, true);
  }
});



---
File: extension/package.json
---
{
  "name": "arxiv-tracker-extension",
  "version": "1.0.0",
  "private": true,
  "scripts": {
    "build": "rollup -c",
    "watch": "rollup -c -w",
    "type-check": "tsc --noEmit",
    "lint": "eslint . --ext .ts",
    "format": "prettier --write \"**/*.{ts,js}\"",
    "clean": "rm -rf dist"
  },
  "dependencies": {
    "gh-store-client": "^0.11.1"
  },
  "devDependencies": {
    "@rollup/plugin-commonjs": "^22.0.0",
    "@rollup/plugin-node-resolve": "^13.3.0",
    "@rollup/plugin-typescript": "^8.3.2",
    "@types/chrome": "^0.0.246",
    "@types/node": "^20.10.6",
    "@typescript-eslint/eslint-plugin": "^6.17.0",
    "@typescript-eslint/parser": "^6.17.0",
    "eslint": "^8.56.0",
    "prettier": "^3.1.1",
    "rollup": "^2.75.6",
    "rollup-plugin-terser": "^7.0.2",
    "tslib": "^2.4.0",
    "typescript": "^5.3.3"
  }
}



---
File: extension/papers/debug.d.ts
---
// extension/papers/debug.d.ts
import { GitHubStoreClient } from 'gh-store-client';
import { PaperManager } from './manager';

declare global {
    const __DEBUG__: {
        paperManager: PaperManager | null;
        getGithubClient: () => GitHubStoreClient | undefined;
        getCurrentPaper: () => any;
        getCurrentSession: () => any;
        getConfig: () => any;
    }
}



---
File: extension/papers/manager.ts
---
// extension/papers/manager.ts
import { GitHubStoreClient } from 'gh-store-client';
import type { Json } from 'gh-store-client';
import { 
  type PaperMetadata, 
  type InteractionLog, 
  type Interaction,
  type ReadingSessionData,
  isInteractionLog
} from './types';
import { SourceManager } from '../source-integration/types';
import { loguru } from '../utils/logger';

const logger = loguru.getLogger('paper-manager');

export class PaperManager {
  constructor(
    private client: GitHubStoreClient,
    private sourceManager: SourceManager
  ) {
    logger.debug('Paper manager initialized');
  }
  
  /**
   * Get paper by source and ID
   */
  async getPaper(sourceId: string, paperId: string): Promise<PaperMetadata | null> {
    const objectId = this.sourceManager.formatObjectId('paper', sourceId, paperId);
    
    try {
      const obj = await this.client.getObject(objectId);
      return obj.data as PaperMetadata;
    } catch (error) {
      if (error instanceof Error && error.message.includes('No object found')) {
        return null;
      }
      throw error;
    }
  }
  
  /**
   * Get or create paper metadata
   */
  async getOrCreatePaper(paperData: PaperMetadata): Promise<PaperMetadata> {
    const { sourceId, paperId } = paperData;
    const objectId = this.sourceManager.formatObjectId('paper', sourceId, paperId);
    const paperIdentifier = this.sourceManager.formatPaperId(sourceId, paperId);
    
    try {
      const obj = await this.client.getObject(objectId);
      const data = obj.data as PaperMetadata;
      logger.debug(`Retrieved existing paper: ${paperIdentifier}`);
      return data;
    } catch (error) {
      if (error instanceof Error && error.message.includes('No object found')) {
        // Create new paper
        const defaultPaperData: PaperMetadata = {
          ...paperData,
          timestamp: new Date().toISOString(),
          rating: paperData.rating || 'novote'
        };

        const newobj = await this.client.createObject(objectId, defaultPaperData);
        logger.debug(`Created new paper: ${paperIdentifier}`);
        // reopen to trigger metadata hydration
        await this.client.fetchFromGitHub(`/issues/${newobj.meta.issueNumber}`, {
          method: "PATCH",
          body: JSON.stringify({ state: "open" })
        });
        return defaultPaperData;
      }
      throw error;
    }
  }

  /**
   * Get or create interaction log for a paper
   */
  private async getOrCreateInteractionLog(sourceId: string, paperId: string): Promise<InteractionLog> {
    const objectId = this.sourceManager.formatObjectId('interactions', sourceId, paperId);
    const paperIdentifier = this.sourceManager.formatPaperId(sourceId, paperId);
    
    try {
      const obj = await this.client.getObject(objectId);
      const data = obj.data as unknown;
      if (isInteractionLog(data)) {
        return data;
      }
      throw new Error('Invalid interaction log format');
    } catch (error) {
      if (error instanceof Error && error.message.includes('No object found')) {
        const newLog: InteractionLog = {
          sourceId,
          paperId,
          interactions: []
        };
        await this.client.createObject(objectId, newLog as unknown as { [key: string]: Json });
        logger.debug(`Created new interaction log: ${paperIdentifier}`);
        return newLog;
      }
      throw error;
    }
  }
  
  /**
   * Get GitHub client instance
   */
  getClient(): GitHubStoreClient {
    return this.client;
  }
  
  /**
   * Log a reading session
   */
  async logReadingSession(
    sourceId: string,
    paperId: string,
    session: ReadingSessionData,
    paperData?: Partial<PaperMetadata>
  ): Promise<void> {
    // Ensure paper exists
    if (paperData) {
      await this.getOrCreatePaper({
        sourceId,
        paperId,
        url: paperData.url || this.sourceManager.formatPaperId(sourceId, paperId),
        title: paperData.title || paperId,
        authors: paperData.authors || '',
        abstract: paperData.abstract || '',
        timestamp: new Date().toISOString(),
        rating: 'novote',
        publishedDate: paperData.publishedDate || '',
        tags: paperData.tags || []
      });
    }

    // Log the session as an interaction
    await this.addInteraction(sourceId, paperId, {
      type: 'reading_session',
      timestamp: new Date().toISOString(),
      data: session as unknown as { [key: string]: Json }
    });
    
    const paperIdentifier = this.sourceManager.formatPaperId(sourceId, paperId);
    logger.info(`Logged reading session for ${paperIdentifier}`, { duration: session.duration_seconds });
  }

  /**
   * Log an annotation
   */
  async logAnnotation(
    sourceId: string,
    paperId: string,
    key: string,
    value: Json,
    paperData?: Partial<PaperMetadata>
  ): Promise<void> {
    // Ensure paper exists
    if (paperData) {
      await this.getOrCreatePaper({
        sourceId,
        paperId,
        url: paperData.url || this.sourceManager.formatPaperId(sourceId, paperId),
        title: paperData.title || paperId,
        authors: paperData.authors || '',
        abstract: paperData.abstract || '',
        timestamp: new Date().toISOString(),
        rating: 'novote',
        publishedDate: paperData.publishedDate || '',
        tags: paperData.tags || []
      });
    }

    // Log the annotation as an interaction
    await this.addInteraction(sourceId, paperId, {
      type: 'annotation',
      timestamp: new Date().toISOString(),
      data: { key, value }
    });
    
    const paperIdentifier = this.sourceManager.formatPaperId(sourceId, paperId);
    logger.info(`Logged annotation for ${paperIdentifier}`, { key });
  }

  /**
   * Update paper rating
   */
  async updateRating(
    sourceId: string,
    paperId: string,
    rating: string,
    paperData?: Partial<PaperMetadata>
  ): Promise<void> {
    // Ensure paper exists and get current data
    const paper = await this.getOrCreatePaper({
      sourceId,
      paperId,
      url: paperData?.url || this.sourceManager.formatPaperId(sourceId, paperId),
      title: paperData?.title || paperId,
      authors: paperData?.authors || '',
      abstract: paperData?.abstract || '',
      timestamp: new Date().toISOString(),
      rating: 'novote',
      publishedDate: paperData?.publishedDate || '',
      tags: paperData?.tags || []
    });

    const objectId = this.sourceManager.formatObjectId('paper', sourceId, paperId);
    
    // Update paper metadata with new rating
    await this.client.updateObject(objectId, { 
      ...paper,
      rating 
    });

    // Log rating change as an interaction
    await this.addInteraction(sourceId, paperId, {
      type: 'rating',
      timestamp: new Date().toISOString(),
      data: { rating }
    });
    
    const paperIdentifier = this.sourceManager.formatPaperId(sourceId, paperId);
    logger.info(`Updated rating for ${paperIdentifier} to ${rating}`);
  }

  /**
   * Add interaction to log
   */
  private async addInteraction(sourceId: string, paperId: string, interaction: Interaction): Promise<void> {
    const log = await this.getOrCreateInteractionLog(sourceId, paperId);
    log.interactions.push(interaction);
    
    const objectId = this.sourceManager.formatObjectId('interactions', sourceId, paperId);
    await this.client.updateObject(objectId, log as unknown as { [key: string]: Json });
  }
}



---
File: extension/papers/types.ts
---
// extension/papers/types.ts
// Updated for heartbeat-based session tracking

import type { Json } from 'gh-store-client';

/**
 * Paper metadata from any source
 */
export interface PaperMetadata {
  // Source identifier
  sourceId: string;
  
  // Paper identifier within the source
  paperId: string;
  
  // Full URL to the paper
  url: string;
  
  // Paper title
  title: string;
  
  // Authors (comma-separated)
  authors: string;
  
  // Abstract or summary
  abstract: string;
  
  // When this paper was first added
  timestamp: string;
  
  // Publication date
  publishedDate: string;
  
  // Tags or categories
  tags: string[];
  
  // User-assigned rating (novote, thumbsup, thumbsdown)
  rating: string;
  
  // Allow additional source-specific properties
  [key: string]: any;
}

/**
 * Reading session data - updated for heartbeat tracking
 */
export interface ReadingSessionData {
  // Session identifier
  session_id: string;
  
  // Paper identifiers
  source_id?: string;
  paper_id?: string;
  
  // Session timing
  start_time: string;
  end_time: string;
  
  // Heartbeat data
  heartbeat_count: number;
  
  // Duration in seconds (derived from heartbeat count)
  duration_seconds: number;
  
  // Legacy properties for backward compatibility
  idle_seconds?: number;
  total_elapsed_seconds?: number;
}

/**
 * Interaction data
 */
export interface Interaction {
  // Type of interaction (reading_session, annotation, rating)
  type: string;
  
  // When interaction occurred
  timestamp: string;
  
  // Additional data
  data: Json;
}

/**
 * Interaction log
 */
export interface InteractionLog {
  // Source identifier
  sourceId: string;
  
  // Paper identifier within the source
  paperId: string;
  
  // List of interactions
  interactions: Interaction[];

  // Index signature to make it compatible with Json type
  [key: string]: string | Interaction[] | any;
}

/**
 * Type guard for interaction log
 */
export function isInteractionLog(data: unknown): data is InteractionLog {
  const log = data as InteractionLog;
  return (
    typeof log === 'object' &&
    log !== null &&
    typeof log.sourceId === 'string' &&
    typeof log.paperId === 'string' &&
    Array.isArray(log.interactions)
  );
}



---
File: extension/popup.html
---
<!DOCTYPE html>
<html>
<head>
  <style>
    body {
      width: 400px;
      padding: 15px;
      font-family: system-ui, -apple-system, sans-serif;
    }
    .paper-info {
      margin-bottom: 15px;
    }
    .paper-title {
      font-weight: bold;
      margin-bottom: 8px;
      font-size: 14px;
      line-height: 1.4;
    }
    .paper-authors {
      font-size: 12px;
      color: #666;
      margin-bottom: 12px;
      line-height: 1.4;
    }
    .rating-buttons {
      display: flex;
      gap: 10px;
      margin-top: 15px;
    }
    button {
      flex: 1;
      padding: 8px;
      border: 1px solid #ddd;
      border-radius: 4px;
      background: #f5f5f5;
      cursor: pointer;
    }
    button:disabled {
      opacity: 0.5;
      cursor: not-allowed;
    }
    button:not(:disabled):hover {
      background: #e5e5e5;
    }
    .status {
      margin-top: 10px;
      font-size: 12px;
      color: #666;
      padding: 8px;
      background: #f5f5f5;
      border-radius: 4px;
      text-align: center;
    }
    /* New styles for manual logging UI */
    .manual-log-section {
      margin-top: 20px;
      padding-top: 15px;
      border-top: 1px solid #eee;
      display: none; /* Hidden by default, shown when no paper detected */
    }
    .manual-log-section h3 {
      font-size: 14px;
      margin-top: 0;
      margin-bottom: 10px;
    }
    .log-button {
      width: 100%;
      padding: 10px;
      background: #2563eb;
      color: white;
      border: none;
      border-radius: 4px;
      cursor: pointer;
      font-weight: 500;
      margin-bottom: 10px;
    }
    .log-button:hover {
      background: #1d4ed8;
    }
  </style>
</head>
<body>
  <div id="currentPaper" class="paper-info">
    <div id="paperTitle" class="paper-title">Loading...</div>
    <div id="paperAuthors" class="paper-authors"></div>
    <div class="rating-buttons">
      <button id="thumbsUp" disabled>ðŸ‘ Interesting</button>
      <button id="thumbsDown" disabled>ðŸ‘Ž Not Relevant</button>
    </div>
    <div id="status" class="status">Loading paper details...</div>
  </div>
  
  <!-- New section for manually logging a paper with one-click -->
  <div id="manualLogSection" class="manual-log-section">
    <h3>This page is not tracked as a paper</h3>
    <button id="logPageButton" class="log-button">Track This Page</button>
  </div>
  
  <script src="dist/popup.bundle.js"></script>
</body>
</html>



---
File: extension/popup.ts
---
// extension/popup.ts
// Popup script with refactored manual paper tracking

import { PaperMetadata } from './papers/types';

console.log('Popup script starting...');

// Function to get paper data from background script
async function getCurrentPaper(): Promise<PaperMetadata | null> {
  return new Promise((resolve) => {
    chrome.runtime.sendMessage({type: 'getCurrentPaper'}, (response) => {
      console.log('Got paper data from background:', response);
      resolve(response as PaperMetadata | null);
    });
  });
}

// Interface for message response
interface MessageResponse {
  success: boolean;
  error?: string;
  metadata?: PaperMetadata;
}

// Function to update UI with paper data
function updateUI(paperData: PaperMetadata | null): void {
  const titleElement = document.getElementById('paperTitle');
  const authorsElement = document.getElementById('paperAuthors');
  const statusElement = document.getElementById('status');
  const manualLogSection = document.getElementById('manualLogSection');

  if (!titleElement || !authorsElement || !statusElement || !manualLogSection) {
    console.error('Required DOM elements not found');
    return;
  }

  if (paperData) {
    // Show detected paper data
    titleElement.textContent = paperData.title || paperData.paperId;
    authorsElement.textContent = paperData.authors;
    statusElement.textContent = 'Paper tracked! Issue created on GitHub.';
    
    // Enable rating buttons
    const thumbsUpButton = document.getElementById('thumbsUp') as HTMLButtonElement;
    const thumbsDownButton = document.getElementById('thumbsDown') as HTMLButtonElement;
    
    if (thumbsUpButton && thumbsDownButton) {
      thumbsUpButton.disabled = false;
      thumbsDownButton.disabled = false;
      
      // Set active state on rating buttons
      thumbsUpButton.classList.toggle('active', paperData.rating === 'thumbsup');
      thumbsDownButton.classList.toggle('active', paperData.rating === 'thumbsdown');
    }
    
    // Hide manual log section
    manualLogSection.style.display = 'none';
  } else {
    // No paper detected - show manual log option
    titleElement.textContent = 'No paper detected';
    authorsElement.textContent = '';
    statusElement.textContent = 'Current page not recognized as a paper';
    
    // Disable rating buttons
    const thumbsUpButton = document.getElementById('thumbsUp') as HTMLButtonElement;
    const thumbsDownButton = document.getElementById('thumbsDown') as HTMLButtonElement;
    
    if (thumbsUpButton && thumbsDownButton) {
      thumbsUpButton.disabled = true;
      thumbsDownButton.disabled = true;
    }
    
    // Show manual log section
    manualLogSection.style.display = 'block';
  }
}

// Function to log current page as a paper (using content script extraction)
async function logCurrentPage(): Promise<void> {
  console.log("attempting to log paper");
  
  // Get the active tab
  const tabs = await chrome.tabs.query({ active: true, currentWindow: true });
  if (!tabs[0] || !tabs[0].id) {
    const statusElement = document.getElementById('status');
    if (statusElement) {
      statusElement.textContent = 'Error: Could not access current tab';
    }
    return;
  }
  
  // Show loading state
  const statusElement = document.getElementById('status');
  if (statusElement) {
    statusElement.textContent = 'Extracting paper metadata...';
  }
  
  // Send message to content script requesting extraction
  chrome.tabs.sendMessage(tabs[0].id, { 
    type: 'extractPaperMetadata' 
  }, (response: MessageResponse) => {
    if (chrome.runtime.lastError) {
      // Handle error
      if (statusElement) {
        statusElement.textContent = 'Error: ' + chrome.runtime.lastError.message;
      }
      return;
    }
    
    if (!response || !response.success || !response.metadata) {
      // Handle extraction failure
      if (statusElement) {
        statusElement.textContent = 'Error: ' + (response?.error || 'Failed to extract metadata');
      }
      return;
    }
    
    // Success - update UI
    updateUI(response.metadata);
    if (statusElement) {
      statusElement.textContent = 'Paper tracked successfully!';
    }
    
    // The content script has already:
    // 1. Sent metadata to background script
    // 2. Started a session if the tab is visible
    
    // Hide manual log section
    const manualLogSection = document.getElementById('manualLogSection');
    if (manualLogSection) {
      manualLogSection.style.display = 'none';
    }
    
    // Enable rating buttons
    const thumbsUpButton = document.getElementById('thumbsUp') as HTMLButtonElement;
    const thumbsDownButton = document.getElementById('thumbsDown') as HTMLButtonElement;
    if (thumbsUpButton && thumbsDownButton) {
      thumbsUpButton.disabled = false;
      thumbsDownButton.disabled = false;
    }
  });
}

// Initialize popup
document.addEventListener('DOMContentLoaded', async () => {
  console.log('Popup opened');
  
  // Get paper from the session tracker
  let paperData: PaperMetadata | null = null;
  let retries = 3;
  
  while (retries > 0 && !paperData) {
    paperData = await getCurrentPaper();
    if (!paperData) {
      await new Promise(resolve => setTimeout(resolve, 500)); // Wait 500ms before retry
      retries--;
    }
  }
  
  updateUI(paperData);
  
  // Set up rating handlers
  const thumbsUpButton = document.getElementById('thumbsUp');
  if (thumbsUpButton) {
    thumbsUpButton.addEventListener('click', () => {
      chrome.runtime.sendMessage({
        type: 'updateRating',
        rating: 'thumbsup'
      }, (response: MessageResponse) => {
        const statusElement = document.getElementById('status');
        const thumbsUpButton = document.getElementById('thumbsUp');
        const thumbsDownButton = document.getElementById('thumbsDown');
        
        if (!statusElement || !thumbsUpButton || !thumbsDownButton) return;
        
        if (response && response.success) {
          statusElement.textContent = 'Rating updated to: thumbs up';
          thumbsUpButton.classList.add('active');
          thumbsDownButton.classList.remove('active');
          setTimeout(() => window.close(), 1500);
        } else {
          statusElement.textContent = 'Error: ' + (response?.error || 'Unknown error');
        }
      });
    });
  }
  
  const thumbsDownButton = document.getElementById('thumbsDown');
  if (thumbsDownButton) {
    thumbsDownButton.addEventListener('click', () => {
      chrome.runtime.sendMessage({
        type: 'updateRating',
        rating: 'thumbsdown'
      }, (response: MessageResponse) => {
        const statusElement = document.getElementById('status');
        const thumbsUpButton = document.getElementById('thumbsUp');
        const thumbsDownButton = document.getElementById('thumbsDown');
        
        if (!statusElement || !thumbsUpButton || !thumbsDownButton) return;
        
        if (response && response.success) {
          statusElement.textContent = 'Rating updated to: thumbs down';
          thumbsDownButton.classList.add('active');
          thumbsUpButton.classList.remove('active');
          setTimeout(() => window.close(), 1500);
        } else {
          statusElement.textContent = 'Error: ' + (response?.error || 'Unknown error');
        }
      });
    });
  }
  
  // Set up one-click logging button
  const logPageButton = document.getElementById('logPageButton');
  if (logPageButton) {
    console.log("Attaching logPageButton event listener...");
    logPageButton.addEventListener('click', () => {
      console.log("logPageButton clicked...");
      logCurrentPage();
    });
  }
});



---
File: extension/rollup.config.js
---
// rollup.config.js
import typescript from '@rollup/plugin-typescript';
import resolve from '@rollup/plugin-node-resolve';
import commonjs from '@rollup/plugin-commonjs';
import { terser } from 'rollup-plugin-terser';

export default [
  // Background script as ESM (module)
  {
    input: 'background.ts',
    output: {
      file: 'dist/background.bundle.js',
      format: 'es',
      sourcemap: true
    },
    plugins: [
      typescript(),
      resolve(),
      commonjs()
    ]
  },
  // Content script as IIFE (non-module)
  {
    input: 'content.ts',
    output: {
      file: 'dist/content-script.js',
      format: 'iife', // Immediately-invoked function expression - no imports needed
      sourcemap: true
    },
    plugins: [
      typescript(),
      resolve(),
      commonjs(),
      terser() // Minify for production (optional)
    ]
  },
  // Options script
  {
    input: 'options.ts',
    output: {
      file: 'dist/options.bundle.js',
      format: 'es',
      sourcemap: true
    },
    plugins: [
      typescript(),
      resolve(),
      commonjs()
    ]
  },
  // Popup script - converted to TypeScript
  {
    input: 'popup.ts',
    output: {
      file: 'dist/popup.bundle.js',
      format: 'es',
      sourcemap: true
    },
    plugins: [
      typescript(),
      resolve(),
      commonjs()
    ]
  }
];



---
File: extension/source-integration/arxiv/index.ts
---
// extension/source-integration/arxiv/index.ts
// ArXiv integration with custom metadata extractor

import { BaseSourceIntegration } from '../base-source';
import { PaperMetadata } from '../../papers/types';
import { MetadataExtractor, ExtractedMetadata } from '../metadata-extractor';
import { loguru } from '../../utils/logger';

const logger = loguru.getLogger('arxiv-integration');

/**
 * Custom metadata extractor for arXiv pages
 */
class ArxivMetadataExtractor extends MetadataExtractor {
  private apiMetadata?: Partial<ExtractedMetadata>;
  
  constructor(document: Document, apiMetadata?: Partial<ExtractedMetadata>) {
    super(document);
    this.apiMetadata = apiMetadata;
  }
  
  /**
   * Override title extraction to use API data if available
   */
  protected extractTitle(): string {
    if (this.apiMetadata?.title) {
      return this.apiMetadata.title;
    }
    
    // arXiv-specific selectors
    //const arxivTitle = this.document.querySelector('.title.mathjax')?.textContent?.trim();
    
    //return arxivTitle || super.extractTitle();
    return super.extractTitle();
  }
  
  /**
   * Override authors extraction to use API data if available
   */
  protected extractAuthors(): string {
    if (this.apiMetadata?.authors) {
      return this.apiMetadata.authors;
    }
    
    // arXiv-specific selectors
    const authorLinks = this.document.querySelectorAll('.authors a');
    if (authorLinks.length > 0) {
      return Array.from(authorLinks)
        .map(link => link.textContent?.trim())
        .filter(Boolean)
        .join(', ');
    }
    
    return super.extractAuthors();
  }
  
  /**
   * Override description extraction to use API data if available
   */
  protected extractDescription(): string {
    if (this.apiMetadata?.description) {
      return this.apiMetadata.description;
    }
    
    // arXiv-specific selectors
    const abstract = this.document.querySelector('.abstract')?.textContent?.trim();
    if (abstract) {
      // Remove "Abstract:" prefix if present
      return abstract.replace(/^Abstract:\s*/i, '');
    }
    
    return super.extractDescription();
  }
  
  /**
   * Override published date extraction to use API data if available
   */
  protected extractPublishedDate(): string {
    if (this.apiMetadata?.publishedDate) {
      return this.apiMetadata.publishedDate;
    }
    
    // arXiv-specific date extraction
    const datelineElement = this.document.querySelector('.dateline');
    if (datelineElement) {
      const dateText = datelineElement.textContent;
      const dateMatch = dateText?.match(/\(Submitted on ([^)]+)\)/);
      if (dateMatch) {
        return dateMatch[1];
      }
    }
    
    return super.extractPublishedDate();
  }
  
  /**
   * Override DOI extraction to use API data if available
   */
  protected extractDoi(): string {
    return this.apiMetadata?.doi || super.extractDoi();
  }
  
  /**
   * Override journal extraction to use API data if available
   */
  protected extractJournalName(): string {
    return this.apiMetadata?.journalName || super.extractJournalName();
  }
  
  /**
   * Override tags extraction to use API data if available
   */
  protected extractTags(): string[] {
    if (this.apiMetadata?.tags) {
      return this.apiMetadata.tags;
    }
    
    // arXiv-specific category extraction
    const subjects = this.document.querySelector('.subjects')?.textContent?.trim();
    if (subjects) {
      return subjects.split(/[;,]/).map(tag => tag.trim()).filter(Boolean);
    }
    
    return super.extractTags();
  }
}

/**
 * ArXiv integration with custom metadata extraction
 */
export class ArXivIntegration extends BaseSourceIntegration {
  readonly id = 'arxiv';
  readonly name = 'arXiv.org';
  
  // URL patterns for papers
  readonly urlPatterns = [
    /arxiv\.org\/(abs|pdf|html)\/([0-9.]+)/,
    /arxiv\.org\/\w+\/([0-9.]+)/
  ];
  
  // Content script matches
  // readonly contentScriptMatches = [
  //   "*://*.arxiv.org/*"
  // ];

  // ArXiv API endpoint
  private readonly API_BASE_URL = 'https://export.arxiv.org/api/query';

  /**
   * Extract paper ID from URL
   */
  extractPaperId(url: string): string | null {
    for (const pattern of this.urlPatterns) {
      const match = url.match(pattern);
      if (match) {
        return match[2] || match[1]; // The capture group with the paper ID
      }
    }
    return null;
  }

  /**
   * Create a custom metadata extractor for arXiv
   */
  protected createMetadataExtractor(document: Document): MetadataExtractor {
    return new ArxivMetadataExtractor(document);
  }

  /**
   * Fetch metadata from ArXiv API
   */
  private async fetchFromApi(paperId: string): Promise<Partial<ExtractedMetadata> | null> {
    try {
      const apiUrl = `${this.API_BASE_URL}?id_list=${paperId}`;
      logger.debug(`Fetching from ArXiv API: ${apiUrl}`);
      
      const response = await fetch(apiUrl);
      if (!response.ok) {
        logger.error(`ArXiv API request failed with status: ${response.status}`);
        return null;
      }
      
      const xmlText = await response.text();
      
      // Parse XML to JSON
      const parser = new DOMParser();
      const xmlDoc = parser.parseFromString(xmlText, 'text/xml');
      
      // Convert XML to a more manageable format
      const entry = xmlDoc.querySelector('entry');
      if (!entry) {
        logger.warn('No entry found in ArXiv API response');
        return null;
      }
      
      // Extract metadata from XML
      const title = entry.querySelector('title')?.textContent?.trim() || '';
      const summary = entry.querySelector('summary')?.textContent?.trim() || '';
      const published = entry.querySelector('published')?.textContent?.trim() || '';
      
      // Extract authors
      const authorElements = entry.querySelectorAll('author name');
      const authors = Array.from(authorElements)
        .map(el => el.textContent?.trim())
        .filter(Boolean)
        .join(', ');
      
      // Extract DOI if available
      const doi = entry.querySelector('arxiv\\:doi, doi')?.textContent?.trim();
      
      // Extract journal reference if available
      const journalRef = entry.querySelector('arxiv\\:journal_ref, journal_ref')?.textContent?.trim();
      
      // Extract categories
      const categoryElements = entry.querySelectorAll('category');
      const categories = Array.from(categoryElements)
        .map(el => el.getAttribute('term'))
        .filter(Boolean) as string[];
      
      return {
        title,
        authors,
        description: summary,
        publishedDate: published,
        doi,
        journalName: journalRef,
        tags: categories
      };
      
    } catch (error) {
      logger.error('Error fetching from ArXiv API', error);
      return null;
    }
  }

  /**
   * Extract metadata from page or fetch from API
   * Override parent method to handle the API fallback
   */
  async extractMetadata(document: Document, paperId: string): Promise<PaperMetadata | null> {
    try {
      logger.info(`Extracting metadata for arXiv ID: ${paperId}`);
      
      // Try to extract from page first
      const extractor = this.createMetadataExtractor(document);
      const pageMetadata = extractor.extract();
      
      // Check if we have the essential fields
      const hasTitle = pageMetadata.title && pageMetadata.title !== document.title;
      const hasAuthors = pageMetadata.authors && pageMetadata.authors.length > 0;
      const hasAbstract = pageMetadata.description && pageMetadata.description.length > 0;
      
      if (hasTitle && hasAuthors && hasAbstract) {
        logger.debug('Successfully extracted complete metadata from page');
        return this.convertToPageMetadata(pageMetadata, paperId, extractor.getSourceType());
      }
      
      // If page extraction is incomplete, fetch from API
      logger.info('Page metadata incomplete, fetching from ArXiv API');
      const apiMetadata = await this.fetchFromApi(paperId);
      
      if (!apiMetadata) {
        logger.warn('Failed to fetch metadata from ArXiv API, using partial page data');
        return this.convertToPageMetadata(pageMetadata, paperId, extractor.getSourceType());
      }
      
      // Create a new extractor with API data
      const enhancedExtractor = new ArxivMetadataExtractor(document, apiMetadata);
      const mergedMetadata = enhancedExtractor.extract();
      
      logger.debug('Merged metadata from page and API', mergedMetadata);
      return this.convertToPageMetadata(mergedMetadata, paperId, enhancedExtractor.getSourceType());
      
    } catch (error) {
      logger.error('Error extracting metadata for arXiv', error);
      return null;
    }
  }

  /**
   * Convert ExtractedMetadata to PaperMetadata
   */
  private convertToPageMetadata(extracted: ExtractedMetadata, paperId: string, sourceType: string): PaperMetadata {
    return {
      sourceId: this.id,
      paperId: paperId,
      url: extracted.url || '',
      title: extracted.title,
      authors: extracted.authors,
      abstract: extracted.description,
      timestamp: new Date().toISOString(),
      rating: 'novote',
      publishedDate: extracted.publishedDate,
      tags: extracted.tags || [],
      doi: extracted.doi,
      journalName: extracted.journalName,
      sourceType: sourceType
    };
  }
}

// Export a singleton instance that can be used by both background and content scripts
export const arxivIntegration = new ArXivIntegration();



---
File: extension/source-integration/base-source.ts
---
// extension/source-integration/base-source.ts
// Base class for source integrations with default identifier formatting
// and metadata extraction capability

import { SourceIntegration } from './types';
import { PaperMetadata } from '../papers/types';
import { loguru } from '../utils/logger';
import { 
  MetadataExtractor, 
  createMetadataExtractor,
  generatePaperIdFromUrl
} from './metadata-extractor';

const logger = loguru.getLogger('base-source');

/**
 * Base class for source integrations
 * Provides default implementations for all methods
 * Specific sources can override as needed
 */
export class BaseSourceIntegration implements SourceIntegration {
  // Default properties - set for generic web pages
  readonly id: string = 'url';
  readonly name: string = 'Web Page';
  readonly urlPatterns: RegExp[] = [
    /^https?:\/\/(?!.*\.pdf($|\?|#)).*$/i  // Match HTTP/HTTPS URLs that aren't PDFs
  ];
  readonly contentScriptMatches: string[] = [];

  /**
   * Check if this integration can handle the given URL
   * Default implementation checks against urlPatterns
   */
  canHandleUrl(url: string): boolean {
    return this.urlPatterns.some(pattern => pattern.test(url));
  }

  /**
   * Extract paper ID from URL
   * Default implementation creates a hash from the URL
   */
  extractPaperId(url: string): string | null {
    return generatePaperIdFromUrl(url);
  }
  
  /**
   * Create a metadata extractor for the given document
   * Override this method to provide a custom extractor for your source
   */
  protected createMetadataExtractor(document: Document): MetadataExtractor {
    return createMetadataExtractor(document);
  }
  
  /**
   * Extract metadata from a page
   * Default implementation uses common metadata extraction
   */
  async extractMetadata(document: Document, paperId: string): Promise<PaperMetadata | null> {
    try {
      logger.debug(`Extracting metadata using base extractor for ID: ${paperId}`);
      
      // Create a metadata extractor for this document
      const extractor = this.createMetadataExtractor(document);
      
      // Extract metadata
      const extracted = extractor.extract();
      const url = document.location.href;
      
      // Determine source type (PDF or URL)
      const sourceType = extractor.getSourceType();
      
      // Create PaperMetadata object
      return {
        sourceId: this.id,
        //paperId: this.formatPaperId(paperId),
        paperId: paperId,
        url: url,
        title: extracted.title || document.title || paperId,
        authors: extracted.authors || '',
        abstract: extracted.description || '',
        timestamp: new Date().toISOString(),
        rating: 'novote',
        publishedDate: extracted.publishedDate || '',
        tags: extracted.tags || [],
        doi: extracted.doi,
        journalName: extracted.journalName,
        sourceType: sourceType // Store the source type for reference
      };
    } catch (error) {
      logger.error('Error extracting metadata with base extractor', error);
      return null;
    }
  }
  
  /**
   * Format a paper identifier for this source
   * Default implementation uses the format: sourceId.paperId
   */
  formatPaperId(paperId: string): string {
    return `${this.id}.${paperId}`;
  }
  
  /**
   * Parse a paper identifier specific to this source
   * Default implementation handles source.paperId format and extracts paperId
   */
  parsePaperId(identifier: string): string | null {
    const prefix = `${this.id}.`;
    
    if (identifier.startsWith(prefix)) {
      return identifier.substring(prefix.length);
    }
    
    // Try legacy format (sourceId:paperId)
    const legacyPrefix = `${this.id}:`;
    if (identifier.startsWith(legacyPrefix)) {
      logger.debug(`Parsed legacy format identifier: ${identifier}`);
      return identifier.substring(legacyPrefix.length);
    }
    
    return null;
  }
  
  /**
   * Format a storage object ID for this source
   * Default implementation uses the format: type:sourceId.paperId
   */
  formatObjectId(type: string, paperId: string): string {
    return `${type}:${this.formatPaperId(paperId)}`;
  }
}



---
File: extension/source-integration/index.ts
---
// extension/source-integration/index.ts
// Export the central registry
export * from './registry';

// Export individual integrations for direct access
// export { arxivIntegration } from './arxiv';
// export { openReviewIntegration } from './openreview';
// export { natureIntegration } from './nature';
//import { pnasIntegration } from './pnas';



---
File: extension/source-integration/link-processor.ts
---
// extension/source-integration/link-processor.ts
// Generic link detection and processing module

import { loguru } from '../utils/logger';

const logger = loguru.getLogger('link-processor');

interface LinkPattern {
  // Source integration ID
  sourceId: string;
  
  // Regular expression to match URLs
  pattern: RegExp;
  
  // Function to extract paper ID from URL
  extractPaperId: (url: string) => string | null;
}

export class LinkProcessor {
  private patterns: LinkPattern[] = [];
  private observer: MutationObserver | null = null;
  private processedLinks = new Set<string>();
  private onLinkFound: (sourceId: string, paperId: string, link: HTMLAnchorElement) => void;
  
  constructor(onLinkFound: (sourceId: string, paperId: string, link: HTMLAnchorElement) => void) {
    this.onLinkFound = onLinkFound;
    logger.debug('Link processor initialized');
  }
  
  /**
   * Register a new link pattern
   */
  registerPattern(pattern: LinkPattern): void {
    this.patterns.push(pattern);
    logger.debug(`Registered pattern for ${pattern.sourceId}`);
  }
  
  /**
   * Process all links in the document
   */
  processLinks(document: Document): void {
    // Process all links in the document
    const links = document.querySelectorAll<HTMLAnchorElement>('a[href]');
    
    links.forEach(link => {
      // Use a unique identifier for this link
      const linkId = this.getLinkId(link);
      
      // Skip if already processed
      if (this.processedLinks.has(linkId)) {
        return;
      }
      
      this.processedLinks.add(linkId);
      
      // Check each pattern
      for (const pattern of this.patterns) {
        if (pattern.pattern.test(link.href)) {
          const paperId = pattern.extractPaperId(link.href);
          
          if (paperId) {
            // Call the callback
            this.onLinkFound(pattern.sourceId, paperId, link);
            break; // Stop after first match
          }
        }
      }
    });
  }
  
  /**
   * Start observing for DOM changes
   */
  startObserving(document: Document): void {
    if (this.observer) {
      this.observer.disconnect();
    }
    
    this.observer = new MutationObserver((mutations) => {
      let newLinks = false;
      
      mutations.forEach(mutation => {
        mutation.addedNodes.forEach(node => {
          if (node.nodeType === Node.ELEMENT_NODE) {
            // If this is an anchor tag, check it
            if ((node as Element).tagName === 'A') {
              newLinks = true;
            }
            
            // Check for any anchor tags within this element
            const links = (node as Element).querySelectorAll('a[href]');
            if (links.length > 0) {
              newLinks = true;
            }
          }
        });
      });
      
      if (newLinks) {
        this.processLinks(document);
      }
    });
    
    this.observer.observe(document.body, {
      childList: true,
      subtree: true
    });
    
    logger.debug('Started observing for DOM changes');
  }
  
  /**
   * Create a unique ID for a link
   */
  private getLinkId(link: HTMLAnchorElement): string {
    // Use href and position in document to create a unique ID
    const path = this.getElementPath(link);
    return `${link.href}|${path}`;
  }
  
  /**
   * Get element path in DOM for identification
   */
  private getElementPath(element: Element): string {
    const path: string[] = [];
    let current: Element | null = element;
    
    while (current && current !== document.body) {
      let selector = current.tagName.toLowerCase();
      
      if (current.id) {
        selector += `#${current.id}`;
      } else {
        const siblings = Array.from(current.parentElement?.children || []);
        const index = siblings.indexOf(current) + 1;
        if (siblings.length > 1) {
          selector += `:nth-child(${index})`;
        }
      }
      
      path.unshift(selector);
      current = current.parentElement;
    }
    
    return path.join(' > ');
  }
  
  /**
   * Stop observing DOM changes
   */
  stopObserving(): void {
    if (this.observer) {
      this.observer.disconnect();
      this.observer = null;
      logger.debug('Stopped observing DOM changes');
    }
  }
}



---
File: extension/source-integration/metadata-extractor.ts
---
// extension/source-integration/metadata-extractor.ts
// Object-oriented metadata extraction system with customizable extraction methods

import { loguru } from '../utils/logger';

const logger = loguru.getLogger('metadata-extractor');

export interface ExtractedMetadata {
  title: string;
  authors: string;
  description: string;
  publishedDate: string;
  doi?: string;
  journalName?: string;
  tags?: string[];
  url?: string;
}

// Constants for standard source types
export const SOURCE_TYPES = {
  PDF: 'pdf',
  URL: 'url',
} as const;

export type SourceType = typeof SOURCE_TYPES[keyof typeof SOURCE_TYPES];

/**
 * Base class for metadata extraction with customizable extraction methods
 * Each method can be overridden to provide source-specific extraction
 */
export class MetadataExtractor {
  protected document: Document;
  protected url: string;
  
  /**
   * Create a new metadata extractor for a document
   */
  constructor(document: Document) {
    this.document = document;
    this.url = document.location.href;
    logger.debug('Initialized metadata extractor for:', this.url);
  }
  
  /**
   * Helper method to get content from meta tags
   */
  protected getMetaContent(selector: string): string {
    const element = this.document.querySelector(selector);
    return element ? element.getAttribute('content') || '' : '';
  }
  
  /**
   * Extract and return all metadata fields
   */
  public extract(): ExtractedMetadata {
    logger.debug('Extracting metadata from page:', this.url);
    
    const metadata: ExtractedMetadata = {
      title: this.extractTitle(),
      authors: this.extractAuthors(),
      description: this.extractDescription(),
      publishedDate: this.extractPublishedDate(),
      doi: this.extractDoi(),
      journalName: this.extractJournalName(),
      tags: this.extractTags(),
      url: this.url
    };
    
    logger.debug('Metadata extraction complete:', metadata);
    return metadata;
  }
  
  /**
   * Extract title from document
   * Considers multiple metadata standards with priority order
   */
  protected extractTitle(): string {
    // Title extraction - priority order
    return (
      // Dublin Core
      this.getMetaContent('meta[name="DC.Title"]') || this.getMetaContent('meta[name="dc.title"]') || 
      // Citation
      this.getMetaContent('meta[name="citation_title"]') ||
      // Open Graph
      this.getMetaContent('meta[property="og:title"]') ||
      // Standard meta
      this.getMetaContent('meta[name="title"]') ||
      // Fallback to document title
      this.document.title
    );
  }
  
  /**
   * Extract authors from document
   * Handles multiple author formats and sources
   */
  protected extractAuthors(): string {
    // Get all citation authors (some pages have multiple citation_author tags)
    const citationAuthors: string[] = [];
    this.document.querySelectorAll('meta[name="citation_author"]').forEach(el => {
      const content = el.getAttribute('content');
      if (content) citationAuthors.push(content);
    });
    
    // Get all DC creators
    const dcCreators: string[] = [];
    this.document.querySelectorAll('meta[name="DC.Creator.PersonalName"]').forEach(el => {
      const content = el.getAttribute('content');
      if (content) dcCreators.push(content);
    });
    
    // Individual author elements
    const dcCreator = this.getMetaContent('meta[name="DC.Creator.PersonalName"]') || this.getMetaContent('meta[name="dc.creator.personalname"]') ;
    const citationAuthor = this.getMetaContent('meta[name="citation_author"]');
    const ogAuthor = this.getMetaContent('meta[property="og:article:author"]') ||
                    this.getMetaContent('meta[name="author"]');
    
    // Set authors with priority
    if (dcCreators.length > 0) {
      return dcCreators.join(', ');
    } else if (citationAuthors.length > 0) {
      return citationAuthors.join(', ');
    } else if (dcCreator) {
      return dcCreator;
    } else if (citationAuthor) {
      return citationAuthor;
    } else if (ogAuthor) {
      return ogAuthor;
    }
    
    return '';
  }
  
  /**
   * Extract description/abstract from document
   */
  protected extractDescription(): string {
    return (
      this.getMetaContent('meta[name="DC.Description"]') || this.getMetaContent('meta[name="dc.description"]') ||
      this.getMetaContent('meta[name="citation_abstract"]') ||
      this.getMetaContent('meta[property="og:description"]') ||
      this.getMetaContent('meta[name="description"]')
    );
  }
  
  /**
   * Extract publication date from document
   */
  protected extractPublishedDate(): string {
    return (
      this.getMetaContent('meta[name="DC.Date.issued"]') || this.getMetaContent('meta[name="dc.date.issued"]') || this.getMetaContent('meta[name="dc.date"]') || this.getMetaContent('meta[name="dc.Date"]') || this.getMetaContent('meta[name="DC.Date"]') || 
      this.getMetaContent('meta[name="citation_date"]') ||
      this.getMetaContent('meta[property="article:published_time"]')
    );
  }
  
  /**
   * Extract DOI (Digital Object Identifier) from document
   */
  protected extractDoi(): string {
    return (
      this.getMetaContent('meta[name="DC.Identifier.DOI"]') || this.getMetaContent('meta[name="dc.identifier.doi"]') ||
      this.getMetaContent('meta[name="citation_doi"]')
    );
  }
  
  /**
   * Extract journal name from document
   */
  protected extractJournalName(): string {
    return (
      this.getMetaContent('meta[name="DC.Source"]') || this.getMetaContent('meta[name="dc.source"]') ||
      this.getMetaContent('meta[name="citation_journal_title"]')
    );
  }
  
  /**
   * Extract keywords/tags from document
   */
  protected extractTags(): string[] {
    const keywords = this.getMetaContent('meta[name="keywords"]') ||
                    this.getMetaContent('meta[name="DC.Subject"]') || this.getMetaContent('meta[name="dc.subject"]');
    
    if (keywords) {
      return keywords.split(',').map(tag => tag.trim());
    }
    
    return [];
  }
  
  /**
   * Determine if the current URL is a PDF
   */
  public isPdf(): boolean {
    return isPdfUrl(this.url);
  }
  
  /**
   * Get the source type (PDF or URL)
   */
  public getSourceType(): SourceType {
    return this.isPdf() ? SOURCE_TYPES.PDF : SOURCE_TYPES.URL;
  }
  
  /**
   * Generate a paper ID for the current URL
   */
  public generatePaperId(): string {
    return generatePaperIdFromUrl(this.url);
  }
}

/**
 * Create a common metadata extractor for a document
 * Factory function for creating the default extractor
 */
export function createMetadataExtractor(document: Document): MetadataExtractor {
  return new MetadataExtractor(document);
}

/**
 * Extract common metadata from a document
 * Convenience function for quick extraction
 */
export function extractCommonMetadata(document: Document): ExtractedMetadata {
  return createMetadataExtractor(document).extract();
}

/**
 * Generate a paper ID from a URL
 * Creates a consistent hash-based identifier
 */
export function generatePaperIdFromUrl(url: string): string {
  // Use a basic hash function to create an ID from the URL
  let hash = 0;
  for (let i = 0; i < url.length; i++) {
    const char = url.charCodeAt(i);
    hash = ((hash << 5) - hash) + char;
    hash = hash & hash; // Convert to 32bit integer
  }
  
  // Create a positive hexadecimal string
  const positiveHash = Math.abs(hash).toString(16).toUpperCase();
  
  // Use the first 8 characters as the ID
  return positiveHash.substring(0, 8);
}

/**
 * Determine if a URL is a PDF
 */
export function isPdfUrl(url: string): boolean {
  return url.toLowerCase().endsWith('.pdf');
}



---
File: extension/source-integration/misc/index.ts
---
// extension/source-integration/misc/index.ts
/*
 * Catch-all for registering with URL pattern only
 */
import { BaseSourceIntegration } from '../base-source';

export class MiscIntegration extends BaseSourceIntegration {
  readonly id = 'url-misc';
  readonly name = 'misc tracked url';

  readonly urlPatterns = []; // set this empty to disable attaching the content injection icon thing
    
  // add URLs here to track
  readonly contentScriptMatches = [
    "sciencedirect.com/science/article/",
    "philpapers.org/rec/",
    "proceedings.neurips.cc/paper_files/paper/",
    "journals.sagepub.com/doi/",
    "link.springer.com/article/",
    ".science.org/doi/",
    "journals.aps.org/prx/abstract/",
    "onlinelibrary.wiley.com/doi/",
    "cell.com/trends/cognitive-sciences/fulltext/",
    "researchgate.net/publication/",
    "psycnet.apa.org/record/",
    "biorxiv.org/content/",
    "osf.io/preprints/",
    "frontiersin.org/journals/",
    "jstor.org/",
    "proceedings.mlr.press/",
    "journals.plos.org/plosone/article",
    "ieeexplore.ieee.org/document/",
    "royalsocietypublishing.org/doi/",
    "papers.nips.cc/paper_files/paper/",
    "philarchive.org/archive/",
    "tandfonline.com/doi/",
    "iopscience.iop.org/article/",
    "academic.oup.com/brain/article/",
    "elifesciences.org/articles/",
    "escholarship.org/content/",
    "pmc.ncbi.nlm.nih.gov/articles/",
    "pubmed.ncbi.nlm.nih.gov/",
    "openaccess.thecvf.com/content/",
    "zenodo.org/records/",
    "journals.asm.org/doi/full/",
    "physoc.onlinelibrary.wiley.com/doi/full/",
    "storage.courtlistener.com/recap/",
    "bmj.com/content/",
    "ntsb.gov/investigations/pages",
    "ntsb.gov/investigations/AccidentReports",
    "aclanthology.org/",
    "journals.ametsoc.org/view/journals/",
    
    "substack.com/p/",
    "citeseerx.",
    "/doi/",
    "/pdf/",

  ];

  canHandleUrl(url: string): boolean {
    return this.contentScriptMatches.some(pattern => url.includes(pattern));
  }
}

export const miscIntegration = new MiscIntegration();



---
File: extension/source-integration/nature/index.ts
---
// extension/source-integration/nature/index.ts
// Nature.com integration with custom metadata extractor

import { BaseSourceIntegration } from '../base-source';
import { PaperMetadata } from '../../papers/types';
import { MetadataExtractor, ExtractedMetadata } from '../metadata-extractor';
import { loguru } from '../../utils/logger';

const logger = loguru.getLogger('nature-integration');

/**
 * Custom metadata extractor for Nature.com pages
 */
class NatureMetadataExtractor extends MetadataExtractor {
  /**
   * Override title extraction to use meta tag first
   */
  protected extractTitle(): string {
    const metaTitle = this.getMetaContent('meta[name="citation_title"]') || 
                      this.getMetaContent('meta[property="og:title"]');
    return metaTitle || super.extractTitle();
  }
  
  /**
   * Override authors extraction to use meta tag first
   */
  protected extractAuthors(): string {
    const metaAuthors = this.getMetaContent('meta[name="citation_author"]');
    if (metaAuthors) {
      return metaAuthors;
    }
    // Fallback to HTML extraction
    const authorElements = this.document.querySelectorAll('.c-article-author-list__item');
    if (authorElements.length > 0) {
      return Array.from(authorElements)
        .map(el => el.textContent?.trim())
        .filter(Boolean)
        .join(', ');
    }
    return super.extractAuthors();
  }
  
  /**
   * Extract keywords/tags from document
   */
  protected extractTags(): string[] {
    const keywords = this.getMetaContent('meta[name="dc.subject"]');
    
    if (keywords) {
      return keywords.split(',').map(tag => tag.trim());
    }
    
    return [];
  }
  

  /**
   * Override description extraction to use meta tag first
   */
  protected extractDescription(): string {
    const metaDescription = this.getMetaContent('meta[name="description"]') ||
                            this.getMetaContent('meta[property="og:description"]');
    return metaDescription || super.extractDescription();
  }

  /**
   * Override published date extraction to use meta tag
   */
  protected extractPublishedDate(): string {
    return this.getMetaContent('meta[name="citation_publication_date"]') || super.extractPublishedDate();
  }

  /**
   * Override DOI extraction to use meta tag
   */
  protected extractDoi(): string {
    return this.getMetaContent('meta[name="citation_doi"]') || super.extractDoi();
  }
}

/**
 * Nature.com integration with custom metadata extraction
 */
export class NatureIntegration extends BaseSourceIntegration {
  readonly id = 'nature';
  readonly name = 'Nature'; 

  // URL pattern for Nature articles with capture group for ID
  readonly urlPatterns = [
    /nature\.com\/articles\/([^?]+)/,
  ];

  // Content script matches  
  // readonly contentScriptMatches = [
  //   "*://*.nature.com/articles/*"
  // ];

  /**
   * Extract paper ID from URL
   */
  extractPaperId(url: string): string | null {
    const match = url.match(this.urlPatterns[0]);
    return match ? match[1] : null;
  }

  /**
   * Create a custom metadata extractor for Nature.com
   */
  protected createMetadataExtractor(document: Document): MetadataExtractor {
    return new NatureMetadataExtractor(document);
  }
}

// Export a singleton instance 
export const natureIntegration = new NatureIntegration();



---
File: extension/source-integration/openreview/index.ts
---
// extension/source-integration/openreview/index.ts
// OpenReview integration with custom metadata extractor

import { BaseSourceIntegration } from '../base-source';
import { PaperMetadata } from '../../papers/types';
import { MetadataExtractor, createMetadataExtractor, ExtractedMetadata } from '..//metadata-extractor';
import { loguru } from '../../utils/logger';

const logger = loguru.getLogger('openreview-integration');

/**
 * Custom metadata extractor for OpenReview pages
 */
class OpenReviewMetadataExtractor extends MetadataExtractor {
  /**
   * Extract metadata from OpenReview pages
   */
  public extract(): ExtractedMetadata {
    // First try to extract using standard methods
    const baseMetadata = super.extract();
    
    try {
      // Get title from OpenReview-specific elements
      const title = this.document.querySelector('.citation_title')?.textContent || 
                   this.document.querySelector('.forum-title h2')?.textContent;
      
      // Get authors
      const authorElements = Array.from(this.document.querySelectorAll('.forum-authors a'));
      const authors = authorElements
        .map(el => el.textContent)
        .filter(Boolean)
        .join(', ');
      
      // Get abstract
      const abstract = this.document.querySelector('meta[name="citation_abstract"]')?.getAttribute('content') ||
                     Array.from(this.document.querySelectorAll('.note-content-field'))
                       .find(el => el.textContent?.includes('Abstract'))
                       ?.nextElementSibling?.textContent;
      
      // Get publication date
      const dateText = this.document.querySelector('.date.item')?.textContent;
      let publishedDate = '';
      if (dateText) {
        const dateMatch = dateText.match(/Published: ([^,]+)/);
        if (dateMatch) {
          publishedDate = dateMatch[1];
        }
      }
      
      // Get DOI if available
      const doi = this.document.querySelector('meta[name="citation_doi"]')?.getAttribute('content') || '';
      
      // Get conference/journal name
      const venueElements = this.document.querySelectorAll('.forum-meta .item');
      let venue = '';
      for (let i = 0; i < venueElements.length; i++) {
        const el = venueElements[i];
        if (el.querySelector('.glyphicon-folder-open')) {
          venue = el.textContent?.trim() || '';
          break;
        }
      }
      
      // Get tags/keywords
      const keywordsElement = Array.from(this.document.querySelectorAll('.note-content-field'))
        .find(el => el.textContent?.includes('Keywords'));
      let tags: string[] = [];
      if (keywordsElement) {
        const keywordsValue = keywordsElement.nextElementSibling?.textContent;
        if (keywordsValue) {
          tags = keywordsValue.split(',').map(tag => tag.trim());
        }
      }
      
      return {
        title: title || baseMetadata.title,
        authors: authors || baseMetadata.authors,
        description: abstract || baseMetadata.description,
        publishedDate: publishedDate || baseMetadata.publishedDate,
        doi: doi || baseMetadata.doi,
        journalName: venue || baseMetadata.journalName,
        tags: tags.length ? tags : baseMetadata.tags,
        url: this.url
      };
    } catch (error) {
      logger.error('Error during OpenReview-specific extraction', error);
      return baseMetadata;
    }
  }
}

/**
 * OpenReview integration with custom metadata extraction
 */
export class OpenReviewIntegration extends BaseSourceIntegration {
  readonly id = 'openreview';
  readonly name = 'OpenReview';
  
  // URL patterns for papers
  readonly urlPatterns = [
    /openreview\.net\/forum\?id=([a-zA-Z0-9]+)/,
    /openreview\.net\/pdf\?id=([a-zA-Z0-9]+)/
  ];
  
  // Content script matches
  // readonly contentScriptMatches = [
  //   "*://*.openreview.net/*"
  // ];

  /**
   * Extract paper ID from URL
   */
  extractPaperId(url: string): string | null {
    for (const pattern of this.urlPatterns) {
      const match = url.match(pattern);
      if (match) {
        return match[1]; // The capture group with the paper ID
      }
    }
    return null;
  }

  /**
   * Create a custom metadata extractor for OpenReview
   */
  protected createMetadataExtractor(document: Document): MetadataExtractor {
    return new OpenReviewMetadataExtractor(document);
  }

  /**
   * Extract metadata from page
   * Override parent method to handle OpenReview-specific extraction
   */
  async extractMetadata(document: Document, paperId: string): Promise<PaperMetadata | null> {
    logger.info(`Extracting metadata for OpenReview ID: ${paperId}`);
    
    // Extract metadata using our custom extractor
    const metadata = await super.extractMetadata(document, paperId);
    
    if (metadata) {
      // Add any OpenReview-specific metadata processing here
      logger.debug('Extracted metadata from OpenReview page');
      
      // Check if we're on a PDF page and adjust metadata accordingly
      if (document.location.href.includes('/pdf?id=')) {
        metadata.sourceType = 'pdf';
      }
    }
    
    return metadata;
  }
}

// Export a singleton instance that can be used by both background and content scripts
export const openReviewIntegration = new OpenReviewIntegration();



---
File: extension/source-integration/pnas/index.ts
---
// extension/source-integration/pnas/index.ts
import { BaseSourceIntegration } from '../base-source';

export class PnasIntegration extends BaseSourceIntegration {
  readonly id = 'pnas';
  readonly name = 'PNAS'; 

  readonly urlPatterns = [
    /pnas\.org\/doi\/10\.1073\/pnas\.([0-9]+)/
  ];

  // readonly contentScriptMatches = [
  //   "*://*.pnas.org/doi/*"
  // ];

  // upstream BaseSourceIntegration.extractPaperId should default to this behavior when able
  extractPaperId(url: string): string | null {
    const match = url.match(this.urlPatterns[0]);
    return match ? match[1] : null;
  }
}

export const pnasIntegration = new PnasIntegration();



---
File: extension/source-integration/registry.ts
---
// extension/source-integration/registry.ts
// Central registry for all source integrations

import { SourceIntegration } from './types';
import { arxivIntegration } from './arxiv';
import { openReviewIntegration } from './openreview';
import { natureIntegration } from './nature';
import { pnasIntegration } from './pnas';
import { miscIntegration } from './misc';

export const sourceIntegrations: SourceIntegration[] = [
  arxivIntegration,
  openReviewIntegration,
  natureIntegration,
  pnasIntegration,
  miscIntegration,
];

/*     *     *     *     */

export function getAllIntegrations(): SourceIntegration[] {
  return sourceIntegrations;
}

export function getIntegrationById(id: string): SourceIntegration | undefined {
  return sourceIntegrations.find(integration => integration.id === id);
}

export function getAllContentScriptMatches(): string[] {
  return sourceIntegrations.flatMap(integration => integration.contentScriptMatches);
}



---
File: extension/source-integration/source-manager.ts
---
// extension/source-integration/source-manager.ts
// Updated SourceIntegrationManager to use source-specific identifier formatting

import { SourceIntegration, SourceManager } from './types';
import { loguru } from '../utils/logger';

const logger = loguru.getLogger('source-manager');

/**
 * Manages source integrations
 */
export class SourceIntegrationManager implements SourceManager {
  private sources: Map<string, SourceIntegration> = new Map();
  
  constructor() {
    logger.info('Source integration manager initialized');
  }
  
  /**
   * Register a source integration
   */
  registerSource(source: SourceIntegration): void {
    if (this.sources.has(source.id)) {
      logger.warning(`Source with ID '${source.id}' already registered, overwriting`);
    }
    
    this.sources.set(source.id, source);
    logger.info(`Registered source: ${source.name} (${source.id})`);
  }
  
  /**
   * Get all registered sources
   */
  getAllSources(): SourceIntegration[] {
    return Array.from(this.sources.values());
  }
  
  /**
   * Get source that can handle a URL
   */
  getSourceForUrl(url: string): SourceIntegration | null {
    for (const source of this.sources.values()) {
      if (source.canHandleUrl(url)) {
        logger.debug(`Found source for URL '${url}': ${source.id}`);
        return source;
      }
    }
    
    logger.debug(`No source found for URL: ${url}`);
    return null;
  }
  
  /**
   * Get source by ID
   */
  getSourceById(sourceId: string): SourceIntegration | null {
    const source = this.sources.get(sourceId);
    return source || null;
  }
  
  /**
   * Extract paper ID from URL using appropriate source
   */
  extractPaperId(url: string): { sourceId: string, paperId: string } | null {
    for (const source of this.sources.values()) {
      if (source.canHandleUrl(url)) {
        const paperId = source.extractPaperId(url);
        if (paperId) {
          logger.debug(`Extracted paper ID '${paperId}' from URL using ${source.id}`);
          return { sourceId: source.id, paperId };
        }
      }
    }
    
    logger.debug(`Could not extract paper ID from URL: ${url}`);
    return null;
  }
  
  /**
   * Format a paper identifier using the appropriate source
   */
  formatPaperId(sourceId: string, paperId: string): string {
    const source = this.sources.get(sourceId);
    
    if (source) {
      return source.formatPaperId(paperId);
    }
    
    // Fallback if source not found
    logger.warning(`Source '${sourceId}' not found, using default format for paper ID`);
    return `${sourceId}.${paperId}`;
  }
  
  /**
   * Format an object ID using the appropriate source
   */
  formatObjectId(type: string, sourceId: string, paperId: string): string {
    const source = this.sources.get(sourceId);
    
    if (source) {
      return source.formatObjectId(type, paperId);
    }
    
    // Fallback if source not found
    logger.warning(`Source '${sourceId}' not found, using default format for object ID`);
    return `${type}:${sourceId}.${paperId}`;
  }
  
  /**
   * Get all content script match patterns
   */
  getAllContentScriptMatches(): string[] {
    const patterns: string[] = [];
    
    for (const source of this.sources.values()) {
      patterns.push(...source.contentScriptMatches);
    }
    
    return patterns;
  }
}



---
File: extension/source-integration/types.ts
---
// extension/source-integration/types.ts
// Updated SourceIntegration interface with identifier formatting methods

import type { Json } from 'gh-store-client';
import type { PaperMetadata } from '../papers/types';

/**
 * Source integration interface
 * Implementations should be importable by both background and content scripts
 */
export interface SourceIntegration {
  // Unique identifier
  readonly id: string;
  
  // Human-readable name
  readonly name: string;
  
  // URL patterns for matching papers from this source (as RegExp patterns)
  readonly urlPatterns: RegExp[];
  
  // Domain match patterns for content script registration
  readonly contentScriptMatches: string[];
  
  // Check if URL is from this source
  canHandleUrl(url: string): boolean;
  
  // Extract paper ID from URL
  extractPaperId(url: string): string | null;
  
  // Extract metadata from page or API
  extractMetadata(document: Document, paperId: string): Promise<PaperMetadata | null>;
  
  // Format a paper identifier (sourceId + paperId) for this source
  formatPaperId(paperId: string): string;
  
  // Parse a paper identifier specific to this source
  parsePaperId(identifier: string): string | null;
  
  // Format a storage object ID for this source
  formatObjectId(type: string, paperId: string): string;
}

/**
 * Manager interface for source integrations
 */
export interface SourceManager {
  // Register a source integration
  registerSource(source: SourceIntegration): void;
  
  // Get all registered sources
  getAllSources(): SourceIntegration[];
  
  // Get source for a given URL
  getSourceForUrl(url: string): SourceIntegration | null;
  
  // Extract paper ID from URL using appropriate source
  extractPaperId(url: string): { sourceId: string, paperId: string } | null;
  
  // Format a paper identifier using the appropriate source
  formatPaperId(sourceId: string, paperId: string): string;
  
  // Format an object ID using the appropriate source
  formatObjectId(type: string, sourceId: string, paperId: string): string;
}

// Other existing types...
// Message types for communication between background and content scripts

// Content script ready notification
export interface ContentScriptReadyMessage {
  type: 'contentScriptReady';
  url: string;
}

// Paper metadata message
export interface PaperMetadataMessage {
  type: 'paperMetadata';
  metadata: PaperMetadata;
}

// Start session message (new)
export interface StartSessionMessage {
  type: 'startSession';
  sourceId: string;
  paperId: string;
}

// Session heartbeat message (new)
export interface SessionHeartbeatMessage {
  type: 'sessionHeartbeat';
  sourceId: string;
  paperId: string;
  timestamp: number;
}

// End session message (new)
export interface EndSessionMessage {
  type: 'endSession';
  sourceId: string;
  paperId: string;
  reason?: string;
}

// Show annotation popup request
export interface ShowAnnotationPopupMessage {
  type: 'showAnnotationPopup';
  sourceId: string;
  paperId: string;
  position: { x: number, y: number };
}

// Popup action message
export interface PopupActionMessage {
  type: 'popupAction';
  action: string;
  sourceId: string;
  paperId: string;
  data: any;
}

// Show popup message
export interface ShowPopupMessage {
  type: 'showPopup';
  sourceId: string;
  paperId: string;
  html: string;
  handlers: Array<{
    selector: string;
    event: string;
    action: string;
  }>;
  position?: { x: number, y: number };
}

// Process page message
export interface ProcessPageMessage {
  type: 'processPage';
}

// Get current paper message
export interface GetCurrentPaperMessage {
  type: 'getCurrentPaper';
}

// Update rating message
export interface UpdateRatingMessage {
  type: 'updateRating';
  rating: string;
}

// Union type for all message types
export type Message = 
  | ContentScriptReadyMessage
  | PaperMetadataMessage
  | StartSessionMessage
  | SessionHeartbeatMessage
  | EndSessionMessage
  | ShowAnnotationPopupMessage
  | PopupActionMessage
  | ShowPopupMessage
  | ProcessPageMessage
  | GetCurrentPaperMessage
  | UpdateRatingMessage;



---
File: extension/tsconfig.json
---
{
  "compilerOptions": {
    "target": "ES2020",
    "module": "ESNext",
    "moduleResolution": "bundler",
    "lib": ["ES2020", "DOM"],
    "esModuleInterop": true,
    "strict": true,
    "skipLibCheck": true,
    "isolatedModules": true,
    "types": ["chrome", "@types/node"],
    "outDir": "dist",
    "baseUrl": "."
  },
  "include": [
    "**/*.ts",
    "background.js",
    "content.js",
    "popup.js",
    "options.js"
  ],
  "exclude": ["node_modules", "dist"]
}



---
File: extension/utils/icon-manager.ts
---
// extension/utils/icon-manager.ts
// Icon management utility with inline SVGs and enhanced features

import { loguru } from './logger';

const logger = loguru.getLogger('icon-manager');

export enum IconState {
  DEFAULT = 'default',
  DETECTED = 'detected',
  TRACKED = 'tracked',
}

// Your excellent SVG definitions (keeping them as-is)
// Accessible color schemes for each state
const ICON_COLORS = {
  [IconState.DEFAULT]: {
    background: '#fef2f2',
    paper: '#fecaca',
    bookmark: '#dc2626',
  },
  [IconState.DETECTED]: {
    background: '#eff6ff',
    paper: '#93c5fd', 
    bookmark: '#2563eb',
  },
  [IconState.TRACKED]: {
    background: '#ecfdf5',
    paper: '#86efac',
    bookmark: '#059669',
  },
} as const;

const ICON_CONFIGS: {
  [K in IconState]: { colors: typeof ICON_COLORS[K]; title: string };
} = {
  [IconState.DEFAULT]: {
    colors: ICON_COLORS[IconState.DEFAULT],
    title: 'Academic Paper Tracker',
  },
  [IconState.DETECTED]: {
    colors: ICON_COLORS[IconState.DETECTED],
    title: 'Paper Detected - Academic Paper Tracker',
  },
  [IconState.TRACKED]: {
    colors: ICON_COLORS[IconState.TRACKED],
    title: 'Paper Tracked - Academic Paper Tracker',
  },
};

const ICON_SIZES = [16, 32, 48, 128];

export class IconManager {
  private tabStates: Map<number, IconState> = new Map();
  private pendingUpdates: Map<number, Promise<void>> = new Map(); // NEW: Prevent race conditions
  private iconCache: Map<string, Record<string, ImageData>> = new Map(); // NEW: Cache rasterized icons

  constructor() {
    this.setupTabListeners();
    this.preloadIcons(); // NEW: Pre-rasterize all icons at startup
    logger.debug('Icon manager initialized');
  }

  private setupTabListeners(): void {
    chrome.tabs.onRemoved.addListener((tabId) => {
      this.tabStates.delete(tabId);
      this.pendingUpdates.delete(tabId);
      logger.debug(`Cleaned up icon state for closed tab ${tabId}`);
    });

    chrome.tabs.onUpdated.addListener((tabId, changeInfo) => {
      if (changeInfo.status === 'loading' && changeInfo.url) {
        this.setIconState(tabId, IconState.DEFAULT);
        logger.debug(`Reset icon for tab ${tabId} navigating to ${changeInfo.url}`);
      }
    });
  }

  // NEW: Pre-generate all icons for better performance
  private async preloadIcons(): Promise<void> {
    try {
      for (const state of Object.values(IconState)) {
        const config = ICON_CONFIGS[state];
        const imageDataMap: Record<string, ImageData> = {};
        
        for (const px of ICON_SIZES) {
          const imgData = this.createCanvasIcon(config.colors, px, px);
          imageDataMap[px.toString()] = imgData;
        }
        
        this.iconCache.set(state, imageDataMap);
      }
      logger.debug('Pre-loaded all icon states');
    } catch (error) {
      logger.error('Failed to preload icons:', error);
    }
  }

  async setIconState(tabId: number, state: IconState): Promise<void> {
    // NEW: Check if already in this state (deduplication)
    const currentState = this.tabStates.get(tabId);
    if (currentState === state) {
      logger.debug(`Icon already in ${state} state for tab ${tabId}, skipping`);
      return;
    }

    // NEW: Wait for any pending updates to avoid race conditions
    const pending = this.pendingUpdates.get(tabId);
    if (pending) {
      try {
        await pending;
      } catch (error) {
        logger.warn(`Previous icon update failed for tab ${tabId}:`, error);
      }
    }

    // Create update promise
    const updatePromise = this.performIconUpdate(tabId, state);
    this.pendingUpdates.set(tabId, updatePromise);

    try {
      await updatePromise;
      this.tabStates.set(tabId, state);
      logger.debug(`Set icon state to ${state} for tab ${tabId}`);
    } catch (error) {
      logger.error(`Failed to set icon state for tab ${tabId}:`, error);
      throw error;
    } finally {
      this.pendingUpdates.delete(tabId);
    }
  }

  private async performIconUpdate(tabId: number, state: IconState): Promise<void> {
    const config = ICON_CONFIGS[state];

    // Check if tab still exists
    try {
      await chrome.tabs.get(tabId);
    } catch (error) {
      logger.debug(`Tab ${tabId} no longer exists, skipping icon update`);
      return;
    }

    try {
      // NEW: Use cached icons if available, otherwise generate on demand
      let imageDataMap = this.iconCache.get(state);
      
      if (!imageDataMap) {
        logger.debug(`Cache miss for ${state}, generating on demand`);
        imageDataMap = {};
        for (const px of ICON_SIZES) {
          const imgData = this.createCanvasIcon(config.colors, px, px);
          imageDataMap[px.toString()] = imgData;
        }
        this.iconCache.set(state, imageDataMap);
      }

      await chrome.action.setIcon({
        tabId,
        imageData: imageDataMap,
      });

      await chrome.action.setTitle({
        tabId,
        title: config.title,
      });

    } catch (error) {
      // Handle specific Chrome API errors gracefully
      const errorMessage = error instanceof Error ? error.message : String(error);
      if (errorMessage.includes('No tab with id') || 
          errorMessage.includes('Cannot access')) {
        logger.debug(`Cannot update icon for tab ${tabId}: ${errorMessage}`);
        return;
      }
      throw error;
    }
  }

  // NEW: Create icon using improved Canvas drawing (no borders, larger bookmark)
  private createCanvasIcon(
    colors: { background: string; paper: string; bookmark: string },
    widthPx: number,
    heightPx: number
  ): ImageData {
    const offscreen = new OffscreenCanvas(widthPx, heightPx);
    const ctx = offscreen.getContext('2d');
    if (!ctx) {
      throw new Error('Failed to get 2D context from OffscreenCanvas');
    }

    // Use full canvas - no padding for maximum space utilization
    const paperWidth = widthPx;
    const paperHeight = heightPx;
    
    // Draw background (full canvas)
    ctx.fillStyle = colors.background;
    ctx.fillRect(0, 0, widthPx, heightPx);
    
    // Draw paper (no rounded corners for cleaner look at small sizes)
    ctx.fillStyle = colors.paper;
    ctx.fillRect(0, 0, paperWidth, paperHeight);
    
    // Draw larger, more prominent bookmark (35% of width)
    const bookmarkWidth = Math.floor(widthPx * 0.35);
    const bookmarkHeight = Math.floor(heightPx * 0.8);
    const bookmarkX = widthPx - bookmarkWidth;
    const bookmarkY = 0;
    
    ctx.fillStyle = colors.bookmark;
    ctx.fillRect(bookmarkX, bookmarkY, bookmarkWidth, bookmarkHeight);
    
    // Draw prominent notch (60% of bookmark width for better visibility)
    const notchSize = Math.floor(bookmarkWidth * 0.6);
    ctx.fillStyle = colors.paper;
    ctx.beginPath();
    ctx.moveTo(bookmarkX, bookmarkY + bookmarkHeight);
    ctx.lineTo(bookmarkX + bookmarkWidth, bookmarkY + bookmarkHeight);
    ctx.lineTo(bookmarkX + bookmarkWidth / 2, bookmarkY + bookmarkHeight - notchSize);
    ctx.closePath();
    ctx.fill();

    return ctx.getImageData(0, 0, widthPx, heightPx);
  }

  getIconState(tabId: number): IconState {
    return this.tabStates.get(tabId) || IconState.DEFAULT;
  }

  async setPaperDetected(tabId: number): Promise<void> {
    await this.setIconState(tabId, IconState.DETECTED);
  }

  async setPaperTracked(tabId: number): Promise<void> {
    await this.setIconState(tabId, IconState.TRACKED);
  }

  async resetIcon(tabId: number): Promise<void> {
    await this.setIconState(tabId, IconState.DEFAULT);
  }

  async setBadgeText(tabId: number, text: string, color?: string): Promise<void> {
    try {
      await chrome.action.setBadgeText({ tabId, text });
      if (color) {
        await chrome.action.setBadgeBackgroundColor({ tabId, color });
      }
      logger.debug(`Set badge text "${text}" for tab ${tabId}`);
    } catch (error) {
      logger.error(`Failed to set badge text for tab ${tabId}:`, error);
    }
  }

  async clearBadge(tabId: number): Promise<void> {
    await this.setBadgeText(tabId, '');
  }

  // NEW: Utility method to add dynamic badges/indicators
  async setPaperCount(tabId: number, count: number): Promise<void> {
    if (count > 0) {
      await this.setBadgeText(tabId, count.toString(), '#FF4444');
    } else {
      await this.clearBadge(tabId);
    }
  }

  // NEW: Reset all tabs to default (useful for extension restart)
  async resetAllIcons(): Promise<void> {
    try {
      const tabs = await chrome.tabs.query({});
      await Promise.allSettled(
        tabs.map(tab => tab.id ? this.resetIcon(tab.id) : Promise.resolve())
      );
      logger.info('Reset all tab icons');
    } catch (error) {
      logger.error('Failed to reset all icons:', error);
    }
  }

  // NEW: Get cache statistics for debugging
  getCacheStats(): { states: number; totalSize: number } {
    let totalSize = 0;
    for (const imageDataMap of this.iconCache.values()) {
      for (const imageData of Object.values(imageDataMap)) {
        totalSize += imageData.data.length;
      }
    }
    return {
      states: this.iconCache.size,
      totalSize
    };
  }
}



---
File: extension/utils/logger.ts
---
// utils/logger.ts
// Logging utility wrapping loguru

/**
 * Logger class for consistent logging throughout the extension
 */
export class Logger {
  constructor(private module: string) {}
  
  /**
   * Log debug message
   */
  debug(message: string, data?: any): void {
    console.debug(`[${this.module}] ${message}`, data !== undefined ? data : '');
  }
  
  /**
   * Log info message
   */
  info(message: string, data?: any): void {
    console.info(`[${this.module}] ${message}`, data !== undefined ? data : '');
  }
  
  /**
   * Log warning message
   */
  warning(message: string, data?: any): void {
    console.warn(`[${this.module}] ${message}`, data !== undefined ? data : '');
  }

  /**
   * Alias for warning method (to match loguru API)
   */
  warn(message: string, data?: any): void {
    this.warning(message, data);
  }
  
  /**
   * Log error message
   */
  error(message: string, data?: any): void {
    console.error(`[${this.module}] ${message}`, data !== undefined ? data : '');
  }
}

/**
 * Loguru mock for browser extension use
 */
class LoguruMock {
  /**
   * Get logger for a module
   */
  getLogger(module: string): Logger {
    return new Logger(module);
  }
}

// Export singleton instance
export const loguru = new LoguruMock();



---
File: extension/utils/popup-manager.ts
---
// extension/utils/popup-manager.ts
// Popup management system integrated with source manager

import { SourceManager } from '../source-integration/types';
import { PaperManager } from '../papers/manager';
import { PaperMetadata } from '../papers/types';
import { loguru } from './logger';

const logger = loguru.getLogger('popup-manager');

/**
 * Popup handler information
 */
interface PopupHandler {
  selector: string;
  event: string;
  action: string;
}

/**
 * Popup message type
 */
interface ShowPopupMessage {
  type: 'showPopup';
  sourceId: string;
  paperId: string;
  html: string;
  handlers: PopupHandler[];
  position?: { x: number, y: number };
}

/**
 * Manages all popup-related functionality
 */
export class PopupManager {
  // Source manager and paper manager
  private sourceManagerProvider: () => SourceManager | null;
  private paperManagerProvider: () => PaperManager | null;
  
  /**
   * Create a new popup manager
   */
  constructor(
    sourceManagerProvider: () => SourceManager | null,
    paperManagerProvider: () => PaperManager | null
  ) {
    this.sourceManagerProvider = sourceManagerProvider;
    this.paperManagerProvider = paperManagerProvider;
    
    this.setupMessageListeners();
    logger.debug('Popup manager initialized');
  }
  
  /**
   * Set up message listeners for popup-related messages
   */
  private setupMessageListeners(): void {
    chrome.runtime.onMessage.addListener((message, sender, sendResponse) => {
      // Handle popup actions (ratings, notes, etc.)
      if (message.type === 'popupAction') {
        this.handlePopupAction(
          message.sourceId,
          message.paperId,
          message.action,
          message.data
        ).then(() => {
          sendResponse({ success: true });
        }).catch(error => {
          logger.error('Error handling popup action', error);
          sendResponse({ 
            success: false, 
            error: error instanceof Error ? error.message : 'Unknown error' 
          });
        });
        
        return true; // Will respond asynchronously
      }
      
      // Handle request to show annotation popup
      if (message.type === 'showAnnotationPopup' && sender.tab?.id) {
        this.handleShowAnnotationPopup(
          sender.tab.id,
          message.sourceId,
          message.paperId,
          message.position
        ).then(() => {
          sendResponse({ success: true });
        }).catch(error => {
          logger.error('Error showing popup', error);
          sendResponse({ 
            success: false, 
            error: error instanceof Error ? error.message : 'Unknown error'
          });
        });
        
        return true; // Will respond asynchronously
      }
      
      return false; // Not handled
    });
  }
  
  /**
   * Handle a request to show an annotation popup
   */
  private async handleShowAnnotationPopup(
    tabId: number,
    sourceId: string,
    paperId: string,
    position: { x: number, y: number }
  ): Promise<void> {
    logger.debug(`Showing annotation popup for ${sourceId}:${paperId}`);
    
    // Check if we have source and paper manager
    const sourceManager = this.sourceManagerProvider();
    const paperManager = this.paperManagerProvider();
    
    if (!sourceManager) {
      throw new Error('Source manager not initialized');
    }
    
    if (!paperManager) {
      throw new Error('Paper manager not initialized');
    }
    
    try {
      // Get paper data
      const paper = await paperManager.getPaper(sourceId, paperId);
      
      // Create popup HTML
      const html = this.createPopupHtml(paper || { 
        sourceId, 
        paperId,
        title: paperId,
        authors: '',
        abstract: '',
        url: '',
        timestamp: new Date().toISOString(),
        publishedDate: '',
        tags: [],
        rating: 'novote'
      });
      
      // Get handlers
      const handlers = this.getStandardPopupHandlers();
      
      // Send message to content script to show popup
      const message: ShowPopupMessage = {
        type: 'showPopup',
        sourceId,
        paperId,
        html,
        handlers,
        position
      };
      
      await chrome.tabs.sendMessage(tabId, message);
      
      logger.debug(`Sent popup to content script for ${sourceId}:${paperId}`);
    } catch (error) {
      logger.error(`Error showing popup for ${sourceId}:${paperId}`, error);
      throw error;
    }
  }
  
  /**
   * Handle popup actions (ratings, notes, etc.)
   */
  private async handlePopupAction(
    sourceId: string,
    paperId: string,
    action: string,
    data: any
  ): Promise<void> {
    const paperManager = this.paperManagerProvider();
    
    if (!paperManager) {
      throw new Error('Paper manager not initialized');
    }
    
    logger.debug(`Handling popup action: ${action}`, { sourceId, paperId });
    
    try {
      if (action === 'rate') {
        await paperManager.updateRating(sourceId, paperId, data.value);
        logger.info(`Updated rating for ${sourceId}:${paperId} to ${data.value}`);
      } 
      else if (action === 'saveNotes') {
        if (data.value) {
          await paperManager.logAnnotation(sourceId, paperId, 'notes', data.value);
          logger.info(`Saved notes for ${sourceId}:${paperId}`);
        }
      }
    } catch (error) {
      logger.error(`Error handling action ${action} for ${sourceId}:${paperId}`, error);
      throw error;
    }
  }
  
  /**
   * Create HTML for paper popup
   */
  private createPopupHtml(paper: PaperMetadata): string {
    return `
      <div class="paper-popup-header">${paper.title || paper.paperId}</div>
      <div class="paper-popup-meta">${paper.authors || ''}</div>
      
      <div class="paper-popup-buttons">
        <button class="vote-button" data-vote="thumbsup" id="btn-thumbsup" ${paper.rating === 'thumbsup' ? 'class="active"' : ''}>ðŸ‘ Interesting</button>
        <button class="vote-button" data-vote="thumbsdown" id="btn-thumbsdown" ${paper.rating === 'thumbsdown' ? 'class="active"' : ''}>ðŸ‘Ž Not Relevant</button>
      </div>
      
      <textarea placeholder="Add notes about this paper..." id="paper-notes"></textarea>
      
      <div class="paper-popup-actions">
        <button class="save-button" id="btn-save">Save</button>
      </div>
    `;
  }
  
  /**
   * Get standard popup event handlers
   */
  private getStandardPopupHandlers(): PopupHandler[] {
    return [
      { selector: '#btn-thumbsup', event: 'click', action: 'rate' },
      { selector: '#btn-thumbsdown', event: 'click', action: 'rate' },
      { selector: '#btn-save', event: 'click', action: 'saveNotes' }
    ];
  }
}



---
File: extension/utils/session-service.ts
---
// session-service.ts
// Simplified session tracking service for background script

import { loguru } from './logger';
import { PaperManager } from '../papers/manager';
import { ReadingSessionData, PaperMetadata } from '../papers/types';

const logger = loguru.getLogger('session-service');

/**
 * Session tracking service for paper reading sessions
 * 
 * Manages session state, heartbeats, and persistence
 * Designed for use in the background script (Service Worker)
 */
export class SessionService {
  private activeSession: {
    sourceId: string;
    paperId: string;
    startTime: Date;
    heartbeatCount: number;
    lastHeartbeatTime: Date;
  } | null = null;
  
  private timeoutId: number | null = null;
  private paperMetadata: Map<string, PaperMetadata> = new Map();
  
  // Configuration
  private readonly HEARTBEAT_TIMEOUT = 15000; // 15 seconds
  
  /**
   * Create a new session service
   */
  constructor(private paperManager: PaperManager | null) {
    logger.debug('Session service initialized');
  }
  
  /**
   * Start a new session for a paper
   */
  startSession(sourceId: string, paperId: string, metadata?: PaperMetadata): void {
    // End any existing session
    this.endSession();
    
    // Create new session
    this.activeSession = {
      sourceId,
      paperId,
      startTime: new Date(),
      heartbeatCount: 0,
      lastHeartbeatTime: new Date()
    };
    
    // Store metadata if provided
    if (metadata) {
      const key = `${sourceId}:${paperId}`;
      this.paperMetadata.set(key, metadata);
      logger.debug(`Stored metadata for ${key}`);
    }
    
    // Start timeout check
    this.scheduleTimeoutCheck();
    
    logger.info(`Started session for ${sourceId}:${paperId}`);
  }
  
  /**
   * Record a heartbeat for the current session
   */
  recordHeartbeat(): boolean {
    if (!this.activeSession) {
      return false;
    }
    
    this.activeSession.heartbeatCount++;
    this.activeSession.lastHeartbeatTime = new Date();
    
    // Reschedule timeout
    this.scheduleTimeoutCheck();
    
    if (this.activeSession.heartbeatCount % 12 === 0) { // Log every minute (12 x 5sec heartbeats)
      logger.debug(`Session received ${this.activeSession.heartbeatCount} heartbeats`);
    }
    
    return true;
  }
  
  /**
   * Schedule a check for heartbeat timeout
   */
  private scheduleTimeoutCheck(): void {
    // Clear existing timeout
    if (this.timeoutId !== null) {
      clearTimeout(this.timeoutId);
    }
    
    // Set new timeout
    this.timeoutId = self.setTimeout(() => {
      this.checkTimeout();
    }, this.HEARTBEAT_TIMEOUT);
  }
  
  /**
   * Check if the session has timed out due to missing heartbeats
   */
  private checkTimeout(): void {
    if (!this.activeSession) return;
    
    const now = Date.now();
    const lastTime = this.activeSession.lastHeartbeatTime.getTime();
    
    if ((now - lastTime) > this.HEARTBEAT_TIMEOUT) {
      logger.info('Session timeout detected');
      this.endSession();
    } else {
      this.scheduleTimeoutCheck();
    }
  }
  
  /**
   * End the current session and get the data
   */
  endSession(): ReadingSessionData | null {
    if (!this.activeSession) return null;
    
    // Clear timeout
    if (this.timeoutId !== null) {
      clearTimeout(this.timeoutId);
      this.timeoutId = null;
    }
    
    const { sourceId, paperId, startTime, heartbeatCount } = this.activeSession;
    const endTime = new Date();
    
    // Calculate duration (5 seconds per heartbeat)
    const duration = heartbeatCount * 5;
    
    // Calculate total elapsed time
    const totalElapsed = endTime.getTime() - startTime.getTime();
    const totalElapsedSeconds = Math.round(totalElapsed / 1000);
    
    // Set idle seconds to the difference (for backward compatibility)
    const idleSeconds = Math.max(0, totalElapsedSeconds - duration);
    
    // Create session data
    const sessionData: ReadingSessionData = {
      session_id: `session_${Date.now()}_${Math.random().toString(36).substring(2, 9)}`,
      source_id: sourceId,
      paper_id: paperId,
      start_time: startTime.toISOString(),
      end_time: endTime.toISOString(),
      heartbeat_count: heartbeatCount,
      duration_seconds: duration,
      // Legacy fields
      idle_seconds: idleSeconds,
      total_elapsed_seconds: totalElapsedSeconds
    };
    
    // Store session if it was meaningful and we have a paper manager
    if (this.paperManager && heartbeatCount > 0) {
      const metadata = this.getPaperMetadata(sourceId, paperId);
      
      this.paperManager.logReadingSession(sourceId, paperId, sessionData, metadata)
        .catch(err => logger.error('Failed to store session', err));
    }
    
    logger.info(`Ended session for ${sourceId}:${paperId}`, {
      duration,
      heartbeats: heartbeatCount
    });
    
    // Clear active session
    this.activeSession = null;
    
    return sessionData;
  }
  
  /**
   * Check if a session is currently active
   */
  hasActiveSession(): boolean {
    return this.activeSession !== null;
  }
  
  /**
   * Get information about the current session
   */
  getCurrentSession(): { sourceId: string, paperId: string } | null {
    if (!this.activeSession) return null;
    
    return {
      sourceId: this.activeSession.sourceId,
      paperId: this.activeSession.paperId
    };
  }
  
  /**
   * Get paper metadata for the current or specified session
   */
  getPaperMetadata(sourceId?: string, paperId?: string): PaperMetadata | undefined {
    if (!sourceId || !paperId) {
      if (!this.activeSession) return undefined;
      sourceId = this.activeSession.sourceId;
      paperId = this.activeSession.paperId;
    }
    
    return this.paperMetadata.get(`${sourceId}:${paperId}`);
  }
  
  /**
   * Store paper metadata
   */
  storePaperMetadata(metadata: PaperMetadata): void {
    const key = `${metadata.sourceId}:${metadata.paperId}`;
    this.paperMetadata.set(key, metadata);
  }
  
  /**
   * Get time since last heartbeat in milliseconds
   */
  getTimeSinceLastHeartbeat(): number | null {
    if (!this.activeSession) {
      return null;
    }
    
    return Date.now() - this.activeSession.lastHeartbeatTime.getTime();
  }
  
  /**
   * Get session statistics for debugging
   */
  getSessionStats(): any {
    if (!this.activeSession) {
      return { active: false };
    }
    
    return {
      active: true,
      sourceId: this.activeSession.sourceId,
      paperId: this.activeSession.paperId,
      startTime: this.activeSession.startTime.toISOString(),
      heartbeatCount: this.activeSession.heartbeatCount,
      lastHeartbeatTime: this.activeSession.lastHeartbeatTime.toISOString(),
      elapsedTime: Math.round((Date.now() - this.activeSession.startTime.getTime()) / 1000)
    };
  }
}



---
File: frontend/index.html
---
<!DOCTYPE html>
<!-- frontend/index.html - Root of GitHub Pages site -->
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>DigThatData Papers Feed</title>
  
  <!-- Tabulator CSS and JS -->
  <link href="https://unpkg.com/tabulator-tables@6.3.0/dist/css/tabulator.min.css" rel="stylesheet">
  <script src="https://unpkg.com/tabulator-tables@6.3.0/dist/js/tabulator.min.js"></script>

  <!-- D3.js for color scales -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/d3/7.8.5/d3.min.js"></script>
  
  <!-- Date parsing and normalizaiton -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/chrono-node/1.0.5/chrono.min.js"></script>
  
  <!-- Font Awesome for icons -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css">
  <link rel="stylesheet" href="papersfeed.css">
</head>
<body>
  <div class="header">
    <div class="header-title">
        <h1>What I Am Reading</h1>
        <p class="header-desc">By <a href="https://bsky.app/profile/digthatdata.bsky.social">@DigThatData</a>. Learn more <a href="https://github.com/dmarx/papers-feed-template">here</a>.</p>
    </div>

    <div class="heatmap-container">
      <div class="heatmap-title">
        <select id="heatmap-metric-selector" class="heatmap-dropdown">
          <option value="papers">Papers per day</option>
          <option value="time">Reading time per day</option>
          <option value="sessions">Sessions per day</option>
          <option value="discoveries">Papers discovered per day</option>
        </select>

        <div class="heatmap-legend">
          <span>Less</span>
          <div class="legend-cell" style="background-color: #ebedf0;"></div>
          <div class="legend-cell" style="background-color: #c6e48b;"></div>
          <div class="legend-cell" style="background-color: #7bc96f;"></div>
          <div class="legend-cell" style="background-color: #239a3b;"></div>
          <div class="legend-cell" style="background-color: #196127;"></div>
          <span>More</span>
        </div>

      </div>
      <div id="reading-heatmap"></div>
    </div>

    <div class="controls">
      <div class="search-box">
        <input type="text" id="search-input" placeholder="Search papers by title, author, or content...">
        <button class="clear-search-btn" id="clear-search" title="Clear search">Ã—</button>
      </div>
      <button class="filter-button" id="sidebar-toggle">
        <i class="fas fa-filter"></i> Filters
      </button>
    </div>
  </div>

  <!-- Filter Status Bar -->
  <div class="filter-status-bar" id="filter-status-bar" style="display: none;">
    <div class="filter-status-content">
      <span class="filter-status-label">Active filters:</span>
      <div class="filter-badges" id="filter-badges"></div>
      <button class="clear-all-filters-btn" id="clear-all-filters">Clear All</button>
    </div>
  </div>
  
  <div class="dashboard-container">
    <div class="main-content">
      <div id="papers-table">
        <div class="loading">Loading papers data...</div>
      </div>
    </div>
    
    <!-- Filter Sidebar -->
    <div class="sidebar" id="sidebar">
      <h3>Filters</h3>
      
      <div class="filter-section">
        <h4>Publication Date</h4>
        <div id="date-filter-controls">
          <div>
            <label for="date-filter-from">From:</label>
            <input type="date" id="date-filter-from">
          </div>
          <div style="margin-top: 10px;">
            <label for="date-filter-to">To:</label>
            <input type="date" id="date-filter-to">
          </div>
          <div style="margin-top: 15px;">
            <button id="apply-date-filter" class="filter-button">Apply</button>
            <button id="clear-date-filter" class="filter-button">Clear</button>
          </div>
        </div>
      </div>
      
      <div class="filter-section">
        <h4>Reading Time</h4>
        <div>
          <label for="min-reading-time">Minimum (minutes):</label>
          <input type="number" id="min-reading-time" min="0" step="1">
        </div>
        <div style="margin-top: 10px;">
          <button id="apply-reading-filter" class="filter-button">Apply</button>
          <button id="clear-reading-filter" class="filter-button">Clear</button>
        </div>
      </div>
      
      <div class="filter-section">
        <h4>Interaction Days</h4>
        <div>
          <label for="min-interaction-days">Minimum days:</label>
          <input type="number" id="min-interaction-days" min="0" step="1">
        </div>
        <div style="margin-top: 10px;">
          <button id="apply-days-filter" class="filter-button">Apply</button>
          <button id="clear-days-filter" class="filter-button">Clear</button>
        </div>
      </div>
      
      <div class="filter-section">
        <h4>Reset All Filters</h4>
        <button id="reset-all-filters" class="filter-button">Reset All</button>
      </div>
    </div>
    
    <div class="sidebar" id="details-sidebar">
      <button class="close-button" onclick="hideDetails()">Ã—</button>
      <div class="details-scroll-content">
        <div id="details-content"></div>
      </div>
    </div>
  </div>
  
  <button id="filter-toggle-btn" title="Toggle Filters">
    <i class="fas fa-filter"></i>
  </button>

  <script src="papersfeed.js"></script>
</body>
</html>



---
File: frontend/papersfeed.css
---
/* frontend/papersfeed.css */
body {
  margin: 0;
  padding: 0;
  font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
  background-color: #f5f7fa;
  display: flex;
  flex-direction: column;
  height: 100vh;
  overflow: hidden;
}

.header {
  display: flex;
  justify-content: space-between;
  align-items: center;
  gap: 30px;
  padding: 20px;
  background-color: white;
  box-shadow: 0 2px 4px rgba(0,0,0,0.1);
}

.header-title {
  flex-shrink: 0;
}

h1 {
  margin: 0 0 10px 0;
  color: #333;
}

/* Heatmap container styles */
.heatmap-container {
  flex: 1;
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  min-width: 0; /* Allow shrinking */
  padding: 0 20px;
  width: 100%; /* Ensure full width */
}

.heatmap-title {
  font-size: 12px;
  color: #666;
  margin-bottom: 8px;
  font-weight: 500;
  min-height: 16px; /* Reserve space to prevent layout shift */
  display: flex;
  align-items: center;
  justify-content: space-between;
  gap: 20px; /* Space between dropdown and legend */
  /* Width will be set dynamically by JavaScript to match heatmap */
}

.heatmap-dropdown {
  font-size: 12px;
  color: #666;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
  padding: 2px 6px;
  cursor: pointer;
  font-weight: 500;
  outline: none;
  flex-shrink: 0; /* Don't shrink the dropdown */
}

.heatmap-dropdown:hover {
  border-color: #1a73e8;
}

.heatmap-dropdown:focus {
  border-color: #1a73e8;
  box-shadow: 0 0 0 2px rgba(26, 115, 232, 0.2);
}

.heatmap-legend {
  display: flex;
  align-items: center;
  gap: 4px;
  font-size: 11px;
  color: #666;
  flex-shrink: 0; /* Don't shrink the legend */
}

.heatmap-legend {
  display: flex;
  align-items: center;
  gap: 4px;
  font-size: 11px;
  color: #666;
  flex-shrink: 0; /* Don't shrink the legend */
}

.legend-cell {
  width: 10px;
  height: 10px;
  border: 1px solid #d1d5db;
  border-radius: 2px;
}

/* Heatmap SVG styles */
.heatmap-cell {
  stroke: #fff;
  stroke-width: 1px;
  cursor: pointer;
  rx: 2px;
  ry: 2px;
}

.heatmap-cell:hover {
  stroke: #333;
  stroke-width: 2px;
}

.month-label {
  font-size: 10px;
  fill: #666;
  font-weight: 500;
}

.day-label {
  font-size: 9px;
  fill: #666;
}

/* Heatmap tooltip */
.heatmap-tooltip {
  position: absolute;
  background: rgba(0, 0, 0, 0.9);
  color: white;
  padding: 8px 12px;
  border-radius: 6px;
  font-size: 12px;
  pointer-events: none;
  z-index: 1000;
  white-space: nowrap;
  box-shadow: 0 4px 12px rgba(0, 0, 0, 0.3);
}

.controls {
  flex: 1;
  max-width: 500px;
  position: relative;
}

.search-box {
  flex-grow: 1;
  position: relative;
}

#search-input {
  width: 100%;
  padding: 12px 40px 12px 16px;
  border: 2px solid #e1e5e9;
  border-radius: 8px;
  font-size: 16px;
  transition: border-color 0.2s;
  box-sizing: border-box;
}

#search-input:focus {
  outline: none;
  border-color: #1a73e8;
}

.clear-search-btn {
  position: absolute;
  right: 10px;
  top: 50%;
  transform: translateY(-50%);
  background: none;
  border: none;
  font-size: 18px;
  color: #666;
  cursor: pointer;
  width: 24px;
  height: 24px;
  border-radius: 50%;
  display: flex;
  align-items: center;
  justify-content: center;
}

.clear-search-btn:hover {
  background-color: #f0f0f0;
  color: #333;
}

.filter-button {
  padding: 8px 15px;
  background-color: #f0f0f0;
  border: 1px solid #ddd;
  border-radius: 4px;
  cursor: pointer;
  display: flex;
  align-items: center;
  gap: 5px;
}

.filter-button:hover {
  background-color: #e8e8e8;
}

/* Filter Status Bar */
.filter-status-bar {
  background-color: #e3f2fd;
  border-bottom: 1px solid #bbdefb;
  padding: 10px 20px;
  transition: all 0.3s ease;
}

.filter-status-content {
  display: flex;
  align-items: center;
  gap: 10px;
  flex-wrap: wrap;
}

.filter-status-label {
  font-weight: 600;
  color: #1565c0;
  font-size: 14px;
}

.filter-badges {
  display: flex;
  gap: 8px;
  flex-wrap: wrap;
  flex: 1;
}

.filter-badge {
  display: inline-flex;
  align-items: center;
  gap: 6px;
  background-color: #1976d2;
  color: white;
  padding: 4px 8px;
  border-radius: 16px;
  font-size: 12px;
  font-weight: 500;
}

.filter-badge-remove {
  background: none;
  border: none;
  color: white;
  cursor: pointer;
  font-size: 14px;
  width: 16px;
  height: 16px;
  border-radius: 50%;
  display: flex;
  align-items: center;
  justify-content: center;
  margin-left: 2px;
}

.filter-badge-remove:hover {
  background-color: rgba(255, 255, 255, 0.2);
}

.clear-all-filters-btn {
  background-color: #f44336;
  color: white;
  border: none;
  padding: 6px 12px;
  border-radius: 4px;
  cursor: pointer;
  font-size: 12px;
  font-weight: 500;
}

.clear-all-filters-btn:hover {
  background-color: #d32f2f;
}

.dashboard-container {
  display: flex;
  flex: 1;
  overflow: hidden;
  position: relative;
}

.main-content {
  flex: 1;
  overflow: hidden;
  display: flex;
  flex-direction: column;
}

#papers-table {
  flex: 1;
  width: 100%;
}

/* Shared sidebar styles */
.sidebar {
  background-color: white;
  box-shadow: -2px 0 5px rgba(0,0,0,0.1);
  overflow: hidden;
  transition: all 0.3s ease;
  position: absolute;
  right: 0;
  top: 0;
  bottom: 0;
  width: 0;
  z-index: 100;
}

.sidebar.active {
  width: 400px;
  padding: 20px;
}

/* Filter sidebar specific */
#sidebar h3 {
  margin-top: 0;
  margin-bottom: 15px;
}

.filter-section {
  margin-bottom: 20px;
}

.filter-section h4 {
  margin-top: 0;
  margin-bottom: 10px;
  border-bottom: 1px solid #eee;
  padding-bottom: 5px;
}

/* Details sidebar specific */
#details-sidebar {
  z-index: 101; /* Higher than filter sidebar */
}

.details-header {
  display: flex;
  justify-content: space-between;
  align-items: flex-start;
  margin-bottom: 20px;
}

.close-button {
  position: absolute;
  top: 15px;
  right: 15px;
  background: none;
  border: none;
  font-size: 20px;
  cursor: pointer;
  color: #666;
  padding: 8px;
  z-index: 10;
}

.close-button:hover {
  color: #333;
}

.details-scroll-content {
  height: 100%;
  overflow-y: auto;
  padding: 20px 20px 20px 20px; /* Top padding leaves space for close button */
}

.details-header h2 {
  margin: 0;
  line-height: 1.3;
}

.detail-section {
  margin-bottom: 25px;
  background-color: #f9f9f9;
  border-radius: 6px;
  padding: 15px;
}

.detail-section h3 {
  margin-top: 0;
  margin-bottom: 15px;
  color: #333;
  font-size: 1.1em;
  border-bottom: 1px solid #eee;
  padding-bottom: 8px;
}

.detail-table {
  width: 100%;
  border-collapse: collapse;
}

.detail-table th {
  text-align: left;
  padding: 8px;
  color: #666;
  font-weight: 600;
  width: 30%;
  vertical-align: top;
}

.detail-table td {
  padding: 8px;
  vertical-align: top;
}

.abstract-box {
  max-height: 300px;
  overflow-y: auto;
  padding: 15px;
  background-color: white;
  border-radius: 4px;
  line-height: 1.5;
  white-space: pre-line;
}

.tag {
  display: inline-block;
  background-color: #e8f0fe;
  padding: 3px 8px;
  margin: 2px;
  border-radius: 12px;
  font-size: 12px;
}

.loading {
  text-align: center;
  padding: 40px;
  font-size: 18px;
  color: #666;
}

.sessions-table {
  width: 100%;
  border-collapse: collapse;
  margin-top: 10px;
}

.sessions-table th {
  background-color: #f2f2f2;
  padding: 8px;
  text-align: left;
}

.sessions-table td {
  padding: 8px;
  border-bottom: 1px solid #eee;
}

/* Toggle button for the sidebar */
#filter-toggle-btn {
  position: fixed;
  right: 20px;
  bottom: 20px;
  width: 50px;
  height: 50px;
  border-radius: 50%;
  background-color: #1a73e8;
  color: white;
  border: none;
  box-shadow: 0 2px 5px rgba(0,0,0,0.2);
  cursor: pointer;
  display: flex;
  align-items: center;
  justify-content: center;
  font-size: 20px;
  transition: background-color 0.3s;
  z-index: 102; /* Above both sidebars */
}

#filter-toggle-btn:hover {
  background-color: #1558b7;
}

/* Tabulator customizations */
.tabulator {
  border: none;
  background-color: transparent;
}

.tabulator-row {
  border-bottom: 1px solid #f0f0f0;
  cursor: pointer;
}

.tabulator-row:hover {
  background-color: #f2f8fd !important;
}

.tabulator-row.tabulator-row-even {
  background-color: #fafafa;
}

/* Responsive adjustments */
@media (max-width: 1200px) {
  .heatmap-container {
    display: none; /* Hide heatmap on smaller screens */
  }
}

@media (max-width: 768px) {
  .header {
    flex-direction: column;
    align-items: stretch;
    gap: 15px;
  }
  
  .controls {
    max-width: none;
  }
  
  .sidebar.active {
    width: 85%;
  }
  
  .detail-grid {
    grid-template-columns: 1fr;
  }

  .filter-status-content {
    flex-direction: column;
    align-items: stretch;
    gap: 8px;
  }

  .filter-badges {
    justify-content: flex-start;
  }
}



---
File: frontend/papersfeed.js
---
// frontend/papersfeed.js
// Global variables
let table;
let allData = [];
let currentDetailsPaper = null;
let readingTimeColorScale = null;
let interactionDaysColorScale = null;
let readingActivityData = [];
let currentHeatmapMetric = 'papers';

// Utility function to normalize dates using Chrono
function normalizeDate(dateString) {
  if (!dateString) return null;
  
  try {
    // Try to parse with Chrono
    const parsedDate = chrono.parseDate(dateString);
    
    if (parsedDate) {
      // Return in YYYY-MM-DD format for consistency
      return parsedDate.toISOString().split('T')[0];
    }
    
    // Fallback to native Date parsing if Chrono fails
    const fallbackDate = new Date(dateString);
    if (!isNaN(fallbackDate.getTime())) {
      return fallbackDate.toISOString().split('T')[0];
    }
    
    // If all parsing fails, return original string
    console.warn(`Could not parse date: ${dateString}`);
    return dateString;
    
  } catch (error) {
    console.warn(`Date parsing error for "${dateString}":`, error);
    return dateString;
  }
}

/**
 * Calculate the number of days between two dates
 * @param {string} startDate - Date in 'YYYY-MM-DD' format
 * @param {string} endDate - Date in 'YYYY-MM-DD' format
 * @returns {number} Number of days between the dates (positive if endDate is after startDate)
 */
function daysBetween(startDate, endDate) {
  const start = new Date(startDate);
  const end = new Date(endDate);
  
  // Calculate the difference in milliseconds
  const diffTime = end - start;
  
  // Convert to days (1 day = 24 * 60 * 60 * 1000 milliseconds)
  const diffDays = Math.ceil(diffTime / (1000 * 60 * 60 * 24));
  
  return diffDays;
}

// Filter Manager for unified filter state
class FilterManager {
  constructor(table) {
    this.table = table;
    this.filters = new Map(); // name -> {fn, description}
    this.listeners = new Set();
  }
  
  setFilter(name, filterFunction, description) {
    this.filters.set(name, { fn: filterFunction, desc: description });
    this.applyFilters();
    this.notifyListeners();
  }
  
  removeFilter(name) {
    this.filters.delete(name);
    this.applyFilters();
    this.notifyListeners();
  }
  
  clearAll() {
    this.filters.clear();
    this.applyFilters();
    this.notifyListeners();
  }
  
  applyFilters() {
    if (this.filters.size === 0) {
      this.table.clearFilter();
    } else {
      this.table.setFilter((data) => {
        return Array.from(this.filters.values())
          .every(filter => filter.fn(data));
      });
    }
    
    // Update heatmap with filtered data
    this.updateHeatmap();
  }
  
  updateHeatmap() {
    // If viewing paper details, show only that paper's activity
    if (currentDetailsPaper) {
      const singlePaperActivity = extractReadingActivityData([currentDetailsPaper], currentHeatmapMetric);
      createReadingHeatmap(singlePaperActivity);
      return;
    }
    
    // Otherwise, get currently filtered data from the table
    const filteredData = this.table.getData("active");
    console.log("Updating heatmap with", filteredData.length, "filtered papers");
    
    // Extract reading activity from filtered data
    const filteredActivityData = extractReadingActivityData(filteredData, currentHeatmapMetric);
    
    // Recreate the heatmap with filtered data
    createReadingHeatmap(filteredActivityData);
  }
  
  getActiveFilters() {
    return Array.from(this.filters.entries())
      .map(([name, {desc}]) => ({name, description: desc}));
  }
  
  addListener(callback) {
    this.listeners.add(callback);
  }
  
  removeListener(callback) {
    this.listeners.delete(callback);
  }
  
  notifyListeners() {
    this.listeners.forEach(callback => callback());
  }
}

// Filter Status Bar UI Component
class FilterStatusBar {
  constructor(filterManager) {
    this.filterManager = filterManager;
    this.container = document.getElementById('filter-status-bar');
    this.badgeContainer = document.getElementById('filter-badges');
    this.clearAllBtn = document.getElementById('clear-all-filters');
    
    // Listen for filter changes
    this.filterManager.addListener(() => this.render());
    
    // Set up clear all button
    this.clearAllBtn.addEventListener('click', () => {
      this.filterManager.clearAll();
    });
  }
  
  render() {
    const activeFilters = this.filterManager.getActiveFilters();
    
    if (activeFilters.length === 0) {
      this.container.style.display = 'none';
      return;
    }
    
    this.container.style.display = 'block';
    this.badgeContainer.innerHTML = '';
    
    activeFilters.forEach(({name, description}) => {
      const badge = this.createFilterBadge(name, description);
      this.badgeContainer.appendChild(badge);
    });
  }
  
  createFilterBadge(name, description) {
    const badge = document.createElement('div');
    badge.className = 'filter-badge';
    
    // Add preview styling for search preview
    if (name === 'search-preview') {
      badge.classList.add('preview');
    }
    
    const text = document.createElement('span');
    text.textContent = description;
    
    const removeBtn = document.createElement('button');
    removeBtn.className = 'filter-badge-remove';
    removeBtn.innerHTML = 'Ã—';
    removeBtn.title = `Remove ${description} filter`;
    removeBtn.addEventListener('click', () => {
      this.filterManager.removeFilter(name);
      
      // If removing search preview, also clear the input
      if (name === 'search-preview') {
        document.getElementById("search-input").value = "";
        currentPreviewSearchTerm = null;
      }
    });
    
    badge.appendChild(text);
    badge.appendChild(removeBtn);
    
    return badge;
  }
}

// Global filter manager instance
let filterManager;
let filterStatusBar;

// Extract reading activity data from interaction data
function extractReadingActivityData(data, metric = 'papers') {
  const dailyActivity = new Map();
  
  data.forEach(paper => {
    if (paper.rawInteractionData && paper.rawInteractionData.length > 0) {
      paper.rawInteractionData.forEach(interaction => {
        if (interaction.type === "reading_session" && interaction.timestamp) {
          const date = new Date(interaction.timestamp);
          const dateStr = d3.timeFormat("%Y-%m-%d")(date);
          
          if (!dailyActivity.has(dateStr)) {
            dailyActivity.set(dateStr, {
              papers: new Set(),
              totalTime: 0,
              sessions: 0,
              discoveries: new Set()
            });
          }
          
          const dayData = dailyActivity.get(dateStr);
          dayData.papers.add(paper.paperKey);
          dayData.totalTime += interaction.data.duration_seconds || 0;
          dayData.sessions += 1;
        }
      });
    }
    
    // Track paper discoveries (first read date)
    if (paper.firstRead) {
      const firstReadStr = paper.firstRead;
      if (!dailyActivity.has(firstReadStr)) {
        dailyActivity.set(firstReadStr, {
          papers: new Set(),
          totalTime: 0,
          sessions: 0,
          discoveries: new Set()
        });
      }
      dailyActivity.get(firstReadStr).discoveries.add(paper.paperKey);
    }
  });
  
  // Convert to array format based on selected metric
  const result = Array.from(dailyActivity.entries()).map(([dateStr, dayData]) => {
    let count;
    switch (metric) {
      case 'papers':
        count = dayData.papers.size;
        break;
      case 'time':
        count = Math.round(dayData.totalTime / 60); // Convert to minutes
        break;
      case 'sessions':
        count = dayData.sessions;
        break;
      case 'discoveries':
        count = dayData.discoveries.size;
        break;
      default:
        count = dayData.papers.size;
    }
    
    return {
      date: new Date(dateStr),
      count: count
    };
  });
  
  return result.filter(d => d.count > 0).sort((a, b) => a.date - b.date);
}

// Create reading activity heatmap
function createReadingHeatmap(data) {
  const container = d3.select("#reading-heatmap");
  container.selectAll("*").remove(); // Clear existing content
  
  if (!data || data.length === 0) {
    container.append("div")
      .style("text-align", "center")
      .style("color", "#666")
      .style("font-size", "12px")
      .style("padding", "20px")
      .text(currentDetailsPaper ? "No reading sessions for this paper" : "No reading activity data available");
    return;
  }
  
  // Calculate date range - 8 months back, ending today
  const endDateTime = new Date();
  endDateTime.setHours(23, 59, 59, 999); // End of today
  
  const startDateTime = new Date(endDateTime);
  startDateTime.setMonth(startDateTime.getMonth() - 8);
  startDateTime.setHours(0, 0, 0, 0); // Start of day 8 months ago
  
  // Calculate the Sunday of the week containing endDateTime (for right alignment)
  const endSunday = new Date(endDateTime);
  endSunday.setDate(endDateTime.getDate() - endDateTime.getDay());
  endSunday.setHours(0, 0, 0, 0);
  
  // Calculate how many weeks we need to show
  const totalWeeks = Math.ceil(d3.timeWeek.count(startDateTime, endSunday)) + 1;
  
  // Dimensions
  const cellSize = 11;
  const cellGap = 2;
  const width = totalWeeks * (cellSize + cellGap);
  const height = 7 * (cellSize + cellGap) + 20; // 7 days + month labels
  
  // Create SVG
  const svg = container
    .append("svg")
    .attr("width", width)
    .attr("height", height);
  
  // Set the header width to match the heatmap width
  const headerElement = document.querySelector('.heatmap-title');
  if (headerElement) {
    headerElement.style.width = width + 'px';
  }
  
  // Create tooltip
  let tooltip = d3.select("body").select(".heatmap-tooltip");
  if (tooltip.empty()) {
    tooltip = d3.select("body")
      .append("div")
      .attr("class", "heatmap-tooltip")
      .style("opacity", 0);
  }
  
  // Process data into a map for quick lookup
  const dataMap = new Map();
  data.forEach(d => {
    const dateStr = d3.timeFormat("%Y-%m-%d")(d.date);
    dataMap.set(dateStr, d.count);
  });
  
  // Create color scale - let D3 handle everything
  const maxCount = d3.max(data, d => d.count) || 1;

  const paletteHeatmap = d3.interpolateGreens; //d3.interpolateYlGn; //d3.interpolateBlues;
  const colorScale = maxCount > 10 
    ? d3.scaleSequentialLog(paletteHeatmap).domain([1, maxCount])
    : d3.scaleSequential(paletteHeatmap).domain([0, maxCount]);
  
  // Generate all dates in our range
  const allDates = d3.timeDays(startDateTime, new Date(endDateTime.getTime() + 24 * 60 * 60 * 1000));
  
  // Create cells
  const cells = svg.selectAll(".heatmap-cell")
    .data(allDates)
    .enter()
    .append("rect")
    .attr("class", "heatmap-cell")
    .attr("width", cellSize)
    .attr("height", cellSize)
    .attr("x", d => {
      // Calculate week position relative to the end date (right-aligned)
      const weeksSinceStart = d3.timeWeek.count(startDateTime, d);
      return weeksSinceStart * (cellSize + cellGap);
    })
    .attr("y", d => {
      const dayOfWeek = d.getDay();
      return dayOfWeek * (cellSize + cellGap) + 20; // Offset for month labels
    })
    .attr("fill", d => {
      const dateStr = d3.timeFormat("%Y-%m-%d")(d);
      const count = dataMap.get(dateStr) || 0;
      return colorScale(count);
    })
    .on("mouseover", function(event, d) {
      const dateStr = d3.timeFormat("%Y-%m-%d")(d);
      const count = dataMap.get(dateStr) || 0;
      const formatDate = d3.timeFormat("%B %d, %Y");
      
      tooltip.transition()
        .duration(200)
        .style("opacity", .9);
      
      // Adjust tooltip text based on context and metric
      let paperText;
      if (currentDetailsPaper) {
        paperText = count > 0 ? "Read this paper" : "No activity";
      } else {
        switch (currentHeatmapMetric) {
          case 'papers':
            paperText = `${count} paper${count !== 1 ? 's' : ''} read`;
            break;
          case 'time':
            paperText = `${count} minute${count !== 1 ? 's' : ''} reading`;
            break;
          case 'sessions':
            paperText = `${count} session${count !== 1 ? 's' : ''}`;
            break;
          case 'discoveries':
            paperText = `${count} paper${count !== 1 ? 's' : ''} discovered`;
            break;
          default:
            paperText = `${count} paper${count !== 1 ? 's' : ''} read`;
        }
      }
      
      tooltip.html(`
        <div><strong>${formatDate(d)}</strong></div>
        <div>${paperText}</div>
      `)
        .style("left", (event.pageX + 10) + "px")
        .style("top", (event.pageY - 28) + "px");
    })
    .on("mouseout", function(d) {
      tooltip.transition()
        .duration(500)
        .style("opacity", 0);
    })
    .on("click", function(event, d) {
      // Only allow filtering when not viewing paper details
      if (currentDetailsPaper) {
        return; // Disable click filtering when viewing single paper
      }
      
      // Filter table to show papers read on this date
      const dateStr = d3.timeFormat("%Y-%m-%d")(d);
      const count = dataMap.get(dateStr) || 0;
      
      if (count > 0) {
        const formatDate = d3.timeFormat("%B %d, %Y");
        const dateFilter = function(data) {
          if (!data.rawInteractionData || data.rawInteractionData.length === 0) return false;
          
          return data.rawInteractionData.some(interaction => {
            if (interaction.type === "reading_session" && interaction.timestamp) {
              const interactionDateStr = d3.timeFormat("%Y-%m-%d")(new Date(interaction.timestamp));
              return interactionDateStr === dateStr;
            }
            return false;
          });
        };
        
        // Remove any existing heatmap-date filter and add new one
        filterManager.removeFilter('heatmap-date');
        filterManager.setFilter('heatmap-date', dateFilter, `Read on ${formatDate(d)}`);
      }
    });
  
  // Add month labels - only show months that have visible weeks
  const monthsInRange = d3.timeMonths(startDateTime, endDateTime);
  svg.selectAll(".month-label")
    .data(monthsInRange)
    .enter()
    .append("text")
    .attr("class", "month-label")
    .attr("x", d => {
      const weeksSinceStart = d3.timeWeek.count(startDateTime, d);
      return weeksSinceStart * (cellSize + cellGap);
    })
    .attr("y", 12)
    .text(d => d3.timeFormat("%b")(d));
  
  // Add day labels (M, W, F)
  const dayLabels = ["M", "", "W", "", "F", "", ""];
  svg.selectAll(".day-label")
    .data(dayLabels)
    .enter()
    .append("text")
    .attr("class", "day-label")
    .attr("x", -8)
    .attr("y", (d, i) => i * (cellSize + cellGap) + 20 + cellSize/2 + 3)
    .attr("text-anchor", "end")
    .text(d => d);
}

// Format date to YYYY-MM-DD format
function formatDate(dateString) {
  if (!dateString) return '';
  const date = new Date(dateString);
  return date.toISOString().split('T')[0]; // YYYY-MM-DD format
}

// Custom cell formatter for tags
function formatTags(cell) {
  const tags = cell.getValue();
  if (!tags || !Array.isArray(tags) || tags.length === 0) {
    return '';
  }
  return tags.map(tag => 
    `<span class="tag">${tag}</span>`
  ).join(' ');
}

function formatReadingTimeWithColor(cell) {
  const seconds = cell.getValue();
  const backgroundColor = readingTimeColorScale(seconds);
  const textColor = getContrastColor(backgroundColor);
  const element = cell.getElement();
  element.style.backgroundColor = backgroundColor;
  element.style.color = textColor;
  return seconds;
}

function formatInteractionDaysWithColor(cell) {
  const seconds = cell.getValue();
  const backgroundColor = interactionDaysColorScale(seconds);
  const textColor = getContrastColor(backgroundColor);
  const element = cell.getElement();
  element.style.backgroundColor = backgroundColor;
  element.style.color = textColor;
  return seconds;
}

// Get contrasting text color for readability
function getContrastColor(rgbColor) {
  // D3 returns rgb() format, parse it
  const rgb = rgbColor.match(/\d+/g);
  if (!rgb) return '#000000';
  
  const r = parseInt(rgb[0]);
  const g = parseInt(rgb[1]); 
  const b = parseInt(rgb[2]);
  
  // Calculate relative luminance
  const luminance = (0.299 * r + 0.587 * g + 0.114 * b) / 255;
  
  // Return black for light backgrounds, white for dark backgrounds
  return luminance > 0.5 ? '#000000' : '#ffffff';
}

function formatInteractions(interactions) {
  if (!interactions || interactions.length === 0) {
    return '<p>No reading sessions recorded</p>';
  }
  
  return `
    <table class="sessions-table">
      <thead>
        <tr>
          <th>Date</th>
          <th>Duration</th>
          <th>Session ID</th>
        </tr>
      </thead>
      <tbody>
        ${interactions.map(interaction => {
          const date = new Date(interaction.timestamp);
          return `
            <tr>
              <td>${date.toLocaleString()}</td>
              <td>${interaction.data.duration_seconds} seconds</td>
              <td>${interaction.data.session_id}</td>
            </tr>
          `;
        }).join('')}
      </tbody>
    </table>
  `;
}

function displayPaperDetails(paperId) {
  console.log("Displaying details for paper ID:", paperId);
  
  const paper = allData.find(p => p.paperKey === paperId);
  if (!paper) {
    console.error('Paper not found:', paperId);
    return;
  }
  
  currentDetailsPaper = paper;
  
  // Update heatmap to show only this paper's activity
  const singlePaperActivity = extractReadingActivityData([paper], currentHeatmapMetric);
  createReadingHeatmap(singlePaperActivity);
  
  const detailsSidebar = document.getElementById('details-sidebar');
  const detailsContent = document.getElementById('details-content');
  
  // Content no longer includes close button - it's now fixed in HTML
  detailsContent.innerHTML = `
    <div class="details-header">
      <h2>${paper.title}</h2>
    </div>
    
    <div class="detail-section">
      <h3>Paper Details</h3>
      <table class="detail-table">
        <tr>
          <th>ID:</th>
          <td>${paper.id}</td>
        </tr>
        <tr>
          <th>Authors:</th>
          <td>${paper.authors}</td>
        </tr>
        <tr>
          <th>Publication Date:</th>
          <td>${paper.published}</td>
        </tr>
        <tr>
          <th>Last Read:</th>
          <td>${paper.lastRead}</td>
        </tr>
        <tr>
          <th>Reading Time:</th>
          <td>${paper.readingTime}</td>
        </tr>
        <tr>
          <th>Interaction Days:</th>
          <td>${paper.interactionDays === 1 ? '1 day' : paper.interactionDays + ' days'}</td>
        </tr>
        <tr>
          <th>arXiv Tags:</th>
          <td>${formatTags({ getValue: () => paper.tags })}</td>
        </tr>
        <tr>
          <th>URL:</th>
          <td><a href="${paper.url}" target="_blank">${paper.url}</a></td>
        </tr>
      </table>
    </div>
    
    <div class="detail-section">
      <h3>Abstract</h3>
      <div class="abstract-box">
        ${paper.abstract}
      </div>
    </div>
    
    <div class="detail-section">
      <h3>Reading Sessions</h3>
      ${formatInteractions(paper.rawInteractionData)}
    </div>
  `;
  
  // Show the sidebar
  detailsSidebar.classList.add('active');
}

function hideDetails() {
  const detailsSidebar = document.getElementById('details-sidebar');
  detailsSidebar.classList.remove('active');
  currentDetailsPaper = null;
  
  // Restore heatmap to show filtered data or all data
  if (filterManager && filterManager.filters.size > 0) {
    // If filters are active, show filtered data
    filterManager.updateHeatmap();
  } else {
    // If no filters, show all data
    const activityData = extractReadingActivityData(allData, currentHeatmapMetric);
    createReadingHeatmap(activityData);
  }
}

function removePrefix(string, prefix, sep = ':') {
  if (string.startsWith(prefix + sep)) {
    return string.slice(prefix.length + sep.length);
  }
  return null;
}

function extractObjectId(string, prefix) {
  // Case 1: Format is "prefix:id"
  let result = removePrefix(string, prefix, ':');
  if (result !== null) return result;
  
  // Case 2: Format is "prefix.id"
  result = removePrefix(string, prefix, '.');
  if (result !== null) return result;
  
  // Case 3: Format is "prefix:prefix:id"
  result = removePrefix(string, prefix + ':' + prefix, ':');
  if (result !== null) return result;
  
  // Case 3 alternate: Format is "prefix.prefix.id"
  result = removePrefix(string, prefix + '.' + prefix, '.');
  if (result !== null) return result;
  
  // Case 4: If none of the above, return the original string
  return string;
}

function extractDomain(url) {
  try {
    const urlObj = new URL(url);
    let domain = urlObj.hostname;
    
    // Remove www. prefix
    if (domain.startsWith('www.')) {
      domain = domain.substring(4);
    }
    
    // Remove .com or .org suffix
    if (domain.endsWith('.com')) {
      domain = domain.substring(0, domain.length - 4);
    } else if (domain.endsWith('.org')) {
      domain = domain.substring(0, domain.length - 4);
    }
    
    return domain;
  } catch (error) {
    // Handle invalid URLs
    console.error("Invalid URL:", error);
    return null;
  }
}

// Simple color formatter for published dates
const publishedColorScale = d3.scaleSequential(d3.interpolateGreens)
  .domain([90, 0]); // 90 days ago = white, 0 days ago = green

function formatPublishedWithColor(cell) {
  const publishedDate = cell.getValue();
  const cellElement = cell.getElement();
  
  if (!publishedDate || publishedDate === 'N/A') {
    cellElement.style.backgroundColor = 'white';
    return publishedDate || '';
  }
  
  try {
    const pubDate = new Date(publishedDate);
    const today = new Date();
    const daysAgo = Math.floor((today - pubDate) / (1000 * 60 * 60 * 24));
    
    if (daysAgo < 0 || daysAgo > 90) {
      // More than 3 months old or future date - white
      cellElement.style.backgroundColor = 'white';
    } else {
      // 0-90 days: use D3 color scale
      const backgroundColor = publishedColorScale(daysAgo);
      const textColor = getContrastColor(backgroundColor);
      cellElement.style.backgroundColor = backgroundColor;
      cellElement.style.color = textColor;
    }
    
    return publishedDate;
  } catch (error) {
    cellElement.style.backgroundColor = 'white';
    return publishedDate;
  }
}

// read and reshape gh-store scnapshot
function processComplexData(data) {
  const result = [];
  const objects = data.objects;
  const paperKeys = Object.keys(objects).filter(key => key.startsWith("paper:"));
  
  for (const paperKey of paperKeys) {
    const paperId = extractObjectId(paperKey, "paper");
    const paperRaw = objects[paperKey];
    const paperData = paperRaw.data;
    const paperMeta = paperRaw.meta;
    const interactionKey = `interactions:${paperId}`;
    const interactionData = objects[interactionKey] ? objects[interactionKey].data : null;
    
    // Calculate reading time
    let totalReadingTime = 0;
    let lastReadDate = null;
    
    // Calculate unique days with interactions
    let uniqueInteractionDays = 0;
    
    if (interactionData && interactionData.interactions) {
      const uniqueDays = new Set();
      
      for (const interaction of interactionData.interactions) {
        if (interaction.type === "reading_session") {
          totalReadingTime += interaction.data.duration_seconds || 0;
          
          // Find the most recent reading session
          const sessionDate = new Date(interaction.timestamp);
          if (!lastReadDate || sessionDate > lastReadDate) {
            lastReadDate = sessionDate;
          }
          
          // Track unique days
          if (interaction.timestamp) {
            const date = new Date(interaction.timestamp);
            const dateString = date.toISOString().split('T')[0]; // YYYY-MM-DD
            uniqueDays.add(dateString);
          }
        }
      }
      
      uniqueInteractionDays = uniqueDays.size;
    }

    const source = paperData.sourceId === 'arxiv' || paperData.sourceType === 'arxiv' ? 
               'arxiv' : (paperData.url ? extractDomain(paperData.url) : null) ||
                 paperData.sourceId || paperData.sourceType;
    
    // Ensure all fields are properly typed
    const authors = Array.isArray(paperData.authors) ? paperData.authors.join(', ') : (paperData.authors || '');
    const title = paperData.title || '';
    const abstract = paperData.abstract || '';
    const tags = paperData.tags || paperData.arxiv_tags || [];
    
    let freshness = -1;
    if (lastReadDate && paperData.publishedDate) {
      const lastReadStr = lastReadDate.toISOString().split('T')[0];  // Convert to YYYY-MM-DD
      const publishedStr = normalizeDate(paperData.publishedDate);  // Normalize first
      freshness = daysBetween(publishedStr, lastReadStr);
    }
    
    // Create the row data
    result.push({
      paperKey: paperKey,
      id: paperId,
      source: source,
      title: title,
      authors: authors,
      abstract: abstract,
      paperFreshness: freshness,
      published: normalizeDate(paperData.publishedDate),
      firstRead: formatDate(paperMeta.created_at),
      lastRead: lastReadDate ? formatDate(lastReadDate) : formatDate(paperMeta.updated_at),
      lastReadTimestamp: lastReadDate ? lastReadDate : paperMeta.updated_at,
      readingTimeSeconds: totalReadingTime,
      interactionDays: uniqueInteractionDays,
      tags: tags,
      url: paperData.url,
      rawInteractionData: interactionData ? interactionData.interactions : []
    });
  }
  
  return result;
}

// Initialize the Tabulator table
function initTable(data) {

  const interactionDays = data.map(d => d.interactionDays).filter(t => t > 0);
  if (interactionDays.length > 0) {
    const max_id = d3.max(interactionDays);
    interactionDaysColorScale = d3.scaleSequential(d3.interpolateBlues)
      .domain([1, max_id]);
  }

  const readingTimes = data.map(d => d.readingTimeSeconds).filter(t => t > 0);
  if (readingTimes.length > 0) {
    const p75 = d3.quantile(readingTimes.sort(d3.ascending), 0.75);
    readingTimeColorScale = d3.scaleSequential(d3.interpolateBlues)
      .domain([1, p75]);
  }
  
  console.log("Reading time color scale domain:", readingTimeColorScale ? readingTimeColorScale.domain() : "No scale");
  
  table = new Tabulator("#papers-table", {
    data: data,
    layout: "fitColumns",
    responsiveLayout: "collapse",
    pagination: "local",
    paginationSize: 1000,
    paginationSizeSelector: [10, 25, 50, 100, 500, 1000, 2000, 5000],
    movableColumns: true,
    groupBy: "lastRead",
    initialSort: [
      {column: "lastReadTimestamp", dir: "desc"},
      {column: "lastRead", dir: "desc"}
    ],
    columns: [
      {
        title: "Read Dates", 
        field: "interactionDays", 
        widthGrow: 1,
        formatter: formatInteractionDaysWithColor
      },
      {
        title: "Read Time (s)", 
        field: "readingTimeSeconds",  
        widthGrow: 1,
        formatter: formatReadingTimeWithColor
      },
      {
        title: "Title", 
        field: "title", 
        widthGrow: 6,
        formatter: function(cell) {
          const value = cell.getValue();
          return value;
        }
      },
      {
        title: "Source", 
        field: "source", 
        widthGrow: 1
      },
      {
        title: "Published", 
        field: "published", 
        widthGrow: 1,
        formatter: formatPublishedWithColor
        // formatter: function(cell) {
        //   const cellElement = cell.getElement();
        //   const freshness = cell.getData().paperFreshness;
        //   cellElement.setAttribute("data-paper-freshness", freshness);
        //   return cell.getData().published;
        // }
      },
      {
        title: "Tags", 
        field: "tags", 
        widthGrow: 1,
        formatter: formatTags
      },
      {
        title: "Last Read Date", 
        field: "lastRead", 
        widthGrow: 1
      },
      {
        title: "Last Read time", 
        field: "lastReadTimestamp", 
        widthGrow: 1
      }
    ],
    rowFormatter: function(row) {
      // Add paper ID as data attribute
      const rowElement = row.getElement();
      const paper_Id = row.getData().paperKey;
      console.log("formatter detected paperId:", paper_Id);
      rowElement.setAttribute("data-paper-id", paper_Id);
    }
  });
  
  // Initialize filter manager and status bar
  filterManager = new FilterManager(table);
  filterStatusBar = new FilterStatusBar(filterManager);
  
  // Remove loading message
  document.querySelector(".loading").style.display = "none";
  
  // Set up global click handler for the table
  document.getElementById("papers-table").addEventListener("click", function(e) {
    // Find the closest row element
    const rowElement = e.target.closest(".tabulator-row");
    if (rowElement) {
      const paperId = rowElement.getAttribute("data-paper-id");
      console.log("detected click on row for paperId:", paperId);
      if (paperId) {
        displayPaperDetails(paperId);
      }
    }
  });
}

// Helper functions for filters
function createSearchFilter(searchTerm) {
  const term = searchTerm.toLowerCase().trim();
  return function(data) {
    if (!term) return true;
    
    const searchableText = [
      data.title,
      data.authors,
      data.abstract,
      ...(data.tags || [])
    ].join(' ').toLowerCase();
    
    return searchableText.includes(term);
  };
}

function createMultiSearchFilter(searchTerms) {
  // OR logic: papers must contain ANY of the search terms
  return function(data) {
    if (!searchTerms || searchTerms.length === 0) return true;
    
    const searchableText = [
      data.title,
      data.authors,
      data.abstract,
      ...(data.tags || [])
    ].join(' ').toLowerCase();
    
    return searchTerms.some(term => 
      searchableText.includes(term.toLowerCase().trim())
    );
  };
}

function createDateRangeFilter(fromDate, toDate) {
  return function(data) {
    if (!fromDate && !toDate) return true;
    if (!data.published) return false;
    
    const publishedDate = data.published;
    
    if (fromDate && toDate) {
      return publishedDate >= fromDate && publishedDate <= toDate;
    }
    
    if (fromDate) {
      return publishedDate >= fromDate;
    }
    
    if (toDate) {
      return publishedDate <= toDate;
    }
    
    return true;
  };
}

function createReadingTimeFilter(minMinutes) {
  const minSeconds = minMinutes * 60;
  return function(data) {
    return data.readingTimeSeconds >= minSeconds;
  };
}

function createInteractionDaysFilter(minDays) {
  return function(data) {
    return data.interactionDays >= minDays;
  };
}

// Multi-search state management
let searchTermCounter = 0;
let currentPreviewSearchTerm = null;

// Setup event listeners for filters and search
function setupEventListeners() {
  const searchInput = document.getElementById("search-input");
  
  // Heatmap metric selector
  document.getElementById("heatmap-metric-selector").addEventListener("change", function(e) {
    currentHeatmapMetric = e.target.value;
    console.log("Heatmap metric changed to:", currentHeatmapMetric);
    
    // Update heatmap based on current state
    if (currentDetailsPaper) {
      const singlePaperActivity = extractReadingActivityData([currentDetailsPaper], currentHeatmapMetric);
      createReadingHeatmap(singlePaperActivity);
    } else if (filterManager && filterManager.filters.size > 0) {
      filterManager.updateHeatmap();
    } else {
      const activityData = extractReadingActivityData(allData, currentHeatmapMetric);
      createReadingHeatmap(activityData);
    }
  });
  
  // Global search with debouncing for preview
  let searchTimeout;
  searchInput.addEventListener("input", function(e) {
    const searchTerm = e.target.value.trim();
    
    // Clear previous timeout
    clearTimeout(searchTimeout);
    
    // Debounce search input for preview
    searchTimeout = setTimeout(() => {
      if (searchTerm) {
        // Show preview of current search term
        currentPreviewSearchTerm = searchTerm;
        filterManager.setFilter('search-preview', createSearchFilter(searchTerm), `Search: "${searchTerm}"`);
      } else {
        // Clear preview when input is empty
        currentPreviewSearchTerm = null;
        filterManager.removeFilter('search-preview');
      }
    }, 300);
  });
  
  // Handle Enter key to commit search term
  searchInput.addEventListener("keydown", function(e) {
    if (e.key === "Enter") {
      e.preventDefault();
      const searchTerm = e.target.value.trim();
      
      if (searchTerm) {
        // Remove the preview filter
        filterManager.removeFilter('search-preview');
        currentPreviewSearchTerm = null;
        
        // Add committed search term with unique ID
        const searchId = `search-${++searchTermCounter}`;
        filterManager.setFilter(searchId, createSearchFilter(searchTerm), `Search: "${searchTerm}"`);
        
        // Clear the input for next search term
        e.target.value = "";
      }
    }
  });
  
  // Clear search button - clears current input and preview
  document.getElementById("clear-search").addEventListener("click", function() {
    document.getElementById("search-input").value = "";
    filterManager.removeFilter('search-preview');
    currentPreviewSearchTerm = null;
  });
  
  // Toggle filter sidebar
  document.getElementById("sidebar-toggle").addEventListener("click", function() {
    document.getElementById("sidebar").classList.toggle("active");
    
    // Close details sidebar if open (to avoid both being open at once)
    document.getElementById("details-sidebar").classList.remove("active");
  });
  
  // Floating filter button
  document.getElementById("filter-toggle-btn").addEventListener("click", function() {
    document.getElementById("sidebar").classList.toggle("active");
    
    // Close details sidebar if open (to avoid both being open at once)
    document.getElementById("details-sidebar").classList.remove("active");
  });
  
  // Toggle details with keyboard escape key
  document.addEventListener("keydown", function(e) {
    if (e.key === "Escape") {
      document.getElementById("details-sidebar").classList.remove("active");
      document.getElementById("sidebar").classList.remove("active");
    }
  });
  
  // Date range filters
  document.getElementById("apply-date-filter").addEventListener("click", function() {
    const fromDate = document.getElementById("date-filter-from").value;
    const toDate = document.getElementById("date-filter-to").value;
    
    if (fromDate || toDate) {
      const description = formatDateRangeDescription(fromDate, toDate);
      filterManager.setFilter('dateRange', createDateRangeFilter(fromDate, toDate), description);
    } else {
      filterManager.removeFilter('dateRange');
    }
  });
  
  document.getElementById("clear-date-filter").addEventListener("click", function() {
    document.getElementById("date-filter-from").value = "";
    document.getElementById("date-filter-to").value = "";
    filterManager.removeFilter('dateRange');
  });
  
  // Reading time filter
  document.getElementById("apply-reading-filter").addEventListener("click", function() {
    const minReading = document.getElementById("min-reading-time").value;
    
    if (minReading && minReading > 0) {
      filterManager.setFilter(
        'readingTime', 
        createReadingTimeFilter(parseInt(minReading)), 
        `Reading time: â‰¥${minReading} min`
      );
    } else {
      filterManager.removeFilter('readingTime');
    }
  });
  
  document.getElementById("clear-reading-filter").addEventListener("click", function() {
    document.getElementById("min-reading-time").value = "";
    filterManager.removeFilter('readingTime');
  });
  
  // Interaction days filter
  document.getElementById("apply-days-filter").addEventListener("click", function() {
    const minDays = document.getElementById("min-interaction-days").value;
    
    if (minDays && minDays > 0) {
      const days = parseInt(minDays);
      filterManager.setFilter(
        'interactionDays', 
        createInteractionDaysFilter(days), 
        `Interaction days: â‰¥${days}`
      );
    } else {
      filterManager.removeFilter('interactionDays');
    }
  });
  
  document.getElementById("clear-days-filter").addEventListener("click", function() {
    document.getElementById("min-interaction-days").value = "";
    filterManager.removeFilter('interactionDays');
  });
  
  // Reset all filters
  document.getElementById("reset-all-filters").addEventListener("click", function() {
    // Clear all input fields
    document.getElementById("search-input").value = "";
    document.getElementById("date-filter-from").value = "";
    document.getElementById("date-filter-to").value = "";
    document.getElementById("min-reading-time").value = "";
    document.getElementById("min-interaction-days").value = "";
    
    // Reset search counter and preview state
    searchTermCounter = 0;
    currentPreviewSearchTerm = null;
    
    // Clear all filters through filter manager
    filterManager.clearAll();
  });
}

// Helper function to format date range descriptions
function formatDateRangeDescription(fromDate, toDate) {
  if (fromDate && toDate) {
    return `Date: ${fromDate} to ${toDate}`;
  } else if (fromDate) {
    return `Date: from ${fromDate}`;
  } else if (toDate) {
    return `Date: until ${toDate}`;
  }
  return 'Date range';
}

// Load and initialize
document.addEventListener("DOMContentLoaded", function() {
  // Fetch data file
  fetch("gh-store-snapshot.json")
    .then(response => {
      if (!response.ok) {
        throw new Error("Failed to load data.json");
      }
      return response.json();
    })
    .then(data => {
      allData = processComplexData(data);
      
      // Initialize table and heatmap
      initTable(allData);
      
      // Create initial heatmap with default metric
      const activityData = extractReadingActivityData(allData, currentHeatmapMetric);
      createReadingHeatmap(activityData);
      
      setupEventListeners();
    })
    .catch(error => {
      document.querySelector(".loading").innerHTML = 
        `Error loading data: ${error.message}. Make sure data.json exists in the same directory as this HTML file.`;
    });
});



---
File: ops/rm.txt
---



---
File: pyproject.toml
---
[project]
name = "papers-feed"
version = "0.1.0"
description = ""
requires-python = ">=3.11"
# dependencies = [
#    "papers_feed"
# ]
readme = "README.md"
license = {file = "LICENSE"}


[tool.summary]
max_file_size_kb = 500  # Skip files larger than 1MB

# File patterns to exclude
exclude_patterns = [
    '.git',
    '.gitignore',
    '.pytest_cache',
    '__pycache__',
    'SUMMARY',
    '.coverage',
    '.env',
    '.venv',
    '.idea',
    '.vscode',
    'README.md',
    'README_LLM.md',
    'package-lock.json',
    'REGISTRY.md',
    'research.yaml',
    'registry.yaml',
    'bibliography',
    '.bibtex',
    'metadata.json',
    'events.log',
    'papers.yaml'
]

# File extensions to include
include_extensions = [
    '.py',
    '.md',
    '.txt',
    '.yml',
    '.yaml',
    '.toml',
    '.json',
    '.html',
    '.css',
    '.js',
    '.ts',
    '.tsx',
    '.j2'
]

# Directories to exclude
exclude_directories = [
    '.git',
    '__pycache__',
    '.pytest_cache',
    '.venv',
    '.idea',
    '.vscode',
    'data',
    'extension/dist/'
]



---
File: requirements.txt
---



---
File: scripts/github_repo_mirror.py
---
#!/usr/bin/env python3
# github_repo_mirror.py

"""
Utility to copy issues, comments, labels and reactions from one GitHub repository to another,
or to clean labels from all issues in a repository.
"""

import os
import sys
from typing import Dict, List, Optional

import fire
from github import Github, GithubException
from github.Issue import Issue
from github.Label import Label
from github.Repository import Repository
from loguru import logger

# Set up logging
logger.remove()
logger.add(sys.stderr, format="{time} {level} {message}", level="INFO")


class GitHubRepoMirror:
    """Class to mirror issues and related data between GitHub repositories."""
    
    def __init__(
        self, 
        token: str,
        source_repo: str = "dmarx/papers-feed",
        target_repo: str = "dmarx/papers-feed-dev",
    ):
        """
        Initialize with GitHub credentials and repository info.
        
        Args:
            token: GitHub personal access token
            source_repo: Source repository in format "owner/repo"
            target_repo: Target repository in format "owner/repo"
        """
        self.source_repo_name = source_repo
        self.target_repo_name = target_repo
        
        # Initialize GitHub client
        self.github = Github(
            token, 
            per_page=100,
            retry=3
        )
        
        # Get repository objects
        self.source_repo = self.github.get_repo(source_repo)
        self.target_repo = self.github.get_repo(target_repo)
        
        # Label cache to avoid creating duplicate labels
        self.label_cache: Dict[str, Label] = {}

    def _create_label_if_not_exists(self, label_name: str, label_color: str, 
                                    label_description: str = "") -> Label:
        """
        Create a label in the target repo if it doesn't already exist.
        
        Args:
            label_name: Name of the label
            label_color: Color of the label (hex code without #)
            label_description: Description of the label
            
        Returns:
            The label object
        """
        # Check cache first
        if label_name in self.label_cache:
            return self.label_cache[label_name]
        
        # Try to get existing label
        try:
            label = self.target_repo.get_label(label_name)
            self.label_cache[label_name] = label
            return label
        except GithubException:
            # Label doesn't exist, create it
            logger.info(f"Creating label '{label_name}' in target repository")
            label = self.target_repo.create_label(
                name=label_name,
                color=label_color,
                description=label_description
            )
            self.label_cache[label_name] = label
            return label

    def _copy_reactions(self, source_obj, target_obj):
        """
        Copy reactions from source to target object.
        
        Args:
            source_obj: Source object with reactions (Issue or IssueComment)
            target_obj: Target object to add reactions to
        """
        # Get all reactions from source
        try:
            reactions = source_obj.get_reactions()
            
            # Add each reaction type to target
            reaction_counts = {}
            for reaction in reactions:
                reaction_type = reaction.content
                reaction_counts[reaction_type] = reaction_counts.get(reaction_type, 0) + 1
            
            # Create reactions on target
            for reaction_type, count in reaction_counts.items():
                logger.debug(f"Adding {count} '{reaction_type}' reactions")
                for _ in range(count):
                    try:
                        target_obj.create_reaction(reaction_type)
                    except GithubException as e:
                        # Creating the same reaction twice will fail
                        if e.status == 422:
                            logger.debug(f"Duplicate reaction '{reaction_type}' - skipping")
                        else:
                            raise
        except GithubException as e:
            logger.warning(f"Could not copy reactions: {str(e)}")

    def clear_all_issue_labels(self, repo_name: str = None):
        """
        Remove all labels from all issues in a repository.
        
        Args:
            repo_name: Repository to clean (defaults to target repo)
        """
        repo = self.target_repo
        if repo_name:
            repo = self.github.get_repo(repo_name)
            
        logger.info(f"Removing all labels from all issues in {repo.full_name}")
        
        # Get all issues (open and closed)
        issues = repo.get_issues(state="all")
        
        # Track progress
        count = 0
        processed = 0
        
        # Process each issue
        for issue in issues:
            processed += 1
            
            # Skip issues with no labels
            if not list(issue.labels):
                continue
            
            logger.info(f"Clearing labels from issue #{issue.number}: {issue.title}")
            
            # Remove all labels
            issue.set_labels()  # Empty list clears all labels
            count += 1
            
            # Log progress occasionally
            if processed % 10 == 0:
                logger.info(f"Processed {processed} issues so far")
        
        logger.info(f"Completed! Removed labels from {count} issues out of {processed} total issues.")
        return count

    def copy_labels(self) -> int:
        """
        Copy all labels from source repository to target repository.
        
        Returns:
            Number of labels created
        """
        logger.info(f"Copying labels from {self.source_repo_name} to {self.target_repo_name}")
        
        created = 0
        
        # Get existing target labels
        target_labels = {label.name: label for label in self.target_repo.get_labels()}
        
        # Copy labels from source to target
        for source_label in self.source_repo.get_labels():
            if source_label.name in target_labels:
                logger.debug(f"Label already exists: {source_label.name}")
                # Cache the label for later use
                self.label_cache[source_label.name] = target_labels[source_label.name]
            else:
                # Create new label
                logger.info(f"Creating new label: {source_label.name}")
                new_label = self.target_repo.create_label(
                    name=source_label.name,
                    color=source_label.color,
                    description=source_label.description or ""
                )
                # Cache the label for later use
                self.label_cache[source_label.name] = new_label
                created += 1
        
        logger.info(f"Label copy completed: {created} created")
        return created

    def copy_issue(self, issue_number: int) -> Issue:
        """
        Copy a single issue and all its comments from source to target repository.
        
        Args:
            issue_number: The issue number in the source repository
            
        Returns:
            The newly created issue in the target repository
        """
        logger.info(f"Copying issue #{issue_number} from {self.source_repo_name}")
        
        # Get source issue
        source_issue = self.source_repo.get_issue(issue_number)
        
        # Create issue in target repo - exact copy of title and body
        target_issue = self.target_repo.create_issue(
            title=source_issue.title,
            body=source_issue.body
        )
        logger.info(f"Created issue #{target_issue.number} at target from source #{source_issue.number}")
        
        # Copy labels
        for label in source_issue.labels:
            target_label = self._create_label_if_not_exists(
                label_name=label.name,
                label_color=label.color,
                label_description=label.description or ""
            )
            target_issue.add_to_labels(target_label)
            
        # Copy state (open/closed)
        if source_issue.state == "closed":
            target_issue.edit(state="closed")
            
        # Copy comments - exact copies without modifications
        for comment in source_issue.get_comments():
            target_comment = target_issue.create_comment(comment.body)
            
            # Copy reactions from comment
            self._copy_reactions(comment, target_comment)
            
        # Copy reactions to the issue itself
        self._copy_reactions(source_issue, target_issue)
        
        return target_issue

    def copy_all_issues(self, issue_range_start: int = None, issue_range_end: int = None) -> List[Issue]:
        """
        Copy all issues from source to target repository, optionally within a specific issue number range.
        
        Args:
            issue_range_start: Optional starting issue number to copy (inclusive)
            issue_range_end: Optional ending issue number to copy (inclusive)
            
        Returns:
            List of created issues in the target repository
        """
        created_issues = []
        
        # First, make sure all labels exist in the target repo
        self.copy_labels()
        
        # Get all issues from source repo with filters, sorted by creation date ascending
        source_issues = self.source_repo.get_issues(state="all", sort="created", direction="asc")
        logger.info(f"Fetching issues from source repository (sorted by creation date)...")
        
        # Process each issue
        for source_issue in source_issues:
            # Skip issues outside the specified range if ranges are provided
            if issue_range_start is not None and source_issue.number < issue_range_start:
                logger.debug(f"Skipping issue #{source_issue.number}: Below range start.")
                continue
                
            if issue_range_end is not None and source_issue.number > issue_range_end:
                logger.info(f"Reached end of specified issue range (#{issue_range_end}), exiting.")
                break
                
            if source_issue.pull_request is not None:
                logger.info(f"Skipping issue #{source_issue.number}: PR.")
                continue
                
            if not source_issue.body:
                logger.info(f"Skipping issue #{source_issue.number}: empty issue body.")
                continue
                
            created_issue = self.copy_issue(source_issue.number)
            created_issues.append(created_issue)
            
            # Log progress occasionally
            if len(created_issues) % 5 == 0:
                logger.info(f"Copied {len(created_issues)} issues so far")
                    
        logger.info(f"Created {len(created_issues)} issues in the target repository")
        return created_issues


def mirror_repository(
    clear_target_labels: bool = False,
    token: str = None,
    source_repo: str = "dmarx/papers-feed",
    target_repo: str = "dmarx/papers-feed-dev",
    issue_range_start: int = None,
    issue_range_end: int = None,
):
    """
    Mirror issues, comments, labels and reactions from source to target repository.
    Can also clear all labels from issues in the target repository.
    
    Args:
        clear_target_labels: If True, remove all labels from all issues in target repository first
        token: GitHub token (or use DEV_REPO_TOKEN environment variable)
        source_repo: Source repository in format "owner/repo"
        target_repo: Target repository in format "owner/repo"
        issue_range_start: Optional starting issue number to copy (inclusive)
        issue_range_end: Optional ending issue number to copy (inclusive)
    """
    # Use provided token or get from environment
    token = token or os.environ.get("DEV_REPO_TOKEN")
    
    if not token:
        logger.error("GitHub token not provided. Use --token or set DEV_REPO_TOKEN environment variable.")
        sys.exit(1)
        
    if source_repo == target_repo:
        logger.error("Source and target repositories must be different.")
        sys.exit(1)
        
    # Create and run the mirroring tool
    mirror = GitHubRepoMirror(
        token=token,
        source_repo=source_repo,
        target_repo=target_repo
    )
    
    # Clear all labels from issues in target repo if requested
    if clear_target_labels:
        logger.info("Clearing all labels from issues in target repository")
        mirror.clear_all_issue_labels()
    
    # Copy all issues from source to target, with optional range limits
    range_info = ""
    if issue_range_start is not None or issue_range_end is not None:
        range_info = f" (issues {issue_range_start or 'start'} to {issue_range_end or 'end'})"
    
    logger.info(f"Mirroring from {source_repo} to {target_repo}{range_info}")
    mirror.copy_all_issues(issue_range_start, issue_range_end)
    logger.info("Repository mirroring completed.")


def clear_issue_labels(
    token: str = None,
    repo_name: str = "dmarx/papers-feed-dev"
):
    """
    Simple function to clear all labels from all issues in a repository.
    
    Args:
        token: GitHub token (or use DEV_REPO_TOKEN environment variable)
        repo_name: Repository in format "owner/repo"
    """
    # Use provided token or get from environment
    token = token or os.environ.get("DEV_REPO_TOKEN")
    
    if not token:
        logger.error("GitHub token not provided. Use --token or set DEV_REPO_TOKEN environment variable.")
        sys.exit(1)
        
    # Create the tool and clear labels
    mirror = GitHubRepoMirror(token=token)
    mirror.clear_all_issue_labels(repo_name)


if __name__ == "__main__":
    fire.Fire({
        'mirror': mirror_repository,
        'clear_labels': clear_issue_labels
    })



---
File: scripts/hydrate_metadata.py
---
# this could probably be rolled into enrichment processing
#!/usr/bin/env python
# fetch_arxiv_metadata.py
"""
Fetches metadata for arXiv papers identified by issue labels and stores it using gh-store.
"""

import json
import sys
import os
import re
from typing import Dict, List, Optional, Any
import fire
from loguru import logger
import arxiv
import requests

from gh_store.core.store import GitHubStore
from gh_store.tools.canonicalize import CanonicalStore
#from gh_store.tools.canonicalize import CanonicalStore as GitHubStore
from gh_store.core.constants import LabelNames
from gh_store.core.types import get_object_id_from_labels, StoredObject
from gh_store.core.exceptions import DuplicateUIDError, ConcurrentUpdateError

def is_metadata_satisfied(data: dict) -> bool:
    return data and data.get('title') and not (data.get('id') in data.get('title'))

def is_valid_arxiv_id(arxiv_id: str) -> bool:
    """Validate arXiv ID format."""
    return bool(re.match(r'\d{4}\.\d{4,5}(v\d+)?|\w+\/\d{7}(v\d+)?', arxiv_id))

def extract_arxiv_id_from_object_id(object_id: str) -> str:
    """Extract the arXiv ID from a paper ID with various prefixing schemes."""
    prefix = 'arxiv'
    
    # Case 1: Format is "prefix:id"
    if object_id.startswith(f"{prefix}:"):
        return object_id[len(prefix)+1:]
    
    # Case 2: Format is "prefix.id"
    if object_id.startswith(f"{prefix}."):
        return object_id[len(prefix)+1:]
    
    # Case 3: Format is "prefix:prefix:id"
    if object_id.startswith(f"{prefix}:{prefix}:"):
        return object_id[len(prefix)*2+2:]
    
    # Case 4: Format is "prefix.prefix.id"
    if object_id.startswith(f"{prefix}.{prefix}."):
        return object_id[len(prefix)*2+2:]
    
    # Case 5: If none of the above, return the original ID
    return object_id

def fetch_arxiv_metadata(arxiv_id: str) -> Dict[str, Any]:
    """Fetch metadata from arXiv API for a given ID using the arxiv client."""
    logger.info(f"Fetching metadata for arXiv ID: {arxiv_id}")
    
    client = arxiv.Client()
    search = arxiv.Search(id_list=[arxiv_id])
    paper = next(client.results(search))
    if not paper:
        raise ValueError(f"No paper found with arXiv ID: {arxiv_id}")
    
    metadata = {
        #'id': paper.entry_id,
        'title': paper.title,
        'authors': [author.name for author in paper.authors],
        'publishedDate': paper.published.isoformat() if paper.published else None,
        #'updated': paper.updated.isoformat() if paper.updated else None,
        'doi': paper.doi,
        'tags': paper.categories,
        'abstract': paper.summary,
        #'links': [{'href': link.href, 'type': link.type} for link in paper.links],
        #'comment': paper.comment,
        #'journal_ref': paper.journal_ref,
        #'primary_category': paper.primary_category,
        #'pdf_url': paper.pdf_url,
    }
    
    logger.info(f"Successfully fetched metadata for arXiv ID: {arxiv_id}")
    logger.info(metadata)
    return metadata
    

def hydrate_issue_metadata(issue: int, token:str, repo:str):
    #store = GitHubStore(token=token, repo=repo, config_path=None)
    store = CanonicalStore(token=token, repo=repo, config_path=None)
    
    obj = store.issue_handler.get_object_by_number(issue)
    object_id = obj.meta.object_id
    #object_id = get_object_id_from_labels(issue)
    if not object_id.startswith("paper:"):
        logger.info("Not a paper object, exiting.")
        sys.exit(0)
    if 'arxiv' != obj.data.get('sourceId'): #'url' in object_id:
        logger.info("Metadata hydration is currently only supported for the arxiv source type.")
        store.process_updates(issue) # ...why is this a separate second step? sheesh, I reaaly did rube goldberg the shit out of this thing
        return
        
    
    paper_id = object_id[len('paper:'):]
    if paper_id.startswith('arxiv'):
        arxiv_id = extract_arxiv_id_from_object_id(paper_id)
    elif is_valid_arxiv_id(paper_id):
        arxiv_id = paper_id
    else:
        raise TypeError(f"Unable to identify arxiv_id from object_id: {object_id}")

    updates = {}
    arxiv_meta = fetch_arxiv_metadata(arxiv_id)
    for k, v_new in arxiv_meta.items():
        #v_old = getattr(obj.data, k)
        v_old = obj.data.get(k)
        if not v_old:
            updates[k] = v_new

    metadata_satisfied = False
    if updates:
        # Issue is open because we are processing it right now, which acts as an implicit lock on updates.
        # so we close it before pushing the new update
        #store.repo.get_issue(issue).edit(state='closed') # ...this is awkward af. in fact, I think I should just eliminate that whole ConcurrentUpdateError
        # finally: what we came here for
        store.update(object_id=object_id, changes=updates)
        store.process_updates(issue) # ...why is this a separate second step? sheesh, I reaaly did rube goldberg the shit out of this thing
        metadata_satisfied = True
    else:
        metadata_satisfied = is_metadata_satisfied(obj.data)

    if metadata_satisfied:
        store.repo.get_issue(issue).remove_from_labels("TODO:hydrate-metadata")    

# TODO: upstream this to gh-store utilities
def get_open_issues(token:str, repo:str, extra_labels: list|None = None):
    store = GitHubStore(token=token, repo=repo, config_path=None)
    #store = CanonicalStore(token=token, repo=repo, config_path=None)
    
    query_labels = [LabelNames.GH_STORE, LabelNames.STORED_OBJECT]
    if extra_labels: # 
        query_labels += extra_labels
    return store.repo.get_issues(
            labels=query_labels,
            state="open"
        )

def hydrate_all_open_issues(token:str, repo:str):
    store = CanonicalStore(token=token, repo=repo, config_path=None)
    for issue in get_open_issues(token=token, repo=repo, extra_labels=["TODO:hydrate-metadata"]):
        try:
            hydrate_issue_metadata(issue=issue.number, token=token, repo=repo)
        except TypeError:
            logger.info("unsupported source for issue %s", issue.number)
        except DuplicateUIDError:
            #logger.info("Issue %s has dupes, skipping for now. Run deduplification." % issue.number)
            logger.info("Issue %s has dupes. Running deduplification." % issue.number)
            #object_id = StoredObject.from_issue(issue).object_id
            object_id = get_object_id_from_labels(issue)
            dedupe_status = store.deduplicate_object(object_id)
            hydrate_issue_metadata(issue=dedupe_status.get('canonical_issue'), token=token, repo=repo)
        except ConcurrentUpdateError:
            logger.info("Issue %s has too many unprocessed concurrent updates. Either adjust this threshold, or reconcile the updates manually.", issue.number)

# class Main:
#     def hydrate_issue_metadata(self, issue: int, token:str, repo:str):
#         hydrate_issue_metadata(issue=issue, token=token, repo=repo)

#     def hydrate_all_open_issues(self, token:str, repo:str):
#         hydrate_all_open_issues(token=token, repo=repo)


if __name__ == "__main__":
    #fire.Fire(Main)
    fire.Fire(
        { "hydrate_issue_metadata":hydrate_issue_metadata, "hydrate_all_open_issues":hydrate_all_open_issues }
    )



---
File: scripts/process_enrichments.py
---
# scripts/process_enrichments.py
"""
Creates new paper features based on GitHub issue specifications.
"""
import ast
from dataclasses import dataclass
import json
import os
from pathlib import Path
from typing import Iterator

from github import Github
from loguru import logger
from duckduckgo_search import DDGS
from llamero.utils import commit_and_push

@dataclass
class Paper:
    """
    Represents an arXiv paper with its associated features.
    
    Args:
        arxiv_id: The arXiv ID of the paper
        data_dir: Root directory containing paper data (default: data/papers)
    """
    arxiv_id: str
    data_dir: Path = Path("data/papers")
    
    def __post_init__(self):
        self.paper_dir = self.data_dir / self.arxiv_id
        self.features_dir = self.paper_dir / "features"
        
    @property
    def pdf_path(self) -> Path:
        """Path to the paper's PDF file."""
        return self.paper_dir / f"{self.arxiv_id}.pdf"
    
    @property
    def available_features(self) -> set[str]:
        """Returns set of available feature types for this paper."""
        if not self.features_dir.exists():
            return set()
            
        return {
            d.name for d in self.features_dir.iterdir() 
            if d.is_dir() and any(d.iterdir())
        }
        
    def has_feature(self, feature_name: str) -> bool:
        """Check if a specific feature is available."""
        return feature_name in self.available_features
        
    def feature_path(self, feature_type: str) -> Path | None:
        """
        Get path to a specific feature file if it exists.
        
        Args:
            feature_type: Name of the feature directory (e.g., 'markdown-grobid')
            
        Returns:
            Path to the feature file, or None if not found
        """
        feature_dir = self.features_dir / feature_type
        if not feature_dir.exists():
            return None
            
        # Look for any file with matching arxiv_id prefix
        for file in feature_dir.iterdir():
            if file.stem == self.arxiv_id:
                return file
                
        return None
        
    def __str__(self) -> str:
        features = ", ".join(sorted(self.available_features)) or "none"
        return f"Paper({self.arxiv_id}, features: {features})"
        
    @classmethod
    def iter_papers(cls, data_dir: Path | str = "data/papers") -> Iterator["Paper"]:
        """
        Yields Paper objects for all papers in the project.
        
        Args:
            data_dir: Root directory containing paper data
        """
        data_dir = Path(data_dir)
        if not data_dir.exists():
            return
            
        for paper_dir in data_dir.iterdir():
            if paper_dir.is_dir():
                yield cls(arxiv_id=paper_dir.name, data_dir=data_dir)


@dataclass
class FeatureRequest:
    """Represents a request to create a new feature."""
    name: str
    inputs: dict[str, str]
    prompt: str
    max_len: int = 20000
    commit_cadence: int = 5
    
    def __post_init__(self):
        if '/' in self.name:
            raise ValueError("Feature name cannot contain '/'")
        if not all(isinstance(v, str) for v in self.inputs.values()):
            raise ValueError("All input mappings must be strings")
    
    @classmethod
    def from_issue(cls, issue_body: str) -> 'FeatureRequest':
        """Creates a FeatureRequest from a GitHub issue body."""
        try:
            # First try standard JSON parsing
            # try:
            #     data = json.loads(issue_body)
            # except json.JSONDecodeError:
            #     # If that fails, try replacing single quotes with double quotes
            #     # but only for the outermost quotes and dict keys
            #     fixed_body = (
            #         issue_body
            #         .replace("{'", '{"')
            #         .replace("'}", '"}')
            #         .replace("':", '":')
            #         .replace("',", '",')
            #     )
            #     data = json.loads(fixed_body)
            data = ast.literal_eval(issue_body)
            
            return cls(
                name=data['name'],
                inputs=data['inputs'],
                prompt=data['prompt'],
                max_len=data.get('max_len', 20000),
                commit_cadence=data.get('commit_cadence', 10),
            )
        except (json.JSONDecodeError, KeyError) as e:
            raise ValueError(f"Invalid feature request format: {e}")


def get_github_context() -> tuple[str, str, str]:
    """
    Gets GitHub repository context from Actions environment.
    
    Returns:
        Tuple of (owner, repo, token)
    """
    repo = os.getenv("GITHUB_REPOSITORY")
    if not repo:
        raise RuntimeError("Must be run in GitHub Actions environment")
    
    token = os.getenv("GITHUB_TOKEN")
    if not token:
        raise RuntimeError("GitHub token not available")
        
    owner, repo = repo.split("/")
    return owner, repo, token


def get_feature_requests(
    owner: str,
    repo: str,
    label: str = "feature-node",
    feature_name: str | None = None,
    token: str | None = None
) -> Iterator[tuple[FeatureRequest, "Issue"]]:
    """
    Yields FeatureRequest objects from labeled GitHub issues.
    
    Args:
        owner: Repository owner
        repo: Repository name
        label: Base label to filter issues
        feature_name: If provided, also filter by feature:<name> label
        token: GitHub token
    """
    g = Github(token) if token else Github()
    repository = g.get_repo(f"{owner}/{repo}")
    
    labels = [label]
    if feature_name:
        labels.append(f"feature:{feature_name}")
    
    for issue in repository.get_issues(labels=labels, state="all"):
        try:
            yield FeatureRequest.from_issue(issue.body), issue
        except ValueError as e:
            logger.warning(f"Skipping issue {issue.number}: {e}")
            continue


def handle_missing_features(
    owner: str,
    repo: str,
    missing_features: set[str],
    token: str | None = None
) -> None:
    """
    Reopens feature creation issues for missing features.
    
    Args:
        owner: Repository owner
        repo: Repository name
        missing_features: Set of feature names that need to be created
        token: GitHub token
    """
    g = Github(token) if token else Github()
    repository = g.get_repo(f"{owner}/{repo}")
    
    # Track which features we've handled to avoid duplicate reopens
    handled_features = set()
    
    for feature in missing_features:
        if feature in handled_features:
            continue
            
        # Find the feature creation issue
        for request, issue in get_feature_requests(
            owner, repo, feature_name=feature, token=token
        ):
            if issue.state == "closed":
                logger.info(f"Reopening issue for feature: {feature}")
                issue.edit(state="open")
                handled_features.add(feature)
                break
        else:
            logger.warning(f"No creation issue found for feature: {feature}")


def create_feature(
    paper: Paper,
    request: FeatureRequest,
    owner: str,
    repo: str,
    token: str | None = None,
    reopen_dependencies: bool = True
) -> bool:
    """
    Creates a new feature for a paper based on the feature request.
    
    Args:
        paper: Paper object to create feature for
        request: Feature request specification
        owner: Repository owner (for dependency reopening)
        repo: Repository name (for dependency reopening)
        token: GitHub token (for dependency reopening)
        reopen_dependencies: Whether to reopen issues for missing dependencies
        
    Returns:
        True if feature was created successfully
    """
    missing_features = set()
    
    # Check if all required input features exist
    for feature_path in request.inputs:
        feature_type = feature_path.split('/')[1]
        if not paper.has_feature(feature_type):
            missing_features.add(feature_type)
            
    if missing_features and reopen_dependencies:
        handle_missing_features(owner, repo, missing_features, token)
        return 
    elif missing_features:
        logger.warning(
            f"Paper {paper.arxiv_id} missing required features: {missing_features}"
        )
        return 
            
    # Create feature directory
    feature_dir = paper.features_dir / request.name
    feature_dir.mkdir(parents=True, exist_ok=True)
    
    # Read input features and format prompt
    input_contents = {}
    for feature_path, var_name in request.inputs.items():
        feature_type = feature_path.split('/')[1]
        path = paper.feature_path(feature_type)
        if path and path.exists():
            content = path.read_text()
            # Truncate content if needed
            if request.max_len > 0:
                available_len = request.max_len - len(request.prompt)
                if len(content) > available_len:
                    logger.warning(
                        f"Truncating content for {paper.arxiv_id} "
                        f"from {len(content)} to {available_len} chars"
                    )
                content = content[:available_len]
            input_contents[var_name] = content
    
    # Format prompt with input contents
    formatted_prompt = request.prompt.format(**input_contents)
    
    # Send to DuckDuckGo chat
    ddg = DDGS()
    try:
        response = ddg.chat(formatted_prompt)
        output_path = feature_dir / f"{paper.arxiv_id}.md"
        output_path.write_text(response)
        logger.info(f"Created {request.name} feature for {paper.arxiv_id}")
        return str(output_path.absolute())
    except Exception as e:
        logger.error(f"Chat API error for {paper.arxiv_id}: {e}")
        return 


def process_feature_requests(
    data_dir: Path | str = "data/papers"
) -> None:
    """
    Process all open feature requests for all papers.
    """
    owner, repo, token = get_github_context()
    requests = []
    for request, _ in get_feature_requests(owner, repo, token=token):
        requests.append(request)
    logger.info(f"Found {len(requests)} feature requests")

    to_commit=[]
    for i, paper in enumerate(Paper.iter_papers(data_dir)):
        for request in requests:
            if paper.has_feature(request.name):
                logger.debug(f"{request.name} feature for paper {paper.arxiv_id} already previously generated. Skipping.")
                continue        

            output_path = create_feature(paper, request, owner, repo, token)
            if output_path:
                to_commit.append(output_path)
        #if i % request.commit_cadence == 0: # per-request commit cadences though... hmmm
        if to_commit and ((len(to_commit) % request.commit_cadence) == 0):
            commit_and_push(to_commit)
            to_commit=[]
    if to_commit:
        commit_and_push(to_commit)


if __name__ == "__main__":
    from fire import Fire
    
    def main(data_dir: str = "data/papers"):
        """CLI entry point to process feature requests."""
        process_feature_requests(data_dir)
        
    Fire(main)



---
File: scripts/process_pdf.py
---
# .github/scripts/process_pdf.py

import os
from pathlib import Path
from typing import Literal

import fire
import requests
from loguru import logger
from lxml import etree
from llamero.utils import commit_and_push

OutputFormat = Literal['markdown', 'tei']

def remove_extra_whitespace(text: str)->str:
    while '\n\n\n' in text:
        text = text.replace('\n\n\n', '\n\n')
    return text

def remove_gibberish(
    text: str,
    cutoff=2000
)->str:
    good_lines = []
    for line in text.split('\n'):
        _line = line[:]
        if _line.startswith("$"):
            _line = _line[1:-1]
        n_tok = len(_line)
        n_space = _line.count(" ")
        # I think this might remove some formulas if we use cutoff=0
        token_sparsity=1
        if n_tok:
            token_sparsity = n_space/n_tok
        
        _line = line[:]
        _line = _line.replace(" ","")

        skip=False
        if (abs(token_sparsity - .5) < .01) and (len(line) > cutoff):
            skip=True
        if "texitsha1_base64" in _line:
            skip=True
        if "texit>" in _line:
            skip=True
        if skip:
            logger.info(f"removing gibberish")
            logger.info(line)
            continue
        good_lines.append(line)
    return '\n'.join(good_lines)

def sanitize_markdown(text: str)->str:
    text=remove_extra_whitespace(text)
    text=remove_gibberish(text)
    return text

def get_feature_path(base_path: Path, feature_type: str, paper_id: str, ext: str) -> Path:
    """Create feature directory if it doesn't exist and return the full path."""
    feature_dir = base_path / 'features' / feature_type
    feature_dir.mkdir(parents=True, exist_ok=True)
    return feature_dir / f"{paper_id}{ext}"

def process_pdf_grobid(
    pdf_path: str, 
    format: OutputFormat = 'markdown', 
    tag: str = "grobid",
    output_path: str | None = None,
    regenerate_tei: bool = True,
) -> None:
    """
    Process a PDF file using Grobid and convert to the specified format.
    
    Output files will be saved in feature-specific directories:
    - TEI XML files go to features/tei-xml-grobid/
    - Markdown files go to features/markdown-grobid/
    
    Args:
        pdf_path: Path to the PDF file relative to the repository root.
        format: Output format, either 'markdown' or 'tei'.
        tag: Optional tag to append to the output filename (default: "grobid").
        output_path: Optional path where the output file should be saved. If provided,
            this overrides the default feature directory behavior.
        regenerate_tei: Whether to regenerate TEI XML even if it exists.
    """
    pdf_path = Path(pdf_path)
    if not pdf_path.exists():
        raise FileNotFoundError(f"PDF file not found: {pdf_path}")

    # Get paper directory
    paper_dir = pdf_path.parent

    # Generate paper ID from PDF filename
    paper_id = pdf_path.stem

    # Determine output paths
    if output_path:
        output_path = Path(output_path)
        tei_path = output_path.with_suffix('.tei.xml')
        md_path = output_path.with_suffix('.md')
    else:
        # Use feature directory structure
        tei_path = get_feature_path(paper_dir, f'tei-xml-{tag}', paper_id, '.xml')
        md_path = get_feature_path(paper_dir, f'markdown-{tag}', paper_id, '.md')
    
    logger.info(f"Processing {pdf_path}")
    logger.info(f"TEI output will go to {tei_path}")
    logger.info(f"Markdown output will go to {md_path}")

    if regenerate_tei or (not tei_path.exists()):
        grobid_host = os.environ.get('GROBID_HOST', 'localhost')
        base_url = f"http://{grobid_host}:8070"
        
        # Call Grobid to process the PDF into TEI XML
        with open(pdf_path, 'rb') as f:
            files = {'input': (pdf_path.name, f, 'application/pdf')}
            resp = requests.post(
                f"{base_url}/api/processFulltextDocument",
                files=files,
                headers={'Accept': 'application/xml'},
                timeout=300  # 5 minute timeout
            )
        
        if resp.status_code != 200:
            raise RuntimeError(f"Grobid processing failed: {resp.status_code}")
        
        # Ensure the feature directory exists and save the TEI output
        tei_path.parent.mkdir(parents=True, exist_ok=True)
        tei_path.write_text(resp.text)
        logger.info(f"Saved TEI XML to {tei_path}")
    
    if format == 'markdown':
        # Convert TEI to Markdown using XSLT
        xslt_path = Path(__file__).parent / 'tei2md.xslt'
        if not xslt_path.exists():
            raise FileNotFoundError(f"XSLT stylesheet not found: {xslt_path}")
        
        xslt = etree.parse(str(xslt_path))
        transform = etree.XSLT(xslt)
        
        tei_doc = etree.parse(str(tei_path))
        markdown = str(transform(tei_doc))
        markdown = sanitize_markdown(markdown)
        
        # Ensure the feature directory exists and save Markdown output
        md_path.parent.mkdir(parents=True, exist_ok=True)
        md_path.write_text(markdown)
        logger.info(f"Saved Markdown to {md_path}")
    else:
        logger.info(f"Output TEI XML saved at {tei_path}")

process_pdf = process_pdf_grobid

# Files to ignore during operations
ignore_files = [
    "gh-store-snapshot.json",
    "papers-archive.json",
    "papers.json",
    "papers.yaml"
]

# def flush_old_conversions(data_path: str = "data/papers", tag: str = "grobid"):
#     """
#     Remove all previous conversions with the specified tag from feature directories.
#     """
#     base_path = Path(data_path).parent
#     tei_dir = base_path / 'features' / f'tei-xml-{tag}'
#     md_dir = base_path / 'features' / f'markdown-{tag}'
    
#     if tei_dir.exists():
#         for fpath in tei_dir.glob("*.xml"):
#             fpath.unlink()
#         tei_dir.rmdir()
    
#     if md_dir.exists():
#         for fpath in md_dir.glob("*.md"):
#             fpath.unlink()
#         md_dir.rmdir()

def generate_missing_conversions(
    data_path: str = "data/papers",
    tag: str = "grobid",
    checkpoint_cadence=5,
    regenerate_tei: bool = True,
):
    """
    Generate missing conversions for PDFs, saving outputs to feature directories.
    """
    data_path = Path(data_path)
    modified_files = []
    
    for i, pdf_fpath in enumerate(data_path.rglob("*.pdf")):
        # Skip PDFs in source directories
        if "source" in str(pdf_fpath):
            continue
            
        # Determine feature paths
        #base_dir = pdf_fpath.parent.parent
        paper_dir = pdf_fpath.parent
        paper_id = pdf_fpath.stem
        md_path = get_feature_path(paper_dir, f'markdown-{tag}', paper_id, '.md')
        
        if not md_path.exists():
            process_pdf_grobid(pdf_fpath, regenerate_tei=regenerate_tei)
            # Add both markdown and TEI paths
            tei_path = get_feature_path(paper_dir, f'tei-xml-{tag}', paper_id, '.xml')
            modified_files.extend([md_path, tei_path])
            logger.info(f"Generated conversions for {pdf_fpath.name}")
            
        if (i % checkpoint_cadence) == 0 and modified_files:
            msg = "Persisting feature conversions"
            commit_and_push(files_to_commit=modified_files, message=msg)
            modified_files = []
            
    if modified_files:
        commit_and_push(files_to_commit=modified_files, message="Persisting remaining feature conversions")

if __name__ == '__main__':
    fire.Fire({
        "process_pdf": process_pdf,
        "generate_missing_conversions": generate_missing_conversions,
        #"flush_old_conversions": flush_old_conversions,
    })



---
File: scripts/process_task.py
---
# scripts/process_task.py
from dataclasses import dataclass
import json
from pathlib import Path

from duckduckgo_search import DDGS
import fire
#from gh_store.core.access import AccessControl
from loguru import logger

ddg = DDGS()

#access_control = AccessControl(self.repo)

# #TODO: access validation as gh-store CLI capability
# issue = self.repo.get_issue(issue_number)
# if not self.access_control.validate_issue_creator(issue):

def with_prompt(
  target: str|Path,
  prompt: str="summarize the following:\n\n {content}",
  max_len: int=1024,
):
  with Path(target).open() as f:
    content = f.read()
  if max_len > 0:
    content=content[:(max_len-len(prompt))]
  msg = prompt.format(content=content) # should probably chunk somehow and iterate over chunks
  logger.info(msg)
  response = ddg.chat(msg)
  return response
  

# ... should just use locals...
OPERATORS={
    "ddg.chat": ddg.chat,
    "with_prompt": with_prompt,
}

@dataclass
class TaskConfig:
    operator: str
    kwargs: dict


def main(config: dict):
    logger.info(config)
    if not isinstance(config, dict):
      config = json.loads(config)
    config = TaskConfig(**config)
    logger.info(config)
    op = OPERATORS[config.operator]
    result = op(**config.kwargs)
    logger.info(result)
    return result

fire.Fire(main)



---
File: scripts/toggle_issues.py
---
# scripts/toggle_issues.py
import os
import requests
from github import Github
from loguru import logger
from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn, TimeRemainingColumn

logger.info("Starting issue toggle process")

# Initialize GitHub client
g = Github(os.environ["GITHUB_TOKEN"])
repo = g.get_repo(os.environ["REPO"])
label = os.environ["LABEL"]
perform_close = os.environ["PERFORM_CLOSE"].lower() == "true"
perform_reopen = os.environ["PERFORM_REOPEN"].lower() == "true"
reopen_all_matching = os.environ["REOPEN_ALL_MATCHING"].lower() == "true"

# Setup for direct API calls that will trigger webhooks
api_headers = {
    "Accept": "application/vnd.github.v3+json",
    "Authorization": f"token {os.environ['GITHUB_TOKEN']}",
    # This header is crucial - it tells GitHub to trigger webhooks
    "X-GitHub-Api-Version": "2022-11-28"
}
api_base_url = f"https://api.github.com/repos/{os.environ['REPO']}/issues"

def reopen_issue_with_webhook(issue_number: int) -> None:
    """Reopen an issue using the REST API to ensure webhook triggering."""
    response = requests.patch(
        f"{api_base_url}/{issue_number}",
        headers=api_headers,
        json={"state": "open"}
    )
    response.raise_for_status()

# Track which issues we close for potential reopening
closed_issue_numbers = []

# Create a progress instance with custom columns
progress = Progress(
    SpinnerColumn(),
    TextColumn("[bold blue]{task.description}"),
    BarColumn(),
    TextColumn("[progress.percentage]{task.percentage:>3.0f}%"),
    TimeRemainingColumn(),
    expand=True
)

with progress:
    if perform_close:
        # Get all open issues with the specified label
        logger.info(f"Finding open issues with label: {label}")
        open_issues = list(repo.get_issues(state="open", labels=[label]))

        if not open_issues:
            logger.warning("No open issues found with specified label")
        else:
            # Close all matching issues while recording their numbers
            logger.info(f"Found {len(open_issues)} issues to close")
            close_task = progress.add_task(
                "[red]Closing issues...", 
                total=len(open_issues)
            )
            
            for issue in open_issues:
                logger.info(f"Closing issue #{issue.number}")
                issue.edit(state="closed")
                closed_issue_numbers.append(issue.number)
                progress.update(close_task, advance=1)
    else:
        logger.info("Skipping close step")

    if perform_reopen:
        if reopen_all_matching:
            # Get all closed issues with the specified label
            logger.info(f"Finding all closed issues with label: {label}")
            closed_issues = list(repo.get_issues(state="closed", labels=[label]))
            
            if not closed_issues:
                logger.warning("No closed issues found with specified label")
            else:
                logger.info(f"Found {len(closed_issues)} issues to reopen")
                reopen_task = progress.add_task(
                    "[green]Reopening all matching issues...", 
                    total=len(closed_issues)
                )
                
                for issue in closed_issues:
                    logger.info(f"Reopening issue #{issue.number}")
                    reopen_issue_with_webhook(issue.number)
                    progress.update(reopen_task, advance=1)
        
        elif closed_issue_numbers:
            # Reopen only issues we just closed
            logger.info("Reopening previously closed issues")
            reopen_task = progress.add_task(
                "[green]Reopening issues from this run...", 
                total=len(closed_issue_numbers)
            )
            
            for number in closed_issue_numbers:
                logger.info(f"Reopening issue #{number}")
                reopen_issue_with_webhook(number)
                progress.update(reopen_task, advance=1)
        else:
            logger.info("No issues to reopen")
    else:
        logger.info("Skipping reopen step")

logger.info("Issue toggle process completed")


