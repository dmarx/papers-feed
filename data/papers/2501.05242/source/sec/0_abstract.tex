\begin{abstract}
3D Gaussian Splatting (3DGS) has recently revolutionized novel view synthesis in the  Simultaneous Localization and Mapping (SLAM). However, existing SLAM methods utilizing 3DGS have failed to provide high-quality novel view rendering for monocular, stereo, and RGB-D cameras simultaneously. Notably, some methods perform well for RGB-D cameras but suffer significant degradation in rendering quality for monocular cameras. In this paper, we present \emph{Scaffold}-SLAM, which delivers simultaneous localization and high-quality photorealistic mapping across monocular, stereo, and RGB-D cameras. We introduce two key innovations to achieve this state-of-the-art visual quality. First, we propose Appearance-from-Motion embedding, enabling 3D Gaussians to better model image appearance variations across different camera poses. Second, we introduce a frequency regularization pyramid to guide the distribution of Gaussians, allowing the model to effectively capture finer details in the scene. Extensive experiments on monocular, stereo, and RGB-D datasets demonstrate that \emph{Scaffold}-SLAM significantly outperforms state-of-the-art methods in photorealistic mapping quality, e.g., PSNR is $16.76\%$ higher in the TUM RGB-D datasets for monocular cameras.  %Notably, among SLAM methods utilizing 3DGS, it is the first decoupled method to achieve higher rendering quality than coupled methods on the TUM RGB-D and Replica datasets. %Moreover, our method ensures real-time rendering and tracking, while maintaining a notably fast training speed, balancing efficiency and accuracy. 

%3DGS最近已经对于SLAM系统的新视角合成产生变革，与神经辐射场相比取得了优越的结果。然而，已有采用3DGS的SLAM方法没能同时实现单目、双目和RGBD相机的高质量新视角渲染。并且，部分方法对于RGB-D中深度图质量较差的场景渲染质量严重下降。 特别地，部分方法在RGB-D场景中工作的很好，但在单目场景中渲染精度严重下降。我们的方法HQ-SLAM 同时实现了单目、双目和RGBD相机的高质量真实感建图与精确的定位。我们引入了两项关键的创新来实现这种SOTA的视觉质量。首先，我们提出了Appearance-from-Motion embedding 使得 3D Gaussians 能更好地学习图像外观变化与不同相机位姿。第二，我们提出了一种 frequency-domain decomposition pyramid 来指导acnhor朝向复杂区域生长，从而使得模型能更好地建模场景中的高频细节。Extensive experiments on monocular, RGB-D, and stereo datasets demonstrate that HQ-SLAM significantly outperforms state-of-the-art methods in novel veiw rendering quality, achieving 16.45\% PSNR improvement on the TUM RGB-D datasets for monocular camera. 特别地，我们方法不仅对于单目、双目和RGBD相机都实现了最高的平均渲染精度，同时我们算法单目相机与RGB-D的渲染结果之间的差距也非常小。
%本文是第一个解耦的方法在渲染精度方面超过耦合的方法
\end{abstract}