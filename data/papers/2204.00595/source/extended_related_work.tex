\section{Extended Related Work}
\label{app:related}
In this section, we extend the related works referenced in the main paper and discuss them in detail.
\paragraph{Sparse Training.} Our work is loosely related to neural network pruning. By iteratively eliminating neurons and connections, pruning has seen great success in compressing complex models. \citet{han2015deep,han2015learning} put forth two naive but effective algorithms to compress models up to 49x and maintain comparable accuracy. \citet{li2016pruning} employ filter pruning to reduce the cost of running convolution models up to 38 $\%$, \citet{NIPS2017_a51fb975} prunes the network at runtime, hence retaining the flexibility of the full model. \citet{dong2017learning} prunes the network locally in a layer by layer manner.  \citet{sanh2020movement} prunes with deterministic first-order information, which is more adaptive to pretrained model weights. \citet{lagunas2021block} prunes transformers models with block sparsity pattern during fine-tuning, which leads to real hardware speed up while maintaining the accuracy. \citet{zhu2017prune} finds large pruned sparse network consistently outperform the small dense networks with the same compute and memory footprints. Although both our and all the pruning methods are aiming to produce sparse models, we differ in our emphasis on the overall efficiency, whereas pruning mostly focuses on inference efficiency and disregards the cost in finding the smaller model.

There has been more recent work on sparse methods that focuses on speeding up
training and not just inference, such as SNFS~\citep{dettmers2019sparse},
RigL~\citep{dettmers2019sparse}, Top-KAST~\citep{jayakumar2021top}.
These methods often focus on FLOP counts, which may not correlate well with
wall-clock time on modern hardware (e.g., GPUs).
Block-sparsity is another approach that exploits the block-oriented nature of
GPUs~\citep{gray2017gpu, child2019generating, guo2020accelerating}.
Sparse models have also been found useful to improve the training process of
dense models.
For example, sparsity can be used to regularize dense models to improve
accuracy~\citep{han2016dsd}, or to alternate between sparse and dense training
to ease deployment~\citep{peste2021ac}.
Our sparse-to-dense reverse sparsification instead focuses on speeding up dense
training, where the sparse model is used for efficiency and not regularization.


In addition, models proposed in our work can be roughly seen as a class of manually constructed lottery tickets. Lottery tickets \citet{frankle2018lottery} are a set of small sub-networks derived from a larger dense network, which outperforms their parent networks in convergence speed and potentially in generalization. A huge number of studies are carried out to analyze these tickets both empirically and theoretically: \citet{morcos2019one} proposed to use one generalized lottery tickets for all vision benchmarks and got comparable results with the specialized lottery tickets; \citet{frankle2019stabilizing} improves the stability of the lottery tickets by iterative pruning; \citet{frankle2020linear} found that subnetworks reach full accuracy only if they are stable against SGD noise during training; \citet{orseau2020logarithmic} provides a logarithmic upper bound for the number of parameters it takes for the optimal sub-networks to exist; \citet{pensia2020optimal} suggests a way to construct the lottery ticket by solving the subset sum problem and it's a proof by construction for the strong lottery ticket hypothesis. Furthermore, follow-up works \citep{liu2020finding, wang2020picking, tanaka2020pruning} show that we can find tickets without any training labels.


\paragraph{Structured matrices and butterfly matrices.}
Structured matrices are those with asymptotically fast matrix-vector
multiplication algorithm ($o(n^2)$ time complexity) and few parameters ($o(n^2)$
space complexity).
Common examples include sparse \& low-rank matrices, and fast transforms such as
Fourier transform, Chebyshev transform, Legendre transform, and more generally
orthogonal polynomial transforms.
These transforms have been widely used in data preprocessing (e.g., DFT in
speech processing~\citep{jurafsky2014speech}) and kernel
approximation~\citep{le2013fastfood,yu2016orthogonal}.
Many generalizations of these transforms have been used in machine learning to
replace dense weight
matrices~\citep{sindhwani2015structured,thomas2018learning,gu2020hippo}.
\citet{desa2018two} shows that any structured matrix (in the form of arithmetic
circuits) can be written as product of sparse matrices,
and~\citet{dao2020kaleidoscope} shows that products of butterfly matrices can
represent these structured matrices almost optimally in terms of runtime and
memory.
The class of butterfly matrices~\citep{parker1995random} have also been used in
kernel models~\citep{munkhoeva2018quadrature, choromanski2019unifying} and deep
learning models~\citep{vahid2020butterfly,lin2021deformable,
  ailon2021sparse}.

\paragraph{Neural Operators for PDEs.}

Deep learning has found application in the domain of differential equations and scientific computing \cite{rackauckas2020universal}, with methods developed for prediction and control problems \cite{kidger2020neural,massaroli2021differentiable}, as well as acceleration of numerical schemes \cite{poli2020hypersolvers,jolicoeur2021gotta}. Specific to the \textit{partial differential equations} (PDEs) are approaches designed to learn solution operators \cite{raissi2019physics,fan2020solving,li2020fourier}, and hybridized solvers \cite{kochkov2021machine}, evaluated primarily on classical fluid dynamics.

The promise of these approaches is to offer, at the cost of an initial training procedure, accurate yet faster solutions than an appropriate numerical method tuned for a specific problem, which can then be leveraged for real-time forecasting or within larger feedback loops. Nonetheless, optimal design of neural operators remains an open problem, with most relying on fast Fourier transforms (FFT) or standard dense neural architectures. Instead, neural operators based on Monarch are capable of approximating all fast transforms, thus allowing automated optimization towards a suitable transform on a given PDE problem.

\paragraph{MRI.} Accelerated multi-coil MRI is an essential mechanism for reducing long scan times and making certain scan types feasible. In multi-coil MRI, data is acquired in the spatial Fourier domain (a.k.a \textit{k-space}) across multiple coils (sensors). To reduce scan time, this data is sampled below the required rate for recovering the underlying signal (i.e. Nyquist rate), which results in signal aliasing (see Appendix \ref{sec:experiment_details_mri}). In these settings, direct application of the inverse fast Fourier transform (FFT) cannot suppress aliasing artifacts.

Classical MRI reconstruction approaches supplement the FFT by leveraging shared information across multiple coils and strong analytical priors to regularize image recovery objectives. SENSE-based methods jointly dealias images across multiple coils and reweight the final image based on the spatial sensitivity profile of each coil \citep{pruessmann1999sense}. Compressed sensing promotes image sparsity in transformation domains (e.g. Fourier, wavelet) while enforcing data consistency between the Fourier transform of the reconstructed image and the observed measurements \citep{lustig2007sparse}. Low-rank methods enforce low rank structure across slowly-varying dimensions or local patches in the data \citep{ong2016beyond,ravishankar2017low,haldar2013low}. Additionally, GRAPPA-based techniques optimize kernels to directly interpolate missing k-space samples to promote smoothness in the Fourier domain \cite{griswold2002generalized}. Despite their efficacy, these methods have long reconstruction times, require explicit analytical priors, and require careful hyperparameter fine-tuning.

CNNs have shown promise as a fast-at-inference, learnable alternative to classical MRI reconstruction methods \cite{knoll2020deep}. In supervised learning, fully convolutional networks (e.g. U-Net \citep{ronneberger2015u} or unrolled networks \citep{sandino2020compressed,hammernik2018learning}) learn a mapping between paired zero-filled and fully-sampled, ground truth images. However, supervised methods require a large fully-sampled (labeled) data corpus and are sensitive to distribution drifts due to patient, hardware, and sequence heterogeneity \cite{darestani2021measuring}. To reduce dependence on labeled data, unsupervised methods have used generative adversarial networks \citep{cole2020unsupervised, mardani2018deep}, self-supervised learning \cite{yaman2020self}, dictionary learning \cite{lahiri2021blind}, and untrained networks \cite{darestani2021accelerated}. Despite their 
label efficiency, these techniques still underperform supervised methods and are also sensitive to distribution shift. Recently, a family of semi-supervised reconstruction methods demonstrated label efficiency and robustness to physics-driven perturbations, such as changes in signal-to-noise ratio or patient motion \citep{desai2021noise2recon, desai2021vortex}. However, these methods require large amounts of unlabeled data, which can be difficult to curate in few-shot settings. Thus, despite their success in controlled environments, prospective clinical deployment of these models has been stifled \citep{chaudhari2020prospective}.

In our work, we propose a model with a single FFT-initialized factorized Monarch matrix. Such a matrix can provide the benefits of both a simple linearized transformation like FFT and a learnable mechanism to remove aliasing artifacts resulting from the undersampled k-space. The smaller learnable parameter set may reduce overfitting in data-limited settings while preserving the transformation structure of Fourier matrices. Thus, our approach can be interpreted as a hybrid between analytically-constrained classical methods and data-dependent CNNs.

