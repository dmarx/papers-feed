\section{Related Work}
\noindent\textbf{RL frameworks.} 
There have been plenty of frameworks for RL, ranging from general-purpose RL systems design for small-scale DNNs~\cite{liang2018rllib, liang2021rllib, openaibaseline, coach, hafner2017tensorflowagents, PytorchRL} to RLHF systems specifically optimized for LLMs~\cite{yao2023deepspeedchat, hu23openrlhf, NeMoAligner, xiao2023adaptive, CollosalChat}. 
We have thoroughly examined closely related work in \textsection\ref{sec:2_bckground_and_motivation} and we discuss more RL frameworks in this section. These RL frameworks~\cite{openaibaseline, coach, hafner2017tensorflowagents, PytorchRL, wang2023gear}, similar to recent RLHF systems, use a hodgepodge of multi-controller frameworks to implement their algorithms. They establish multiple long-running distributed programs with each component coordinating the execution order with hard-coded data synchronization. Gear~\cite{wang2023gear} further optimized the experience replay segment of the RL pipeline. However, all these frameworks fail to support LLM training, inference, and generation in RLHF.






\noindent\textbf{LLM training and serving systems.}
TorchDDP~\cite{paszke2019pytorch} and Horovod~\cite{sergeev2018horovod} support data parallel training. ByteScheduler~\cite{pengGenericCommunicationScheduler2019} and DeepSpeed~\cite{rasley2020deepspeed} extend data parallelism with communication and memory optimizations. 
Numerous systems~\cite{shoeybi2019megatron, jiang2024megascale, lu2017flexflow, wang2019tofu, narayanan2021efficient, fan2021dapple, zhang2022accelerating} optimized large model training through model parallelisms such as tensor parallelism and pipeline parallelism to partition models across devices. 
LLM serving systems~\cite{kwon2023efficient, agrawal2023sarathi, zhongDistServeDisaggregatingPrefill2024, yu2022orca, nvidiaTensorRTLLM, song2023powerinfer} also adopts data and model parallelism to accelerate auto-regressive generation with specialized optimizations like continuous-batching~\cite{yu2022orca} and chunked-prefill~\cite{agrawal2023sarathi}.
Note that all the above frameworks adopt multi-controller paradigm for efficient computation.  



\noindent\textbf{Dataflow systems.}
Dataflow systems like MapReduce~\cite{dean2008mapreduce}, Spark~\cite{zaharia2016spark}, Dryad~\cite{isard2007dryad}, and Naiad~\cite{murray2013naiad} are popular for analytics and ML workloads but they lack support for dynamic task graphs. 
Ray~\cite{moritz2018ray} unifies task-parallel and actor programming models in a single dynamic task graph and implements a scalable distributed scheduler and a global control store, which is adopted by many RL frameworks~\cite{liang2018rllib, liang2021rllib}. 
Pathways~\cite{barham2022pathways}, a closed-source project for TPUs, are designed to easily express complex parallelism patterns and fine-grain control flow within a single DNN model, such as pipeline parallelism and Mixture-of-Experts with sparse computation. It employs an asynchronous distributed dataflow design that enables parallel control plane execution despite data dependencies, reducing the dispatch overhead from single-controller paradigm. Its main focus lies on single-model training, requiring complex compilations of each sub-network of a DNN model. \sysname{} can integrate Pathways as a submodule to implement the computation of models in the RLHF dataflow.







