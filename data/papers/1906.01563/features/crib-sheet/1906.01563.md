- **Hamiltonian Neural Networks (HNNs)**: A neural network architecture inspired by Hamiltonian mechanics, designed to learn and respect conservation laws in an unsupervised manner.

- **Key Equation**: The Hamiltonian \( H(q, p) \) relates the state of a system to conserved quantities, typically energy, and is defined such that:
  \[
  \frac{dq}{dt} = \frac{\partial H}{\partial p}, \quad \frac{dp}{dt} = -\frac{\partial H}{\partial q}
  \]

- **Training Objective**: The loss function for HNNs is defined as:
  \[
  L_{HNN} = \frac{\partial H_\theta}{\partial p} - \frac{\partial q}{\partial t}^2 + \frac{\partial H_\theta}{\partial q} + \frac{\partial p}{\partial t}^2
  \]

- **Properties of HNNs**:
  - **Conservation of Energy**: HNNs learn to conserve energy-like quantities from data.
  - **Reversibility**: The mapping from \((q, p)\) at one time to another is bijective.
  - **Counterfactual Analysis**: Allows manipulation of conserved quantities by integrating along the gradient of \( H \).

- **Tasks Evaluated**:
  - **Ideal Mass-Spring System**: Hamiltonian given by:
    \[
    H = \frac{1}{2} k q^2 + \frac{p^2}{2m}
    \]
    (Set \( k = m = 1 \)).
  
  - **Ideal Pendulum**: Hamiltonian defined as:
    \[
    H = 2mgl(1 - \cos q) + \frac{l^2 p^2}{2m}
    \]
    (Set \( m = l = 1 \), \( g = 3 \)).

  - **Real Pendulum**: Utilizes noisy data from a real-world pendulum, demonstrating HNNs' performance on biased data.

  - **Two-Body Problem**: Hamiltonian for two interacting point particles:
    \[
    H = \frac{|p_{CM}|^2}{2(m_1 + m_2)} + \frac{|p_1|^2}{2m_1} + \frac{|p_2|^2}{2m_2} + g \frac{m_1 m_2}{|q_1 - q_2|^2}
    \]
    (Set \( m_1 = m_2 = g = 1 \)).

- **Training Methodology**:
  - **Optimizer**: Adam optimizer with a learning rate of \( 10^{-3} \).
  - **Batch Size**: Set to the total number of examples due to small training sets.
  - **Model Architecture**: Fully-connected neural networks with three layers and 200 hidden units using tanh activations.

- **Performance Metrics**:
  - **L2 Train Loss**: Measures model fitting to individual data points.
  - **L2 Test Loss**: Evaluates generalization to unseen data.
  - **Mean Squared Error (MSE)**: Assesses divergence from true dynamics over time.

- **Integration Method**: Utilizes the fourth-order Runge-Kutta integrator for simulating dynamics, with an error tolerance of \( 10^{-9} \).

- **Results Summary**:
  - HNNs demonstrate superior performance in conserving energy-like quantities compared to baseline models, which tend to drift over time.
  - HNNs maintain stability and accuracy in predictions, even in the presence of noise and bias in real-world data.