- **Hamiltonian Neural Networks (HNNs)**: A neural network architecture inspired by Hamiltonian mechanics, designed to learn and respect conservation laws in an unsupervised manner.

- **Key Concept**: HNNs parameterize the Hamiltonian \( H(q, p) \) using a neural network, allowing the model to learn conserved quantities directly from data.

- **Hamiltonian Mechanics**: 
  - Defines dynamics through the equations:
    \[
    \frac{dq}{dt} = \frac{\partial H}{\partial p}, \quad \frac{dp}{dt} = -\frac{\partial H}{\partial q}
    \]
  - The Hamiltonian \( H \) relates the state of a system to conserved quantities, typically energy.

- **Training Objective**: 
  - The loss function for HNNs is defined as:
    \[
    L_{HNN} = \frac{\partial H_\theta}{\partial p} - \frac{\partial q}{\partial t}^2 + \frac{\partial H_\theta}{\partial q} + \frac{\partial p}{\partial t}^2
    \]
  - This loss encourages the model to learn dynamics that conserve energy-like quantities.

- **Model Properties**:
  - **Reversibility**: HNNs are perfectly reversible; the mapping from \((q, p)\) at one time to another is bijective.
  - **Counterfactual Analysis**: HNNs can simulate changes in conserved quantities, e.g., "What if we added 1 Joule of energy?"

- **Tasks Evaluated**:
  - **Ideal Mass-Spring System**: 
    \[
    H = \frac{1}{2} k q^2 + \frac{p^2}{2m}
    \]
    - Parameters: \( k = m = 1 \), energy sampled from \([0.2, 1]\).
  
  - **Ideal Pendulum**: 
    \[
    H = 2mgl(1 - \cos q) + \frac{l^2 p^2}{2m}
    \]
    - Parameters: \( m = l = 1 \), \( g = 3 \), energy sampled from \([1.3, 2.3]\).

  - **Real Pendulum**: Utilizes noisy data from a real-world pendulum, demonstrating HNNs' performance on biased data.

- **Performance Metrics**:
  - **L2 Train Loss**: Measures model fit to training data.
  - **L2 Test Loss**: Measures model fit to test data.
  - **Mean Squared Error (MSE)**: Evaluates divergence from true dynamics over time.

- **Results Summary**:
  - HNNs train as quickly as baseline models but outperform them in energy conservation metrics, showing less divergence over time.

- **Two-Body Problem**: 
  - Hamiltonian given by:
    \[
    H = \frac{|p_{CM}|^2}{2(m_1 + m_2)} + \frac{|p_1|^2 + |p_2|^2}{2\mu} + g \frac{m_1 m_2}{|q_1 - q_2|^2}
    \]
  - Involves multiple degrees of freedom, showcasing HNNs' scalability to complex systems.

- **Conclusion**: HNNs effectively learn conservation laws and demonstrate superior generalization and stability in dynamic systems compared to traditional neural networks.