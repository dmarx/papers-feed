
\subsection{Sentiment Analysis}
\label{subsec:sentiment_exp}
Table \ref{tab:sent_results} present results on sentiment analysis. 
Across all datasets, models trained with \ssmba\ outperform baseline models and all other data augmentation methods on OOD data.
%On ID data, CNNs trained with \ssmba\ outperform other models on all datasets, with RNNs trained with \ssmba\ outperforming other models on 3/4 ID datasets.
On ID data, \ssmba\ outperforms baseline models and other data augmentation methods on all datasets for CNN models, and 3/4 datasets for RNN models.
On average, \ssmba\ improves OOD performance by 1.1\% for RNN models and 0.7\% for CNN models, and ID performance by 0.8\% for RNN models and 0.4\% for CNN model.
Other methods achieve much smaller OOD generalization gains and perform worse than baseline models on multiple datasets.

On the AR-Full dataset, RNNs trained with \ssmba\ demonstrate improvements in OOD accuracy of 1.1\% over baseline models.
On the AR-Clothing dataset, which exhibits less domain shift than AR-Full, RNNs trained with \ssmba\ exhibit slightly lower OOD improvement.
CNN models exhibit about the same boost in OOD accuracy across both Amazon review datasets.

On the Movies dataset where we observe a large difference in average sentence length between the two domains, \ssmba\ still manages to present considerable gains in OOD performance.
%, outperforming other data augmentation methods which fail to improve either ID or OOD generalization.
Although RNNs trained with \ssmba\ fail to improve ID performance, their OOD performance in this setting still beats other data augmentation methods.

On the Yelp dataset, we observe large performance gains on both ID and OOD data for RNN models.
The improvements on CNN models are more modest, but notably our method is the only one that improves OOD generalization.


\begin{table}[t!]
\small
\centering
\begin{tabular}{lcccc}
\toprule
& \multicolumn{2}{c}{\textbf{MNLI}} & \multicolumn{2}{c}{\textbf{ANLI}}\\
\cmidrule(lr){2-3}
\cmidrule(lr){4-5}
Augmentation  & ID & OOD & ID & OOD \\
\midrule
None & 84.29 & 80.61 & 42.54 & \textbf{43.80} \\
EDA & 83.44 & 80.34 & 45.59 & 42.77 \\
CBERT & 84.24 & 80.34 & 46.68 & 43.53 \\
UDA & 84.24 & 80.99 & 45.85 & 42.89 \\
\midrule
\ssmba\ & \textbf{85.71} & \textbf{82.44\rlap{$^{*\dagger}$}} & \textbf{48.46\rlap{$^{*\dagger}$}} & \textbf{43.80}  \\
\bottomrule
\end{tabular}
\caption{Average in-domain and out-of-domain accuracy (\%) for RoBERTa models trained on NLI tasks. Accuracies marked with a $*$ and $\dagger$
are statistically significantly higher than unaugmented models and the next best model respectively, both with $p<0.01$.}
\label{tab:nli_results}
\end{table}

\subsection{Natural Language Inference}
\label{subsec:nli_exp}
Table \ref{tab:nli_results} presents results on NLI tasks.
Models trained with \ssmba\ outperform or match baseline models and data augmentation methods on both ID and OOD data. 
Even with a more difficult task and stronger baseline model, \ssmba\ still confers large accuracy gains.
On MNLI, \ssmba\ improves OOD accuracy by 1.8\%, while
the best performing baseline achieves only 0.3\% improvement.
Our method also improves ID accuracy by 1.4\%.
All other baseline methods hurt both ID and OOD accuracy, or confer negligible improvements.

On the intentionally difficult ANLI, \ssmba\ maintains baseline OOD accuracy while conferring a large 6\% improvement on ID data. 
Other augmentation methods improve ID accuracy by a much smaller margin while degrading OOD accuracy.
Surprisingly, pseudo-labelling augmented examples in the R2 and R3 domains produced the best results, even when the labelling model had poor in-domain performance.


\begin{table}[t!]
\small
\centering
\begin{tabular}{lc}
\toprule
System & BLEU\\
\midrule
ConvS2S \citep{edunov-etal-2018-classical} & 32.2 \\
Transformer \citep{wu2018pay} & 34.4 \\
DynamicConv \citep{wu2018pay} & 35.2 \\
\midrule
Transformer (ours) & 34.70 \\
+ Word Dropout & 34.43 \\
+ RAML & 35.00 \\
+ SwitchOut & 35.28 \\
\midrule
+ \ssmba\ & \textbf{36.10\rlap{$^{*\dagger}$}} \\
\bottomrule
\end{tabular}
\caption{Results on IWSLT de$\to$en for models trained with different data augmentation methods. Scores marked with a $*$ and $\dagger$ are statistically significantly higher than baseline transformers and the next best model, both with $p<0.01$.}
\label{tab:iwslt_results}
\end{table}

\begin{table}[t!]
\small
\centering
\begin{tabular}{lcccc}
\toprule
& \multicolumn{2}{c}{\textbf{OPUS}} & \multicolumn{2}{c}{\textbf{de$\to$rm}} \\
\cmidrule(lr){2-3}
\cmidrule(lr){4-5}
Augmentation & ID & OOD & ID & OOD \\
\midrule
None & \textbf{56.99} & 10.24 & 51.53 & 12.23 \\
Word Dropout  & 56.26 & 10.15 & 50.23 & 12.23 \\
RAML & 56.76 & 10.10 & 51.52 & 12.49 \\
SwitchOut  & 55.50 & 9.27 & 51.34 & 13.59 \\
\midrule
\ssmba\  & 54.88 & \textbf{10.65} & \textbf{51.97} & \textbf{14.67\rlap{$^{*\dagger}$}} \\
\bottomrule
\end{tabular}
\caption{Average in-domain and out-of-domain BLEU for models trained on OPUS (de$\to$en) and de$\to$rm data. Scores marked with a $*$ and $\dagger$ are statistically significantly higher than baseline transformers and the next best model, both with $p<0.01$.}
\label{tab:nmt_results}
\end{table}

\subsection{Machine Translation}
\label{subsec:nmt_exp}
Table \ref{tab:iwslt_results} presents results on IWSLT14 de$\to$en.
We compare our results with convolutional models \citep{edunov-etal-2018-classical} and strong baseline transformer and dynamic convolution models \citep{wu2018pay}.
\ssmba\ improves BLEU by almost 1.5 points, outperforming all other baseline and comparison models.
Compared to \ssmba, other augmentation methods offer much smaller improvements or even degrade performance.

Table \ref{tab:nmt_results} presents results on OPUS and de$\to$rm.
On OPUS, where the training domain contains highly specialized language and differs significantly both from other domains and the learned MLM manifold, 
\ssmba\ offers a small boost in OOD BLEU but degrades ID performance. 
All other augmentation methods degrade both ID and OOD performance.
On de$\to$rm, \ssmba\ improves OOD BLEU by a large margin of 2.4 points, and ID BLEU by 0.4 points. 
Other augmentation methods offer much smaller OOD improvements while degrading ID performance.