In this paper, we introduce \ssmba, a method for generating synthetic data in settings where the underlying data manifold is difficult to characterize.
In contrast to other data augmentation methods, \ssmba\ is applicable to any supervised task, requires no task-specific knowledge, and does not rely on dataset-specific fine-tuning.
We demonstrate \ssmba's effectiveness on three NLP tasks spanning classification and sequence modeling: sentiment analysis, natural language inference, and machine translation.
We achieve gains of 0.8\% accuracy on OOD Amazon reviews, 1.8\% accuracy on OOD MNLI, and 1.4 BLEU on in-domain IWSLT14 de$\to$en.
%We show that \ssmba\ consistently improves both in-domain performance and OOD robustness, outperforming baselines and other augmentation methods. % which often fail to generalize.
Our analysis shows that \ssmba\ is robust to the initial dataset size, reconstruction model choice, and corruption amount, offering OOD robustness improvements in most settings.
Future work will explore applying \ssmba\ to the target side manifold in structured prediction tasks, as well as other natural language tasks and settings where data augmentation is difficult.