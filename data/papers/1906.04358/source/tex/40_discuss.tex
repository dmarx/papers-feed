%!TeX root=../main.tex

In this work we introduced a method to search for simple neural network architectures with strong inductive biases. % for performing a given task.
%
Since networks are optimized to perform well using a shared weight over a range of values, this single parameter can easily be tuned to increase performance.
%
%Individual weight values can then be further tuned as offsets from the best shared weight. The ability to quickly fine-tune weights may find uses in continual lifelong learning where agents need to continually acquire, fine-tune, and transfer skills throughout their lifespan~\cite{parisi2018continual}.
Individual weights can be further tuned from a best shared weight. The ability to quickly fine-tune weights is useful in few-shot learning~\cite{finn2017model} and may find uses in continual learning~\cite{parisi2018continual} where agents continually acquire, fine-tune, and transfer skills throughout their lifespan, as in animals~\cite{zador2019critique}.
%
Inspired by the Baldwin effect~\cite{baldwin1896new}, weight tolerant networks have long linked theories of evolution and learning in AI~\cite{ackley1991interactions,hinton1996learning,smith1987learning}.

%Researchers inspired by the Baldwin effect~\cite{baldwin1896new} have long linked theories of evolution and learning with weight tolerant networks ~\cite{ackley1991interactions,hinton1996learning,smith1987learning}.

%Inspired by the Baldwin effect~\cite{baldwin1896new}, researchers have long used weight tolerant networks to link theories of evolution and learning in AI~\cite{ackley1991interactions,hinton1996learning,smith1987learning}.

%Early works~\cite{ackley1991interactions,hinton1996learning,smith1987learning} connected the evolution of weight tolerant networks to the Baldwin effect~\cite{baldwin1896new}.

% Geoff Hinton comment:
% connections to Baldwin effect. It seems very relevant to evolving architectures that are weight tolerant. It shows that innate skills can be developed by using learning to do nearly all of the search. Learning completely changes the landscape for evolution.
% MAML (finn2017model): also a method of getting weights 'close' to what they should be, allowing few-shot learning for generalization and adaptability
% 

To develop a single WANN capable of encoding many different useful tasks in its environment, one might consider developing a WANN with a strong intrinsic bias for intrinsic motivation~\cite{schmidhuber1991curious,oudeyer2007intrinsic,pathak2017curiosity}, and continuously optimize its architecture to perform well at pursuing novelty in an open-ended environment~\cite{lehman2008exploiting}. Such a WANN might encode, through a curiosity reward signal, a multitude of skills that can easily be fine-tuned for a particular downstream task in its environment later on.

While our approach learns network architectures of increasing complexity by adding connections, network pruning approaches find new architectures by their removal. It is also possible to learn  a pruned network capable of performing additional tasks without learning weights~\cite{mallya2018piggyback}. A concurrent work~\cite{zhou2019deconstructing} to ours learns a \textit{supermask} where the sub-network pruned using this mask performs well at image recognition even with randomly initialized weights -- it is interesting that their approach achieves a similar range of performance on MNIST compared to ours. While our search method is based on evolution, future work may extend the approach by incorporating recent ideas that formulate architecture search in a differentiable manner~\cite{liu2018darts} to make the search more efficient.

The success of deep learning is attributed to our ability to train the weights of large neural networks that consist of well-designed building blocks on large datasets, using gradient descent. While much progress has been made, there are also limitations, as we are confined to the space of architectures that gradient descent is able to train. For instance, effectively training models that rely on discrete components~\cite{jang2016categorical,graves2014neural} or utilize adaptive computation mechanisms~\cite{graves2016adaptive} with gradient-based methods remain a challenging research area. We hope this work will encourage further research that facilitates the discovery of new architectures that not only possess inductive biases for practical domains, but can also be trained with algorithms that may not require gradient computation.

That the networks found in this work do not match the performance of convolutional neural networks is not surprising. It would be an almost embarrassing achievement if they did. For decades CNN architectures have been refined by human scientists and engineers -- but it was not the reshuffling of existing structures which originally unlocked the capabilities of CNNs. Convolutional layers were themselves once novel building blocks, building blocks with strong biases toward vision tasks, whose discovery and application have been instrumental in the incredible progress made in deep learning.
%
%If we hope to achieve more than incremental improvements in network architectures, it is worth experimenting with new building blocks, not just their arrangements.
% I'm not sure about ending on this note -- do we have a strong case to say we are creating building blocks? (DH: modified)
% Compute resources available to the research community has grown significantly since the time convolutional neural networks have been discovered. If we are devoting such resources to automated discovery and hope to achieve more than incremental improvements in network architectures, we believe it is also worth looking for new building blocks, not just their arrangements. (in case get called out)
The computational resources available to the research community have grown significantly since the time convolutional neural networks were discovered. If we are devoting such resources to automated discovery and hope to achieve more than incremental improvements in network architectures, we believe it is also worth trying to discover new building blocks, not just their arrangements.

Finally, we see similar ideas circulating in the neuroscience community. A recent neuroscience commentary, \textit{“What artificial neural networks can learn from animal brains”}~\cite{zador2019critique} provides a critique of how \textit{learning} (and also \textit{meta-learning}) is currently implemented in artificial neural networks. Zador~\cite{zador2019critique} highlights the stark contrast with how biological learning happens in animals:

\textit{“The first lesson from neuroscience is that much of animal behavior is innate, and does not arise from learning. Animal brains are not the blank slates, equipped with a general purpose learning algorithm ready to learn anything, as envisioned by some AI researchers; there is strong selection pressure for animals to restrict their learning to just what is needed for their survival.”} \cite{zador2019critique}

This paper is strongly motivated towards these goals of blending innate behavior and learning, and we believe it is a step towards addressing the challenge posed by Zador. We hope this work will help bring neuroscience and machine learning communities closer together to tackle these challenges.
