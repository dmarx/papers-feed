\documentclass{article}
   
% if you need to pass options to natbib, use, e.g.:
% \PassOptionsToPackage{numbers, compress}{natbib}
% before loading nips_2019

% ready for submission
%\usepackage[nonatbib]{neurips_2019}

% to compile a preprint version, e.g., for submission to arXiv, add
% add the [preprint] option:

%\usepackage[nonatbib]{neurips_2019} % anon
\usepackage[final,nonatbib]{neurips_2019}
%\usepackage[preprint,nonatbib]{neurips_2019}
\usepackage[square,sort,comma,numbers]{natbib}

% to avoid loading the natbib package, add option nonatbib:
% \usepackage[nonatbib]{neurips_2019}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts

%\usepackage{CJKutf8}

\usepackage{hyperref}       % hyperlinks
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=blue,
}
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography

\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{wrapfig}
\usepackage{enumitem}
\usepackage{subfigure}

\usepackage{amssymb,amsmath}
\usepackage{mathtools}

\usepackage{lipsum} % Filler text

\newcommand{\dhcom}[1]{\textcolor{magenta}{[DH: #1]}}

\def \websiteurl {https://weightagnostic.github.io/}
%\def \websiteurl {https://anonwann.github.io/}

\usepackage[table,xcdraw]{xcolor} % Tables and Color
\usepackage{multirow}
\usepackage[normalem]{ulem} % Underline
\useunder{\uline}{\ul}{}

\makeatletter
\renewcommand*{\@fnsymbol}[1]{\ifcase#1\or \ensuremath{\dagger} \else\@arabic{#1}\fi}
\makeatother

\title{Weight Agnostic Neural Networks}

\author{
  Adam Gaier\thanks{Work done while at Google Brain.}\\
  Bonn-Rhein-Sieg University of Applied Sciences\\
  Inria / CNRS / Universit\'e de Lorraine \\
  \texttt{adam.gaier@h-brs.de} \\
  \And
  David Ha \\
  Google Brain\\
  Tokyo, Japan \\
  \texttt{hadavid@google.com} \\
}

\begin{document}

\maketitle

\begin{abstract}
Not all neural network architectures are created equal, some perform much better than others for certain tasks. But how important are the weight parameters of a neural network compared to its architecture? In this work, we question to what extent neural network architectures alone, without learning any weight parameters, can encode solutions for a given task. We propose a search method for neural network architectures that can already perform a task without any explicit weight training. To evaluate these networks, we populate the connections with a single shared weight parameter sampled from a uniform random distribution, and measure the expected performance. We demonstrate that our method can find minimal neural network architectures that can perform several reinforcement learning tasks without weight training. On a supervised learning domain, we find network architectures that achieve much higher than chance accuracy on MNIST using random weights.
%
Interactive version of this paper at \url{\websiteurl}
\end{abstract}

\section{Introduction} 
\vskip -0.03in % useful knobs to optimize layout
\input{tex/00_intro}

\vskip -0.05in % useful knobs to optimize layout
\section{Related Work} 
\vskip -0.05in % useful knobs to optimize layout
\input{tex/10_relwork}
% -- to here around 2.5 pages -- %

%\newpage
\vskip -0.05in % useful knobs to optimize layout
\section{Weight Agnostic Neural Network Search} % ~ 2 pgs
\vskip -0.09in % useful knobs to optimize layout
\input{tex/20_method}

%\newpage
\vskip -0.05in % useful knobs to optimize layout
\section{Experimental Results} % ~ 2.5 pgs
\vskip -0.05in % useful knobs to optimize layout
\input{tex/30_results}

%\newpage
\vskip -0.15in % useful knobs to optimize layout
\section{Discussion and Future Work} % ~ 1pg
\vskip -0.10in % useful knobs to optimize layout
\input{tex/40_discuss}

\vskip -0.15in % useful knobs to optimize layout
\subsection*{Acknowledgments}
\vskip -0.10in % useful knobs to optimize layout
\input{tex/50_ack}

\input{tex/60_appendix} % uncomment for arxiv version. comment for neurips main text version.

\small
\newpage
\bibliography{main}
\bibliographystyle{abbrv}
%\bibliographystyle{plain}

\end{document}
