- **Dataset Overview**: Nemotron-CC is a 6.3T token long-horizon pretraining dataset derived from English Common Crawl, consisting of 4.4T globally deduplicated original tokens and 1.9T synthetically generated tokens.

- **Key Contributions**:
  - Achieved a 5.6 MMLU improvement over DCLM with a 1.1T-token high-quality subset.
  - Full dataset matches DCLM on MMLU while containing 4Ã— more unique real tokens.
  - An 8B parameter model trained on 15T tokens using Nemotron-CC outperforms Llama 3.1 in multiple benchmarks.

- **Methodology**:
  - **Classifier Ensembling**: Utilizes multiple model-based classifiers to enhance token quality selection.
  - **Synthetic Data Generation**: Employs rephrasing techniques to create diverse and high-quality data from low-quality sources.
  - **Heuristic Filter Reduction**: Minimizes reliance on traditional heuristic filters to retain more high-quality tokens.

- **Quality Labeling Pipeline**:
  - Ensemble three classifiers to score documents and categorize them into five quality levels based on downstream task performance.
  - Quality scoring involves a maximum operation on integer scores from classifiers, ensuring a diverse selection of high-quality documents.

- **Synthetic Data Generation Techniques**:
  - For low-quality data: Focus on reducing noise and errors through rephrasing.
  - For high-quality data: Generate diverse QA pairs, concise rewrites, knowledge extraction, and organized knowledge lists.

- **Performance Metrics**:
  - MMLU: 70.3 for Nemotron-CC trained model vs. 65.3 for Llama 3.1.
  - ARC-Challenge: +3.1 improvement over Llama 3.1.

- **Extraction and Filtering**:
  - Comparison of HTML-to-text extractors (Justext vs. Trafilatura) shows Justext yields more high-quality tokens (+28.6%).
  - Heuristic filters traditionally remove significant portions of high-quality tokens; proposed method limits their application to low-quality splits.

- **Ablation Studies Findings**:
  - Ensembling classifiers increases the diversity of high-quality tokens.
  - Rephrasing enhances data quality and reduces noise.
  - Disabling heuristic filters for high-quality tokens improves overall token yield.

- **Guiding Principle**: Transition from static heuristic pipelines to a learned, adaptive system that improves over time as data quality and model performance enhance.

- **Dataset Access**: Available at [Nemotron-CC Dataset](https://data.commoncrawl.org/contrib/Nemotron/Nemotron-CC/index.html).