\begin{thebibliography}{65}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[exp()]{explicitdata}
tungdop2/nsfw\_caption.
\newblock \url{https://huggingface.co/datasets/tungdop2/nsfw_caption}, note =
  {Accessed: 2024-10-30}.

\bibitem[nud()]{nudenet}
Nudenet: lightweight nudity detection.
\newblock \url{https://github.com/notAI-tech/NudeNet}.
\newblock Accessed: 2024-10-30.

\bibitem[fal(2022)]{falsepositive}
some-notes-on-the-stable-diffusion-safety-filter.
\newblock
  \url{https://vickiboykis.com/2022/11/18/some-notes-on-the-stable-diffusion-safety-filter/},
  2022.

\bibitem[aut(2023)]{autocrawler}
Autocrawler.
\newblock \url{https://github.com/YoongiKim/AutoCrawler}, 2023.

\bibitem[log(2023)]{logov4}
modern-logo-v4 dataset.
\newblock
  \url{https://huggingface.co/datasets/logo-wizard/modern-logo-dataset}, 2023.

\bibitem[pok(2023)]{pokemon}
pokemon dataset.
\newblock
  \url{https://huggingface.co/datasets/lambdalabs/pokemon-blip-captions}, 2023.

\bibitem[saf(2023)]{safetychecker}
stable-diffusion-safety-checker.
\newblock \url{https://huggingface.co/CompVis/stable-diffusion-safety-checker},
  2023.

\bibitem[sd1(2023{\natexlab{a}})]{sd14}
stable diffusion v1.4.
\newblock \url{https://huggingface.co/CompVis/stable-diffusion-v1-4},
  2023{\natexlab{a}}.

\bibitem[sd1(2023{\natexlab{b}})]{sd15}
stable diffusion v1.5.
\newblock \url{https://huggingface.co/runwayml/stable-diffusion-v1-5},
  2023{\natexlab{b}}.

\bibitem[sd2(2023)]{sd21}
stable diffusion v2.1.
\newblock \url{https://huggingface.co/runwayml/stable-diffusion-v1-5}, 2023.

\bibitem[dif(2024)]{diffusionwallpaper}
Diffusion wallpaper.
\newblock \url{https://serp.ai/tools/diffusion-wallpaper/}, 2024.

\bibitem[ope(2024)]{opencvfacedet}
Opencv face recognition.
\newblock \url{https://opencv.org/opencv-face-recognition/}, 2024.

\bibitem[Chefer et~al.(2023)Chefer, Lang, Geva, Polosukhin, Shocher, Irani,
  Mosseri, and Wolf]{chefer2023hidden}
H.~Chefer, O.~Lang, M.~Geva, V.~Polosukhin, A.~Shocher, M.~Irani, I.~Mosseri,
  and L.~Wolf.
\newblock The hidden language of diffusion models.
\newblock \emph{arXiv preprint arXiv:2306.00966}, 2023.

\bibitem[Chen et~al.(2024)Chen, Mo, Hou, Wu, Liao, Sun, Yan, and
  Lin]{chen2024topiq}
C.~Chen, J.~Mo, J.~Hou, H.~Wu, L.~Liao, W.~Sun, Q.~Yan, and W.~Lin.
\newblock Topiq: A top-down approach from semantics to distortions for image
  quality assessment.
\newblock \emph{IEEE Transactions on Image Processing}, 2024.

\bibitem[Chen et~al.(2019)Chen, Chen, He, Gao, Li, Lou, and
  Wang]{chen2019lambdaopt}
Y.~Chen, B.~Chen, X.~He, C.~Gao, Y.~Li, J.-G. Lou, and Y.~Wang.
\newblock $\lambda$opt: Learn to regularize recommender models in finer levels.
\newblock In \emph{Proceedings of the 25th ACM SIGKDD International Conference
  on Knowledge Discovery \& Data Mining}, pages 978--986, 2019.

\bibitem[Cui et~al.(2023{\natexlab{a}})Cui, Ren, Lin, Xu, He, Xing, Fan, Liu,
  and Tang]{cui2023ft}
Y.~Cui, J.~Ren, Y.~Lin, H.~Xu, P.~He, Y.~Xing, W.~Fan, H.~Liu, and J.~Tang.
\newblock Ft-shield: A watermark against unauthorized fine-tuning in
  text-to-image diffusion models.
\newblock \emph{arXiv preprint arXiv:2310.02401}, 2023{\natexlab{a}}.

\bibitem[Cui et~al.(2023{\natexlab{b}})Cui, Ren, Xu, He, Liu, Sun, and
  Tang]{cui2023diffusionshield}
Y.~Cui, J.~Ren, H.~Xu, P.~He, H.~Liu, L.~Sun, and J.~Tang.
\newblock Diffusionshield: A watermark for copyright protection against
  generative diffusion models.
\newblock \emph{arXiv preprint arXiv:2306.04642}, 2023{\natexlab{b}}.

\bibitem[Dash et~al.(2022)Dash, Balasubramanian, and
  Sharma]{dash2022evaluating}
S.~Dash, V.~N. Balasubramanian, and A.~Sharma.
\newblock Evaluating and mitigating bias in image classifiers: A causal
  perspective using counterfactuals.
\newblock In \emph{Proceedings of the IEEE/CVF Winter Conference on
  Applications of Computer Vision}, pages 915--924, 2022.

\bibitem[Derner and Batisti{\v{c}}(2023)]{derner2023beyond}
E.~Derner and K.~Batisti{\v{c}}.
\newblock Beyond the safeguards: Exploring the security risks of chatgpt.
\newblock \emph{arXiv preprint arXiv:2305.08005}, 2023.

\bibitem[Fan et~al.(2023)Fan, Liu, Zhang, Wei, Wong, and Liu]{fan2023salun}
C.~Fan, J.~Liu, Y.~Zhang, D.~Wei, E.~Wong, and S.~Liu.
\newblock Salun: Empowering machine unlearning via gradient-based weight
  saliency in both image classification and generation.
\newblock \emph{arXiv preprint arXiv:2310.12508}, 2023.

\bibitem[Finn et~al.(2017)Finn, Abbeel, and Levine]{finn2017model}
C.~Finn, P.~Abbeel, and S.~Levine.
\newblock Model-agnostic meta-learning for fast adaptation of deep networks.
\newblock In \emph{International conference on machine learning}, pages
  1126--1135. PMLR, 2017.

\bibitem[Gamage et~al.(2022)Gamage, Ghasiya, Bonagiri, Whiting, and
  Sasahara]{gamage2022deepfakes}
D.~Gamage, P.~Ghasiya, V.~Bonagiri, M.~E. Whiting, and K.~Sasahara.
\newblock Are deepfakes concerning? analyzing conversations of deepfakes on
  reddit and exploring societal implications.
\newblock In \emph{Proceedings of the 2022 CHI Conference on Human Factors in
  Computing Systems}, pages 1--19, 2022.

\bibitem[Gandikota et~al.(2024)Gandikota, Orgad, Belinkov, Materzy{\'n}ska, and
  Bau]{gandikota2024unified}
R.~Gandikota, H.~Orgad, Y.~Belinkov, J.~Materzy{\'n}ska, and D.~Bau.
\newblock Unified concept editing in diffusion models.
\newblock In \emph{Proceedings of the IEEE/CVF Winter Conference on
  Applications of Computer Vision}, pages 5111--5120, 2024.

\bibitem[Gosse and Burkell(2020)]{gosse2020politics}
C.~Gosse and J.~Burkell.
\newblock Politics and porn: how news media characterizes problems presented by
  deepfakes.
\newblock \emph{Critical Studies in Media Communication}, 37\penalty0
  (5):\penalty0 497--511, 2020.

\bibitem[Harwell(2017)]{harwell2017ai}
D.~Harwell.
\newblock Ai-generated child sex images spawn new nightmare for the web.
\newblock \emph{The Wall Street Journal}, 2017.

\bibitem[Heikkil{\"a}(2022)]{heikkila2022artist}
M.~Heikkil{\"a}.
\newblock This artist is dominating ai-generated art. and he’s not happy
  about it.
\newblock \emph{MIT Technology Review}, 125\penalty0 (6):\penalty0 9--10, 2022.

\bibitem[Hessel et~al.(2021)Hessel, Holtzman, Forbes, Bras, and
  Choi]{hessel2021clipscore}
J.~Hessel, A.~Holtzman, M.~Forbes, R.~L. Bras, and Y.~Choi.
\newblock Clipscore: A reference-free evaluation metric for image captioning.
\newblock \emph{arXiv preprint arXiv:2104.08718}, 2021.

\bibitem[Heusel et~al.(2017)Heusel, Ramsauer, Unterthiner, Nessler, and
  Hochreiter]{heusel2017gans}
M.~Heusel, H.~Ramsauer, T.~Unterthiner, B.~Nessler, and S.~Hochreiter.
\newblock Gans trained by a two time-scale update rule converge to a local nash
  equilibrium.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Hwang and Masud(2012)]{hwang2012multiple}
C.-L. Hwang and A.~S.~M. Masud.
\newblock \emph{Multiple objective decision making—methods and applications:
  a state-of-the-art survey}, volume 164.
\newblock Springer Science \& Business Media, 2012.

\bibitem[Jayasumana et~al.(2024)Jayasumana, Ramalingam, Veit, Glasner,
  Chakrabarti, and Kumar]{jayasumana2024rethinking}
S.~Jayasumana, S.~Ramalingam, A.~Veit, D.~Glasner, A.~Chakrabarti, and
  S.~Kumar.
\newblock Rethinking fid: Towards a better evaluation metric for image
  generation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 9307--9315, 2024.

\bibitem[Jinjin et~al.(2020)Jinjin, Haoming, Haoyu, Xiaoxing, Ren, and
  Chao]{jinjin2020pipal}
G.~Jinjin, C.~Haoming, C.~Haoyu, Y.~Xiaoxing, J.~S. Ren, and D.~Chao.
\newblock Pipal: a large-scale image quality assessment dataset for perceptual
  image restoration.
\newblock In \emph{Computer Vision--ECCV 2020: 16th European Conference,
  Glasgow, UK, August 23--28, 2020, Proceedings, Part XI 16}, pages 633--651.
  Springer, 2020.

\bibitem[Kahla et~al.(2022)Kahla, Chen, Just, and Jia]{kahla2022label}
M.~Kahla, S.~Chen, H.~A. Just, and R.~Jia.
\newblock Label-only model inversion attacks via boundary repulsion.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision
  and pattern recognition}, pages 15045--15053, 2022.

\bibitem[Karras et~al.(2022)Karras, Aittala, Aila, and
  Laine]{karras2022elucidating}
T.~Karras, M.~Aittala, T.~Aila, and S.~Laine.
\newblock Elucidating the design space of diffusion-based generative models.
\newblock \emph{Advances in Neural Information Processing Systems},
  35:\penalty0 26565--26577, 2022.

\bibitem[Kim and Tompkin(2021)]{kim2021testing}
K.~I. Kim and J.~Tompkin.
\newblock Testing using privileged information by adapting features with
  statistical dependence.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 9405--9413, 2021.

\bibitem[Kim et~al.(2022)Kim, Hwang, Ahn, Park, and Kwak]{kim2022learning}
N.~Kim, S.~Hwang, S.~Ahn, J.~Park, and S.~Kwak.
\newblock Learning debiased classifier with biased committee.
\newblock \emph{Advances in Neural Information Processing Systems},
  35:\penalty0 18403--18415, 2022.

\bibitem[Kingma and Ba(2014)]{kingma2014adam}
D.~P. Kingma and J.~Ba.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{arXiv preprint arXiv:1412.6980}, 2014.

\bibitem[Kumar et~al.(2009)Kumar, Berg, Belhumeur, and
  Nayar]{kumar2009attribute}
N.~Kumar, A.~C. Berg, P.~N. Belhumeur, and S.~K. Nayar.
\newblock Attribute and simile classifiers for face verification.
\newblock In \emph{2009 IEEE 12th international conference on computer vision},
  pages 365--372. IEEE, 2009.

\bibitem[Lee et~al.(2018)Lee, Ajanthan, and Torr]{lee2018snip}
N.~Lee, T.~Ajanthan, and P.~H. Torr.
\newblock Snip: Single-shot network pruning based on connection sensitivity.
\newblock \emph{arXiv preprint arXiv:1810.02340}, 2018.

\bibitem[Li et~al.(2023)Li, Li, Savarese, and Hoi]{li2023blip}
J.~Li, D.~Li, S.~Savarese, and S.~Hoi.
\newblock Blip-2: Bootstrapping language-image pre-training with frozen image
  encoders and large language models.
\newblock In \emph{International conference on machine learning}, pages
  19730--19742. PMLR, 2023.

\bibitem[Liu et~al.(2018)Liu, Simonyan, and Yang]{liu2018darts}
H.~Liu, K.~Simonyan, and Y.~Yang.
\newblock Darts: Differentiable architecture search.
\newblock \emph{arXiv preprint arXiv:1806.09055}, 2018.

\bibitem[Liu et~al.(2021)Liu, Zhang, Kuang, Zhou, Xue, Wang, Chen, Yang, Liao,
  and Zhang]{liu2021group}
L.~Liu, S.~Zhang, Z.~Kuang, A.~Zhou, J.-H. Xue, X.~Wang, Y.~Chen, W.~Yang,
  Q.~Liao, and W.~Zhang.
\newblock Group fisher pruning for practical network compression.
\newblock In \emph{International Conference on Machine Learning}, pages
  7021--7032. PMLR, 2021.

\bibitem[Liu et~al.(2015)Liu, Luo, Wang, and Tang]{liu2015faceattributes}
Z.~Liu, P.~Luo, X.~Wang, and X.~Tang.
\newblock Deep learning face attributes in the wild.
\newblock In \emph{Proceedings of International Conference on Computer Vision
  (ICCV)}, December 2015.

\bibitem[Podell et~al.(2023)Podell, English, Lacey, Blattmann, Dockhorn,
  M{\"u}ller, Penna, and Rombach]{podell2023sdxl}
D.~Podell, Z.~English, K.~Lacey, A.~Blattmann, T.~Dockhorn, J.~M{\"u}ller,
  J.~Penna, and R.~Rombach.
\newblock Sdxl: Improving latent diffusion models for high-resolution image
  synthesis.
\newblock \emph{arXiv preprint arXiv:2307.01952}, 2023.

\bibitem[Rombach et~al.(2022)Rombach, Blattmann, Lorenz, Esser, and
  Ommer]{rombach2022high}
R.~Rombach, A.~Blattmann, D.~Lorenz, P.~Esser, and B.~Ommer.
\newblock High-resolution image synthesis with latent diffusion models.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision
  and pattern recognition}, pages 10684--10695, 2022.

\bibitem[Ronneberger et~al.(2015)Ronneberger, Fischer, and
  Brox]{ronneberger2015u}
O.~Ronneberger, P.~Fischer, and T.~Brox.
\newblock U-net: Convolutional networks for biomedical image segmentation.
\newblock In \emph{Medical image computing and computer-assisted
  intervention--MICCAI 2015: 18th international conference, Munich, Germany,
  October 5-9, 2015, proceedings, part III 18}, pages 234--241. Springer, 2015.

\bibitem[Royer et~al.(2020)Royer, Bousmalis, Gouws, Bertsch, Mosseri, Cole, and
  Murphy]{royer2020xgan}
A.~Royer, K.~Bousmalis, S.~Gouws, F.~Bertsch, I.~Mosseri, F.~Cole, and
  K.~Murphy.
\newblock Xgan: Unsupervised image-to-image translation for many-to-many
  mappings.
\newblock \emph{Domain Adaptation for Visual Understanding}, pages 33--49,
  2020.

\bibitem[Ruiz et~al.(2023)Ruiz, Li, Jampani, Pritch, Rubinstein, and
  Aberman]{ruiz2023dreambooth}
N.~Ruiz, Y.~Li, V.~Jampani, Y.~Pritch, M.~Rubinstein, and K.~Aberman.
\newblock Dreambooth: Fine tuning text-to-image diffusion models for
  subject-driven generation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 22500--22510, 2023.

\bibitem[Russakovsky et~al.(2015)Russakovsky, Deng, Su, Krause, Satheesh, Ma,
  Huang, Karpathy, Khosla, Bernstein, et~al.]{russakovsky2015imagenet}
O.~Russakovsky, J.~Deng, H.~Su, J.~Krause, S.~Satheesh, S.~Ma, Z.~Huang,
  A.~Karpathy, A.~Khosla, M.~Bernstein, et~al.
\newblock Imagenet large scale visual recognition challenge.
\newblock \emph{International journal of computer vision}, 115:\penalty0
  211--252, 2015.

\bibitem[Schuhmann et~al.(2022)Schuhmann, Beaumont, Vencu, Gordon, Wightman,
  Cherti, Coombes, Katta, Mullis, Wortsman, et~al.]{schuhmann2022laion}
C.~Schuhmann, R.~Beaumont, R.~Vencu, C.~Gordon, R.~Wightman, M.~Cherti,
  T.~Coombes, A.~Katta, C.~Mullis, M.~Wortsman, et~al.
\newblock Laion-5b: An open large-scale dataset for training next generation
  image-text models.
\newblock \emph{Advances in Neural Information Processing Systems},
  35:\penalty0 25278--25294, 2022.

\bibitem[Serengil and Ozpinar(2024)]{serengil2024lightface}
S.~Serengil and A.~Ozpinar.
\newblock A benchmark of facial recognition pipelines and co-usability
  performances of modules.
\newblock \emph{Journal of Information Technologies}, 17\penalty0 (2):\penalty0
  95--107, 2024.
\newblock \doi{10.17671/gazibtd.1399077}.
\newblock URL
  \url{https://dergipark.org.tr/en/pub/gazibtd/issue/84331/1399077}.

\bibitem[Shan et~al.(2023)Shan, Cryan, Wenger, Zheng, Hanocka, and
  Zhao]{shan2023glaze}
S.~Shan, J.~Cryan, E.~Wenger, H.~Zheng, R.~Hanocka, and B.~Y. Zhao.
\newblock Glaze: Protecting artists from style mimicry by $\{$Text-to-Image$\}$
  models.
\newblock In \emph{32nd USENIX Security Symposium (USENIX Security 23)}, pages
  2187--2204, 2023.

\bibitem[Somepalli et~al.(2024)Somepalli, Gupta, Gupta, Palta, Goldblum,
  Geiping, Shrivastava, and Goldstein]{somepalli2024measuring}
G.~Somepalli, A.~Gupta, K.~Gupta, S.~Palta, M.~Goldblum, J.~Geiping,
  A.~Shrivastava, and T.~Goldstein.
\newblock Measuring style similarity in diffusion models.
\newblock \emph{arXiv preprint arXiv:2404.01292}, 2024.

\bibitem[Tan et~al.(2019)Tan, Chan, Aguirre, and Tanaka]{artgan2018}
W.~R. Tan, C.~S. Chan, H.~Aguirre, and K.~Tanaka.
\newblock Improved artgan for conditional synthesis of natural image and
  artwork.
\newblock \emph{IEEE Transactions on Image Processing}, 28\penalty0
  (1):\penalty0 394--409, 2019.
\newblock \doi{10.1109/TIP.2018.2866698}.
\newblock URL \url{https://doi.org/10.1109/TIP.2018.2866698}.

\bibitem[Verma et~al.(2024)Verma, Rassin, Das, Bhatt, Seshadri, Shah, Bilmes,
  Hajishirzi, and Elazar]{verma2024many}
S.~Verma, R.~Rassin, A.~Das, G.~Bhatt, P.~Seshadri, C.~Shah, J.~Bilmes,
  H.~Hajishirzi, and Y.~Elazar.
\newblock How many van goghs does it take to van gogh? finding the imitation
  threshold.
\newblock \emph{arXiv preprint arXiv:2410.15002}, 2024.

\bibitem[Webson and Pavlick(2021)]{webson2021prompt}
A.~Webson and E.~Pavlick.
\newblock Do prompt-based models really understand the meaning of their
  prompts?
\newblock \emph{arXiv preprint arXiv:2109.01247}, 2021.

\bibitem[Wolf et~al.(2019)Wolf, Debut, Sanh, Chaumond, Delangue, Moi, Cistac,
  Rault, Louf, Funtowicz, et~al.]{wolf2019huggingface}
T.~Wolf, L.~Debut, V.~Sanh, J.~Chaumond, C.~Delangue, A.~Moi, P.~Cistac,
  T.~Rault, R.~Louf, M.~Funtowicz, et~al.
\newblock Huggingface's transformers: State-of-the-art natural language
  processing.
\newblock \emph{arXiv preprint arXiv:1910.03771}, 2019.

\bibitem[Wu et~al.(2024)Wu, Le, Hayat, and Harandi]{wu2024erasediff}
J.~Wu, T.~Le, M.~Hayat, and M.~Harandi.
\newblock Erasediff: Erasing data influence in diffusion models.
\newblock \emph{arXiv preprint arXiv:2401.05779}, 2024.

\bibitem[Xu et~al.(2023)Xu, Long, and Nie]{xu2023learning}
W.~Xu, C.~Long, and Y.~Nie.
\newblock Learning dynamic style kernels for artistic style transfer.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 10083--10092, 2023.

\bibitem[Ye et~al.(2023)Ye, Huang, An, and Wang]{ye2023duaw}
X.~Ye, H.~Huang, J.~An, and Y.~Wang.
\newblock Duaw: Data-free universal adversarial watermark against stable
  diffusion customization.
\newblock \emph{arXiv preprint arXiv:2308.09889}, 2023.

\bibitem[Yu et~al.(2023)Yu, Yu, Yu, Huang, and Li]{yu2023language}
L.~Yu, B.~Yu, H.~Yu, F.~Huang, and Y.~Li.
\newblock Language models are super mario: Absorbing abilities from homologous
  models as a free lunch.
\newblock \emph{arXiv preprint arXiv:2311.03099}, 2023.

\bibitem[Zeiler and Fergus(2014)]{zeiler2014visualizing}
M.~D. Zeiler and R.~Fergus.
\newblock Visualizing and understanding convolutional networks.
\newblock In \emph{Computer Vision--ECCV 2014: 13th European Conference,
  Zurich, Switzerland, September 6-12, 2014, Proceedings, Part I 13}, pages
  818--833. Springer, 2014.

\bibitem[Zhang et~al.(2023)Zhang, Li, Yu, Xu, Li, and
  Zhang]{zhang2023editguard}
X.~Zhang, R.~Li, J.~Yu, Y.~Xu, W.~Li, and J.~Zhang.
\newblock Editguard: Versatile image watermarking for tamper localization and
  copyright protection.
\newblock \emph{arXiv preprint arXiv:2312.08883}, 2023.

\bibitem[Zhang et~al.(2020)Zhang, Deng, Wang, Hu, Li, Zhao, and
  Wen]{zhang2020global}
Y.~Zhang, W.~Deng, M.~Wang, J.~Hu, X.~Li, D.~Zhao, and D.~Wen.
\newblock Global-local gcn: Large-scale label noise cleansing for face
  recognition.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 7731--7740, 2020.

\bibitem[Zhao et~al.(2023)Zhao, Pang, Du, Yang, Cheung, and
  Lin]{zhao2023recipe}
Y.~Zhao, T.~Pang, C.~Du, X.~Yang, N.-M. Cheung, and M.~Lin.
\newblock A recipe for watermarking diffusion models.
\newblock \emph{arXiv preprint arXiv:2303.10137}, 2023.

\bibitem[Zheng and Yeh(2023)]{zheng2023imma}
Y.~Zheng and R.~A. Yeh.
\newblock Imma: Immunizing text-to-image models against malicious adaptation.
\newblock \emph{arXiv preprint arXiv:2311.18815}, 2023.

\end{thebibliography}
