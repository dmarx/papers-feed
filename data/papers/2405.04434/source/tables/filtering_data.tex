\begin{table}[ht]
\centering
\begin{tabular}{@{}l|cccc@{}}
\toprule
\textbf{Agreement}  & \textbf{Ground-Truth Label} & \textbf{Annotator 1} & \textbf{Annotator 2} & \textbf{Annotator 3} \\ 
\midrule
\textbf{Ground-Truth Label} & 100.0\%~~ & 66.7\% & 59.8\% & 42.1\% \\ 
\textbf{Annotator 1} & 66.7\% & 100.0\%~~ & 57.9\% & 69.0\% \\ 
\textbf{Annotator 2} & 59.8\% & 57.9\% & 100.0\%~~ & 65.5\% \\ 
\textbf{Annotator 3} & 42.1\% & 69.0\% & 65.5\% & 100.0\%~~ \\ 
\bottomrule            
\end{tabular}
\caption{
Three well-educated human annotators conduct independent annotations on 420 moral scenarios from the MMLU Humanity-Moral subset, on which \dsvii{} and its competitive models demonstrate performance inconsistency. 
Three annotators and the ground-truth label exhibit a low agreement with each other. 
This indicates that the answers to the Humanity-Moral subset can be contentious according to specific regional cultures. 
}
\label{tab:filtering_data}
\end{table}