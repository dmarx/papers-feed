@article{qi2023zero,
  title={Zero Bubble Pipeline Parallelism},
  author={Qi, Penghui and Wan, Xinyi and Huang, Guangxing and Lin, Min},
  journal={arXiv preprint arXiv:2401.10241},
  year={2023}
}

@inproceedings{mgsm,
  author       = {Freda i and
                  Mirac Suzgun and
                  Markus Freitag and
                  Xuezhi Wang and
                  Suraj Srivats and
                  Soroush Vosoughi and
                  Hyung Won Chung and
                  Yi Tay and
                  Sebastian Ruder and
                  Denny Zhou and
                  Dipanjan Das and
                  Jason Wei},
  title        = {Language models are multilingual chain-of-thought reasoners},
  booktitle    = {The Eleventh International Conference on Learning Representations,
                  {ICLR} 2023, Kigali, Rwanda, May 1-5, 2023},
  publisher    = {OpenReview.net},
  year         = {2023},
  url          = {https://openreview.net/pdf?id=fR3wGCk-IXp},
  timestamp    = {Fri, 30 Jun 2023 14:55:53 +0200},
  biburl       = {https://dblp.org/rec/conf/iclr/ShiSF0SVCTRZ0W23.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{jain2024livecodebench,
  title={LiveCodeBench: Holistic and Contamination Free Evaluation of Large Language Models for Code},
  author={Jain, Naman and Han, King and Gu, Alex and Li, Wen-Ding and Yan, Fanjia and Zhang, Tianjun and Wang, Sida and Solar-Lezama, Armando and Sen, Koushik and Stoica, Ion},
  journal={arXiv preprint arXiv:2403.07974},
  year={2024}
}

@article{su2024roformer,
  title={Roformer: Enhanced transformer with rotary position embedding},
  author={Su, Jianlin and Ahmed, Murtadha and Lu, Yu and Pan, Shengfeng and Bo, Wen and Liu, Yunfeng},
  journal={Neurocomputing},
  volume={568},
  pages={127063},
  year={2024},
  publisher={Elsevier}
}

@article{ainslie2023gqa,
  title={GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints},
  author={Ainslie, Joshua and Lee-Thorp, James and de Jong, Michiel and Zemlyanskiy, Yury and Lebr{\'o}n, Federico and Sanghai, Sumit},
  journal={arXiv preprint arXiv:2305.13245},
  year={2023}
}

@article{mqa,
  author       = {Noam Shazeer},
  title        = {Fast Transformer Decoding: One Write-Head is All You Need},
  journal      = {CoRR},
  volume       = {abs/1911.02150},
  year         = {2019},
  url          = {http://arxiv.org/abs/1911.02150},
}

@article{wizardmath,
  title={Wizardmath: Empowering mathematical reasoning for large language models via reinforced evol-instruct},
  author={Luo, Haipeng and Sun, Qingfeng and Xu, Can and Zhao, Pu and Lou, Jianguang and Tao, Chongyang and Geng, Xiubo and Lin, Qingwei and Chen, Shifeng and Zhang, Dongmei},
  journal={arXiv preprint arXiv:2308.09583},
  year={2023}
}

@article{tora,
  author       = {Zhibin Gou and
                  Zhihong Shao and
                  Yeyun Gong and
                  Yelong Shen and
                  Yujiu Yang and
                  Minlie Huang and
                  Nan Duan and
                  Weizhu Chen},
  title        = {ToRA: {A} Tool-Integrated Reasoning Agent for Mathematical Problem
                  Solving},
  journal      = {CoRR},
  volume       = {abs/2309.17452},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2309.17452},
  doi          = {10.48550/ARXIV.2309.17452},
  eprinttype    = {arXiv},
  eprint       = {2309.17452},
  timestamp    = {Tue, 17 Oct 2023 13:50:54 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2309-17452.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{pot,
  author       = {Wenhu Chen and
                  Xueguang Ma and
                  Xinyi Wang and
                  William W. Cohen},
  title        = {Program of Thoughts Prompting: Disentangling Computation from Reasoning
                  for Numerical Reasoning Tasks},
  journal      = {CoRR},
  volume       = {abs/2211.12588},
  year         = {2022},
  url          = {https://doi.org/10.48550/arXiv.2211.12588},
  doi          = {10.48550/ARXIV.2211.12588},
  eprinttype    = {arXiv},
  eprint       = {2211.12588},
  timestamp    = {Tue, 29 Nov 2022 17:41:18 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2211-12588.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{pal,
  author       = {Luyu Gao and
                  Aman Madaan and
                  Shuyan Zhou and
                  Uri Alon and
                  Pengfei Liu and
                  Yiming Yang and
                  Jamie Callan and
                  Graham Neubig},
  editor       = {Andreas Krause and
                  Emma Brunskill and
                  Kyunghyun Cho and
                  Barbara Engelhardt and
                  Sivan Sabato and
                  Jonathan Scarlett},
  title        = {{PAL:} Program-aided Language Models},
  booktitle    = {International Conference on Machine Learning, {ICML} 2023, 23-29 July
                  2023, Honolulu, Hawaii, {USA}},
  series       = {Proceedings of Machine Learning Research},
  volume       = {202},
  pages        = {10764--10799},
  publisher    = {{PMLR}},
  year         = {2023},
  url          = {https://proceedings.mlr.press/v202/gao23f.html},
  timestamp    = {Mon, 28 Aug 2023 17:23:08 +0200},
  biburl       = {https://dblp.org/rec/conf/icml/GaoMZ00YCN23.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{cot,
  author       = {Jason Wei and
                  Xuezhi Wang and
                  Dale Schuurmans and
                  Maarten Bosma and
                  Brian Ichter and
                  Fei Xia and
                  Ed H. Chi and
                  Quoc V. Le and
                  Denny Zhou},
  title        = {Chain-of-Thought Prompting Elicits Reasoning in Large Language Models},
  booktitle    = {NeurIPS},
  year         = {2022},
  url          = {http://papers.nips.cc/paper\_files/paper/2022/hash/9d5609613524ecf4f15af0f7b31abca4-Abstract-Conference.html},
  timestamp    = {Thu, 11 May 2023 17:08:21 +0200},
  biburl       = {https://dblp.org/rec/conf/nips/Wei0SBIXCLZ22.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{lila,
  author       = {Swaroop Mishra and
                  Matthew Finlayson and
                  Pan Lu and
                  Leonard Tang and
                  Sean Welleck and
                  Chitta Baral and
                  Tanmay Rajpurohit and
                  Oyvind Tafjord and
                  Ashish Sabharwal and
                  Peter Clark and
                  Ashwin Kalyan},
  editor       = {Yoav Goldberg and
                  Zornitsa Kozareva and
                  Yue Zhang},
  title        = {{LILA:} {A} Unified Benchmark for Mathematical Reasoning},
  booktitle    = {Proceedings of the 2022 Conference on Empirical Methods in Natural
                  Language Processing, {EMNLP} 2022, Abu Dhabi, United Arab Emirates,
                  December 7-11, 2022},
  pages        = {5807--5832},
  publisher    = {Association for Computational Linguistics},
  year         = {2022},
  url          = {https://doi.org/10.18653/v1/2022.emnlp-main.392},
  doi          = {10.18653/V1/2022.EMNLP-MAIN.392},
  timestamp    = {Thu, 10 Aug 2023 12:35:34 +0200},
  biburl       = {https://dblp.org/rec/conf/emnlp/MishraFLTWBRTSC22.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{MathInstruct,
  author       = {Xiang Yue and
                  Xingwei Qu and
                  Ge Zhang and
                  Yao Fu and
                  Wenhao Huang and
                  Huan Sun and
                  Yu Su and
                  Wenhu Chen},
  title        = {MAmmoTH: Building Math Generalist Models through Hybrid Instruction
                  Tuning},
  journal      = {CoRR},
  volume       = {abs/2309.05653},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2309.05653},
  doi          = {10.48550/ARXIV.2309.05653},
  eprinttype    = {arXiv},
  eprint       = {2309.05653},
  timestamp    = {Fri, 15 Sep 2023 12:26:52 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2309-05653.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{metamath,
  author       = {Longhui Yu and
                  Weisen Jiang and
                  Han Shi and
                  Jincheng Yu and
                  Zhengying Liu and
                  Yu Zhang and
                  James T. Kwok and
                  Zhenguo Li and
                  Adrian Weller and
                  Weiyang Liu},
  title        = {MetaMath: Bootstrap Your Own Mathematical Questions for Large Language
                  Models},
  journal      = {CoRR},
  volume       = {abs/2309.12284},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2309.12284},
  doi          = {10.48550/ARXIV.2309.12284},
  eprinttype    = {arXiv},
  eprint       = {2309.12284},
  timestamp    = {Mon, 25 Sep 2023 15:34:00 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2309-12284.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{joshi-etal-2017-triviaqa,
    title = "{T}rivia{QA}: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension",
    author = "Joshi, Mandar  and
      Choi, Eunsol  and
      Weld, Daniel  and
      Zettlemoyer, Luke",
    editor = "Barzilay, Regina  and
      Kan, Min-Yen",
    booktitle = "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2017",
    address = "Vancouver, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P17-1147",
    doi = "10.18653/v1/P17-1147",
    pages = "1601--1611",
    abstract = "We present TriviaQA, a challenging reading comprehension dataset containing over 650K question-answer-evidence triples. TriviaQA includes 95K question-answer pairs authored by trivia enthusiasts and independently gathered evidence documents, six per question on average, that provide high quality distant supervision for answering the questions. We show that, in comparison to other recently introduced large-scale datasets, TriviaQA (1) has relatively complex, compositional questions, (2) has considerable syntactic and lexical variability between questions and corresponding answer-evidence sentences, and (3) requires more cross sentence reasoning to find answers. We also present two baseline algorithms: a feature-based classifier and a state-of-the-art neural network, that performs well on SQuAD reading comprehension. Neither approach comes close to human performance (23{\%} and 40{\%} vs. 80{\%}), suggesting that TriviaQA is a challenging testbed that is worth significant future study.",
}

@misc{brown2020language,
      title={Language Models are Few-Shot Learners}, 
      author={Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
      year={2020},
      eprint={2005.14165},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{gpt2,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@misc{chatgpt,
    title = {Introducing {ChatGPT}} ,
    author = {OpenAI},
    url = {https://openai.com/blog/chatgpt},
    year = {2022}
}

@misc{haillm,
    title = {HAI-LLM: 高效且轻量的大模型训练工具} ,
    author = {High-flyer},
    institution = {High-flyer},
    url = {https://www.high-flyer.cn/en/blog/hai-llm},
    year = {2023}
}

@article{megatron,
  title={Megatron-lm: Training multi-billion parameter language models using model parallelism},
  author={Shoeybi, Mohammad and Patwary, Mostofa and Puri, Raul and LeGresley, Patrick and Casper, Jared and Catanzaro, Bryan},
  journal={arXiv preprint arXiv:1909.08053},
  year={2019}
}

@inproceedings{megatron2,
  title={Efficient large-scale language model training on gpu clusters using megatron-lm},
  author={Narayanan, Deepak and Shoeybi, Mohammad and Casper, Jared and LeGresley, Patrick and Patwary, Mostofa and Korthikanti, Vijay and Vainbrand, Dmitri and Kashinkunti, Prethvi and Bernauer, Julie and Catanzaro, Bryan and others},
  booktitle={Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
  pages={1--15},
  year={2021}
}

@article{megatron3,
  title={Reducing activation recomputation in large transformer models},
  author={Korthikanti, Vijay Anand and Casper, Jared and Lym, Sangkug and McAfee, Lawrence and Andersch, Michael and Shoeybi, Mohammad and Catanzaro, Bryan},
  journal={Proceedings of Machine Learning and Systems},
  volume={5},
  year={2023}
}

@inproceedings{dao2022flashattention,
  title={Flash{A}ttention: Fast and Memory-Efficient Exact Attention with {IO}-Awareness},
  author={Dao, Tri and Fu, Daniel Y. and Ermon, Stefano and Rudra, Atri and R{\'e}, Christopher},
  booktitle={Advances in Neural Information Processing Systems},
  year={2022}
}

@misc{dao2023flashattention2,
  title={Flash{A}ttention-2: Faster Attention with Better Parallelism and Work Partitioning},
  author={Dao, Tri},
  year={2023}
}

@inproceedings{vllm,
  title={Efficient Memory Management for Large Language Model Serving with PagedAttention},
  author={Woosuk Kwon and Zhuohan Li and Siyuan Zhuang and Ying Sheng and Lianmin Zheng and Cody Hao Yu and Joseph E. Gonzalez and Hao Zhang and Ion Stoica},
  booktitle={Proceedings of the ACM SIGOPS 29th Symposium on Operating Systems Principles},
  year={2023}
}

@article{transformer,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{zero,
  title={Zero: Memory optimizations toward training trillion parameter models},
  author={Rajbhandari, Samyam and Rasley, Jeff and Ruwase, Olatunji and He, Yuxiong},
  booktitle={SC20: International Conference for High Performance Computing, Networking, Storage and Analysis},
  pages={1--16},
  year={2020},
  organization={IEEE}
}

@misc{li2021ccpm,
      title={CCPM: A Chinese Classical Poetry Matching Dataset}, 
      author={Wenhao Li and Fanchao Qi and Maosong Sun and Xiaoyuan Yi and Jiarui Zhang},
      year={2021},
      eprint={2106.01979},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{mihaylov2018suit,
      title={Can a Suit of Armor Conduct Electricity? A New Dataset for Open Book Question Answering}, 
      author={Todor Mihaylov and Peter Clark and Tushar Khot and Ashish Sabharwal},
      year={2018},
      eprint={1809.02789},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{claude,
  title = {Introducing {Claude}},
  author = {Anthropic},
  institution = {Anthropic},
  url = {https://www.anthropic.com/index/introducing-claude},
  year={2023}
}

@misc{bard,
  title = {An important next step on our {AI} journey},
  author = {Google},
  url = {https://blog.google/technology/ai/bard-google-ai-search-updates/},
  year={2023}
}

@misc{gemini,
  title = {Introducing Gemini: our largest and most capable AI model},
  author = {Google},
  url = {https://blog.google/technology/ai/google-gemini-ai/},
  year={2023}
}

@misc{sun2019investigating,
      title={Investigating Prior Knowledge for Challenging Chinese Machine Reading Comprehension}, 
      author={Kai Sun and Dian Yu and Dong Yu and Claire Cardie},
      year={2019},
      eprint={1904.09679},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{cui-etal-2019-span,
    title = "A Span-Extraction Dataset for {C}hinese Machine Reading Comprehension",
    author = "Cui, Yiming  and
      Liu, Ting  and
      Che, Wanxiang  and
      Xiao, Li  and
      Chen, Zhipeng  and
      Ma, Wentao  and
      Wang, Shijin  and
      Hu, Guoping",
    editor = "Inui, Kentaro  and
      Jiang, Jing  and
      Ng, Vincent  and
      Wan, Xiaojun",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-1600",
    doi = "10.18653/v1/D19-1600",
    pages = "5883--5889",
    abstract = "Machine Reading Comprehension (MRC) has become enormously popular recently and has attracted a lot of attention. However, the existing reading comprehension datasets are mostly in English. In this paper, we introduce a Span-Extraction dataset for Chinese machine reading comprehension to add language diversities in this area. The dataset is composed by near 20,000 real questions annotated on Wikipedia paragraphs by human experts. We also annotated a challenge set which contains the questions that need comprehensive understanding and multi-sentence inference throughout the context. We present several baseline systems as well as anonymous submissions for demonstrating the difficulties in this dataset. With the release of the dataset, we hosted the Second Evaluation Workshop on Chinese Machine Reading Comprehension (CMRC 2018). We hope the release of the dataset could further accelerate the Chinese machine reading comprehension research. Resources are available: \url{https://github.com/ymcui/cmrc2018}",
}

@misc{sakaguchi2019winogrande,
      title={WinoGrande: An Adversarial Winograd Schema Challenge at Scale}, 
      author={Keisuke Sakaguchi and Ronan Le Bras and Chandra Bhagavatula and Yejin Choi},
      year={2019},
      eprint={1907.10641},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{wei2023cmath,
      title={CMATH: Can Your Language Model Pass Chinese Elementary School Math Test?}, 
      author={Tianwen Wei and Jian Luan and Wei Liu and Shuang Dong and Bin Wang},
      year={2023},
      eprint={2306.16636},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{mmlu,
  title={Measuring massive multitask language understanding},
  author={Hendrycks, Dan and Burns, Collin and Basart, Steven and Zou, Andy and Mazeika, Mantas and Song, Dawn and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2009.03300},
  year={2020}
}

@article{bbh,
  title={Challenging big-bench tasks and whether chain-of-thought can solve them},
  author={Suzgun, Mirac and Scales, Nathan and Sch{\"a}rli, Nathanael and Gehrmann, Sebastian and Tay, Yi and Chung, Hyung Won and Chowdhery, Aakanksha and Le, Quoc V and Chi, Ed H and Zhou, Denny and others},
  journal={arXiv preprint arXiv:2210.09261},
  year={2022}
}

@article{mbpp,
  title={Program synthesis with large language models},
  author={Austin, Jacob and Odena, Augustus and Nye, Maxwell and Bosma, Maarten and Michalewski, Henryk and Dohan, David and Jiang, Ellen and Cai, Carrie and Terry, Michael and Le, Quoc and others},
  journal={arXiv preprint arXiv:2108.07732},
  year={2021}
}

@inproceedings{clue,
  author       = {Liang Xu and
                  Hai Hu and
                  Xuanwei Zhang and
                  Lu Li and
                  Chenjie Cao and
                  Yudong Li and
                  Yechen Xu and
                  Kai Sun and
                  Dian Yu and
                  Cong Yu and
                  Yin Tian and
                  Qianqian Dong and
                  Weitang Liu and
                  Bo Shi and
                  Yiming Cui and
                  Junyi Li and
                  Jun Zeng and
                  Rongzhao Wang and
                  Weijian Xie and
                  Yanting Li and
                  Yina Patterson and
                  Zuoyu Tian and
                  Yiwen Zhang and
                  He Zhou and
                  Shaoweihua Liu and
                  Zhe Zhao and
                  Qipeng Zhao and
                  Cong Yue and
                  Xinrui Zhang and
                  Zhengliang Yang and
                  Kyle Richardson and
                  Zhenzhong Lan},
  editor       = {Donia Scott and
                  N{\'{u}}ria Bel and
                  Chengqing Zong},
  title        = {{CLUE:} {A} Chinese Language Understanding Evaluation Benchmark},
  booktitle    = {Proceedings of the 28th International Conference on Computational
                  Linguistics, {COLING} 2020, Barcelona, Spain (Online), December 8-13,
                  2020},
  pages        = {4762--4772},
  publisher    = {International Committee on Computational Linguistics},
  year         = {2020},
  url          = {https://doi.org/10.18653/v1/2020.coling-main.419},
  doi          = {10.18653/V1/2020.COLING-MAIN.419},
  timestamp    = {Tue, 12 Dec 2023 12:16:23 +0100},
  biburl       = {https://dblp.org/rec/conf/coling/XuHZLCLXSYYTDLS20.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{cmmlu,
  title={{CMMLU}: Measuring massive multitask language understanding in {Chinese}},
  author={Li, Haonan and Zhang, Yixuan and Koto, Fajri and Yang, Yifei and Zhao, Hai and Gong, Yeyun and Duan, Nan and Baldwin, Timothy},
  journal={arXiv preprint arXiv:2306.09212},
  year={2023}
}

@inproceedings{chid,
  author       = {Chujie Zheng and
                  Minlie Huang and
                  Aixin Sun},
  editor       = {Anna Korhonen and
                  David R. Traum and
                  Llu{\'{\i}}s M{\`{a}}rquez},
  title        = {ChID: {A} Large-scale Chinese IDiom Dataset for Cloze Test},
  booktitle    = {Proceedings of the 57th Conference of the Association for Computational
                  Linguistics, {ACL} 2019, Florence, Italy, July 28- August 2, 2019,
                  Volume 1: Long Papers},
  pages        = {778--787},
  publisher    = {Association for Computational Linguistics},
  year         = {2019},
  url          = {https://doi.org/10.18653/v1/p19-1075},
  doi          = {10.18653/V1/P19-1075},
  timestamp    = {Sun, 02 Oct 2022 15:53:46 +0200},
  biburl       = {https://dblp.org/rec/conf/acl/ZhengHS19.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{race,
  author       = {Guokun Lai and
                  Qizhe Xie and
                  Hanxiao Liu and
                  Yiming Yang and
                  Eduard H. Hovy},
  editor       = {Martha Palmer and
                  Rebecca Hwa and
                  Sebastian Riedel},
  title        = {{RACE:} Large-scale ReAding Comprehension Dataset From Examinations},
  booktitle    = {Proceedings of the 2017 Conference on Empirical Methods in Natural
                  Language Processing, {EMNLP} 2017, Copenhagen, Denmark, September
                  9-11, 2017},
  pages        = {785--794},
  publisher    = {Association for Computational Linguistics},
  year         = {2017},
  url          = {https://doi.org/10.18653/v1/d17-1082},
  doi          = {10.18653/V1/D17-1082},
  timestamp    = {Fri, 06 Aug 2021 00:40:22 +0200},
  biburl       = {https://dblp.org/rec/conf/emnlp/LaiXLYH17.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{drop,
  author       = {Dheeru Dua and
                  Yizhong Wang and
                  Pradeep Dasigi and
                  Gabriel Stanovsky and
                  Sameer Singh and
                  Matt Gardner},
  editor       = {Jill Burstein and
                  Christy Doran and
                  Thamar Solorio},
  title        = {{DROP:} {A} Reading Comprehension Benchmark Requiring Discrete Reasoning
                  Over Paragraphs},
  booktitle    = {Proceedings of the 2019 Conference of the North American Chapter of
                  the Association for Computational Linguistics: Human Language Technologies,
                  {NAACL-HLT} 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long
                  and Short Papers)},
  pages        = {2368--2378},
  publisher    = {Association for Computational Linguistics},
  year         = {2019},
  url          = {https://doi.org/10.18653/v1/n19-1246},
  doi          = {10.18653/V1/N19-1246},
  timestamp    = {Fri, 06 Aug 2021 00:41:31 +0200},
  biburl       = {https://dblp.org/rec/conf/naacl/DuaWDSS019.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{ceval,
  title={{C-Eval}: A multi-level multi-discipline chinese evaluation suite for foundation models},
  author={Huang, Yuzhen and Bai, Yuzhuo and Zhu, Zhihao and Zhang, Junlei and Zhang, Jinghan and Su, Tangjun and Liu, Junteng and Lv, Chuancheng and Zhang, Yikai and Lei, Jiayi and others},
  journal={arXiv preprint arXiv:2305.08322},
  year={2023}
}

@article{llama,
  title={{LLaMA}: Open and efficient foundation language models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}

@article{llama2,
  author       = {Hugo Touvron and
                  Louis Martin and
                  Kevin Stone and
                  Peter Albert and
                  Amjad Almahairi and
                  Yasmine Babaei and
                  Nikolay Bashlykov and
                  Soumya Batra and
                  Prajjwal Bhargava and
                  Shruti Bhosale and
                  Dan Bikel and
                  Lukas Blecher and
                  Cristian Canton{-}Ferrer and
                  Moya Chen and
                  Guillem Cucurull and
                  David Esiobu and
                  Jude Fernandes and
                  Jeremy Fu and
                  Wenyin Fu and
                  Brian Fuller and
                  Cynthia Gao and
                  Vedanuj Goswami and
                  Naman Goyal and
                  Anthony Hartshorn and
                  Saghar Hosseini and
                  Rui Hou and
                  Hakan Inan and
                  Marcin Kardas and
                  Viktor Kerkez and
                  Madian Khabsa and
                  Isabel Kloumann and
                  Artem Korenev and
                  Punit Singh Koura and
                  Marie{-}Anne Lachaux and
                  Thibaut Lavril and
                  Jenya Lee and
                  Diana Liskovich and
                  Yinghai Lu and
                  Yuning Mao and
                  Xavier Martinet and
                  Todor Mihaylov and
                  Pushkar Mishra and
                  Igor Molybog and
                  Yixin Nie and
                  Andrew Poulton and
                  Jeremy Reizenstein and
                  Rashi Rungta and
                  Kalyan Saladi and
                  Alan Schelten and
                  Ruan Silva and
                  Eric Michael Smith and
                  Ranjan Subramanian and
                  Xiaoqing Ellen Tan and
                  Binh Tang and
                  Ross Taylor and
                  Adina Williams and
                  Jian Xiang Kuan and
                  Puxin Xu and
                  Zheng Yan and
                  Iliyan Zarov and
                  Yuchen Zhang and
                  Angela Fan and
                  Melanie Kambadur and
                  Sharan Narang and
                  Aur{\'{e}}lien Rodriguez and
                  Robert Stojnic and
                  Sergey Edunov and
                  Thomas Scialom},
  title        = {Llama 2: Open Foundation and Fine-Tuned Chat Models},
  journal      = {CoRR},
  volume       = {abs/2307.09288},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2307.09288},
  doi          = {10.48550/arXiv.2307.09288},
  eprinttype    = {arXiv},
  eprint       = {2307.09288}
}

@article{code_llama,
  title={Code {Llama}: Open foundation models for code},
  author={Rozi{\`e}re, Baptiste and Gehring, Jonas and Gloeckle, Fabian and Sootla, Sten and Gat, Itai and Tan, Xiaoqing Ellen and Adi, Yossi and Liu, Jingyu and Remez, Tal and Rapin, J{\'e}r{\'e}my and others},
  journal={arXiv preprint arXiv:2308.12950},
  year={2023}
}

@article{gsm8k,
  title={Training verifiers to solve math word problems},
  author={Cobbe, Karl and Kosaraju, Vineet and Bavarian, Mohammad and Chen, Mark and Jun, Heewoo and Kaiser, Lukasz and Plappert, Matthias and Tworek, Jerry and Hilton, Jacob and Nakano, Reiichiro and others},
  journal={arXiv preprint arXiv:2110.14168},
  year={2021}
}


@article{pile,
  title={The {Pile}: An {800GB} dataset of diverse text for language modeling},
  author={Gao, Leo and Biderman, Stella and Black, Sid and Golding, Laurence and Hoppe, Travis and Foster, Charles and Phang, Jason and He, Horace and Thite, Anish and Nabeshima, Noa and others},
  journal={arXiv preprint arXiv:2101.00027},
  year={2020}
}

@article{agieval,
  author       = {Wanjun Zhong and
                  Ruixiang Cui and
                  Yiduo Guo and
                  Yaobo Liang and
                  Shuai Lu and
                  Yanlin Wang and
                  Amin Saied and
                  Weizhu Chen and
                  Nan Duan},
  title        = {{AGIEval}: {A} Human-Centric Benchmark for Evaluating Foundation Models},
  journal      = {CoRR},
  volume       = {abs/2304.06364},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2304.06364},
  doi          = {10.48550/arXiv.2304.06364},
  eprinttype    = {arXiv},
  eprint       = {2304.06364},
  timestamp    = {Wed, 19 Apr 2023 12:42:23 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2304-06364.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{codex,
  author       = {Mark Chen and
                  Jerry Tworek and
                  Heewoo Jun and
                  Qiming Yuan and
                  Henrique Pond{\'{e}} de Oliveira Pinto and
                  Jared Kaplan and
                  Harrison Edwards and
                  Yuri Burda and
                  Nicholas Joseph and
                  Greg Brockman and
                  Alex Ray and
                  Raul Puri and
                  Gretchen Krueger and
                  Michael Petrov and
                  Heidy Khlaaf and
                  Girish Sastry and
                  Pamela Mishkin and
                  Brooke Chan and
                  Scott Gray and
                  Nick Ryder and
                  Mikhail Pavlov and
                  Alethea Power and
                  Lukasz Kaiser and
                  Mohammad Bavarian and
                  Clemens Winter and
                  Philippe Tillet and
                  Felipe Petroski Such and
                  Dave Cummings and
                  Matthias Plappert and
                  Fotios Chantzis and
                  Elizabeth Barnes and
                  Ariel Herbert{-}Voss and
                  William Hebgen Guss and
                  Alex Nichol and
                  Alex Paino and
                  Nikolas Tezak and
                  Jie Tang and
                  Igor Babuschkin and
                  Suchir Balaji and
                  Shantanu Jain and
                  William Saunders and
                  Christopher Hesse and
                  Andrew N. Carr and
                  Jan Leike and
                  Joshua Achiam and
                  Vedant Misra and
                  Evan Morikawa and
                  Alec Radford and
                  Matthew Knight and
                  Miles Brundage and
                  Mira Murati and
                  Katie Mayer and
                  Peter Welinder and
                  Bob McGrew and
                  Dario Amodei and
                  Sam McCandlish and
                  Ilya Sutskever and
                  Wojciech Zaremba},
  title        = {Evaluating Large Language Models Trained on Code},
  journal      = {CoRR},
  volume       = {abs/2107.03374},
  year         = {2021},
  url          = {https://arxiv.org/abs/2107.03374},
  eprinttype    = {arXiv},
  eprint       = {2107.03374},
}

@misc{gu2024cruxeval,
      title={CRUXEval: A Benchmark for Code Reasoning, Understanding and Execution}, 
      author={Alex Gu and Baptiste Rozière and Hugh Leather and Armando Solar-Lezama and Gabriel Synnaeve and Sida I. Wang},
      year={2024},
      eprint={2401.03065},
      archivePrefix={arXiv},
      primaryClass={cs.SE}
}

@misc{lin2022truthfulqa,
      title={TruthfulQA: Measuring How Models Mimic Human Falsehoods}, 
      author={Stephanie Lin and Jacob Hilton and Owain Evans},
      year={2022},
      eprint={2109.07958},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{hellaswag,
  author       = {Rowan Zellers and
                  Ari Holtzman and
                  Yonatan Bisk and
                  Ali Farhadi and
                  Yejin Choi},
  editor       = {Anna Korhonen and
                  David R. Traum and
                  Llu{\'{\i}}s M{\`{a}}rquez},
  title        = {{HellaSwag}: Can a Machine Really Finish Your Sentence?},
  booktitle    = {Proceedings of the 57th Conference of the Association for Computational
                  Linguistics, {ACL} 2019, Florence, Italy, July 28- August 2, 2019,
                  Volume 1: Long Papers},
  pages        = {4791--4800},
  publisher    = {Association for Computational Linguistics},
  year         = {2019},
  url          = {https://doi.org/10.18653/v1/p19-1472},
  doi          = {10.18653/v1/p19-1472},
  timestamp    = {Sat, 29 Apr 2023 10:09:26 +0200},
  biburl       = {https://dblp.org/rec/conf/acl/ZellersHBFC19.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}



@inproceedings{piqa,
  author       = {Yonatan Bisk and
                  Rowan Zellers and
                  Ronan Le Bras and
                  Jianfeng Gao and
                  Yejin Choi},
  title        = {{PIQA:} Reasoning about Physical Commonsense in Natural Language},
  booktitle    = {The Thirty-Fourth {AAAI} Conference on Artificial Intelligence, {AAAI}
                  2020, The Thirty-Second Innovative Applications of Artificial Intelligence
                  Conference, {IAAI} 2020, The Tenth {AAAI} Symposium on Educational
                  Advances in Artificial Intelligence, {EAAI} 2020, New York, NY, USA,
                  February 7-12, 2020},
  pages        = {7432--7439},
  publisher    = {{AAAI} Press},
  year         = {2020},
  url          = {https://doi.org/10.1609/aaai.v34i05.6239},
  doi          = {10.1609/aaai.v34i05.6239},
  timestamp    = {Mon, 04 Sep 2023 16:50:23 +0200},
  biburl       = {https://dblp.org/rec/conf/aaai/BiskZLGC20.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{hendrycks2021measuring,
  title={Measuring mathematical problem solving with the math dataset},
  author={Hendrycks, Dan and Burns, Collin and Kadavath, Saurav and Arora, Akul and Basart, Steven and Tang, Eric and Song, Dawn and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2103.03874},
  year={2021}
}

@article{siqa,
  author       = {Maarten Sap and
                  Hannah Rashkin and
                  Derek Chen and
                  Ronan Le Bras and
                  Yejin Choi},
  title        = {{SocialIQA}: Commonsense Reasoning about Social Interactions},
  journal      = {CoRR},
  volume       = {abs/1904.09728},
  year         = {2019},
  url          = {http://arxiv.org/abs/1904.09728},
  eprinttype    = {arXiv},
  eprint       = {1904.09728},
  timestamp    = {Sat, 29 Apr 2023 10:09:27 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1904-09728.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{gaokao-bench,
  author       = {Xiaotian Zhang and
                  Chunyang Li and
                  Yi Zong and
                  Zhengyu Ying and
                  Liang He and
                  Xipeng Qiu},
  title        = {Evaluating the Performance of Large Language Models on {GAOKAO} Benchmark},
  journal      = {CoRR},
  volume       = {abs/2305.12474},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2305.12474},
  doi          = {10.48550/arXiv.2305.12474},
  eprinttype    = {arXiv},
  eprint       = {2305.12474},
  timestamp    = {Fri, 26 May 2023 11:29:33 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2305-12474.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{mathshepherd,
  title={Math-Shepherd: A Label-Free Step-by-Step Verifier for LLMs in Mathematical Reasoning},
  author={Wang, Peiyi and Li, Lei and Shao, Zhihong and Xu, RX and Dai, Damai and Li, Yifei and Chen, Deli and Wu, Y and Sui, Zhifang},
  journal={arXiv preprint arXiv:2312.08935},
  year={2023}
}
@article{deepseekmath,
  title={Deepseekmath: Pushing the limits of mathematical reasoning in open language models},
  author={Shao, Zhihong and Wang, Peiyi and Zhu, Qihao and Xu, Runxin and Song, Junxiao and Zhang, Mingchuan and Li, YK and Wu, Y and Guo, Daya},
  journal={arXiv preprint arXiv:2402.03300},
  year={2024}
}
@article{minicpm,
  title={MiniCPM: Unveiling the Potential of Small Language Models with Scalable Training Strategies},
  author={Hu, Shengding and Tu, Yuge and Han, Xu and He, Chaoqun and Cui, Ganqu and Long, Xiang and Zheng, Zhi and Fang, Yewei and Huang, Yuxiang and Zhao, Weilin and others},
  journal={arXiv preprint arXiv:2404.06395},
  year={2024}
}

@article{arc,
  author       = {Peter Clark and
                  Isaac Cowhey and
                  Oren Etzioni and
                  Tushar Khot and
                  Ashish Sabharwal and
                  Carissa Schoenick and
                  Oyvind Tafjord},
  title        = {Think you have Solved Question Answering? Try ARC, the {AI2} Reasoning
                  Challenge},
  journal      = {CoRR},
  volume       = {abs/1803.05457},
  year         = {2018},
  url          = {http://arxiv.org/abs/1803.05457},
  eprinttype    = {arXiv},
  eprint       = {1803.05457},
  timestamp    = {Mon, 13 Aug 2018 16:48:43 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1803-05457.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{alpaca2.0,
  title={Length-Controlled AlpacaEval: A Simple Way to Debias Automatic Evaluators},
  author={Dubois, Yann and Galambosi, Bal{\'a}zs and Liang, Percy and Hashimoto, Tatsunori B},
  journal={arXiv preprint arXiv:2404.04475},
  year={2024}
}
@article{wei2022emergent,
  title={Emergent abilities of large language models},
  author={Wei, Jason and Tay, Yi and Bommasani, Rishi and Raffel, Colin and Zoph, Barret and Borgeaud, Sebastian and Yogatama, Dani and Bosma, Maarten and Zhou, Denny and Metzler, Donald and others},
  journal={arXiv preprint arXiv:2206.07682},
  year={2022}
}

@inproceedings{boolq,
  author       = {Christopher Clark and
                  Kenton Lee and
                  Ming{-}Wei Chang and
                  Tom Kwiatkowski and
                  Michael Collins and
                  Kristina Toutanova},
  editor       = {Jill Burstein and
                  Christy Doran and
                  Thamar Solorio},
  title        = {BoolQ: Exploring the Surprising Difficulty of Natural Yes/No Questions},
  booktitle    = {Proceedings of the 2019 Conference of the North American Chapter of
                  the Association for Computational Linguistics: Human Language Technologies,
                  {NAACL-HLT} 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long
                  and Short Papers)},
  pages        = {2924--2936},
  publisher    = {Association for Computational Linguistics},
  year         = {2019},
  url          = {https://doi.org/10.18653/v1/n19-1300},
  doi          = {10.18653/v1/n19-1300},
  timestamp    = {Tue, 16 Aug 2022 23:04:27 +0200},
  biburl       = {https://dblp.org/rec/conf/naacl/ClarkLCK0T19.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{IFeval,
  title={Instruction-Following Evaluation for Large Language Models},
  author={Zhou, Jeffrey and Lu, Tianjian and Mishra, Swaroop and Brahma, Siddhartha and Basu, Sujoy and Luan, Yi and Zhou, Denny and Hou, Le},
  journal={arXiv preprint arXiv:2311.07911},
  year={2023}
}

@misc{chatglm2,
    title={{ChatGLM2-6B}: An Open Bilingual Chat {LLM}},
    author={{ChatGLM2 Team}},
    url = {https://github.com/THUDM/ChatGLM2-6B},
    year={2023}
}

@inproceedings{glm,
  title={GLM: General Language Model Pretraining with Autoregressive Blank Infilling},
  author={Du, Zhengxiao and Qian, Yujie and Liu, Xiao and Ding, Ming and Qiu, Jiezhong and Yang, Zhilin and Tang, Jie},
  booktitle={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={320--335},
  year={2022}
}

@article{mistral,
  title={Mistral 7B},
  author={Jiang, Albert Q and Sablayrolles, Alexandre and Mensch, Arthur and Bamford, Chris and Chaplot, Devendra Singh and Casas, Diego de las and Bressand, Florian and Lengyel, Gianna and Lample, Guillaume and Saulnier, Lucile and others},
  journal={arXiv preprint arXiv:2310.06825},
  year={2023}
}

@article{qwen,
  title={Qwen Technical Report},
  author={Jinze Bai and Shuai Bai and Yunfei Chu and Zeyu Cui and Kai Dang and Xiaodong Deng and Yang Fan and Wenbin Ge and Yu Han and Fei Huang and Binyuan Hui and Luo Ji and Mei Li and Junyang Lin and Runji Lin and Dayiheng Liu and Gao Liu and Chengqiang Lu and Keming Lu and Jianxin Ma and Rui Men and Xingzhang Ren and Xuancheng Ren and Chuanqi Tan and Sinan Tan and Jianhong Tu and Peng Wang and Shijie Wang and Wei Wang and Shengguang Wu and Benfeng Xu and Jin Xu and An Yang and Hao Yang and Jian Yang and Shusheng Yang and Yang Yao and Bowen Yu and Hongyi Yuan and Zheng Yuan and Jianwei Zhang and Xingxuan Zhang and Yichang Zhang and Zhenru Zhang and Chang Zhou and Jingren Zhou and Xiaohuan Zhou and Tianhang Zhu},
  journal={arXiv preprint arXiv:2309.16609},
  year={2023}
}

@techreport{baichuan2,
    author = {Aiyuan Yang and Bin Xiao and Bingning Wang and Borong Zhang and Chao Yin and Chenxu Lv and Da Pan and Dian Wang and Dong Yan and Fan Yang and Fei Deng and Feng Wang and Feng Liu and Guangwei Ai and Guosheng Dong and Haizhou Zhao and Hang Xu and Haoze Sun and Hongda Zhang and Hui Liu and Jiaming Ji and Jian Xie and Juntao Dai and Kun Fang and Lei Su and Liang Song and Lifeng Liu and Liyun Ru and Luyao Ma and Mang Wang and Mickel Liu and MingAn Lin and Nuolan Nie and Peidong Guo and Ruiyang Sun and Tao Zhang and Tianpeng Li and Tianyu Li and Wei Cheng and Weipeng Chen and Xiangrong Zeng and Xiaochuan Wang and Xiaoxi Chen and Xin Men and Xin Yu and Xuehai Pan and Yanjun Shen and Yiding Wang and Yiyu Li and Youxin Jiang and Yuchen Gao and Yupeng Zhang and Zenan Zhou and Zhiying Wu},
    title = {Baichuan 2: Open Large-scale Language Models},
    institution = {Baichuan Inc.},
    year = {2023},
    url = {https://cdn.baichuan-ai.com/paper/Baichuan2-technical-report.pdf}
}

@inproceedings{commonsenseqa,
  author       = {Alon Talmor and
                  Jonathan Herzig and
                  Nicholas Lourie and
                  Jonathan Berant},
  editor       = {Jill Burstein and
                  Christy Doran and
                  Thamar Solorio},
  title        = {{CommonsenseQA}: {A} Question Answering Challenge Targeting Commonsense
                  Knowledge},
  booktitle    = {Proceedings of the 2019 Conference of the North American Chapter of
                  the Association for Computational Linguistics: Human Language Technologies,
                  {NAACL-HLT} 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long
                  and Short Papers)},
  pages        = {4149--4158},
  publisher    = {Association for Computational Linguistics},
  year         = {2019},
  url          = {https://doi.org/10.18653/v1/n19-1421},
  doi          = {10.18653/v1/n19-1421},
  timestamp    = {Fri, 06 Aug 2021 00:41:31 +0200},
  biburl       = {https://dblp.org/rec/conf/naacl/TalmorHLB19.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{adamW,
  title={Decoupled weight decay regularization},
  author={Loshchilov, Ilya and Hutter, Frank},
  journal={arXiv preprint arXiv:1711.05101},
  year={2017}
}

@article{roberta,
  title={{RoBERTa}: A robustly optimized {BERT} pretraining approach},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1907.11692},
  year={2019}
}

@article{bert,
  title={{BERT}: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{scalinglaw,
  author       = {Jared Kaplan and
                  Sam McCandlish and
                  Tom Henighan and
                  Tom B. Brown and
                  Benjamin Chess and
                  Rewon Child and
                  Scott Gray and
                  Alec Radford and
                  Jeffrey Wu and
                  Dario Amodei},
  title        = {Scaling Laws for Neural Language Models},
  journal      = {CoRR},
  volume       = {abs/2001.08361},
  year         = {2020},
  url          = {https://arxiv.org/abs/2001.08361},
  eprinttype    = {arXiv},
  eprint       = {2001.08361},
  timestamp    = {Wed, 03 Jun 2020 10:55:13 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2001-08361.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{chinchilla,
  author       = {Jordan Hoffmann and
                  Sebastian Borgeaud and
                  Arthur Mensch and
                  Elena Buchatskaya and
                  Trevor Cai and
                  Eliza Rutherford and
                  Diego de Las Casas and
                  Lisa Anne Hendricks and
                  Johannes Welbl and
                  Aidan Clark and
                  Tom Hennigan and
                  Eric Noland and
                  Katie Millican and
                  George van den Driessche and
                  Bogdan Damoc and
                  Aurelia Guy and
                  Simon Osindero and
                  Karen Simonyan and
                  Erich Elsen and
                  Jack W. Rae and
                  Oriol Vinyals and
                  Laurent Sifre},
  title        = {Training Compute-Optimal Large Language Models},
  journal      = {CoRR},
  volume       = {abs/2203.15556},
  year         = {2022},
  url          = {https://doi.org/10.48550/arXiv.2203.15556},
  doi          = {10.48550/ARXIV.2203.15556},
  eprinttype    = {arXiv},
  eprint       = {2203.15556},
  timestamp    = {Mon, 04 Apr 2022 18:01:21 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2203-15556.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{naturalquestions,
  author       = {Tom Kwiatkowski and
                  Jennimaria Palomaki and
                  Olivia Redfield and
                  Michael Collins and
                  Ankur P. Parikh and
                  Chris Alberti and
                  Danielle Epstein and
                  Illia Polosukhin and
                  Jacob Devlin and
                  Kenton Lee and
                  Kristina Toutanova and
                  Llion Jones and
                  Matthew Kelcey and
                  Ming{-}Wei Chang and
                  Andrew M. Dai and
                  Jakob Uszkoreit and
                  Quoc Le and
                  Slav Petrov},
  title        = {Natural Questions: a Benchmark for Question Answering Research},
  journal      = {Trans. Assoc. Comput. Linguistics},
  volume       = {7},
  pages        = {452--466},
  year         = {2019},
  url          = {https://doi.org/10.1162/tacl\_a\_00276},
  doi          = {10.1162/tacl\_a\_00276},
  timestamp    = {Tue, 16 Aug 2022 23:05:11 +0200},
  biburl       = {https://dblp.org/rec/journals/tacl/KwiatkowskiPRCP19.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{tsinghua_safety,
      title={Safety Assessment of Chinese Large Language Models}, 
      author={Hao Sun and Zhexin Zhang and Jiawen Deng and Jiale Cheng and Minlie Huang},
      journal={arXiv preprint arXiv:2304.10436},
      year={2023}
}

@article{align_bench,
  author       = {Xiao Liu and
                  Xuanyu Lei and
                  Shengyuan Wang and
                  Yue Huang and
                  Zhuoer Feng and
                  Bosi Wen and
                  Jiale Cheng and
                  Pei Ke and
                  Yifan Xu and
                  Weng Lam Tam and
                  Xiaohan Zhang and
                  Lichao Sun and
                  Hongning Wang and
                  Jing Zhang and
                  Minlie Huang and
                  Yuxiao Dong and
                  Jie Tang},
  title        = {AlignBench: Benchmarking Chinese Alignment of Large Language Models},
  journal      = {CoRR},
  volume       = {abs/2311.18743},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2311.18743},
  doi          = {10.48550/ARXIV.2311.18743},
  eprinttype    = {arXiv},
  eprint       = {2311.18743},
  timestamp    = {Tue, 05 Dec 2023 14:40:42 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2311-18743.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{switch,
  author    = {William Fedus and
               Barret Zoph and
               Noam Shazeer},
  title     = {Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity},
  journal   = {CoRR},
  volume    = {abs/2101.03961},
  year      = {2021},
  url       = {https://arxiv.org/abs/2101.03961},
  archivePrefix = {arXiv},
  eprint    = {2101.03961},
}

@article{dpo,
      title={Direct Preference Optimization: Your Language Model is Secretly a Reward Model}, 
      author={Rafael Rafailov and Archit Sharma and Eric Mitchell and Stefano Ermon and Christopher D. Manning and Chelsea Finn},
      year={2023},
}

@article{gpt4,
  title={{GPT4} technical report},
  author={OpenAI},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@article{yi,
  title={Yi: Open foundation models by 01. ai},
  author={Young, Alex and Chen, Bei and Li, Chao and Huang, Chengen and Zhang, Ge and Zhang, Guanwei and Li, Heng and Zhu, Jiangcheng and Chen, Jianqun and Chang, Jing and others},
  journal={arXiv preprint arXiv:2403.04652},
  year={2024}
}

@article{lima,
  title={Lima: Less is more for alignment},
  author={Zhou, Chunting and Liu, Pengfei and Xu, Puxin and Iyer, Srinivasan and Sun, Jiao and Mao, Yuning and Ma, Xuezhe and Efrat, Avia and Yu, Ping and Yu, Lili and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{tulu2,
      title={Camels in a Changing Climate: Enhancing LM Adaptation with Tulu 2}, 
      author={Hamish Ivison and Yizhong Wang and Valentina Pyatkin and Nathan Lambert and Matthew Peters and Pradeep Dasigi and Joel Jang and David Wadden and Noah A. Smith and Iz Beltagy and Hannaneh Hajishirzi},
      year={2023},
}

@misc{mtbench,
      title={Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena}, 
      author={Lianmin Zheng and Wei-Lin Chiang and Ying Sheng and Siyuan Zhuang and Zhanghao Wu and Yonghao Zhuang and Zi Lin and Zhuohan Li and Dacheng Li and Eric. P Xing and Hao Zhang and Joseph E. Gonzalez and Ion Stoica},
      year={2023},
}

@article{donotanswer,
  author       = {Yuxia Wang and
                  Haonan Li and
                  Xudong Han and
                  Preslav Nakov and
                  Timothy Baldwin},
  title        = {Do-Not-Answer: {A} Dataset for Evaluating Safeguards in LLMs},
  journal      = {CoRR},
  volume       = {abs/2308.13387},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2308.13387},
  doi          = {10.48550/ARXIV.2308.13387},
  eprinttype    = {arXiv},
  eprint       = {2308.13387},
  timestamp    = {Fri, 01 Sep 2023 14:25:01 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2308-13387.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{refinedweb,
  title={The RefinedWeb dataset for Falcon LLM: outperforming curated corpora with web data, and web data only},
  author={Penedo, Guilherme and Malartic, Quentin and Hesslow, Daniel and Cojocaru, Ruxandra and Cappelli, Alessandro and Alobeidli, Hamza and Pannier, Baptiste and Almazrouei, Ebtesam and Launay, Julien},
  journal={arXiv preprint arXiv:2306.01116},
  year={2023}
}

@misc{hftokenizers,
    title={{Tokenizers}: Fast State-of-the-Art Tokenizers optimized for Research and Production},
    author={{Huggingface Team}},
    url = {https://github.com/huggingface/tokenizers},
    year={2019}
}

@article{lee2021deduplicating,
  title={Deduplicating training data makes language models better},
  author={Lee, Katherine and Ippolito, Daphne and Nystrom, Andrew and Zhang, Chiyuan and Eck, Douglas and Callison-Burch, Chris and Carlini, Nicholas},
  journal={arXiv preprint arXiv:2107.06499},
  year={2021}
}

@software{redpajama,
  author = {Together Computer},
  title = {RedPajama: an Open Dataset for Training Large Language Models},
  month = October,
  year = 2023,
  url = {https://github.com/togethercomputer/RedPajama-Data}
}

@article{longpre2023pretrainer,
  title={A Pretrainer's Guide to Training Data: Measuring the Effects of Data Age, Domain Coverage, Quality, \& Toxicity},
  author={Longpre, Shayne and Yauney, Gregory and Reif, Emily and Lee, Katherine and Roberts, Adam and Zoph, Barret and Zhou, Denny and Wei, Jason and Robinson, Kevin and Mimno, David and others},
  journal={arXiv preprint arXiv:2305.13169},
  year={2023}
}

@article{gunasekar2023textbooks,
  title={Textbooks Are All You Need},
  author={Gunasekar, Suriya and Zhang, Yi and Aneja, Jyoti and Mendes, Caio C{\'e}sar Teodoro and Del Giorno, Allie and Gopi, Sivakanth and Javaheripi, Mojan and Kauffmann, Piero and de Rosa, Gustavo and Saarikivi, Olli and others},
  journal={arXiv preprint arXiv:2306.11644},
  year={2023}
}


% Scaling 
@article{mccandlish2018empirical,
  title={An empirical model of large-batch training},
  author={McCandlish, Sam and Kaplan, Jared and Amodei, Dario and Team, OpenAI Dota},
  journal={arXiv preprint arXiv:1812.06162},
  year={2018}
}

@article{shallue2019measuring,
  title={Measuring the effects of data parallelism on neural network training},
  author={Shallue, Christopher J and Lee, Jaehoon and Antognini, Joseph and Sohl-Dickstein, Jascha and Frostig, Roy and Dahl, George E},
  journal={Journal of Machine Learning Research},
  volume={20},
  number={112},
  pages={1--49},
  year={2019}
}

@article{smith2017don,
  title={Don't decay the learning rate, increase the batch size},
  author={Smith, Samuel L and Kindermans, Pieter-Jan and Ying, Chris and Le, Quoc V},
  journal={arXiv preprint arXiv:1711.00489},
  year={2017}
}

@article{goyal2017accurate,
  title={Accurate, large minibatch sgd: Training imagenet in 1 hour},
  author={Goyal, Priya and Doll{\'a}r, Piotr and Girshick, Ross and Noordhuis, Pieter and Wesolowski, Lukasz and Kyrola, Aapo and Tulloch, Andrew and Jia, Yangqing and He, Kaiming},
  journal={arXiv preprint arXiv:1706.02677},
  year={2017}
}

@article{hestness2017deep,
  title={Deep learning scaling is predictable, empirically},
  author={Hestness, Joel and Narang, Sharan and Ardalani, Newsha and Diamos, Gregory and Jun, Heewoo and Kianinejad, Hassan and Patwary, Md Mostofa Ali and Yang, Yang and Zhou, Yanqi},
  journal={arXiv preprint arXiv:1712.00409},
  year={2017}
}

@article{dai2019transformer,
  title={Transformer-xl: Attentive language models beyond a fixed-length context},
  author={Dai, Zihang and Yang, Zhilin and Yang, Yiming and Carbonell, Jaime and Le, Quoc V and Salakhutdinov, Ruslan},
  journal={arXiv preprint arXiv:1901.02860},
  year={2019}
}

@article{henighan2020scaling,
  title={Scaling laws for autoregressive generative modeling},
  author={Henighan, Tom and Kaplan, Jared and Katz, Mor and Chen, Mark and Hesse, Christopher and Jackson, Jacob and Jun, Heewoo and Brown, Tom B and Dhariwal, Prafulla and Gray, Scott and others},
  journal={arXiv preprint arXiv:2010.14701},
  year={2020}
}

@article{smith2022using,
  title={Using deepspeed and megatron to train megatron-turing nlg 530b, a large-scale generative language model},
  author={Smith, Shaden and Patwary, Mostofa and Norick, Brandon and LeGresley, Patrick and Rajbhandari, Samyam and Casper, Jared and Liu, Zhun and Prabhumoye, Shrimai and Zerveas, George and Korthikanti, Vijay and others},
  journal={arXiv preprint arXiv:2201.11990},
  year={2022}
}

@article{zhang2019algorithmic,
  title={Which algorithmic choices matter at which batch sizes? insights from a noisy quadratic model},
  author={Zhang, Guodong and Li, Lala and Nado, Zachary and Martens, James and Sachdeva, Sushant and Dahl, George and Shallue, Chris and Grosse, Roger B},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

% arch
@article{zhang2019root,
  title={Root mean square layer normalization},
  author={Zhang, Biao and Sennrich, Rico},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{shazeer2020glu,
  title={Glu variants improve transformer},
  author={Shazeer, Noam},
  journal={arXiv preprint arXiv:2002.05202},
  year={2020}
}

@inproceedings{moe,
  author    = {Noam Shazeer and
               Azalia Mirhoseini and
               Krzysztof Maziarz and
               Andy Davis and
               Quoc V. Le and
               Geoffrey E. Hinton and
               Jeff Dean},
  title     = {Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer},
  booktitle = {5th International Conference on Learning Representations, {ICLR} 2017},
  publisher = {OpenReview.net},
  year      = {2017},
  url       = {https://openreview.net/forum?id=B1ckMDqlg},
}

@article{deepseekmoe,
  author       = {Damai Dai and
                  Chengqi Deng and
                  Chenggang Zhao and
                  R. X. Xu and
                  Huazuo Gao and
                  Deli Chen and
                  Jiashi Li and
                  Wangding Zeng and
                  Xingkai Yu and
                  Y. Wu and
                  Zhenda Xie and
                  Y. K. Li and
                  Panpan Huang and
                  Fuli Luo and
                  Chong Ruan and
                  Zhifang Sui and
                  Wenfeng Liang},
  title        = {DeepSeekMoE: Towards Ultimate Expert Specialization in Mixture-of-Experts
                  Language Models},
  journal      = {CoRR},
  volume       = {abs/2401.06066},
  year         = {2024},
  url          = {https://doi.org/10.48550/arXiv.2401.06066},
}

@inproceedings{gshard,
  author    = {Dmitry Lepikhin and
               HyoukJoong Lee and
               Yuanzhong Xu and
               Dehao Chen and
               Orhan Firat and
               Yanping Huang and
               Maxim Krikun and
               Noam Shazeer and
               Zhifeng Chen},
  title     = {GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding},
  booktitle = {9th International Conference on Learning Representations, {ICLR} 2021},
  publisher = {OpenReview.net},
  year      = {2021},
  url       = {https://openreview.net/forum?id=qrwe7XHTmYb},
}

@article{deepseek1,
  author       = {DeepSeek-AI},
  title        = {DeepSeek {LLM:} Scaling Open-Source Language Models with Longtermism},
  journal      = {CoRR},
  volume       = {abs/2401.02954},
  year         = {2024},
  url          = {https://doi.org/10.48550/arXiv.2401.02954},
}

@inproceedings{bpr,
  author       = {Carlos Riquelme and
                  Joan Puigcerver and
                  Basil Mustafa and
                  Maxim Neumann and
                  Rodolphe Jenatton and
                  Andr{\'{e}} Susano Pinto and
                  Daniel Keysers and
                  Neil Houlsby},
  title        = {Scaling Vision with Sparse Mixture of Experts},
  booktitle    = {Advances in Neural Information Processing Systems 34: Annual Conference
                  on Neural Information Processing Systems 2021, NeurIPS 2021},
  pages        = {8583--8595},
  year         = {2021},
  url          = {https://proceedings.neurips.cc/paper/2021/hash/48237d9f2dea8c74c2a72126cf63d933-Abstract.html},
}

@article{kv_quant,
  author       = {Coleman Hooper and
                  Sehoon Kim and
                  Hiva Mohammadzadeh and
                  Michael W. Mahoney and
                  Yakun Sophia Shao and
                  Kurt Keutzer and
                  Amir Gholami},
  title        = {KVQuant: Towards 10 Million Context Length {LLM} Inference with {KV}
                  Cache Quantization},
  journal      = {CoRR},
  volume       = {abs/2401.18079},
  year         = {2024},
  url          = {https://doi.org/10.48550/arXiv.2401.18079},
}

@article{atom,
  author       = {Yilong Zhao and
                  Chien{-}Yu Lin and
                  Kan Zhu and
                  Zihao Ye and
                  Lequn Chen and
                  Size Zheng and
                  Luis Ceze and
                  Arvind Krishnamurthy and
                  Tianqi Chen and
                  Baris Kasikci},
  title        = {Atom: Low-bit Quantization for Efficient and Accurate {LLM} Serving},
  journal      = {CoRR},
  volume       = {abs/2310.19102},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2310.19102},
}

@article{peng2023yarn,
  title={Yarn: Efficient context window extension of large language models},
  author={Peng, Bowen and Quesnelle, Jeffrey and Fan, Honglu and Shippole, Enrico},
  journal={arXiv preprint arXiv:2309.00071},
  year={2023}
}

@article{wang2023making,
  title={Making large language models better reasoners with alignment},
  author={Wang, Peiyi and Li, Lei and Chen, Liang and Song, Feifan and Lin, Binghuai and Cao, Yunbo and Liu, Tianyu and Sui, Zhifang},
  journal={arXiv preprint arXiv:2309.02144},
  year={2023}
}

@article{wang2023math,
  title={Math-shepherd: Verify and reinforce llms step-by-step without human annotations},
  author={Wang, Peiyi and Li, Lei and Shao, Zhihong and Xu, RX and Dai, Damai and Li, Yifei and Chen, Deli and Wu, Y and Sui, Zhifang},
  journal={CoRR, abs/2312.08935},
  year={2023}
}

@misc{shoeybi2020megatronlm,
  title={Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism}, 
  author={Mohammad Shoeybi and Mostofa Patwary and Raul Puri and Patrick LeGresley and Jared Casper and Bryan Catanzaro},
  year={2020},
  eprint={1909.08053},
  archivePrefix={arXiv},
  primaryClass={cs.CL}
}

@inproceedings{kwon2023efficient,
  title={Efficient Memory Management for Large Language Model Serving with PagedAttention},
  author={Woosuk Kwon and Zhuohan Li and Siyuan Zhuang and Ying Sheng and Lianmin Zheng and Cody Hao Yu and Joseph E. Gonzalez and Hao Zhang and Ion Stoica},
  booktitle={Proceedings of the ACM SIGOPS 29th Symposium on Operating Systems Principles},
  year={2023}
}

@misc{llama3,
  title={Llama 3 Model Card},
  author={AI@Meta},
  year={2024},
  url = {https://github.com/meta-llama/llama3/blob/main/MODEL_CARD.md}
}

@misc{mixtral8x22b,
  title = {Cheaper, Better, Faster, Stronger: Continuing to push the frontier of AI and making it accessible to all},
  author = {Mistral},
  url = {https://mistral.ai/news/mixtral-8x22b},
  year={2024}
}

@misc{qwen1_5,
  title = {Introducing Qwen1.5},
  author = {Qwen},
  url = {https://qwenlm.github.io/blog/qwen1.5},
  year={2024}
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}