\input{preamble}

\section{Conclusion}
\label{sec:conclusion}

We propose a novel video architecture \ssm\ that alternates gated linear recurrent units (LRUs) modelling the temporal dynamics in the video with ViT blocks modelling the spatial and channel dimensions.
The proposed model outperforms or obtains competitive performance compared to strong baselines (ViViT-L, VideoMAE) on supervised and self-supervised tasks, while having a much smaller number of parameters and significantly reduced memory footprint and FLOPs count. In terms of limitations, our study focuses on doing a first investigation into using LRUs for the video domain and we obtain favourable results on multiple datasets and tasks compared to strong baselines. However, more experimentation and model scaling are required to obtain SOTA results on all these tasks. Given that the training dynamics for gated LRUs are stable and controllable by design, plus the reliance on (pre-trained) ViT blocks give a strong indication that achieving SOTA is possible. We leave this investigation for future work, together with further analysis of training dynamics, and integration into various downstream tasks, \eg video-language tasks or Robotics tasks. 