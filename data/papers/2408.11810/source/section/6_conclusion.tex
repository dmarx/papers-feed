\section{Conclusion}

In this paper, we present the first framework designed to effectively protect images manipulation by Pixel-domain Diffusion Models (PDMs). We demonstrate that while denoising UNets appear robust to conventional PGD-based attacks, their feature space remains vulnerable to attack. Our proposed feature attacking loss exploit the vulnerabilities to empower adversarial images to mislead PDMs, thereby producing low-quality output images. We approach this image protection problem as a constrained optimization problem, solving it through alternating optimization. Additionally, our latent optimization strategy via VAE enhances the naturalness of our adversarial images. Extensive experiments validate the efficacy of our method, achieving state-of-the-art performance in attacking PDMs.
