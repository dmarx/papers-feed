\begin{thebibliography}{50}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Ahn et~al.(2024)Ahn, Ahn, Yoo, Kim, and Nam]{ahn2024imperceptible}
N.~Ahn, W.~Ahn, K.~Yoo, D.~Kim, and S.-H. Nam.
\newblock Imperceptible protection against style imitation from diffusion models.
\newblock \emph{arXiv preprint arXiv:2403.19254}, 2024.

\bibitem[Andersen(2023)]{andersen2023}
S.~Andersen.
\newblock Us district court for the northern district of california.
\newblock January 2023.

\bibitem[Balaji et~al.(2022)Balaji, Nah, Huang, Vahdat, Song, Kreis, Aittala, Aila, Laine, Catanzaro, et~al.]{balaji2022ediffi}
Y.~Balaji, S.~Nah, X.~Huang, A.~Vahdat, J.~Song, K.~Kreis, M.~Aittala, T.~Aila, S.~Laine, B.~Catanzaro, et~al.
\newblock ediffi: Text-to-image diffusion models with an ensemble of expert denoisers.
\newblock \emph{arXiv preprint arXiv:2211.01324}, 2022.

\bibitem[Carlini and Wagner(2017)]{carlini2017towards}
N.~Carlini and D.~Wagner.
\newblock Towards evaluating the robustness of neural networks.
\newblock In \emph{2017 ieee symposium on security and privacy (sp)}, pages 39--57. Ieee, 2017.

\bibitem[Chen et~al.(2024)Chen, Dong, and Xie]{chen2024smoothattack}
J.~Chen, J.~Dong, and X.~Xie.
\newblock Exploring adversarial attacks against latent diffusion model from the perspective of adversarial transferability.
\newblock \emph{arXiv preprint arXiv:2401.07087}, 2024.

\bibitem[Cui et~al.(2023)Cui, Ren, Xu, He, Liu, Sun, and Tang]{cui2023diffusionshield}
Y.~Cui, J.~Ren, H.~Xu, P.~He, H.~Liu, L.~Sun, and J.~Tang.
\newblock Diffusionshield: A watermark for copyright protection against generative diffusion models.
\newblock \emph{arXiv preprint arXiv:2306.04642}, 2023.

\bibitem[Deng et~al.(2009)Deng, Dong, Socher, Li, Li, and Fei-Fei]{deng2009imagenet}
J.~Deng, W.~Dong, R.~Socher, L.-J. Li, K.~Li, and L.~Fei-Fei.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In \emph{2009 IEEE conference on computer vision and pattern recognition}, pages 248--255. Ieee, 2009.

\bibitem[Dhariwal and Nichol(2021)]{guideddiffusion}
P.~Dhariwal and A.~Nichol.
\newblock Diffusion models beat gans on image synthesis.
\newblock \emph{Advances in Neural Information Processing Systems}, 34:\penalty0 8780--8794, 2021.

\bibitem[Gal et~al.(2022)Gal, Alaluf, Atzmon, Patashnik, Bermano, Chechik, and Cohen-Or]{textualinversion}
R.~Gal, Y.~Alaluf, Y.~Atzmon, O.~Patashnik, A.~H. Bermano, G.~Chechik, and D.~Cohen-Or.
\newblock An image is worth one word: Personalizing text-to-image generation using textual inversion.
\newblock \emph{arXiv preprint arXiv:2208.01618}, 2022.

\bibitem[Gandikota et~al.(2023)Gandikota, Orgad, Belinkov, Materzy{\'n}ska, and Bau]{gandikota2023unified}
R.~Gandikota, H.~Orgad, Y.~Belinkov, J.~Materzy{\'n}ska, and D.~Bau.
\newblock Unified concept editing in diffusion models.
\newblock \emph{arXiv preprint arXiv:2308.14761}, 2023.

\bibitem[Goodfellow et~al.(2014)Goodfellow, Shlens, and Szegedy]{goodfellow2014fgsm}
I.~J. Goodfellow, J.~Shlens, and C.~Szegedy.
\newblock Explaining and harnessing adversarial examples.
\newblock \emph{arXiv preprint arXiv:1412.6572}, 2014.

\bibitem[Heng and Soh(2023)]{heng2023continual}
A.~Heng and H.~Soh.
\newblock Continual learning for forgetting in deep generative models.
\newblock 2023.

\bibitem[Heusel et~al.(2017)Heusel, Ramsauer, Unterthiner, Nessler, and Hochreiter]{fid}
M.~Heusel, H.~Ramsauer, T.~Unterthiner, B.~Nessler, and S.~Hochreiter.
\newblock Gans trained by a two time-scale update rule converge to a local nash equilibrium.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Ho et~al.(2020)Ho, Jain, and Abbeel]{ddpm}
J.~Ho, A.~Jain, and P.~Abbeel.
\newblock Denoising diffusion probabilistic models.
\newblock \emph{Advances in Neural Information Processing Systems}, 33:\penalty0 6840--6851, 2020.

\bibitem[Ho et~al.(2022)Ho, Salimans, Gritsenko, Chan, Norouzi, and Fleet]{vdm}
J.~Ho, T.~Salimans, A.~Gritsenko, W.~Chan, M.~Norouzi, and D.~J. Fleet.
\newblock Video diffusion models.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 8633--8646, 2022.

\bibitem[Hu et~al.(2021)Hu, Shen, Wallis, Allen-Zhu, Li, Wang, Wang, and Chen]{lora}
E.~J. Hu, Y.~Shen, P.~Wallis, Z.~Allen-Zhu, Y.~Li, S.~Wang, L.~Wang, and W.~Chen.
\newblock Lora: Low-rank adaptation of large language models.
\newblock \emph{arXiv preprint arXiv:2106.09685}, 2021.

\bibitem[Huang et~al.(2023)Huang, Park, Wang, Denk, Ly, Chen, Zhang, Zhang, Yu, Frank, et~al.]{huang2023noise2music}
Q.~Huang, D.~S. Park, T.~Wang, T.~I. Denk, A.~Ly, N.~Chen, Z.~Zhang, Z.~Zhang, J.~Yu, C.~Frank, et~al.
\newblock Noise2music: Text-conditioned music generation with diffusion models.
\newblock \emph{arXiv preprint arXiv:2302.03917}, 2023.

\bibitem[Kumari et~al.(2023)Kumari, Zhang, Zhang, Shechtman, and Zhu]{la-score}
N.~Kumari, B.~Zhang, R.~Zhang, E.~Shechtman, and J.-Y. Zhu.
\newblock Multi-concept customization of text-to-image diffusion.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 1931--1941, 2023.

\bibitem[Liang and Wu(2023)]{liang2023mist}
C.~Liang and X.~Wu.
\newblock Mist: Towards improved adversarial examples for diffusion models.
\newblock \emph{arXiv preprint arXiv:2305.12683}, 2023.

\bibitem[Liang et~al.(2023)Liang, Wu, Hua, Zhang, Xue, Song, Xue, Ma, and Guan]{advdm}
C.~Liang, X.~Wu, Y.~Hua, J.~Zhang, Y.~Xue, T.~Song, Z.~Xue, R.~Ma, and H.~Guan.
\newblock Adversarial example does good: Preventing painting imitation from diffusion models via adversarial examples.
\newblock In \emph{International Conference on Machine Learning}, pages 20763--20786. PMLR, 2023.

\bibitem[Lin et~al.(2022)Lin, Gao, Tang, Takikawa, Zeng, Huang, Kreis, Fidler, Liu, and Lin]{lin2022magic3d}
C.-H. Lin, J.~Gao, L.~Tang, T.~Takikawa, X.~Zeng, X.~Huang, K.~Kreis, S.~Fidler, M.-Y. Liu, and T.-Y. Lin.
\newblock Magic3d: High-resolution text-to-3d content creation.
\newblock \emph{arXiv preprint arXiv:2211.10440}, 2022.

\bibitem[Liu et~al.(2023)Liu, Fan, Dai, Chen, Zhou, and Sun]{metacloak}
Y.~Liu, C.~Fan, Y.~Dai, X.~Chen, P.~Zhou, and L.~Sun.
\newblock Toward robust imperceptible perturbation against unauthorized text-to-image diffusion-based synthesis.
\newblock \emph{arXiv preprint arXiv:2311.13127}, 3, 2023.

\bibitem[Madry et~al.(2018)Madry, Makelov, Schmidt, Tsipras, and Vladu]{pgd}
A.~Madry, A.~Makelov, L.~Schmidt, D.~Tsipras, and A.~Vladu.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Meng et~al.(2021)Meng, He, Song, Song, Wu, Zhu, and Ermon]{meng2021sdedit}
C.~Meng, Y.~He, Y.~Song, J.~Song, J.~Wu, J.-Y. Zhu, and S.~Ermon.
\newblock Sdedit: Guided image synthesis and editing with stochastic differential equations.
\newblock In \emph{International Conference on Learning Representations}, 2021.

\bibitem[Mittal et~al.(2021)Mittal, Engel, Hawthorne, and Simon]{musicdiff}
G.~Mittal, J.~Engel, C.~Hawthorne, and I.~Simon.
\newblock Symbolic music generation with diffusion models.
\newblock \emph{arXiv preprint arXiv:2103.16091}, 2021.

\bibitem[Nie et~al.(2022)Nie, Guo, Huang, Xiao, Vahdat, and Anandkumar]{nie2022diffusion}
W.~Nie, B.~Guo, Y.~Huang, C.~Xiao, A.~Vahdat, and A.~Anandkumar.
\newblock Diffusion models for adversarial purification.
\newblock \emph{arXiv preprint arXiv:2205.07460}, 2022.

\bibitem[Pan et~al.(2022)Pan, Qin, Li, Xue, and Chen]{pan2022story}
X.~Pan, P.~Qin, Y.~Li, H.~Xue, and W.~Chen.
\newblock Synthesizing coherent story with auto-regressive latent diffusion models.
\newblock \emph{arXiv preprint arXiv:2211.10950}, 2022.

\bibitem[Peebles and Xie(2023)]{dit}
W.~Peebles and S.~Xie.
\newblock Scalable diffusion models with transformers.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 4195--4205, 2023.

\bibitem[Peng et~al.(2023)Peng, Chen, Wang, and Jia]{peng2023protecting}
S.~Peng, Y.~Chen, C.~Wang, and X.~Jia.
\newblock Protecting the intellectual property of diffusion models by the watermark diffusion process.
\newblock \emph{arXiv preprint arXiv:2306.03436}, 2023.

\bibitem[Poole et~al.(2023)Poole, Jain, Barron, and Mildenhall]{poole2022dreamfusion}
B.~Poole, A.~Jain, J.~T. Barron, and B.~Mildenhall.
\newblock Dreamfusion: Text-to-3d using 2d diffusion.
\newblock In \emph{The Eleventh International Conference on Learning Representations}, 2023.

\bibitem[Rahman et~al.(2023)Rahman, Lee, Ren, Tulyakov, Mahajan, and Sigal]{rahman2023make}
T.~Rahman, H.-Y. Lee, J.~Ren, S.~Tulyakov, S.~Mahajan, and L.~Sigal.
\newblock Make-a-story: Visual memory conditioned consistent story generation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 2493--2502, 2023.

\bibitem[Rombach et~al.(2022)Rombach, Blattmann, Lorenz, Esser, and Ommer]{ldm}
R.~Rombach, A.~Blattmann, D.~Lorenz, P.~Esser, and B.~Ommer.
\newblock High-resolution image synthesis with latent diffusion models.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 10684--10695, 2022.

\bibitem[Salman et~al.(2023)Salman, Khaddaj, Leclerc, Ilyas, and Madry]{salman2023raising}
H.~Salman, A.~Khaddaj, G.~Leclerc, A.~Ilyas, and A.~Madry.
\newblock Raising the cost of malicious ai-powered image editing.
\newblock \emph{arXiv preprint arXiv:2302.06588}, 2023.

\bibitem[Sandoval-Segura et~al.(2023)Sandoval-Segura, Geiping, and Goldstein]{sandoval2023jpeg}
P.~Sandoval-Segura, J.~Geiping, and T.~Goldstein.
\newblock Jpeg compressed images can bypass protections against ai editing.
\newblock \emph{arXiv preprint arXiv:2304.02234}, 2023.

\bibitem[Schuhmann et~al.(2022)Schuhmann, Beaumont, Vencu, Gordon, Wightman, Cherti, Coombes, Katta, Mullis, Wortsman, et~al.]{schuhmann2022laion}
C.~Schuhmann, R.~Beaumont, R.~Vencu, C.~Gordon, R.~Wightman, M.~Cherti, T.~Coombes, A.~Katta, C.~Mullis, M.~Wortsman, et~al.
\newblock Laion-5b: An open large-scale dataset for training next generation image-text models.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 25278--25294, 2022.

\bibitem[Setty(2023)]{setty2023}
R.~Setty.
\newblock Ai art generators hit with copyright suit over artistsâ€™ images.
\newblock January 2023.

\bibitem[Shan et~al.(2023)Shan, Cryan, Wenger, Zheng, Hanocka, and Zhao]{glaze}
S.~Shan, J.~Cryan, E.~Wenger, H.~Zheng, R.~Hanocka, and B.~Y. Zhao.
\newblock Glaze: Protecting artists from style mimicry by text-to-image models.
\newblock \emph{arXiv preprint arXiv:2302.04222}, 2023.

\bibitem[Shonenkov et~al.()Shonenkov, Konstantinov, Bakshandaeva, Schuhmann, Ivanova, and Klokova]{deepfloyd}
A.~Shonenkov, M.~Konstantinov, D.~Bakshandaeva, C.~Schuhmann, K.~Ivanova, and N.~Klokova.
\newblock {IF}.
\newblock \url{https://github.com/deep-floyd/IF}.

\bibitem[Singer et~al.(2022)Singer, Polyak, Hayes, Yin, An, Zhang, Hu, Yang, Ashual, Gafni, et~al.]{makeavideo}
U.~Singer, A.~Polyak, T.~Hayes, X.~Yin, J.~An, S.~Zhang, Q.~Hu, H.~Yang, O.~Ashual, O.~Gafni, et~al.
\newblock Make-a-video: Text-to-video generation without text-video data.
\newblock \emph{arXiv preprint arXiv:2209.14792}, 2022.

\bibitem[Song et~al.(2020)Song, Sohl-Dickstein, Kingma, Kumar, Ermon, and Poole]{song2020score}
Y.~Song, J.~Sohl-Dickstein, D.~P. Kingma, A.~Kumar, S.~Ermon, and B.~Poole.
\newblock Score-based generative modeling through stochastic differential equations.
\newblock \emph{arXiv preprint arXiv:2011.13456}, 2020.

\bibitem[Wang et~al.(2004)Wang, Bovik, Sheikh, and Simoncelli]{ssim}
Z.~Wang, A.~C. Bovik, H.~R. Sheikh, and E.~P. Simoncelli.
\newblock Image quality assessment: from error visibility to structural similarity.
\newblock \emph{IEEE transactions on image processing}, 13\penalty0 (4):\penalty0 600--612, 2004.

\bibitem[Xue et~al.(2023)Xue, Liang, Wu, and Chen]{sdsattack}
H.~Xue, C.~Liang, X.~Wu, and Y.~Chen.
\newblock Toward effective protection against diffusion-based mimicry through score distillation.
\newblock In \emph{The Twelfth International Conference on Learning Representations}, 2023.

\bibitem[Xue et~al.(2024)Xue, Araujo, Hu, and Chen]{diff-pgd}
H.~Xue, A.~Araujo, B.~Hu, and Y.~Chen.
\newblock Diffusion-based adversarial sample generation for improved stealthiness and controllability.
\newblock \emph{Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem[Zhang et~al.(2023{\natexlab{a}})Zhang, Zhang, Zhang, and Kweon]{zhang2023text}
C.~Zhang, C.~Zhang, M.~Zhang, and I.~S. Kweon.
\newblock Text-to-image diffusion model in generative ai: A survey.
\newblock \emph{arXiv preprint arXiv:2303.07909}, 2023{\natexlab{a}}.

\bibitem[Zhang et~al.(2023{\natexlab{b}})Zhang, Wang, Xu, Wang, and Shi]{zhang2023forget}
E.~Zhang, K.~Wang, X.~Xu, Z.~Wang, and H.~Shi.
\newblock Forget-me-not: Learning to forget in text-to-image diffusion models.
\newblock \emph{arXiv preprint arXiv:2303.17591}, 2023{\natexlab{b}}.

\bibitem[Zhang et~al.(2023{\natexlab{c}})Zhang, Xu, Cui, Meng, Wu, and Lyu]{zhang2023robustness}
J.~Zhang, Z.~Xu, S.~Cui, C.~Meng, W.~Wu, and M.~R. Lyu.
\newblock On the robustness of latent diffusion models.
\newblock \emph{arXiv preprint arXiv:2306.08257}, 2023{\natexlab{c}}.

\bibitem[Zhang et~al.(2018)Zhang, Isola, Efros, Shechtman, and Wang]{lpips}
R.~Zhang, P.~Isola, A.~A. Efros, E.~Shechtman, and O.~Wang.
\newblock The unreasonable effectiveness of deep features as a perceptual metric.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and pattern recognition}, pages 586--595, 2018.

\bibitem[Zhao et~al.(2023{\natexlab{a}})Zhao, Pang, Du, Yang, Cheung, and Lin]{zhao2023recipe}
Y.~Zhao, T.~Pang, C.~Du, X.~Yang, N.-M. Cheung, and M.~Lin.
\newblock A recipe for watermarking diffusion models.
\newblock \emph{arXiv preprint arXiv:2303.10137}, 2023{\natexlab{a}}.

\bibitem[Zhao et~al.(2023{\natexlab{b}})Zhao, Duan, Xu, Wang, Guo, and Hu]{zhao2023can}
Z.~Zhao, J.~Duan, K.~Xu, C.~Wang, R.~Z. Z. D.~Q. Guo, and X.~Hu.
\newblock Can protective perturbation safeguard personal data from being exploited by stable diffusion?
\newblock \emph{arXiv preprint arXiv:2312.00084}, 2023{\natexlab{b}}.

\bibitem[Zheng et~al.(2023)Zheng, Liang, Wu, and Liu]{mist-v2}
B.~Zheng, C.~Liang, X.~Wu, and Y.~Liu.
\newblock Understanding and improving adversarial attacks on latent diffusion model.
\newblock \emph{arXiv preprint arXiv:2310.04687}, 2023.

\end{thebibliography}
