\ifx\mcitethebibliography\mciteundefinedmacro
\PackageError{utphys.bst}{mciteplus.sty has not been loaded}
{This bibstyle requires the use of the mciteplus package.}\fi
\providecommand{\href}[2]{#2}\begingroup\raggedright\begin{mcitethebibliography}{10}

\bibitem{dirac1930principles}
P.~A.~M. Dirac, {\em The Principles of Quantum Mechanics}.
\newblock No.~27 in The International Series of Monographs on Physics. Oxford
  University Press, 1930.

\bibitem{von2018mathematical}
J.~von Neumann, {\em Mathematical Foundations of Quantum Mechanics}.
\newblock Princeton University Press, 1955.

\bibitem{carnot1890reflections}
S.~Carnot, {\em Reflections on the Motive Power of Heat and on Machines Fitted
  to Develop that Power}.
\newblock J. Wiley, 1890.
\newblock Trans. by R. H. Thurston from \emph{Réflexions sur la puissance
  motrice du feu et sur les machines propres à développer cette puissance}
  (1824).

\bibitem{landau}
M.~Bessarab, {\em Landau}.
\newblock M., Moscow worker, 1971. Trans. by B. Hanin from the original Russian
  source.
\newblock \url{http://www.ega-math.narod.ru/Landau/Dau1971.htm}.

\bibitem{Polchinski:2017vik}
J.~Polchinski, ``{Memories of a Theoretical Physicist},''
  \href{http://arxiv.org/abs/1708.09093}{{\ttfamily arXiv:1708.09093
  [physics.hist-ph]}}.

\bibitem{rosenblatt1961principles}
F.~Rosenblatt, ``Principles of Neurodynamics: Perceptrons and the Theory of
  Brain Mechanism,'' tech. rep., Cornell Aeronautical Lab, Inc., 1961.

\bibitem{mcculloch1943logical}
W.~S. McCulloch and W.~Pitts, ``A logical calculus of the ideas immanent in
  nervous activity,'' {\em The bulletin of mathematical biophysics} {\bfseries
  5} no.~4, (1943) 115--133.

\bibitem{rosenblatt1958perceptron}
F.~Rosenblatt, ``The perceptron: a probabilistic model for information storage
  and organization in the brain.,'' {\em Psychological review} {\bfseries 65}
  no.~6, (1958) 386.

\bibitem{ImageNet2012}
A.~Krizhevsky, I.~Sutskever, and G.~E. Hinton, ``ImageNet Classification with
  Deep Convolutional Neural Networks,'' in {\em Advances in Neural Information
  Processing Systems}, vol.~25, pp.~1097--1105.
\newblock 2012.

\bibitem{fukushima1980neocognitron}
K.~Fukushima, ``Neocognitron: a self organizing neural network model for a
  mechanism of pattern recognition unaffected by shift in position,'' {\em
  Biological Cybernetics} {\bfseries 36} no.~4, (1980) 193--202.

\bibitem{lecun89conv}
Y.~LeCun, ``Generalization and Network Design Strategies,'' No.~CRG-TR-89-4.
\newblock 1989.

\bibitem{LeCunZipCode1989}
Y.~LeCun, B.~Boser, J.~S. Denker, D.~Henderson, R.~E. Howard, W.~Hubbard, and
  L.~D. Jackel, ``Backpropagation Applied to Handwritten Zip Code
  Recognition,'' \href{http://dx.doi.org/10.1162/neco.1989.1.4.541}{{\em Neural
  Computation} {\bfseries 1} no.~4, (1989) 541--551}.

\bibitem{lecun1998gradient}
Y.~LeCun, L.~Bottou, Y.~Bengio, and P.~Haffner, ``Gradient-based learning
  applied to document recognition,'' {\em Proceedings of the IEEE} {\bfseries
  86} no.~11, (1998) 2278--2324.

\bibitem{attention2017}
A.~Vaswani, N.~Shazeer, N.~Parmar, J.~Uszkoreit, L.~Jones, A.~N. Gomez, L.~u.
  Kaiser, and I.~Polosukhin, ``Attention is All you Need,'' in {\em Advances in
  Neural Information Processing Systems}, vol.~30, pp.~5998--6008.
\newblock 2017.
\newblock \href{http://arxiv.org/abs/1706.03762}{{\ttfamily arXiv:1706.03762
  [cs.CL]}}.

\bibitem{rumelhart1985learning}
D.~E. Rumelhart, G.~E. Hinton, and R.~J. Williams, ``Learning Internal
  Representations by Error Propagation,'' in {\em Parallel Distributed
  Processing: Explorations in the Microstructure of Cognition. Volume 1:
  Foundations}, D.~E. Rumelhart, J.~L. McClelland, and the PDP Research~Group,
  eds., ch.~8, pp.~318--362.
\newblock MIT Press, Cambridge, MA, 1986.

\bibitem{lecun2012efficient}
Y.~A. LeCun, L.~Bottou, G.~B. Orr, and K.-R. M{\"u}ller, ``Efficient
  backprop,'' in {\em Neural Networks: tricks of the trade}, pp.~9--48.
\newblock Springer, 1998.

\bibitem{periodic-activations}
{Gallant} and {White}, \href{http://dx.doi.org/10.1109/ICNN.1988.23903}{``There
  exists a neural network that does not make avoidable mistakes,''} in {\em
  IEEE 1988 International Conference on Neural Networks}, pp.~657--664 vol.1.
\newblock 1988.

\bibitem{nair2010rectified}
V.~Nair and G.~E. Hinton, ``Rectified Linear Units Improve Restricted Boltzmann
  Machines,'' in {\em International Conference on Machine Learning}.
\newblock 2010.

\bibitem{glorot2011deep}
X.~Glorot, A.~Bordes, and Y.~Bengio, ``Deep Sparse Rectifier Neural Networks,''
  in {\em Proceedings of the Fourteenth International Conference on Artificial
  Intelligence and Statistics}, pp.~315--323, JMLR Workshop and Conference
  Proceedings.
\newblock 2011.

\bibitem{maas2013rectifier}
A.~L. Maas, A.~Y. Hannun, and A.~Y. Ng, ``Rectifier nonlinearities improve
  neural network acoustic models,'' in {\em ICML Workshop on Deep Learning for
  Audio, Speech, and Language Processing}.
\newblock 2013.

\bibitem{dugas2000incorporating}
C.~Dugas, Y.~Bengio, F.~B{\'e}lisle, C.~Nadeau, and R.~Garcia, ``Incorporating
  Second-Order Functional Knowledge for Better Option Pricing,'' in {\em
  Advances in Neural Information Processing Systems}, vol.~13, pp.~472--478.
\newblock 2000.

\bibitem{ramachandran2017searching}
P.~Ramachandran, B.~Zoph, and Q.~V. Le, ``Searching for Activation Functions,''
  \href{http://arxiv.org/abs/1710.05941}{{\ttfamily arXiv:1710.05941 [cs.NE]}}.

\bibitem{hendrycks2016gaussian}
D.~Hendrycks and K.~Gimpel, ``Gaussian Error Linear Units (GELUs),''
  \href{http://arxiv.org/abs/1606.08415}{{\ttfamily arXiv:1606.08415 [cs.LG]}}.

\bibitem{turing1952chemical}
A.~M. Turing, ``The chemical basis of morphogenesis,'' {\em Philosophical
  Transactions of the Royal Society of London. Series B, Biological Sciences}
  {\bfseries 237} no.~641, (1952) 37--72.

\bibitem{saxe2013exact}
A.~M. Saxe, J.~L. McClelland, and S.~Ganguli, ``Exact solutions to the
  nonlinear dynamics of learning in deep linear neural networks,''
  \href{http://arxiv.org/abs/1312.6120}{{\ttfamily arXiv:1312.6120 [cs.NE]}}.

\bibitem{ZavatonePehlevanFinite}
J.~A. Zavatone{-}Veth and C.~Pehlevan, ``Exact priors of finite neural
  networks,'' \href{http://arxiv.org/abs/2104.11734}{{\ttfamily
  arXiv:2104.11734 [cs.LG]}}.

\bibitem{mcgreevy2010holographic}
J.~McGreevy, ``Holographic duality with a view toward many-body physics,'' {\em
  Adv. High Energy Phys.} {\bfseries 2010} (2010) 723105,
  \href{http://arxiv.org/abs/0909.0518}{{\ttfamily arXiv:0909.0518 [hep-th]}}.

\bibitem{neal1996priors}
R.~M. Neal, ``Priors for infinite networks,'' in {\em Bayesian Learning for
  Neural Networks}, pp.~29--53.
\newblock Springer, 1996.

\bibitem{lee2018deep}
J.~Lee, Y.~Bahri, R.~Novak, S.~S. Schoenholz, J.~Pennington, and
  J.~Sohl-Dickstein, ``Deep Neural Networks as Gaussian Processes,'' in {\em
  International Conference on Learning Representations}.
\newblock 2018.
\newblock \href{http://arxiv.org/abs/1711.00165}{{\ttfamily arXiv:1711.00165
  [stat.ML]}}.

\bibitem{matthews2018gaussian}
A.~G. de~G.~Matthews, M.~Rowland, J.~Hron, R.~E. Turner, and Z.~Ghahramani,
  ``Gaussian Process Behaviour in Wide Deep Neural Networks,'' in {\em
  International Conference on Learning Representations}.
\newblock 2018.
\newblock \href{http://arxiv.org/abs/1804.11271}{{\ttfamily arXiv:1804.11271
  [stat.ML]}}.

\bibitem{Yaida2019}
S.~Yaida, ``Non-{G}aussian Processes and Neural Networks at Finite Widths,'' in
  {\em Mathematical and Scientific Machine Learning Conference}.
\newblock 2020.
\newblock \href{http://arxiv.org/abs/1910.00019}{{\ttfamily arXiv:1910.00019
  [stat.ML]}}.

\bibitem{DysonEq}
F.~J. Dyson, ``The $S$ Matrix in Quantum Electrodynamics,''
  \href{http://dx.doi.org/10.1103/PhysRev.75.1736}{{\em Phys. Rev.} {\bfseries
  75} (Jun, 1949) 1736--1755}.

\bibitem{Schwinger452}
J.~Schwinger, ``On the Green{\textquoteright}s functions of quantized fields.
  I,'' \href{http://dx.doi.org/10.1073/pnas.37.7.452}{{\em Proceedings of the
  National Academy of Sciences} {\bfseries 37} no.~7, (1951) 452--455}.

\bibitem{Rob}
M.~D. Zeiler and R.~Fergus, ``Visualizing and Understanding Convolutional
  Networks,'' in {\em Computer Vision -- ECCV 2014}, pp.~818--833.
\newblock 2014.

\bibitem{NIPS2007_3182}
A.~Rahimi and B.~Recht, ``Random Features for Large-Scale Kernel Machines,'' in
  {\em Advances in Neural Information Processing Systems}, vol.~20,
  pp.~1177--1184.
\newblock 2008.

\bibitem{BERT2018}
J.~Devlin, M.~Chang, K.~Lee, and K.~Toutanova, ``{BERT:} Pre-training of Deep
  Bidirectional Transformers for Language Understanding,''
  \href{http://arxiv.org/abs/1810.04805}{{\ttfamily arXiv:1810.04805 [cs.CL]}}.

\bibitem{gellmanlow}
M.~Gell-Mann and F.~E. Low, ``Quantum Electrodynamics at Small Distances,''
  \href{http://dx.doi.org/10.1103/PhysRev.95.1300}{{\em Phys. Rev.} {\bfseries
  95} (Sep, 1954) 1300--1312}.

\bibitem{PhysRevB.4.3174}
K.~G. Wilson, ``Renormalization Group and Critical Phenomena. I.
  Renormalization Group and the Kadanoff Scaling Picture,''
  \href{http://dx.doi.org/10.1103/PhysRevB.4.3174}{{\em Phys. Rev. B}
  {\bfseries 4} (Nov, 1971) 3174--3183}.

\bibitem{PhysRevB.4.3184}
K.~G. Wilson, ``Renormalization Group and Critical Phenomena. II. Phase-Space
  Cell Analysis of Critical Behavior,''
  \href{http://dx.doi.org/10.1103/PhysRevB.4.3184}{{\em Phys. Rev. B}
  {\bfseries 4} (Nov, 1971) 3184--3205}.

\bibitem{Petermann:1953wpa}
E.~C.~G. Stueckelberg~de Breidenbach and A.~Petermann, ``{Normalization of
  constants in the quanta theory},''
  \href{http://dx.doi.org/10.5169/seals-112426}{{\em Helv. Phys. Acta}
  {\bfseries 26} (1953) 499--520}.

\bibitem{goldenfeld2018lectures}
N.~Goldenfeld, {\em Lectures on phase transitions and the renormalization
  group}.
\newblock CRC Press, 2018.

\bibitem{cardy_1996}
J.~Cardy, \href{http://dx.doi.org/10.1017/CBO9781316036440}{{\em Scaling and
  Renormalization in Statistical Physics}}.
\newblock Cambridge Lecture Notes in Physics. Cambridge University Press, 1996.

\bibitem{miskypapertperceptron}
M.~Minsky and S.~A. Papert, {\em {Perceptrons: An Introduction to Computational
  Geometry}}.
\newblock MIT Press, 1988.

\bibitem{Coleman:1985rnk}
S.~Coleman, \href{http://dx.doi.org/10.1017/CBO9780511565045}{{\em {Aspects of
  Symmetry}: {Selected Erice Lectures}}}.
\newblock Cambridge University Press, Cambridge, U.K., 1985.

\bibitem{poole2016exponential}
B.~Poole, S.~Lahiri, M.~Raghu, J.~Sohl-Dickstein, and S.~Ganguli, ``Exponential
  Expressivity in Deep Neural Networks Through Transient Chaos,'' in {\em
  Advances in Neural Information Processing Systems}, vol.~29, pp.~3360--3368.
\newblock 2016.
\newblock \href{http://arxiv.org/abs/1606.05340}{{\ttfamily arXiv:1606.05340
  [stat.ML]}}.

\bibitem{raghu2017expressive}
M.~Raghu, B.~Poole, J.~Kleinberg, S.~Ganguli, and J.~Sohl-Dickstein, ``On the
  Expressive Power of Deep Neural Networks,'' in {\em International Conference
  on Machine Learning}, pp.~2847--2854.
\newblock 2017.
\newblock \href{http://arxiv.org/abs/1606.05336}{{\ttfamily arXiv:1606.05336
  [stat.ML]}}.

\bibitem{schoenholz2016deep}
S.~S. Schoenholz, J.~Gilmer, S.~Ganguli, and J.~Sohl{-}Dickstein, ``Deep
  Information Propagation,'' in {\em 5th International Conference on Learning
  Representations}.
\newblock 2017.
\newblock \href{http://arxiv.org/abs/1611.01232}{{\ttfamily arXiv:1611.01232
  [stat.ML]}}.

\bibitem{he2015delving}
K.~He, X.~Zhang, S.~Ren, and J.~Sun, ``Delving Deep into Rectifiers: Surpassing
  Human-Level Performance on ImageNet Classification,'' in {\em Proceedings of
  the IEEE international conference on computer vision}, pp.~1026--1034.
\newblock 2015.
\newblock \href{http://arxiv.org/abs/1502.01852}{{\ttfamily arXiv:1502.01852
  [cs.CV]}}.

\bibitem{Kadanoff:1971pc}
L.~Kadanoff, ``{Critical Behavior. Universality and Scaling},'' in {\em
  Proceedings of the International School of Physics Enrico Fermi, Course LI
  (27 July – 8 August 1970)}.
\newblock 1971.

\bibitem{jaynes2003probability}
E.~T. Jaynes, {\em Probability Theory: The Logic of Science}.
\newblock Cambridge University Press, 2003.

\bibitem{occam}
L.~Froidmont, {\em On Christian Philosophy of the Soul}.
\newblock 1649.

\bibitem{mackay1995probable}
D.~J. MacKay, ``Probable networks and plausible predictions—a review of
  practical Bayesian methods for supervised neural networks,'' {\em Network:
  computation in neural systems} {\bfseries 6} no.~3, (1995) 469--505.

\bibitem{williams-infinite}
C.~K.~I. Williams, ``Computing with Infinite Networks,'' in {\em Advances in
  Neural Information Processing Systems}, vol.~9, p.~295–301.
\newblock 1996.

\bibitem{hinton2015distilling}
G.~Hinton, O.~Vinyals, and J.~Dean, ``Distilling the Knowledge in a Neural
  Network,'' in {\em NIPS Deep Learning and Representation Learning Workshop}.
\newblock 2015.
\newblock \href{http://arxiv.org/abs/1503.02531}{{\ttfamily arXiv:1503.02531
  [stat.ML]}}.

\bibitem{hebb2005organization}
D.~Hebb, {\em The Organization of Behavior: A Neuropsychological Theory}.
\newblock Taylor \& Francis, 2005.

\bibitem{Coleman:2020put}
S.~Coleman, ``{Sidney Coleman's Dirac Lecture `Quantum Mechanics in Your
  Face'},'' \href{http://arxiv.org/abs/2011.12671}{{\ttfamily arXiv:2011.12671
  [physics.hist-ph]}}.

\bibitem{jacot2018neural}
A.~Jacot, F.~Gabriel, and C.~Hongler, ``Neural tangent kernel: Convergence and
  generalization in neural networks,'' in {\em Advances in Neural Information
  Processing Systems}, vol.~31, pp.~8571--8580.
\newblock 2018.
\newblock \href{http://arxiv.org/abs/1806.07572}{{\ttfamily arXiv:1806.07572
  [cs.LG]}}.

\bibitem{hochreiter1991untersuchungen}
S.~Hochreiter, {\em Untersuchungen zu dynamischen neuronalen Netzen}.
\newblock Diploma, Technische Universit{\"a}t M{\"u}nchen, 1991.

\bibitem{bengio-evgp-recurrent}
Y.~Bengio, P.~Frasconi, and P.~Simard,
  \href{http://dx.doi.org/10.1109/ICNN.1993.298725}{``The problem of learning
  long-term dependencies in recurrent networks,''} in {\em IEEE International
  Conference on Neural Networks}, vol.~3, pp.~1183--1188, IEEE.
\newblock 1993.

\bibitem{pascanu2013difficulty}
R.~Pascanu, T.~Mikolov, and Y.~Bengio, ``On the difficulty of training
  Recurrent Neural Networks,'' in {\em International Conference on Machine
  Learning}, pp.~1310--1318, PMLR.
\newblock 2013.
\newblock \href{http://arxiv.org/abs/1211.5063}{{\ttfamily arXiv:1211.5063
  [cs.LG]}}.

\bibitem{gaussquote}
M.~Kline, {\em Mathematical Thought From Ancient to Modern Times: Volume 3}.
\newblock Oxford University Press, 1990.

\bibitem{brainNTK2019}
J.~Lee, L.~Xiao, S.~Schoenholz, Y.~Bahri, R.~Novak, J.~Sohl-Dickstein, and
  J.~Pennington, ``Wide Neural Networks of Any Depth Evolve as Linear Models
  Under Gradient Descent,'' in {\em Advances in Neural Information Processing
  Systems}, vol.~32, pp.~8572--8583.
\newblock 2019.
\newblock \href{http://arxiv.org/abs/1902.06720}{{\ttfamily arXiv:1902.06720
  [stat.ML]}}.

\bibitem{fix1952discriminatory}
E.~Fix and J.~Hodges, ``Discriminatory Analysis. Nonparametric Discrimination:
  Consistency Properties,'' {\em USAF School of Aviation Medicine, Project
  Number: 21-49-004, Report Number: 4} (1951) .

\bibitem{Cover1967NearestNP}
T.~Cover and P.~Hart, ``Nearest neighbor pattern classification,'' {\em IEEE
  Trans. Inf. Theory} {\bfseries 13} (1967) 21--27.

\bibitem{einstein-simple}
A.~Einstein, ``On the Method of Theoretical Physics,'' {\em Philosophy of
  Science} {\bfseries 1} no.~2, (1934) 163--169.

\bibitem{boris-nica}
B.~Hanin and M.~Nica, ``Finite Depth and Width Corrections to the Neural
  Tangent Kernel,'' in {\em International Conference on Learning
  Representations}.
\newblock 2020.
\newblock \href{http://arxiv.org/abs/1909.05989}{{\ttfamily arXiv:1909.05989
  [cs.LG]}}.

\bibitem{dyer2019asymptotics}
E.~Dyer and G.~Gur-Ari, ``Asymptotics of Wide Networks from Feynman Diagrams,''
  in {\em International Conference on Learning Representations}.
\newblock 2020.
\newblock \href{http://arxiv.org/abs/1909.11304}{{\ttfamily arXiv:1909.11304
  [cs.LG]}}.

\bibitem{Giudice:2008bi}
G.~F. Giudice, ``{Naturally Speaking: The Naturalness Criterion and Physics at
  the LHC},'' \href{http://arxiv.org/abs/0801.2562}{{\ttfamily arXiv:0801.2562
  [hep-ph]}}.

\bibitem{feynman2006classic}
F.~J. Dyson, ``Forward,'' in {\em Classic Feynman: All the Adventures of a
  Curious Character}, R.~Leighton, ed., pp.~5--9.
\newblock W. W. Norton \& Company Ltd., 2006.

\bibitem{chizat2018note}
L.~Chizat, E.~Oyallon, and F.~Bach, ``On Lazy Training in Differentiable
  Programming,'' in {\em Advances in Neural Information Processing Systems},
  vol.~32.
\newblock 2019.
\newblock \href{http://arxiv.org/abs/1812.07956}{{\ttfamily arXiv:1812.07956
  [math.OC]}}.

\bibitem{mackay2003information}
D.~J. MacKay, {\em Information Theory, Inference and Learning Algorithms}.
\newblock Cambridge University Press, 2003.

\bibitem{kaplan2020scaling}
J.~Kaplan, S.~McCandlish, T.~Henighan, T.~B. Brown, B.~Chess, R.~Child,
  S.~Gray, A.~Radford, J.~Wu, and D.~Amodei, ``Scaling laws for neural language
  models,'' \href{http://arxiv.org/abs/2001.08361}{{\ttfamily arXiv:2001.08361
  [cs.LG]}}.

\bibitem{zhang2016understanding}
C.~Zhang, S.~Bengio, M.~Hardt, B.~Recht, and O.~Vinyals, ``{Understanding deep
  learning requires rethinking generalization},''
  \href{http://arxiv.org/abs/1611.03530}{{\ttfamily arXiv:1611.03530 [cs.LG]}}.

\bibitem{wolpert1996lack}
D.~H. Wolpert, ``The lack of a priori distinctions between learning
  algorithms,'' {\em Neural computation} {\bfseries 8} no.~7, (1996)
  1341--1390.

\bibitem{wolpert1997no}
D.~H. Wolpert and W.~G. Macready, ``No free lunch theorems for optimization,''
  {\em IEEE transactions on evolutionary computation} {\bfseries 1} no.~1,
  (1997) 67--82.

\bibitem{boltzman-quote}
L.~Boltzmann, ``On Certain Questions of the Theory of Gases,''
  \href{http://dx.doi.org/10.1038/051413b0}{{\em Nature} {\bfseries 51}
  no.~1322, (1895) 413--415}.

\bibitem{boltzmann}
L.~Boltzmann, {\em Lectures on Gas Theory}.
\newblock Berkeley, University of California Press, 1964.
\newblock Trans. by S. G. Brush from \emph{Vorlesungen ueber Gastheorie} (2
  vols., 1896 \& 1898).

\bibitem{Shannon-1}
C.~E. Shannon, ``A mathematical theory of communication,''
  \href{http://dx.doi.org/10.1002/j.1538-7305.1948.tb01338.x}{{\em The Bell
  System Technical Journal} {\bfseries 27} no.~3, (1948) 379--423}.

\bibitem{Shannon-2}
C.~E. Shannon, ``A mathematical theory of communication,''
  \href{http://dx.doi.org/10.1002/j.1538-7305.1948.tb00917.x}{{\em The Bell
  System Technical Journal} {\bfseries 27} no.~4, (1948) 623--656}.

\bibitem{PhysRev.106.620}
E.~T. Jaynes, ``Information Theory and Statistical Mechanics,''
  \href{http://dx.doi.org/10.1103/PhysRev.106.620}{{\em Phys. Rev.} {\bfseries
  106} (May, 1957) 620--630}.

\bibitem{PhysRev.108.171}
E.~T. Jaynes, ``Information Theory and Statistical Mechanics. II,''
  \href{http://dx.doi.org/10.1103/PhysRev.108.171}{{\em Phys. Rev.} {\bfseries
  108} (Oct, 1957) 171--190}.

\bibitem{brain-damage}
Y.~LeCun, J.~Denker, and S.~Solla, ``Optimal Brain Damage,'' in {\em Advances
  in Neural Information Processing Systems}, vol.~2.
\newblock Morgan-Kaufmann, 1990.

\bibitem{frankle2018the}
J.~Frankle and M.~Carbin, ``The Lottery Ticket Hypothesis: Finding Sparse,
  Trainable Neural Networks,'' in {\em International Conference on Learning
  Representations}.
\newblock 2019.
\newblock \href{http://arxiv.org/abs/1803.03635}{{\ttfamily arXiv:1803.03635
  [cs.LG]}}.

\bibitem{banks1982phase}
T.~Banks and A.~Zaks, ``On the phase structure of vector-like gauge theories
  with massless fermions,'' {\em Nuclear Physics B} {\bfseries 196} no.~2,
  (1982) 189--204.

\bibitem{linsker1988self}
R.~Linsker, ``Self-organization in a perceptual network,'' {\em Computer}
  {\bfseries 21} no.~3, (1988) 105--117.

\bibitem{becker1992self}
S.~Becker and G.~E. Hinton, ``Self-organizing neural network that discovers
  surfaces in random-dot stereograms,'' {\em Nature} {\bfseries 355} no.~6356,
  (1992) 161--163.

\bibitem{BttFP2}
B.~Gale, R.~Zemeckis, M.~J. Fox, and C.~Lloyd, {\em Back to the Future Part
  II}.
\newblock Universal Pictures, 1989.

\bibitem{he2016deep}
K.~He, X.~Zhang, S.~Ren, and J.~Sun, ``Deep residual learning for image
  recognition,'' in {\em Proceedings of the IEEE conference on computer vision
  and pattern recognition}, pp.~770--778.
\newblock 2016.

\bibitem{batch-norm}
S.~Ioffe and C.~Szegedy, ``Batch Normalization: Accelerating Deep Network
  Training by Reducing Internal Covariate Shift,'' in {\em International
  Conference on Machine Learning}, pp.~448--456.
\newblock 2015.
\newblock \href{http://arxiv.org/abs/1502.03167}{{\ttfamily arXiv:1502.03167
  [cs.LG]}}.

\bibitem{resnet-as-ensemble}
A.~Veit, M.~Wilber, and S.~Belongie, ``Residual Networks Behave Like Ensembles
  of Relatively Shallow Networks,'' in {\em Advances in Neural Information
  Processing Systems}, vol.~30, pp.~550--558.
\newblock 2016.
\newblock \href{http://arxiv.org/abs/1605.06431}{{\ttfamily arXiv:1605.06431
  [cs.CV]}}.

\bibitem{ba2016layer}
J.~L. Ba, J.~R. Kiros, and G.~E. Hinton, ``Layer Normalization,'' in {\em Deep
  Learning Symposium, Neural Information Processing Systems}.
\newblock 2016.
\newblock \href{http://arxiv.org/abs/1607.06450}{{\ttfamily arXiv:1607.06450
  [stat.ML]}}.

\end{mcitethebibliography}\endgroup
