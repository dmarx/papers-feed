\documentclass[10pt,twocolumn,letterpaper]{article}
\pdfoutput=1 

%%%%%%%%% PAPER TYPE  - PLEASE UPDATE FOR FINAL VERSION
\usepackage[pagenumbers]{cvpr} % To force page numbers, e.g. for an arXiv version

% Include other packages here, before hyperref.
% \usepackage[draft]{graphicx}
\usepackage[]{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{tabularray}    
\usepackage[x11names]{xcolor}
\usepackage[export]{adjustbox}
\usepackage{tikz}
\usepackage{soul}


% It is strongly recommended to use hyperref, especially for the review version.
% hyperref with option pagebackref eases the reviewers' job.
% Please disable hyperref *only* if you encounter grave issues, e.g. with the
% file validation for the camera-ready version.
%
% If you comment hyperref and then uncomment it, you should delete
% ReviewTempalte.aux before re-running LaTeX.
% (Or just hit 'q' on the first LaTeX run, let it finish, and you
%  should be clear).

\usepackage[pagebackref,breaklinks,colorlinks]{hyperref}
\urlstyle{same}

\input{definitions}

% Support for easy cross-referencing
\usepackage[capitalize]{cleveref}
\crefname{section}{Sec.}{Secs.}
\Crefname{section}{Section}{Sections}
\Crefname{table}{Table}{Tables}
\crefname{table}{Tab.}{Tabs.}

\title{Project Aria: A New Tool for Egocentric Multi-Modal AI Research}
\author{{Jakob Engel, Kiran Somasundaram, Michael Goesele, Albert Sun, Alexander Gamino, Andrew Turner, Arjang Talattof, Arnie Yuan, Bilal Souti, Brighid Meredith, Cheng Peng, Chris Sweeney, Cole Wilson, Dan Barnes, Daniel DeTone, David Caruso, Derek Valleroy , Dinesh Ginjupalli, Duncan Frost, Edward~Miller, Elias Mueggler, Evgeniy Oleinik, Fan Zhang, Guruprasad Somasundaram, Gustavo Solaira, Harry~Lanaras, Henry Howard-Jenkins, Huixuan Tang, Hyo Jin Kim, Jaime Rivera, Ji Luo, Jing Dong, Julian Straub, Kevin Bailey, Kevin Eckenhoff, Lingni Ma, Luis Pesqueira, Mark Schwesinger, Maurizio Monge, Nan Yang, Nick Charron, Nikhil Raina, Omkar Parkhi, Peter Borschowa, Pierre Moulon, Prince Gupta, Raul Mur-Artal, Robbie Pennington, Sachin Kulkarni, Sagar Miglani, Santosh Gondi, Saransh Solanki, Sean Diener, Shangyi Cheng, Simon Green, Steve Saarinen, Suvam Patra, Tassos Mourikis, Thomas Whelan, Tripti Singh, Vasileios Balntas, Vijay Baiyya, Wilson Dreewes, Xiaqing Pan, Yang Lou, Yipu Zhao, Yusuf Mansour, Yuyang Zou, Zhaoyang Lv, Zijian Wang, Mingfei Yan, Carl Ren, Renzo De Nardi, Richard Newcombe}\\[2mm]
Meta Reality Labs Research}
\date{June 2023}

\begin{document}

\maketitle

%%%%%%%%% ABSTRACT
\begin{abstract}
   Egocentric, multi-modal data as available on future augmented reality (AR) devices provides unique challenges and opportunities for machine perception. These future devices will need to be all-day wearable in a socially acceptable form-factor to support always available, context-aware and personalized AI applications. Our team at Meta Reality Labs Research built the \AriaDevice: An egocentric, multi-modal data recording and streaming device with the goal to foster and accelerate research in this area. In this paper, we describe the \AriaDevice{} hardware including its sensor configuration, the corresponding software tools, and the available machine perception functionalities that make it the ideal tool for egocentric machine perception and contextual AI research.
\end{abstract}

\input{intro}

\input{device}

\input{tools}

\input{mps}

\input{privacy}

\input{applications_new}

\input{conclusion}

\section*{Acknowledgements}

\ProjectAria{} was made possible by the contributions of the \ProjectAria{} team from Meta Reality Labs Research. We are indebted to the complete team and all partners of \ProjectAria{} who enabled its inception and continue to develop the platform.


%\bibliographystyle{plain} % We choose the "plain" reference style
%\bibliography{papers} % Entries are in the refs.bib file

\begin{thebibliography}{10}

\bibitem{ariadocs}
Project {A}ria {D}ocumentation.
\newblock \url{https://facebookresearch.github.io/projectaria_tools/}.

\bibitem{ariapilot}
Project {A}ria {P}ilot {D}ataset.
\newblock
  \url{https://facebookresearch.github.io/projectaria_tools/docs/open_datasets/pilot_dataset}.

\bibitem{ariatools}
Project {A}ria {T}ools on {G}it{H}ub.
\newblock \url{https://github.com/facebookresearch/projectaria_tools}.

\bibitem{ariawebsite}
Project {A}ria {W}ebsite.
\newblock \url{https://www.projectaria.com/}.

\bibitem{communityguidelines}
Project {A}ria {C}ommunity {G}uidelines.
\newblock
  \url{https://about.meta.com/realitylabs/projectaria/community-guidelines/}.

\bibitem{engel2014lsd}
Jakob Engel, Thomas Sch{\"o}ps, and Daniel Cremers.
\newblock {LSD-SLAM}: Large-scale direct monocular {SLAM}.
\newblock In {\em Computer Vision--ECCV 2014: 13th European Conference, Zurich,
  Switzerland, September 6-12, 2014, Proceedings, Part II 13}, pages 834--849.
  Springer, 2014.

\bibitem{touvron2023llama}
Hugo~Touvron et.al.
\newblock Llama 2: Open foundation and fine-tuned chat models, 2023.

\bibitem{han2022umetrack}
Shangchen Han, Po{-}Chen Wu, Yubo Zhang, Beibei Liu, Linguang Zhang, Zheng
  Wang, Weiguang Si, Peizhao Zhang, Yujun Cai, Tomas Hodan, Randi Cabezas, Luan
  Tran, Muzaffer Akbay, Tsz{-}Ho Yu, Cem Keskin, and Robert Wang.
\newblock Umetrack: Unified multi-view end-to-end hand tracking for {VR}.
\newblock In {\em {SIGGRAPH} Asia 2022 Conference Papers, {SA} 2022, Daegu,
  Republic of Korea, December 6-9, 2022}, 2022.

\bibitem{conf/icra/HarrisonN11}
Alastair Harrison and Paul Newman.
\newblock {TICSync}: Knowing when things happened.
\newblock In {\em 2011 IEEE International Conference on Robotics and
  Automation}, pages 356--363, 2011.

\bibitem{he2017mask}
Kaiming He, Georgia Gkioxari, Piotr Doll{\'a}r, and Ross Girshick.
\newblock Mask {R-CNN}.
\newblock In {\em Proceedings of the IEEE International Conference on Computer
  Vision}, pages 2961--2969, 2017.

\bibitem{kirillov2023segment}
Alexander Kirillov, Eric Mintun, Nikhila Ravi, Hanzi Mao, Chloe Rolland, Laura
  Gustafson, Tete Xiao, Spencer Whitehead, Alexander~C Berg, Wan-Yen Lo, et~al.
\newblock Segment anything.
\newblock {\em arXiv preprint arXiv:2304.02643}, 2023.

\bibitem{metari}
Meta {R}esponsible {I}nnovation {P}rinciples.
\newblock \url{https://about.meta.com/metaverse/responsible-innovation/}.

\bibitem{mourikis2007multi}
Anastasios~I Mourikis and Stergios~I Roumeliotis.
\newblock A multi-state constraint {K}alman filter for vision-aided inertial
  navigation.
\newblock In {\em Proceedings 2007 IEEE International Conference on Robotics
  and Automation}, pages 3565--3572. IEEE, 2007.

\bibitem{mur2017orb}
Raul Mur-Artal and Juan~D Tard{\'o}s.
\newblock {ORB-SLAM2}: An open-source slam system for monocular, stereo, and
  {RBG-D} cameras.
\newblock {\em IEEE Transactions on Robotics}, 33(5):1255--1262, 2017.

\bibitem{openai2023gpt4}
OpenAI.
\newblock {GPT-4} technical report.
\newblock {\em arXiv preprint arXiv:2303.08774}, 2023.

\bibitem{oquab2023dinov2}
Maxime Oquab, Timoth{\'e}e Darcet, Th{\'e}o Moutakanni, Huy Vo, Marc
  Szafraniec, Vasil Khalidov, Pierre Fernandez, Daniel Haziza, Francisco Massa,
  Alaaeldin El-Nouby, et~al.
\newblock {Dinov2}: Learning robust visual features without supervision.
\newblock {\em arXiv preprint arXiv:2304.07193}, 2023.

\bibitem{poole2022dreamfusion}
Ben Poole, Ajay Jain, Jonathan~T. Barron, and Ben Mildenhall.
\newblock {DreamFusion}: {Text-to-3D} using {2D} diffusion.
\newblock {\em arXiv}, 2022.

\bibitem{radford2021learning}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh,
  Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark,
  et~al.
\newblock Learning transferable visual models from natural language
  supervision.
\newblock In {\em International Conference on Machine Learning}, pages
  8748--8763. PMLR, 2021.

\bibitem{ramesh2022hierarchical}
Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen.
\newblock Hierarchical text-conditional image generation with clip latents.
\newblock {\em arXiv preprint arXiv:2204.06125}, 2022.

\bibitem{smptet}
Linear {T}imecode.
\newblock \url{https://en.wikipedia.org/wiki/Linear_timecode}.

\bibitem{nerfstudio}
Matthew Tancik, Ethan Weber, Evonne Ng, Ruilong Li, Brent Yi, Justin Kerr,
  Terrance Wang, Alexander Kristoffersen, Jake Austin, Kamyar Salahi, Abhik
  Ahuja, David McAllister, and Angjoo Kanazawa.
\newblock Nerfstudio: A modular framework for neural radiance field
  development.
\newblock In {\em ACM SIGGRAPH 2023 Conference Proceedings}, SIGGRAPH '23,
  2023.

\bibitem{vrsdocs}
{VRS} {D}ocumentation.
\newblock \url{https://facebookresearch.github.io/vrs/docs/Overview}.

\end{thebibliography}

\end{document}
