- **Objective of Poincaré Embeddings**: Learn hierarchical representations of symbolic data by embedding into hyperbolic space (Poincaré ball) to capture both hierarchy and similarity.

- **Hyperbolic Geometry**: Non-Euclidean geometry with constant negative curvature, suitable for modeling hierarchical data structures (e.g., trees).

- **Poincaré Ball Model**: 
  - Defined as \( B^d = \{ x \in \mathbb{R}^d \mid \|x\| < 1 \} \).
  - Riemannian metric tensor: \( g_x = \frac{2}{1 - \|x\|^2} g_E \).
  - Distance between points \( u, v \in B^d \): 
    \[
    d(u, v) = \text{arcosh}\left(1 + \frac{2 \|u - v\|^2}{(1 - \|u\|^2)(1 - \|v\|^2)}\right).
    \]

- **Key Properties**:
  - Locality: Distance changes smoothly with respect to the location of points.
  - Self-organizing property: Hierarchical organization determined by distance to the origin.

- **Optimization Problem**: 
  - Find embeddings \( \Theta = \{ \theta_i \}_{i=1}^n \) such that:
    \[
    \Theta \leftarrow \arg \min_\Theta L(\Theta) \quad \text{s.t.} \quad \forall \theta_i \in \Theta: \|\theta_i\| < 1.
    \]

- **Riemannian Optimization**:
  - Use stochastic Riemannian optimization methods (e.g., RSGD, RSVRG).
  - Update rule for RSGD:
    \[
    \theta_{t+1} = R_{\theta_t}(-\eta_t \nabla_R L(\theta_t)),
    \]
    where \( R_{\theta_t} \) is the retraction onto \( B^d \).

- **Gradient Computation**:
  - Riemannian gradient \( \nabla_R \) derived from Euclidean gradient \( \nabla_E \) using the inverse of the Poincaré ball metric tensor.
  - Partial derivative of Poincaré distance:
    \[
    \frac{\partial d(\theta, x)}{\partial \theta} = \frac{4 \beta \gamma^2 - 1}{x^2 - 2 \langle \theta, x \rangle + 1} \cdot \left( \frac{1}{\alpha^2} \theta - x \right),
    \]
    where \( \alpha = 1 - \|\theta\|^2 \) and \( \beta = 1 - \|x\|^2 \).

- **Applications**: 
  - Taxonomy embedding, link prediction in networks, and lexical entailment prediction.
  - Poincaré embeddings outperform Euclidean embeddings, especially in low dimensions.

- **Experimental Results**: 
  - High-quality embeddings for large taxonomies, effective in predicting links in collaboration networks, and state-of-the-art performance for lexical entailment tasks.