\section{Experiment Details} \label{app:exp_details}


%

%



\subsection{Informer Forecasting} \label{app:informer_details}

\textbf{Dataset details}. In Table~\ref{tab:informer-s-long}, we evaluate all methods with datasets and horizon tasks from the Informer benchmark~\citep{zhou2021informer}. We use the datasets and horizons evaluated on in recent works~\citep{wu2021autoformer, zhou2022fedformer, zhou2022film, zeng2022transformers}, which evaluate on electricity transformer temperature time series (ETTh1, ETTh2, ETTm1, ETTm2) with forecasting horizons \{96, 192, 336, 720\}. 
We extend this comparison in Appendix~\ref{appendix:informer_extended} to all datasets and forecasting horizons in \cite{zhou2021informer}, which also consider weather and electricity (ECL) time series data. 

\textbf{Training details.}
%
We train \ourmethod{} on all datasets for $50$ epochs using AdamW optimizer~\citep{loshchilov2017decoupled}, cosine scheduling, and early stopping based on best validation standardized MSE. We performed a grid search over number of SSMs \{64, 128\} and weight decay $\{0, 0.0001\}$. Like prior forecasting works, we treat the input lag sequence as a hyperparameter, and train to predict each forecasting horizon with either 336 or 720 time-step-long input sequences for all datasets and horizons. 
%
For all datasets, we use a 3-layer \ourmethod{} network with 128 SSMs per layer. We train with learning rate $0.01$, weight decay $0.0001$, batch size $32$, and dropout $0.25$. 
% A complete list of input sequence length and forecasting horizons used is in Table~\ref{}. 

\textbf{Hardware details.}
All experiments were run on a single NVIDIA Tesla P100 GPU.




%
\subsection{Monash Forecasting} \label{app:monash_details} 

The Monash Time Series Forecasting Repository \citep{godahewa2021monash} provides an extensive benchmark suite for time series forecasting models, with over $30$ datasets (including various configurations) spanning finance, traffic, weather and medical domains. We compare \ourmethod{} against $13$ baselines provided by the Monash benchmark: simple exponential smoothing (SES)~\citep{gardner1985exponential}, Theta~\citep{assimakopoulos2000theta}, TBATS~\citep{de2011forecasting}, ETS~\citep{winters1960forecasting}, DHR--ARIMA~\citep{hyndman2018forecasting}, Pooled Regression (PR)~\citep{trapero2015identification}, CatBoost~\citep{dorogush2018catboost}, FFNN, DeepAR~\citep{salinas2020deepar}, N-BEATS~\cite{oreshkin2019n}, WaveNet~\citep{oord2016wavenet}, vanilla Transformer~\citep{vaswani2017attention}. A complete list of the datasets considered and baselines, including test results (average RMSE across $3$ seeded runs) is available in Table \ref{tab:monash}.

\textbf{Training details.}
%
We optimize \ourmethod{} on all datasets using Adam optimizer for $40$ epochs with a linear learning rate warmup phase of $20$ epochs and cosine decay. We initialize learning rate at $0.001$, reach $0.004$ after warmup, and decay to $0.0001$. We do not use weight decay or dropout.

We perform a grid search over number of layers \{3, 4, 5, 6\}, number of SSMs per layer \{8, 16, 32, 64, 128\} and number of channels (width of the model) \{1, 4, 8, 16\}. Hyperparameter tuning is performed for each dataset. We pick the model based on best validation RMSE performance.

\textbf{Hardware details.}
All experiments were run on a single NVIDIA GeForce RTX 3090 GPU.
%

\subsection{Time Series Classification} \label{app:classification_exps} 

\textbf{ECG classification (motivation and dataset description).} Electrocardiograms (ECG) are commonly used as one of the first examination tools for assessing and diagnosing cardiovascular diseases, which are a major cause of mortality around the world~\citep{amini2021trend}.
However, ECG interpretation remains a challenging task for cardiologists and general practitioners~\citep{jablonover2014ecgcompetency, cook2020accuracy}. 
Incorrect interpretation of ECG can result in misdiagnosis and delayed treatment, which can be potentially life-threatening in critical situations such as emergency rooms, where an accurate interpretation is needed quickly.

% \KG{should have one para of related work of deep learning for ECG here} 

To mitigate these challenges, deep learning approaches are increasingly being applied to interpret ECGs. 
%
These approaches have been used for predicting the ECG rhythm class~\citep{hannun2019cardiologist}, detecting atrial fibrillation~\citep{attia2019artificial}, rare cardiac diseases like cardiac amyloidosis~\citep{goto2021artificial}, and a variety of other abnormalities~\citep{attia2019screening, siontis2021artificial}. 
%
Deep learning approaches have shown preliminary promise in matching the performance of cardiologists and emergency residents in triaging ECGs, which would permit accurate interpretations in settings where specialists may not be present~\citep{ribeiro2020automatic, hannun2019cardiologist}. 

We use the publicly available PTB-XL dataset \citep{Wagner:2020PTBXL, Wagner2020:ptbxlphysionet, Goldberger2020:physionet}, which contains $21{,}837$ $12$-lead ECG recordings of $10$ seconds each obtained from $18{,}885$ patients.
Each ECG recording is annotated by up to two cardiologists with one or more of the $71$ ECG statements (labels). 
%
These ECG statements conform to the SCP-ECG standard \citep{iso2009ecgstatements}. Each statement belongs to one or more of the following three categories -- diagnostic, form, and rhythm statements. The diagnostic statements are further organised in a hierarchy containing 5 superclasses and 24 subclasses.

This provides six sets of annotations for the ECG statements based on the different categories and granularities: all (all ECG statements), diagnostic (only diagnostic statements including both subclass and superclass statements), diagnostic subclass (only diagnostic subclass statements), diagnostic superclass (only diagnostic superclass statements), form (only form statements), and rhythm (only rhythm statements).
These six sets of annotations form different prediction tasks which are referred to as all, diag, sub-diag, super-diag, form, and rhythm respectively.
The diagnostic superclass task is multi-class classification, and the other tasks are multi-label classification.

\textbf{ECG classification training details.} To tune \ourmethod{} and S4, we performed a grid search over the learning rate $\{0.01, 0.001\}$, model dropout $\{0.1, 0.2\}$, number of SSMs per layer $\{128, 256\}$, and number of layers  $\{4,6\}$, and chose the parameters that resulted in highest validation AUROC. The SSM state dimension was fixed to $64$, with gated linear units as the non-linearity between stacked layers. We additionally apply layer normalization. We use a  cosine learning rate scheduler, with a warmup period of 5 epochs. We train all models for $100$ epochs. 


\textbf{Speech Commands training details.} To train \ourmethod{}, we use the same hyperparameters used by S4: a learning rate of $0.01$ with a plateau scheduler with patience $20$, dropout of $0.1$, $128$ SSMs per layer, $6$ layers, batch normalization, trained for $200$ epochs.

\textbf{Hardware details.}
For both ECG and Speech Commands, all experiments were run on a single NVIDIA Tesla A100 Ampere 40 GB GPU.


