\clearpage
\appendix
\begin{center}{\bf {\LARGE Appendix} }\end{center}
\vspace{-0.15in}
\begin{center}
{\bf \large Automatic Jailbreaking of the
Text-to-Image Generative AI Systems}\end{center}
\vspace{-0.2in}
\section{Experimental detail}\label{app:exp_detail}
\subsection{Dataset details} \label{app:dataset}
We constructed a copyright violation dataset for T2I models, termed VioT. Our dataset consists of five types of IP content categories: products, logos, characters, art, and architecture. There are 20 images in each category, as shown in Table~\ref{table:table0}. For each image, we paired keywords for keyword penalties in $S_k$. For products, the product name and the company name are mapped as keywords. For logos, the company name is mapped as the logo's keyword. For characters, the character name, along with the associated movie or TV program, is paired as keywords. For art, the artwork name and the artist are paired as keywords. For architecture, the architecture name and the owner of the architecture are designated as keywords. For single example, we need target image and the keywords for the image. As there can be several images for target contents, several target images with the same single keyword pair also can be used. The keyword that we used for the evaluation in the main paper is in Table~\ref{table:table_keyword}, and Table~\ref{table:table_keyword2}.
\input{Table/table_dataset} 

\vspace{3in}
\paragraph{ChatGPT policy}\label{app:chatgpt_policy_leakage}
This dataset is also aligned with the ChatGPT internal image generation policy. We asked image generation policy of ChatGPT to GPT-4 and we were able to retrieve the information as shown in the following.
\input{Figure/chatgpt_policy}

\subsection{Inference detail}
\paragraph{Pipeline}~\label{app:pipeline}
In the seed description step, we utilize GPT4-vision as a VLM $g$ and GPT3.5-turbo as an LLM $f_1$. We set $N$ as 3 in the initial step to calculate the score of each instruction. We used "What is the image precisely?", "Describe the image specifically." and "Generate caption of the image." prompts as initial instructions. For the CLIP score ($c_i$), we deploy ViT-B/32 pretrained CLIP models. We conduct the optimization with hyper-parameter $r$ as 3. 

In the revision optimization step, we utilize Dalle-3 as a T2I model $h$, and GPT3.5-turbo as an LLM $f_2$. We generate three ($M$) QA pairs with GPT4-vision and employ GPT3.5-turbo for $l$ and $v$ LLM models. We conduct the optimization with steps $T=5$. For experiment, we employ a single 2080Ti GPU and GPT3.5-Turbo, GPT4-vision API. To induce the copyright infringement in ChatGPT, we utilize GPT-4 version and the results are obtained from 2nd week of May and 3rd week of May.
\input{Figure/figure_app_detail_pipeline}
\paragraph{Prompt template}~\label{app:prompt_template}
To utilize the LLM as an optimizer in the seed prompt generation step, we employ the following prompt template.
\input{Table/table_app_prompt_template}
To utilize the LLM as an optimizer in the prompt revision step, we employ the following prompt template.
\input{Table/table_app_prompt_revision}
To utilize the VLM as an QA set generator for self-generated QA score, we employ the following prompt template.
\input{Table/table_app_prompt_qa_gen}

\subsection{Evaluation detail}
\paragraph{Human evaluation}\label{app:human_evaluation}
We informed the participants regarding human evaluation and surveyed as shown in Figure~\ref{app:human_eval_example}. We recruited a total of 63 participants. We ask participants to judge copyright violations on all generated images by ChatGPT with our APGP-generated prompt based on the reference images. There are four choices whether to determine the copyright. 
\input{Figure/human_eval_example}
\paragraph{Automatic QA evaluation}
We generated 5 or 10 questions per target image using VLM. Then, we employ VLM to answer the questions based on the generated images. Then, evaluate the response with verifier LLM. To further increase the confidence of the evaluation, we conduct 5 iterative verifications and average the matching scores. We employ GPT4-Turbo for VLM and GPT3.5 for LLM.  

\subsection{Experimental detail}
\paragraph{Table 2. Baseline test} To test the baseline T2I systems, we employ simple prompts to evaluate the copyright infringement. We give ``Generate an image of {keyword} by {keyword}.''. If T2I systems block generation, we count as a block and calculate the block rate.
\paragraph{Table 3. Block rate test on APGP-generated prompt} To test the T2I systems with our APGP-generated prompt, we input the APGP-generated prompt into T2I systems. We count if the T2I system blocks the generations. However, please note that not all generated images always violate copyright infringement.
\paragraph{Figure 5. Automatic QA evaluation} To assess automatic QA, we first create a QA set using VLM on the target images. Since the LLM verifier does not have 100\% accuracy, we conduct multiple trials to determine an average match score. Figure 5 demonstrates that the LLM verifier does not always correctly match the target image, yet it typically achieves a high average score. Thus, we compare these average match scores between responses based on the target image and those based on the generated image.
\paragraph{Block mechanisms in ChatGPT} ChatGPT has four types of responses to copyright infringement requests: 
1. It may block the text that violates copyright.
\newline
2. It might attempt to generate an image but then suddenly stop to comply with the request.
\newline
3. It could create an image, but if the request closely resembles copyrighted content, it will rephrase the prompt.
\newline
4. It might generate copyrighted image
\newline
If the content is block in first or second case, it means the prompt is easily detectable by internal censor mechanism. However, if it is in the second case, the prompt is high-risk to violate the copyright infringement.
\paragraph{Figure 10. Detection based filtering defense} In order to filter out copyright infringement using the target image, we employ the representation similarity in DINO~\citep{caron2021emerging}. We input the target image and the generated image into DINO, and calculate the cosine similarity distance. If the similarity distance exceeds 0.8, we filter out the generated images.similarity distance. Then, if the similarity distance exceeds 0.8 we filter out the generated images.

\section{Additional experimental results}\label{app:additional_result}
\subsection{Baseline test results}\label{app:base_result}\label{app:denial_results}
On naive prompts, Copilot, and Gemini-Pro rarely block the generations. Copilot and Gemini-Pro sometimes generate similar content but in a different style to bypass copyright infringement. On naive prompts, ChatGPT denies generating copyright-protected images as shown in Figure~\ref{app:base_result}. ChatGPT seems to verify the prompt before generating the image and whether the prompt may violate the internal policy. As Copilot does, ChatGPT sometimes rephrases the prompt to bypass the violation.
\input{Figure/figure_app_base_result}

\subsection{Manual trial}\label{app:manual_trial}
Assuming we are the IP owner of Mickey Mouse, we attempted to evoke Mickey Mouse manually in ChatGPT to assess the risk of copyright reproduction violation. However, as illustrated in Figure~\ref{app:fig_manual_trial2}, ChatGPT consistently reformulated the prompts to circumvent potential infringement. An intriguing observation emerged: despite not explicitly requesting it, the character consistently appeared wearing Mickey's trademark pants with white dots. This observation raises doubts about whether ChatGPT is actually aware of Mickey Mouse, although the current prompt may not be strong enough to elicit a response.

\input{Figure/figure_app_manual_trial}

\subsection{Generated results and APGP-generated prompts examples}\label{app:prompt_results}
We append all the successful cases with APGP-generated prompts. Furthermore, when we attempt multiple trials, we are also able to induce copyright infringement in ChatGPT, as shown in Figure~\ref{app:multiple_trials}. Examples of successful prompts can be found in the Table~\ref{app:apgp_prompt}.

\input{Table/table_app_apgp_prompt}

\input{Figure/figure_app_final}
\subsection{Suffix prompt results} \label{app:suffix_result_screenshot}
As shown in Figure~\ref{app:suffix_screenshot}, our suffix prompt injection may lead to bypassing the block system. Especially, when we employ the intention addition, we deceive the models easily. Keyword suppression is especially effective in inducing copyright infringement in character categories. If we change the name of the character to a generic word we can bypass the word-based detection.
\input{Figure/figure_app_suffix_screenshot}

\subsection{Unlearning model}
\input{Figure/figure_app_unlearning}
Although restoring the erased concept may be easier with our prompts than with human prompts, if the concept is highly correlated with another word, as~\citep{kumari2023ablating} observed with the Van Gogh concept, which is closely associated with stars or night, human prompts may evoke the erased concept as ours do. (Figure~\ref{app:unlearning_model}).
