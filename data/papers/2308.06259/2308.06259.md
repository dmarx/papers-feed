---
abstract: |
  We present a scalable method to build a high quality instruction following language model by automatically labelling human-written text with corresponding instructions. Our approach, named *instruction backtranslation*, starts with a language model finetuned on a small amount of seed data, and a given web corpus. The seed model is used to construct training examples by generating instruction prompts for web documents (*self-augmentation*), and then selecting high quality examples from among these candidates (*self-curation*). This data is then used to finetune a stronger model. Finetuning LLaMa on two iterations of our approach yields a model that outperforms all other LLaMa-based models on the Alpaca leaderboard not relying on distillation data, demonstrating highly effective self-alignment.
author:
- |
  Xian Li, Ping Yu, Chunting Zhou, Timo Schick, Omer Levy, Luke Zettlemoyer  
  **Jason Weston** & **Mike Lewis**  
  Meta  
  `{xianl,jase,mikelewis}@meta.com`  
bibliography:
- ref.bib
citation-style: ieee
header-includes:
- 
- 
link-citations: true
reference-section-title: References
title: Self-Alignment with Instruction Backtranslation
---





