- **Method Overview**: Instruction backtranslation involves two main steps: self-augmentation and self-curation, iteratively improving instruction-following capabilities of language models.

- **Self-Augmentation**: 
  - Generate instructions for unlabelled data using a backward model \( M_{yx} \) to create candidate pairs \( A = \{(x_i, y_i)\} \).
  - Finetune the base model on seed data to predict instructions from outputs.

- **Self-Curation**: 
  - Use the model \( M_0 \) to score candidate pairs based on quality, selecting those with scores \( a_i \geq k \) for training.
  - Iteratively refine the model \( M_t \) using curated data from previous iterations.

- **Initialization**: 
  - Seed data consists of 3200 human-annotated (instruction, output) pairs.
  - Unlabelled data sourced from a web corpus, processed to extract self-contained segments.

- **Finetuning Details**: 
  - Base model: LLaMa (7B, 33B, 65B parameters).
  - Hyperparameters: Learning rate \( 1e^{-5} \) decaying to \( 9e^{-6} \), weight decay \( 0.1 \), batch size \( 32 \) (or \( 8 \) for <3000 examples), dropout \( 0.1 \).

- **Evaluation Metrics**: 
  - Win rate against baselines (e.g., text-davinci-003) using various test prompts.
  - Human preference evaluation alongside automatic evaluation using AlpacaEval.

- **Key Findings**: 
  - High-quality data significantly improves model performance; low-quality data does not enhance instruction-following capabilities.
  - The scaling coefficient \( \alpha \) for Humpback is \( 6.95 \), indicating efficient data scaling compared to other models.

- **Baselines for Comparison**: 
  - text-davinci-003: Instruction-following model based on GPT-3.
  - LIMA: LLaMa models with 1000 manually selected instruction examples.
  - Guanaco: LLaMa models with 9000 examples from the OpenAssistant dataset.

- **Data Quality vs. Quantity**: 
  - Training on high-quality augmented data leads to better performance than simply increasing data quantity without curation.

- **Iterative Process**: 
  - The iterative self-curation process allows the model to continuously improve its ability to select high-quality training examples, enhancing overall performance.

- **System Prompts**: 
  - Tagging data sources during finetuning: 
    - Seed data: "Answer in the style of an AI Assistant."
    - Augmented data: "Answer with knowledge from web search."