\begin{table}[!h]
\centering
\caption{\textbf{Hyper-parameters used for \svdacro and LoRA training.} We perform a sweep on certain sensitive hyper-parameters  across methods for fair comparison.}
% \vspace{-3.5mm}
\begin{tabular}{ll}
\toprule
\multicolumn{2}{c}{\textbf{\svdacro Hyperparameters}} \\
\midrule
Initial mean value of $z$ & $0.1$ \\
Initial variance value of $z$ & $1 \times 10^{-3}$ \\
Global batch size & $256$ \\
Learning rate & $2 \times 10^{-3}$ \\
Clip max norm & $1 \times 10^{-3}$ \\
KL coefficient $\lambda$ & $0.0$, $0.1$, $0.2$, $0.3$ \\
\midrule
\multicolumn{2}{c}{\textbf{LoRA Hyperparameters}} \\
\midrule
Rank & $16$ \\
LoRA alpha & $32$ \\
LoRA dropout & $0.05$ \\
Global batch size & $256$ \\
Learning rate & $1 \times 10^{-5}$, $5 \times 10^{-5}$, $1 \times 10^{-4}$ \\
Clip max norm & $1 \times 10^{-3}$, $1.0$ \\
\bottomrule
\end{tabular}
\label{app:tab:hyperparameters}
\end{table}