
\section{Notation and Terminology}

Let $\mathcal{A}$ be a model trained on a task A.

\begin{equation}
    \mathcal{A}: \text{Model trained on task A} 
\end{equation}
% \begin{equation}
%     \mathcal{B}: \text{Model trained on task B} 
% \end{equation}

Let $\mathtt{M}$ be a set of components which model $\mathcal{A}$  consists of. These can have arbitrary nature, i.e. from complex multi-head attention components to simple layer norm layers. Let $\textbf{A}_\mathtt{m}$ be a single component and $\textbf{a}_\mathtt{m}$ be the representation of an example when passed through the respective component.

\begin{equation}
    \mathcal{A} = \{\textbf{A}_\mathtt{m},  \forall \mathtt{m} \in \mathtt{M} \} : \text{Components of model $\mathcal{A}$ }
\end{equation}

Let $\Theta(\cdot)$ retrieve the parameters of a component, where $\Theta_0(\cdot)$ represents the parameter initialization before training, $I(\cdot)$ retrieves the parameter indices, and $\alpha(\cdot)$ retrieve the implementation of the architecture of a component. 

\begin{equation}
    \Theta(\cdot) : \text{Parameters of a component } \cdot
\end{equation}
\begin{equation}
    \Theta_0(\cdot) : \text{Parameters initialization of a component } \cdot
\end{equation}
\begin{equation}
    I(\cdot) : \text{Parameters indices of a component } \cdot
\end{equation}
\begin{equation}
    \alpha(\cdot) : \text{Architecture of a component } \cdot
\end{equation}

% Let $\Theta$ be a set of (pre-trained) weights of a large deep neural network.

% \begin{equation}
%     \Theta: \text{(Pre-trained) weights shared by all modules}
% \end{equation}

\subsection{Modularity through Designated Parameters}

Let $\mathcal{A}$ and $\mathcal{B}$ be two models trained on tasks A and B.

Let $\mathtt{S}$ be the set of components which are \textit{shared} between tasks A and B and $\mathtt{D}^A$ ad $\mathtt{D}^B$ be the sets of components which are \textit{distinct} for each respective model. 

We can define three different setups:

\paragraph{1) The models have the same architecture:}

\begin{equation}
    \mathtt{D}^A = \mathtt{D}^B = \mathtt{D} : \text{The sets of components is the same between the two models.}
\end{equation}

\begin{equation}
    \alpha(\textbf{A}^\mathtt{d}) = \alpha(\textbf{B}^\mathtt{d}), \forall \mathtt{d} \in \mathtt{D} : \text{The architecture for each component is the same.}
\end{equation}
    
\begin{equation}
    \Theta(\textbf{A}^\mathtt{d}) \neq \Theta(\textbf{B}^\mathtt{d}) , \forall \mathtt{d} \in \mathtt{D} : \text{The parameters of each component are \textbf{not} the same; each component has learned task specific weights.}
\end{equation}

\begin{equation}
    \Theta(\textbf{A}^\mathtt{S}) = \Theta(\textbf{B}^\mathtt{s}) , \forall \mathtt{s} \in \mathtt{S} : \text{The parameters of each component which are shared between the two tasks  \textbf{are} the same;  each component has learned  weights used by both tasks.}
\end{equation}

Here the shared  parameters \textbf{can} receive the same initialization before training: 

\begin{equation}
    \Theta_0(\textbf{A}^\mathtt{d}) = \Theta_0(\textbf{B}^\mathtt{d}) , \forall \mathtt{d} \in \mathtt{D} : \text{The parameters of each component \textbf{can} receive the same initialization.}
\end{equation}

\paragraph{2) The models have the same components, with different architectures:}


\begin{equation}
    \mathtt{D}^A = \mathtt{D}^B = \mathtt{D} : \text{The sets of components is the same between the two models.}
\end{equation}


\begin{equation}
    |\textbf{a}^\mathtt{d}| = |\textbf{a}^\mathtt{d}|, \forall \mathtt{d} \in \mathtt{D} : \text{ (Usually) the output dimensionality $|\cdot|$ of each component is the same}
\end{equation}


\begin{equation}
    \alpha(\textbf{A}^\mathtt{d}) \neq \alpha(\textbf{B}^\mathtt{d}), \forall \mathtt{d} \in \mathtt{D} : \text{The architecture for each component is \textbf{not} the same.}
\end{equation}
    
% \begin{equation}
%     \Theta(\textbf{A}^\mathtt{d}) \neq \Theta(\textbf{B}^\mathtt{d}) , \forall \mathtt{d} \in \mathtt{D} : \text{The parameters of each component are \textbf{not} the same; each component has learned task specific weights.}
% \end{equation}

\begin{equation}
    \Theta(\textbf{A}^\mathtt{S}) = \Theta(\textbf{B}^\mathtt{s}) , \forall \mathtt{s} \in \mathtt{S} : \text{The parameters of each component which are shared between the two tasks  \textbf{are} the same;  each component has learned  weights used by both tasks.}
\end{equation}

\paragraph{2) The models don't have the same distinct components:}


\begin{equation}
    \mathtt{D}^A \neq \mathtt{D}^B = \mathtt{D} : \text{The sets of components is \textbf{not} the same between the two models.}
\end{equation}


    
% \begin{equation}
%     \Theta(\textbf{A}^\mathtt{d}) \neq \Theta(\textbf{B}^\mathtt{d}) , \forall \mathtt{d} \in \mathtt{D} : \text{The parameters of each component are \textbf{not} the same; each component has learned task specific weights.}
% \end{equation}

\begin{equation}
    \Theta(\textbf{A}^\mathtt{S}) = \Theta(\textbf{B}^\mathtt{s}) , \forall \mathtt{s} \in \mathtt{S} : \text{The parameters of each component which are shared between the two tasks  \textbf{are} the same;  each component has learned  weights used by both tasks.}
\end{equation}

% Let $\Phi$ be a set of newly introduced weights.
% \begin{equation}
%     \Phi: \text{Newly introduced weights }
% \end{equation}
% \begin{equation}
%     \Phi \notin \Theta
% \end{equation}

% \paragraph{All modules have the same architecture.}

% \begin{equation}
%     \phi \in \Phi^a \land \phi \in \Phi^b, \forall \phi \in  \{\Phi^a \cap \Phi^b\}
% \end{equation}

% \paragraph{Not all modules have the same architecture.}

% \begin{equation}
%   \exists \phi \notin \Phi^a \land \phi \in \Phi^b
% \end{equation}

\subsection{Modularity as Sparse Sub-networks}
Sparse weights (e.g. Lottery Tickets) starting from pre-trained weights. 


Let the model's be initialized with the same set of weights

\begin{equation}
    \Theta_0(\mathcal{A}) = \Theta_0(\mathcal{B}) = \Theta_0
\end{equation}

and the same architecture:
\begin{equation}
    \alpha(\mathcal{A}) = \alpha(\mathcal{B}) 
\end{equation}

There is a subset $S$ of parameters which overlap between the trained models $\mathcal{A}$ and $\mathcal{B}$. If the models are trained sparsely, these parameters might be zero, alternatively these parameters remain untrained and are the same as in the initialization $\Theta_0$.

\begin{equation}
    \Theta_S(\mathcal{A}) =  \Theta_S(\mathcal{B}) 
\end{equation}

There is a subset $D$ of parameters which are  between the trained models $\mathcal{A}$ and $\mathcal{B}$. If the models are trained sparsely, these parameters might be zero.

\begin{equation}
    \Theta_D(\mathcal{A}) \neq  \Theta_D(\mathcal{B}) 
\end{equation}

\begin{equation}
    \Theta_S(\mathcal{A}) \cup \Theta_D(\mathcal{A}) =  \Theta(\mathcal{A}) 
\end{equation}


\begin{equation}
    \Theta_S(\mathcal{A}) \cap \Theta_D(\mathcal{A}) =  \{\}
\end{equation}

% \begin{equation}
%     \Psi  \propto \Theta 
% \end{equation}

% Sparse weights $\Psi$ follow the general architecture and initialization as $\Theta$.

% However,
% \begin{equation}
%     |\Psi|  << |\Theta| 
% \end{equation}
% the total number of non-zero weights in $\Psi$ is considerably smaller than $\Theta$.
