{
  "snapshot_time": "2025-01-25T05:30:23.408360+00:00",
  "repository": "dmarx/papers-feed",
  "objects": {
    "interactions:2310.16410": {
      "data": {
        "paper_id": "2310.16410",
        "interactions": [
          {
            "type": "reading_session",
            "timestamp": "2025-01-24T08:29:08.482Z",
            "data": {
              "session_id": "session_1737707335861_ub76jpd",
              "duration_seconds": 7,
              "idle_seconds": 0,
              "start_time": "2025-01-24T08:28:55.861Z",
              "end_time": "2025-01-24T08:29:02.492Z",
              "total_elapsed_seconds": 7
            }
          }
        ]
      },
      "meta": {
        "created_at": "2025-01-24T08:29:03+00:00",
        "updated_at": "2025-01-24T08:29:27+00:00",
        "version": 5
      }
    },
    "paper:2310.16410": {
      "data": {
        "arxivId": "2310.16410",
        "url": "https://arxiv.org/abs/2310.16410",
        "title": "Bridging the Human-AI Knowledge Gap: Concept Discovery and Transfer in\n  AlphaZero",
        "authors": "Lisa Schut, Nenad Tomasev, Tom McGrath, Demis Hassabis, Ulrich Paquet, Been Kim",
        "abstract": "Artificial Intelligence (AI) systems have made remarkable progress, attaining\nsuper-human performance across various domains. This presents us with an\nopportunity to further human knowledge and improve human expert performance by\nleveraging the hidden knowledge encoded within these highly performant AI\nsystems. Yet, this knowledge is often hard to extract, and may be hard to\nunderstand or learn from. Here, we show that this is possible by proposing a\nnew method that allows us to extract new chess concepts in AlphaZero, an AI\nsystem that mastered the game of chess via self-play without human supervision.\nOur analysis indicates that AlphaZero may encode knowledge that extends beyond\nthe existing human knowledge, but knowledge that is ultimately not beyond human\ngrasp, and can be successfully learned from. In a human study, we show that\nthese concepts are learnable by top human experts, as four top chess\ngrandmasters show improvements in solving the presented concept prototype\npositions. This marks an important first milestone in advancing the frontier of\nhuman knowledge by leveraging AI; a development that could bear profound\nimplications and help us shape how we interact with AI systems across many AI\napplications.",
        "timestamp": "2025-01-24T08:28:29.420Z",
        "rating": "novote",
        "published_date": "2023-10-25T06:49:26Z",
        "arxiv_tags": [
          "cs.AI",
          "cs.HC",
          "cs.LG",
          "stat.ML"
        ]
      },
      "meta": {
        "created_at": "2025-01-24T08:28:29+00:00",
        "updated_at": "2025-01-24T08:28:32+00:00",
        "version": 2
      }
    },
    "interactions:2501.04697": {
      "data": {
        "paper_id": "2501.04697",
        "interactions": []
      },
      "meta": {
        "created_at": "2025-01-24T08:25:00+00:00",
        "updated_at": "2025-01-24T08:25:03+00:00",
        "version": 2
      }
    },
    "paper:2501.04697": {
      "data": {
        "arxivId": "2501.04697",
        "url": "https://arxiv.org/abs/2501.04697",
        "title": "Grokking at the Edge of Numerical Stability",
        "authors": "Lucas Prieto, Melih Barsbey, Pedro A. M. Mediano, Tolga Birdal",
        "abstract": "Grokking, the sudden generalization that occurs after prolonged overfitting,\nis a surprising phenomenon challenging our understanding of deep learning.\nAlthough significant progress has been made in understanding grokking, the\nreasons behind the delayed generalization and its dependence on regularization\nremain unclear. In this work, we argue that without regularization, grokking\ntasks push models to the edge of numerical stability, introducing floating\npoint errors in the Softmax function, which we refer to as Softmax Collapse\n(SC). We demonstrate that SC prevents grokking and that mitigating SC enables\ngrokking without regularization. Investigating the root cause of SC, we find\nthat beyond the point of overfitting, the gradients strongly align with what we\ncall the na\\\"ive loss minimization (NLM) direction. This component of the\ngradient does not alter the model's predictions but decreases the loss by\nscaling the logits, typically by scaling the weights along their current\ndirection. We show that this scaling of the logits explains the delay in\ngeneralization characteristic of grokking and eventually leads to SC, halting\nfurther learning. To validate our hypotheses, we introduce two key\ncontributions that address the challenges in grokking tasks: StableMax, a new\nactivation function that prevents SC and enables grokking without\nregularization, and $\\perp$Grad, a training algorithm that promotes quick\ngeneralization in grokking tasks by preventing NLM altogether. These\ncontributions provide new insights into grokking, elucidating its delayed\ngeneralization, reliance on regularization, and the effectiveness of existing\ngrokking-inducing methods. Code for this paper is available at\nhttps://github.com/LucasPrietoAl/grokking-at-the-edge-of-numerical-stability.",
        "timestamp": "2025-01-24T08:24:55.685Z",
        "rating": "novote",
        "published_date": "2025-01-08T18:58:48Z",
        "arxiv_tags": [
          "cs.LG",
          "cs.AI",
          "cs.CV",
          "stat.ML"
        ]
      },
      "meta": {
        "created_at": "2025-01-24T08:24:56+00:00",
        "updated_at": "2025-01-24T08:24:59+00:00",
        "version": 2
      }
    },
    "interactions:2002.09291": {
      "data": {
        "paper_id": "2002.09291",
        "interactions": [
          {
            "type": "reading_session",
            "timestamp": "2025-01-24T07:09:06.090Z",
            "data": {
              "session_id": "session_1737702535793_x55fw99",
              "duration_seconds": 9,
              "idle_seconds": 0,
              "start_time": "2025-01-24T07:08:55.793Z",
              "end_time": "2025-01-24T07:09:05.184Z",
              "total_elapsed_seconds": 9
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-01-25T05:29:19.260Z",
            "data": {
              "session_id": "session_1737782950954_orhggu3",
              "duration_seconds": 7,
              "idle_seconds": 0,
              "start_time": "2025-01-25T05:29:10.954Z",
              "end_time": "2025-01-25T05:29:17.671Z",
              "total_elapsed_seconds": 7
            }
          }
        ]
      },
      "meta": {
        "created_at": "2025-01-24T07:09:06+00:00",
        "updated_at": "2025-01-25T05:29:30+00:00",
        "version": 7
      }
    },
    "paper:2002.09291": {
      "data": {
        "arxivId": "2002.09291",
        "url": "https://arxiv.org/abs/2002.09291",
        "title": "Transformer Hawkes Process",
        "authors": "Simiao Zuo, Haoming Jiang, Zichong Li, Tuo Zhao, Hongyuan Zha",
        "abstract": "Modern data acquisition routinely produce massive amounts of event sequence\ndata in various domains, such as social media, healthcare, and financial\nmarkets. These data often exhibit complicated short-term and long-term temporal\ndependencies. However, most of the existing recurrent neural network based\npoint process models fail to capture such dependencies, and yield unreliable\nprediction performance. To address this issue, we propose a Transformer Hawkes\nProcess (THP) model, which leverages the self-attention mechanism to capture\nlong-term dependencies and meanwhile enjoys computational efficiency. Numerical\nexperiments on various datasets show that THP outperforms existing models in\nterms of both likelihood and event prediction accuracy by a notable margin.\nMoreover, THP is quite general and can incorporate additional structural\nknowledge. We provide a concrete example, where THP achieves improved\nprediction performance for learning multiple point processes when incorporating\ntheir relational information.",
        "timestamp": "2025-01-24T07:08:55.938Z",
        "rating": "novote",
        "published_date": "2020-02-21T13:48:13Z",
        "arxiv_tags": [
          "cs.LG",
          "stat.ML"
        ]
      },
      "meta": {
        "created_at": "2025-01-24T07:08:56+00:00",
        "updated_at": "2025-01-24T07:08:59+00:00",
        "version": 2
      }
    },
    "paper:2002.08521": {
      "data": {
        "arxivId": "2002.08521",
        "url": "https://arxiv.org/pdf/2002.08521",
        "title": "Group Network Hawkes Process",
        "authors": "Guanhua Fang, Ganggang Xu, Haochen Xu, Xuening Zhu, Yongtao Guan",
        "abstract": "In this work, we study the event occurrences of individuals interacting in a\nnetwork. To characterize the dynamic interactions among the individuals, we\npropose a group network Hawkes process (GNHP) model whose network structure is\nobserved and fixed. In particular, we introduce a latent group structure among\nindividuals to account for the heterogeneous user-specific characteristics. A\nmaximum likelihood approach is proposed to simultaneously cluster individuals\nin the network and estimate model parameters. A fast EM algorithm is\nsubsequently developed by utilizing the branching representation of the\nproposed GNHP model. Theoretical properties of the resulting estimators of\ngroup memberships and model parameters are investigated under both settings\nwhen the number of latent groups $G$ is over-specified or correctly specified.\nA data-driven criterion that can consistently identify the true $G$ under mild\nconditions is derived. Extensive simulation studies and an application to a\ndata set collected from Sina Weibo are used to illustrate the effectiveness of\nthe proposed methodology.",
        "timestamp": "2025-01-24T07:07:58.196Z",
        "rating": "novote",
        "published_date": "2020-02-20T01:30:42Z",
        "arxiv_tags": [
          "stat.ME",
          "math.ST",
          "stat.TH"
        ]
      },
      "meta": {
        "created_at": "2025-01-24T07:07:58+00:00",
        "updated_at": "2025-01-24T07:08:01+00:00",
        "version": 2
      }
    },
    "interactions:2312.00752": {
      "data": {
        "paper_id": "2312.00752",
        "interactions": [
          {
            "type": "reading_session",
            "timestamp": "2025-01-23T07:26:06.418Z",
            "data": {
              "session_id": "session_1737617143583_9cgks93",
              "duration_seconds": 23,
              "idle_seconds": 0,
              "start_time": "2025-01-23T07:25:43.583Z",
              "end_time": "2025-01-23T07:26:06.402Z",
              "total_elapsed_seconds": 23
            }
          }
        ]
      },
      "meta": {
        "created_at": "2025-01-23T07:25:37+00:00",
        "updated_at": "2025-01-23T21:30:38+00:00",
        "version": 4
      }
    },
    "paper:2312.00752": {
      "data": {
        "arxivId": "2312.00752",
        "url": "https://arxiv.org/abs/2312.00752",
        "title": "Mamba: Linear-Time Sequence Modeling with Selective State Spaces",
        "authors": "Albert Gu, Tri Dao",
        "abstract": "Foundation models, now powering most of the exciting applications in deep\nlearning, are almost universally based on the Transformer architecture and its\ncore attention module. Many subquadratic-time architectures such as linear\nattention, gated convolution and recurrent models, and structured state space\nmodels (SSMs) have been developed to address Transformers' computational\ninefficiency on long sequences, but they have not performed as well as\nattention on important modalities such as language. We identify that a key\nweakness of such models is their inability to perform content-based reasoning,\nand make several improvements. First, simply letting the SSM parameters be\nfunctions of the input addresses their weakness with discrete modalities,\nallowing the model to selectively propagate or forget information along the\nsequence length dimension depending on the current token. Second, even though\nthis change prevents the use of efficient convolutions, we design a\nhardware-aware parallel algorithm in recurrent mode. We integrate these\nselective SSMs into a simplified end-to-end neural network architecture without\nattention or even MLP blocks (Mamba). Mamba enjoys fast inference (5$\\times$\nhigher throughput than Transformers) and linear scaling in sequence length, and\nits performance improves on real data up to million-length sequences. As a\ngeneral sequence model backbone, Mamba achieves state-of-the-art performance\nacross several modalities such as language, audio, and genomics. On language\nmodeling, our Mamba-3B model outperforms Transformers of the same size and\nmatches Transformers twice its size, both in pretraining and downstream\nevaluation.",
        "timestamp": "2025-01-23T07:24:53.349Z",
        "rating": "novote",
        "published_date": "2023-12-01T18:01:34Z",
        "arxiv_tags": [
          "cs.LG",
          "cs.AI"
        ]
      },
      "meta": {
        "created_at": "2025-01-23T07:24:53+00:00",
        "updated_at": "2025-01-23T07:24:56+00:00",
        "version": 2
      }
    },
    "interactions:2402.18012": {
      "data": {
        "paper_id": "2402.18012",
        "interactions": [
          {
            "type": "reading_session",
            "timestamp": "2025-01-23T02:00:14.220Z",
            "data": {
              "session_id": "session_1737597587001_4wifmlu",
              "duration_seconds": 26,
              "idle_seconds": 0,
              "start_time": "2025-01-23T01:59:47.001Z",
              "end_time": "2025-01-23T02:00:13.427Z",
              "total_elapsed_seconds": 26
            }
          }
        ]
      },
      "meta": {
        "created_at": "2025-01-23T02:00:15+00:00",
        "updated_at": "2025-01-24T08:14:42+00:00",
        "version": 3
      }
    },
    "paper:2402.18012": {
      "data": {
        "arxivId": "2402.18012",
        "url": "https://arxiv.org/abs/2402.18012",
        "title": "Diffusion Models as Constrained Samplers for Optimization with Unknown\n  Constraints",
        "authors": "Lingkai Kong, Yuanqi Du, Wenhao Mu, Kirill Neklyudov, Valentin De Bortoli, Dongxia Wu, Haorui Wang, Aaron Ferber, Yi-An Ma, Carla P. Gomes, Chao Zhang",
        "abstract": "Addressing real-world optimization problems becomes particularly challenging\nwhen analytic objective functions or constraints are unavailable. While\nnumerous studies have addressed the issue of unknown objectives, limited\nresearch has focused on scenarios where feasibility constraints are not given\nexplicitly. Overlooking these constraints can lead to spurious solutions that\nare unrealistic in practice. To deal with such unknown constraints, we propose\nto perform optimization within the data manifold using diffusion models. To\nconstrain the optimization process to the data manifold, we reformulate the\noriginal optimization problem as a sampling problem from the product of the\nBoltzmann distribution defined by the objective function and the data\ndistribution learned by the diffusion model. Depending on the differentiability\nof the objective function, we propose two different sampling methods. For\ndifferentiable objectives, we propose a two-stage framework that begins with a\nguided diffusion process for warm-up, followed by a Langevin dynamics stage for\nfurther correction. For non-differentiable objectives, we propose an iterative\nimportance sampling strategy using the diffusion model as the proposal\ndistribution. Comprehensive experiments on a synthetic dataset, six real-world\nblack-box optimization datasets, and a multi-objective molecule optimization\ndataset show that our method achieves better or comparable performance with\nprevious state-of-the-art baselines.",
        "timestamp": "2025-01-23T01:59:47.272Z",
        "rating": "novote",
        "published_date": "2024-02-28T03:09:12Z",
        "arxiv_tags": [
          "cs.LG",
          "cs.AI"
        ]
      },
      "meta": {
        "created_at": "2025-01-23T01:59:47+00:00",
        "updated_at": "2025-01-23T01:59:50+00:00",
        "version": 2
      }
    },
    "interactions:1503.02531": {
      "data": {
        "paper_id": "1503.02531",
        "interactions": []
      },
      "meta": {
        "created_at": "2025-01-22T23:53:11+00:00",
        "updated_at": "2025-01-24T08:14:55+00:00",
        "version": 1
      }
    },
    "paper:1503.02531": {
      "data": {
        "arxivId": "1503.02531",
        "url": "https://arxiv.org/abs/1503.02531",
        "title": "Distilling the Knowledge in a Neural Network",
        "authors": "Geoffrey Hinton, Oriol Vinyals, Jeff Dean",
        "abstract": "A very simple way to improve the performance of almost any machine learning\nalgorithm is to train many different models on the same data and then to\naverage their predictions. Unfortunately, making predictions using a whole\nensemble of models is cumbersome and may be too computationally expensive to\nallow deployment to a large number of users, especially if the individual\nmodels are large neural nets. Caruana and his collaborators have shown that it\nis possible to compress the knowledge in an ensemble into a single model which\nis much easier to deploy and we develop this approach further using a different\ncompression technique. We achieve some surprising results on MNIST and we show\nthat we can significantly improve the acoustic model of a heavily used\ncommercial system by distilling the knowledge in an ensemble of models into a\nsingle model. We also introduce a new type of ensemble composed of one or more\nfull models and many specialist models which learn to distinguish fine-grained\nclasses that the full models confuse. Unlike a mixture of experts, these\nspecialist models can be trained rapidly and in parallel.",
        "timestamp": "2025-01-22T23:52:59.719Z",
        "rating": "novote",
        "published_date": "2015-03-09T15:44:49Z",
        "arxiv_tags": [
          "stat.ML",
          "cs.LG",
          "cs.NE"
        ]
      },
      "meta": {
        "created_at": "2025-01-22T23:53:00+00:00",
        "updated_at": "2025-01-22T23:53:02+00:00",
        "version": 2
      }
    },
    "interactions:2212.07677": {
      "data": {
        "paper_id": "2212.07677",
        "interactions": [
          {
            "type": "reading_session",
            "timestamp": "2025-01-22T23:51:48.964Z",
            "data": {
              "session_id": "session_1737589861712_6k0limt",
              "duration_seconds": 46,
              "idle_seconds": 0,
              "start_time": "2025-01-22T23:51:01.712Z",
              "end_time": "2025-01-22T23:51:48.063Z",
              "total_elapsed_seconds": 46
            }
          }
        ]
      },
      "meta": {
        "created_at": "2025-01-22T23:51:49+00:00",
        "updated_at": "2025-01-24T08:14:59+00:00",
        "version": 3
      }
    },
    "paper:2212.07677": {
      "data": {
        "arxivId": "2212.07677",
        "url": "https://arxiv.org/abs/2212.07677",
        "title": "Transformers learn in-context by gradient descent",
        "authors": "Johannes von Oswald, Eyvind Niklasson, Ettore Randazzo, Jo\u00e3o Sacramento, Alexander Mordvintsev, Andrey Zhmoginov, Max Vladymyrov",
        "abstract": "At present, the mechanisms of in-context learning in Transformers are not\nwell understood and remain mostly an intuition. In this paper, we suggest that\ntraining Transformers on auto-regressive objectives is closely related to\ngradient-based meta-learning formulations. We start by providing a simple\nweight construction that shows the equivalence of data transformations induced\nby 1) a single linear self-attention layer and by 2) gradient-descent (GD) on a\nregression loss. Motivated by that construction, we show empirically that when\ntraining self-attention-only Transformers on simple regression tasks either the\nmodels learned by GD and Transformers show great similarity or, remarkably, the\nweights found by optimization match the construction. Thus we show how trained\nTransformers become mesa-optimizers i.e. learn models by gradient descent in\ntheir forward pass. This allows us, at least in the domain of regression\nproblems, to mechanistically understand the inner workings of in-context\nlearning in optimized Transformers. Building on this insight, we furthermore\nidentify how Transformers surpass the performance of plain gradient descent by\nlearning an iterative curvature correction and learn linear models on deep data\nrepresentations to solve non-linear regression tasks. Finally, we discuss\nintriguing parallels to a mechanism identified to be crucial for in-context\nlearning termed induction-head (Olsson et al., 2022) and show how it could be\nunderstood as a specific case of in-context learning by gradient descent\nlearning within Transformers. Code to reproduce the experiments can be found at\nhttps://github.com/google-research/self-organising-systems/tree/master/transformers_learn_icl_by_gd .",
        "timestamp": "2025-01-22T23:51:01.971Z",
        "rating": "novote",
        "published_date": "2022-12-15T09:21:21Z",
        "arxiv_tags": [
          "cs.LG",
          "cs.AI",
          "cs.CL"
        ]
      },
      "meta": {
        "created_at": "2025-01-22T23:51:02+00:00",
        "updated_at": "2025-01-22T23:51:05+00:00",
        "version": 2
      }
    },
    "interactions:2501.12374": {
      "data": {
        "paper_id": "2501.12374",
        "interactions": []
      },
      "meta": {
        "created_at": "2025-01-22T23:29:34+00:00",
        "updated_at": "2025-01-22T23:29:38+00:00",
        "version": 2
      }
    },
    "paper:2501.12374": {
      "data": {
        "arxivId": "2501.12374",
        "url": "https://arxiv.org/abs/2501.12374",
        "title": "Expertise elevates AI usage: experimental evidence comparing laypeople\n  and professional artists",
        "authors": "Thomas F. Eisenmann, Andres Karjus, Mar Canet Sola, Levin Brinkmann, Bramantyo Ibrahim Supriyatno, Iyad Rahwan",
        "abstract": "Novel capacities of generative AI to analyze and generate cultural artifacts\nraise inevitable questions about the nature and value of artistic education and\nhuman expertise. Has AI already leveled the playing field between professional\nartists and laypeople, or do trained artistic expressive capacity, curation\nskills and experience instead enhance the ability to use these new tools? In\nthis pre-registered study, we conduct experimental comparisons between 50\nactive artists and a demographically matched sample of laypeople. We designed\ntwo tasks to approximate artistic practice for testing their capabilities in\nboth faithful and creative image creation: replicating a reference image, and\nmoving as far away as possible from it. We developed a bespoke platform where\nparticipants used a modern text-to-image model to complete both tasks. We also\ncollected and compared participants' sentiments towards AI. On average, artists\nproduced more faithful and creative outputs than their lay counterparts,\nalthough only by a small margin. While AI may ease content creation,\nprofessional expertise is still valuable - even within the confined space of\ngenerative AI itself. Finally, we also explored how well an exemplary\nvision-capable large language model (GPT-4o) would complete the same tasks, if\ngiven the role of an image generation agent, and found it performed on par in\ncopying but outperformed even artists in the creative task. The very best\nresults were still produced by humans in both tasks. These outcomes highlight\nthe importance of integrating artistic skills with AI training to prepare\nartists and other visual professionals for a technologically evolving\nlandscape. We see a potential in collaborative synergy with generative AI,\nwhich could reshape creative industries and education in the arts.",
        "timestamp": "2025-01-22T23:29:08.663Z",
        "rating": "novote",
        "published_date": "2025-01-21T18:53:21Z",
        "arxiv_tags": [
          "cs.HC",
          "cs.AI",
          "cs.CY"
        ]
      },
      "meta": {
        "created_at": "2025-01-22T23:29:09+00:00",
        "updated_at": "2025-01-22T23:29:12+00:00",
        "version": 2
      }
    },
    "interactions:2007.12927": {
      "data": {
        "paper_id": "2007.12927",
        "interactions": []
      },
      "meta": {
        "created_at": "2025-01-22T23:10:40+00:00",
        "updated_at": "2025-01-22T23:10:42+00:00",
        "version": 2
      }
    },
    "paper:2007.12927": {
      "data": {
        "arxivId": "2007.12927",
        "url": "https://arxiv.org/pdf/2007.12927",
        "title": "Neural networks with late-phase weights",
        "authors": "Johannes von Oswald, Seijin Kobayashi, Alexander Meulemans, Christian Henning, Benjamin F. Grewe, Jo\u00e3o Sacramento",
        "abstract": "The largely successful method of training neural networks is to learn their\nweights using some variant of stochastic gradient descent (SGD). Here, we show\nthat the solutions found by SGD can be further improved by ensembling a subset\nof the weights in late stages of learning. At the end of learning, we obtain\nback a single model by taking a spatial average in weight space. To avoid\nincurring increased computational costs, we investigate a family of\nlow-dimensional late-phase weight models which interact multiplicatively with\nthe remaining parameters. Our results show that augmenting standard models with\nlate-phase weights improves generalization in established benchmarks such as\nCIFAR-10/100, ImageNet and enwik8. These findings are complemented with a\ntheoretical analysis of a noisy quadratic problem which provides a simplified\npicture of the late phases of neural network learning.",
        "timestamp": "2025-01-22T23:00:32.558Z",
        "rating": "novote",
        "published_date": "2020-07-25T13:23:37Z",
        "arxiv_tags": [
          "cs.LG",
          "cs.CV",
          "stat.ML"
        ]
      },
      "meta": {
        "created_at": "2025-01-22T23:00:33+00:00",
        "updated_at": "2025-01-22T23:00:36+00:00",
        "version": 2
      }
    },
    "interactions:2212.13345": {
      "data": {
        "paper_id": "2212.13345",
        "interactions": [
          {
            "type": "reading_session",
            "timestamp": "2025-01-22T22:08:59.431Z",
            "data": {
              "duration_seconds": 12
            }
          }
        ]
      },
      "meta": {
        "created_at": "2025-01-22T22:06:24+00:00",
        "updated_at": "2025-01-24T08:15:21+00:00",
        "version": 7
      }
    },
    "paper:2212.13345": {
      "data": {
        "arxivId": "2212.13345",
        "url": "https://arxiv.org/abs/2212.13345",
        "title": "The Forward-Forward Algorithm: Some Preliminary Investigations",
        "authors": "Geoffrey Hinton",
        "abstract": "The aim of this paper is to introduce a new learning procedure for neural\nnetworks and to demonstrate that it works well enough on a few small problems\nto be worth further investigation. The Forward-Forward algorithm replaces the\nforward and backward passes of backpropagation by two forward passes, one with\npositive (i.e. real) data and the other with negative data which could be\ngenerated by the network itself. Each layer has its own objective function\nwhich is simply to have high goodness for positive data and low goodness for\nnegative data. The sum of the squared activities in a layer can be used as the\ngoodness but there are many other possibilities, including minus the sum of the\nsquared activities. If the positive and negative passes could be separated in\ntime, the negative passes could be done offline, which would make the learning\nmuch simpler in the positive pass and allow video to be pipelined through the\nnetwork without ever storing activities or stopping to propagate derivatives.",
        "timestamp": "2025-01-22T22:06:19.707Z",
        "rating": "thumbsup",
        "published_date": "2022-12-27T02:54:46Z",
        "arxiv_tags": [
          "cs.LG"
        ]
      },
      "meta": {
        "created_at": "2025-01-22T22:06:20+00:00",
        "updated_at": "2025-01-24T08:15:32+00:00",
        "version": 3
      }
    },
    "interactions:2112.04215": {
      "data": {
        "paper_id": "2112.04215",
        "interactions": [
          {
            "type": "reading_session",
            "timestamp": "2025-01-22T07:09:51.236Z",
            "data": {
              "duration_seconds": 25
            }
          }
        ]
      },
      "meta": {
        "created_at": "2025-01-22T07:08:39+00:00",
        "updated_at": "2025-01-24T08:15:39+00:00",
        "version": 8
      }
    },
    "paper:2112.04215": {
      "data": {
        "arxivId": "2112.04215",
        "url": "https://arxiv.org/abs/2112.04215",
        "title": "Self-Supervised Models are Continual Learners",
        "authors": "Enrico Fini, Victor G. Turrisi da Costa, Xavier Alameda-Pineda, Elisa Ricci, Karteek Alahari, Julien Mairal",
        "abstract": "Self-supervised models have been shown to produce comparable or better visual\nrepresentations than their supervised counterparts when trained offline on\nunlabeled data at scale. However, their efficacy is catastrophically reduced in\na Continual Learning (CL) scenario where data is presented to the model\nsequentially. In this paper, we show that self-supervised loss functions can be\nseamlessly converted into distillation mechanisms for CL by adding a predictor\nnetwork that maps the current state of the representations to their past state.\nThis enables us to devise a framework for Continual self-supervised visual\nrepresentation Learning that (i) significantly improves the quality of the\nlearned representations, (ii) is compatible with several state-of-the-art\nself-supervised objectives, and (iii) needs little to no hyperparameter tuning.\nWe demonstrate the effectiveness of our approach empirically by training six\npopular self-supervised models in various CL settings.",
        "timestamp": "2025-01-22T07:08:23.330Z",
        "rating": "novote",
        "published_date": "2021-12-08T10:39:13Z",
        "arxiv_tags": [
          "cs.CV",
          "cs.LG"
        ]
      },
      "meta": {
        "created_at": "2025-01-22T07:08:23+00:00",
        "updated_at": "2025-01-22T07:08:26+00:00",
        "version": 2
      }
    },
    "interactions:2412.09315": {
      "data": {
        "paper_id": "2412.09315",
        "interactions": []
      },
      "meta": {
        "created_at": "2025-01-21T20:16:58+00:00",
        "updated_at": "2025-01-21T20:17:01+00:00",
        "version": 2
      }
    },
    "paper:2412.09315": {
      "data": {
        "arxivId": "2412.09315",
        "url": "https://arxiv.org/abs/2412.09315",
        "title": "Beware of Metacognitive Laziness: Effects of Generative Artificial\n  Intelligence on Learning Motivation, Processes, and Performance",
        "authors": "Yizhou Fan, Luzhen Tang, Huixiao Le, Kejie Shen, Shufang Tan, Yueying Zhao, Yuan Shen, Xinyu Li, Dragan Ga\u0161evi\u0107",
        "abstract": "With the continuous development of technological and educational innovation,\nlearners nowadays can obtain a variety of support from agents such as teachers,\npeers, education technologies, and recently, generative artificial intelligence\nsuch as ChatGPT. The concept of hybrid intelligence is still at a nascent\nstage, and how learners can benefit from a symbiotic relationship with various\nagents such as AI, human experts and intelligent learning systems is still\nunknown. The emerging concept of hybrid intelligence also lacks deep insights\nand understanding of the mechanisms and consequences of hybrid human-AI\nlearning based on strong empirical research. In order to address this gap, we\nconducted a randomised experimental study and compared learners' motivations,\nself-regulated learning processes and learning performances on a writing task\namong different groups who had support from different agents (ChatGPT, human\nexpert, writing analytics tools, and no extra tool). A total of 117 university\nstudents were recruited, and their multi-channel learning, performance and\nmotivation data were collected and analysed. The results revealed that:\nlearners who received different learning support showed no difference in\npost-task intrinsic motivation; there were significant differences in the\nfrequency and sequences of the self-regulated learning processes among groups;\nChatGPT group outperformed in the essay score improvement but their knowledge\ngain and transfer were not significantly different. Our research found that in\nthe absence of differences in motivation, learners with different supports\nstill exhibited different self-regulated learning processes, ultimately leading\nto differentiated performance. What is particularly noteworthy is that AI\ntechnologies such as ChatGPT may promote learners' dependence on technology and\npotentially trigger metacognitive laziness.",
        "timestamp": "2025-01-21T20:05:49.177Z",
        "rating": "novote",
        "published_date": "2024-12-12T14:32:39Z",
        "arxiv_tags": [
          "cs.AI",
          "cs.HC"
        ]
      },
      "meta": {
        "created_at": "2025-01-21T20:05:49+00:00",
        "updated_at": "2025-01-21T20:05:53+00:00",
        "version": 2
      }
    },
    "interactions:2412.12095": {
      "data": {
        "paper_id": "2412.12095",
        "interactions": []
      },
      "meta": {
        "created_at": "2025-01-21T16:27:01+00:00",
        "updated_at": "2025-01-21T16:27:05+00:00",
        "version": 2
      }
    },
    "paper:2412.12095": {
      "data": {
        "arxivId": "2412.12095",
        "url": "https://arxiv.org/abs/2412.12095",
        "title": "Causal Diffusion Transformers for Generative Modeling",
        "authors": "Chaorui Deng, Deyao Zhu, Kunchang Li, Shi Guang, Haoqi Fan",
        "abstract": "We introduce Causal Diffusion as the autoregressive (AR) counterpart of\nDiffusion models. It is a next-token(s) forecasting framework that is friendly\nto both discrete and continuous modalities and compatible with existing\nnext-token prediction models like LLaMA and GPT. While recent works attempt to\ncombine diffusion with AR models, we show that introducing sequential\nfactorization to a diffusion model can substantially improve its performance\nand enables a smooth transition between AR and diffusion generation modes.\nHence, we propose CausalFusion - a decoder-only transformer that\ndual-factorizes data across sequential tokens and diffusion noise levels,\nleading to state-of-the-art results on the ImageNet generation benchmark while\nalso enjoying the AR advantage of generating an arbitrary number of tokens for\nin-context reasoning. We further demonstrate CausalFusion's multimodal\ncapabilities through a joint image generation and captioning model, and\nshowcase CausalFusion's ability for zero-shot in-context image manipulations.\nWe hope that this work could provide the community with a fresh perspective on\ntraining multimodal models over discrete and continuous data.",
        "timestamp": "2025-01-21T16:26:49.971Z",
        "rating": "novote",
        "published_date": "2024-12-16T18:59:29Z",
        "arxiv_tags": [
          "cs.CV"
        ]
      },
      "meta": {
        "created_at": "2025-01-21T16:26:50+00:00",
        "updated_at": "2025-01-21T16:26:53+00:00",
        "version": 2
      }
    },
    "paper:2501.05441": {
      "data": {
        "arxivId": "2501.05441",
        "url": "https://arxiv.org/abs/2501.05441",
        "title": "The GAN is dead; long live the GAN! A Modern GAN Baseline",
        "authors": "Yiwen Huang, Aaron Gokaslan, Volodymyr Kuleshov, James Tompkin",
        "abstract": "There is a widely-spread claim that GANs are difficult to train, and GAN\narchitectures in the literature are littered with empirical tricks. We provide\nevidence against this claim and build a modern GAN baseline in a more\nprincipled manner. First, we derive a well-behaved regularized relativistic GAN\nloss that addresses issues of mode dropping and non-convergence that were\npreviously tackled via a bag of ad-hoc tricks. We analyze our loss\nmathematically and prove that it admits local convergence guarantees, unlike\nmost existing relativistic losses. Second, our new loss allows us to discard\nall ad-hoc tricks and replace outdated backbones used in common GANs with\nmodern architectures. Using StyleGAN2 as an example, we present a roadmap of\nsimplification and modernization that results in a new minimalist baseline --\nR3GAN. Despite being simple, our approach surpasses StyleGAN2 on FFHQ,\nImageNet, CIFAR, and Stacked MNIST datasets, and compares favorably against\nstate-of-the-art GANs and diffusion models.",
        "timestamp": "2025-01-21T16:24:13.360Z",
        "rating": "novote",
        "published_date": "2025-01-09T18:53:06Z",
        "arxiv_tags": [
          "cs.LG",
          "cs.CV"
        ]
      },
      "meta": {
        "created_at": "2025-01-21T16:24:13+00:00",
        "updated_at": "2025-01-21T16:24:17+00:00",
        "version": 2
      }
    },
    "interactions:2501.05441": {
      "data": {
        "paper_id": "2501.05441",
        "interactions": []
      },
      "meta": {
        "created_at": "2025-01-21T16:24:38+00:00",
        "updated_at": "2025-01-21T16:24:42+00:00",
        "version": 2
      }
    },
    "interactions:2407.05872": {
      "data": {
        "paper_id": "2407.05872",
        "interactions": []
      },
      "meta": {
        "created_at": "2025-01-20T19:45:01+00:00",
        "updated_at": "2025-01-20T19:45:03+00:00",
        "version": 2
      }
    },
    "paper:2407.05872": {
      "data": {
        "arxivId": "2407.05872",
        "url": "https://arxiv.org/abs/2407.05872",
        "title": "Scaling Exponents Across Parameterizations and Optimizers",
        "authors": "Katie Everett, Lechao Xiao, Mitchell Wortsman, Alexander A. Alemi, Roman Novak, Peter J. Liu, Izzeddin Gur, Jascha Sohl-Dickstein, Leslie Pack Kaelbling, Jaehoon Lee, Jeffrey Pennington",
        "abstract": "Robust and effective scaling of models from small to large width typically\nrequires the precise adjustment of many algorithmic and architectural details,\nsuch as parameterization and optimizer choices. In this work, we propose a new\nperspective on parameterization by investigating a key assumption in prior work\nabout the alignment between parameters and data and derive new theoretical\nresults under weaker assumptions and a broader set of optimizers. Our extensive\nempirical investigation includes tens of thousands of models trained with all\ncombinations of three optimizers, four parameterizations, several alignment\nassumptions, more than a dozen learning rates, and fourteen model sizes up to\n26.8B parameters. We find that the best learning rate scaling prescription\nwould often have been excluded by the assumptions in prior work. Our results\nshow that all parameterizations, not just maximal update parameterization\n(muP), can achieve hyperparameter transfer; moreover, our novel per-layer\nlearning rate prescription for standard parameterization outperforms muP.\nFinally, we demonstrate that an overlooked aspect of parameterization, the\nepsilon parameter in Adam, must be scaled correctly to avoid gradient underflow\nand propose Adam-atan2, a new numerically stable, scale-invariant version of\nAdam that eliminates the epsilon hyperparameter entirely.",
        "timestamp": "2025-01-20T19:44:42.999Z",
        "rating": "novote",
        "published_date": "2024-07-08T12:32:51Z",
        "arxiv_tags": [
          "cs.LG"
        ]
      },
      "meta": {
        "created_at": "2025-01-20T19:44:43+00:00",
        "updated_at": "2025-01-20T19:44:46+00:00",
        "version": 2
      }
    },
    "interactions:2402.06184": {
      "data": {
        "paper_id": "2402.06184",
        "interactions": [
          {
            "type": "reading_session",
            "timestamp": "2025-01-20T19:26:52.959Z",
            "data": {
              "duration_seconds": 6
            }
          }
        ]
      },
      "meta": {
        "created_at": "2025-01-20T19:26:46+00:00",
        "updated_at": "2025-01-24T08:17:12+00:00",
        "version": 4
      }
    },
    "paper:2402.06184": {
      "data": {
        "arxivId": "2402.06184",
        "url": "https://arxiv.org/abs/2402.06184",
        "title": "The boundary of neural network trainability is fractal",
        "authors": "Jascha Sohl-Dickstein",
        "abstract": "Some fractals -- for instance those associated with the Mandelbrot and\nquadratic Julia sets -- are computed by iterating a function, and identifying\nthe boundary between hyperparameters for which the resulting series diverges or\nremains bounded. Neural network training similarly involves iterating an update\nfunction (e.g. repeated steps of gradient descent), can result in convergent or\ndivergent behavior, and can be extremely sensitive to small changes in\nhyperparameters. Motivated by these similarities, we experimentally examine the\nboundary between neural network hyperparameters that lead to stable and\ndivergent training. We find that this boundary is fractal over more than ten\ndecades of scale in all tested configurations.",
        "timestamp": "2025-01-20T19:26:32.219Z",
        "rating": "novote",
        "published_date": "2024-02-09T04:46:48Z",
        "arxiv_tags": [
          "cs.LG",
          "cs.NE",
          "nlin.CD"
        ]
      },
      "meta": {
        "created_at": "2025-01-20T19:26:32+00:00",
        "updated_at": "2025-01-20T19:26:37+00:00",
        "version": 2
      }
    },
    "interactions:2410.05229": {
      "data": {
        "paper_id": "2410.05229",
        "interactions": [
          {
            "type": "reading_session",
            "timestamp": "2025-01-20T09:41:41.160Z",
            "data": {
              "duration_seconds": 108
            }
          }
        ]
      },
      "meta": {
        "created_at": "2025-01-20T09:41:36+00:00",
        "updated_at": "2025-01-24T08:17:19+00:00",
        "version": 4
      }
    },
    "interactions:2411.04872": {
      "data": {
        "paper_id": "2411.04872",
        "interactions": [
          {
            "type": "reading_session",
            "timestamp": "2025-01-20T09:39:40.379Z",
            "data": {
              "duration_seconds": 30
            }
          }
        ]
      },
      "meta": {
        "created_at": "2025-01-20T09:38:50+00:00",
        "updated_at": "2025-01-24T08:17:26+00:00",
        "version": 5
      }
    },
    "paper:2410.05229": {
      "data": {
        "arxivId": "2410.05229",
        "url": "https://arxiv.org/abs/2410.05229",
        "title": "GSM-Symbolic: Understanding the Limitations of Mathematical Reasoning in\n  Large Language Models",
        "authors": "Iman Mirzadeh, Keivan Alizadeh, Hooman Shahrokhi, Oncel Tuzel, Samy Bengio, Mehrdad Farajtabar",
        "abstract": "Recent advancements in Large Language Models (LLMs) have sparked interest in\ntheir formal reasoning capabilities, particularly in mathematics. The GSM8K\nbenchmark is widely used to assess the mathematical reasoning of models on\ngrade-school-level questions. While the performance of LLMs on GSM8K has\nsignificantly improved in recent years, it remains unclear whether their\nmathematical reasoning capabilities have genuinely advanced, raising questions\nabout the reliability of the reported metrics. To address these concerns, we\nconduct a large-scale study on several SOTA open and closed models. To overcome\nthe limitations of existing evaluations, we introduce GSM-Symbolic, an improved\nbenchmark created from symbolic templates that allow for the generation of a\ndiverse set of questions. GSM-Symbolic enables more controllable evaluations,\nproviding key insights and more reliable metrics for measuring the reasoning\ncapabilities of models.Our findings reveal that LLMs exhibit noticeable\nvariance when responding to different instantiations of the same question.\nSpecifically, the performance of all models declines when only the numerical\nvalues in the question are altered in the GSM-Symbolic benchmark. Furthermore,\nwe investigate the fragility of mathematical reasoning in these models and show\nthat their performance significantly deteriorates as the number of clauses in a\nquestion increases. We hypothesize that this decline is because current LLMs\ncannot perform genuine logical reasoning; they replicate reasoning steps from\ntheir training data. Adding a single clause that seems relevant to the question\ncauses significant performance drops (up to 65%) across all state-of-the-art\nmodels, even though the clause doesn't contribute to the reasoning chain needed\nfor the final answer. Overall, our work offers a more nuanced understanding of\nLLMs' capabilities and limitations in mathematical reasoning.",
        "timestamp": "2025-01-20T09:39:37.110Z",
        "rating": "novote",
        "published_date": "2024-10-07T17:36:37Z",
        "arxiv_tags": [
          "cs.LG",
          "cs.AI"
        ]
      },
      "meta": {
        "created_at": "2025-01-20T09:39:37+00:00",
        "updated_at": "2025-01-20T09:39:40+00:00",
        "version": 2
      }
    },
    "paper:2411.04872": {
      "data": {
        "arxivId": "2411.04872",
        "url": "https://arxiv.org/abs/2411.04872",
        "title": "FrontierMath: A Benchmark for Evaluating Advanced Mathematical Reasoning\n  in AI",
        "authors": "Elliot Glazer, Ege Erdil, Tamay Besiroglu, Diego Chicharro, Evan Chen, Alex Gunning, Caroline Falkman Olsson, Jean-Stanislas Denain, Anson Ho, Emily de Oliveira Santos, Olli J\u00e4rviniemi, Matthew Barnett, Robert Sandler, Matej Vrzala, Jaime Sevilla, Qiuyu Ren, Elizabeth Pratt, Lionel Levine, Grant Barkley, Natalie Stewart, Bogdan Grechuk, Tetiana Grechuk, Shreepranav Varma Enugandla, Mark Wildon",
        "abstract": "We introduce FrontierMath, a benchmark of hundreds of original, exceptionally\nchallenging mathematics problems crafted and vetted by expert mathematicians.\nThe questions cover most major branches of modern mathematics -- from\ncomputationally intensive problems in number theory and real analysis to\nabstract questions in algebraic geometry and category theory. Solving a typical\nproblem requires multiple hours of effort from a researcher in the relevant\nbranch of mathematics, and for the upper end questions, multiple days.\nFrontierMath uses new, unpublished problems and automated verification to\nreliably evaluate models while minimizing risk of data contamination. Current\nstate-of-the-art AI models solve under 2% of problems, revealing a vast gap\nbetween AI capabilities and the prowess of the mathematical community. As AI\nsystems advance toward expert-level mathematical abilities, FrontierMath offers\na rigorous testbed that quantifies their progress.",
        "timestamp": "2025-01-20T09:38:38.997Z",
        "rating": "novote",
        "published_date": "2024-11-07T17:07:35Z",
        "arxiv_tags": [
          "cs.AI"
        ]
      },
      "meta": {
        "created_at": "2025-01-20T09:38:39+00:00",
        "updated_at": "2025-01-20T09:38:42+00:00",
        "version": 2
      }
    },
    "paper:1910.02054": {
      "data": {
        "arxivId": "1910.02054",
        "url": "https://arxiv.org/abs/1910.02054",
        "title": "ZeRO: Memory Optimizations Toward Training Trillion Parameter Models",
        "authors": "Samyam Rajbhandari, Jeff Rasley, Olatunji Ruwase, Yuxiong He",
        "abstract": "Large deep learning models offer significant accuracy gains, but training\nbillions to trillions of parameters is challenging. Existing solutions such as\ndata and model parallelisms exhibit fundamental limitations to fit these models\ninto limited device memory, while obtaining computation, communication and\ndevelopment efficiency. We develop a novel solution, Zero Redundancy Optimizer\n(ZeRO), to optimize memory, vastly improving training speed while increasing\nthe model size that can be efficiently trained. ZeRO eliminates memory\nredundancies in data- and model-parallel training while retaining low\ncommunication volume and high computational granularity, allowing us to scale\nthe model size proportional to the number of devices with sustained high\nefficiency. Our analysis on memory requirements and communication volume\ndemonstrates: ZeRO has the potential to scale beyond 1 Trillion parameters\nusing today's hardware.\n  We implement and evaluate ZeRO: it trains large models of over 100B parameter\nwith super-linear speedup on 400 GPUs, achieving throughput of 15 Petaflops.\nThis represents an 8x increase in model size and 10x increase in achievable\nperformance over state-of-the-art. In terms of usability, ZeRO can train large\nmodels of up to 13B parameters (e.g., larger than Megatron GPT 8.3B and T5 11B)\nwithout requiring model parallelism which is harder for scientists to apply.\nLast but not the least, researchers have used the system breakthroughs of ZeRO\nto create the world's largest language model (Turing-NLG, 17B parameters) with\nrecord breaking accuracy.",
        "timestamp": "2025-01-20T07:32:15.795Z",
        "rating": "novote",
        "published_date": "2019-10-04T17:29:39Z",
        "arxiv_tags": [
          "cs.LG",
          "cs.DC",
          "stat.ML"
        ]
      },
      "meta": {
        "created_at": "2025-01-20T07:32:16+00:00",
        "updated_at": "2025-01-20T07:32:19+00:00",
        "version": 2
      }
    },
    "interactions:2104.07857": {
      "data": {
        "paper_id": "2104.07857",
        "interactions": [
          {
            "type": "reading_session",
            "timestamp": "2025-01-20T07:31:48.486Z",
            "data": {
              "duration_seconds": 10
            }
          }
        ]
      },
      "meta": {
        "created_at": "2025-01-20T07:31:40+00:00",
        "updated_at": "2025-01-24T08:17:35+00:00",
        "version": 4
      }
    },
    "paper:2104.07857": {
      "data": {
        "arxivId": "2104.07857",
        "url": "https://arxiv.org/abs/2104.07857",
        "title": "ZeRO-Infinity: Breaking the GPU Memory Wall for Extreme Scale Deep\n  Learning",
        "authors": "Samyam Rajbhandari, Olatunji Ruwase, Jeff Rasley, Shaden Smith, Yuxiong He",
        "abstract": "In the last three years, the largest dense deep learning models have grown\nover 1000x to reach hundreds of billions of parameters, while the GPU memory\nhas only grown by 5x (16 GB to 80 GB). Therefore, the growth in model scale has\nbeen supported primarily though system innovations that allow large models to\nfit in the aggregate GPU memory of multiple GPUs. However, we are getting close\nto the GPU memory wall. It requires 800 NVIDIA V100 GPUs just to fit a trillion\nparameter model for training, and such clusters are simply out of reach for\nmost data scientists. In addition, training models at that scale requires\ncomplex combinations of parallelism techniques that puts a big burden on the\ndata scientists to refactor their model.\n  In this paper we present ZeRO-Infinity, a novel heterogeneous system\ntechnology that leverages GPU, CPU, and NVMe memory to allow for unprecedented\nmodel scale on limited resources without requiring model code refactoring. At\nthe same time it achieves excellent training throughput and scalability,\nunencumbered by the limited CPU or NVMe bandwidth. ZeRO-Infinity can fit models\nwith tens and even hundreds of trillions of parameters for training on current\ngeneration GPU clusters. It can be used to fine-tune trillion parameter models\non a single NVIDIA DGX-2 node, making large models more accessible. In terms of\ntraining throughput and scalability, it sustains over 25 petaflops on 512\nNVIDIA V100 GPUs(40% of peak), while also demonstrating super linear\nscalability. An open source implementation of ZeRO-Infinity is available\nthrough DeepSpeed, a deep learning optimization library that makes distributed\ntraining easy, efficient, and effective.",
        "timestamp": "2025-01-20T07:31:26.129Z",
        "rating": "novote",
        "published_date": "2021-04-16T02:22:12Z",
        "arxiv_tags": [
          "cs.DC",
          "cs.AI",
          "cs.LG",
          "cs.PF"
        ]
      },
      "meta": {
        "created_at": "2025-01-20T07:31:26+00:00",
        "updated_at": "2025-01-20T07:31:29+00:00",
        "version": 2
      }
    },
    "interactions:2501.00663": {
      "data": {
        "paper_id": "2501.00663",
        "interactions": []
      },
      "meta": {
        "created_at": "2025-01-20T07:23:16+00:00",
        "updated_at": "2025-01-20T07:23:18+00:00",
        "version": 2
      }
    },
    "paper:2501.00663": {
      "data": {
        "arxivId": "2501.00663",
        "url": "https://arxiv.org/abs/2501.00663",
        "title": "Titans: Learning to Memorize at Test Time",
        "authors": "Ali Behrouz, Peilin Zhong, Vahab Mirrokni",
        "abstract": "Over more than a decade there has been an extensive research effort on how to\neffectively utilize recurrent models and attention. While recurrent models aim\nto compress the data into a fixed-size memory (called hidden state), attention\nallows attending to the entire context window, capturing the direct\ndependencies of all tokens. This more accurate modeling of dependencies,\nhowever, comes with a quadratic cost, limiting the model to a fixed-length\ncontext. We present a new neural long-term memory module that learns to\nmemorize historical context and helps attention to attend to the current\ncontext while utilizing long past information. We show that this neural memory\nhas the advantage of fast parallelizable training while maintaining a fast\ninference. From a memory perspective, we argue that attention due to its\nlimited context but accurate dependency modeling performs as a short-term\nmemory, while neural memory due to its ability to memorize the data, acts as a\nlong-term, more persistent, memory. Based on these two modules, we introduce a\nnew family of architectures, called Titans, and present three variants to\naddress how one can effectively incorporate memory into this architecture. Our\nexperimental results on language modeling, common-sense reasoning, genomics,\nand time series tasks show that Titans are more effective than Transformers and\nrecent modern linear recurrent models. They further can effectively scale to\nlarger than 2M context window size with higher accuracy in needle-in-haystack\ntasks compared to baselines.",
        "timestamp": "2025-01-20T07:22:12.333Z",
        "rating": "novote",
        "published_date": "2024-12-31T22:32:03Z",
        "arxiv_tags": [
          "cs.LG",
          "cs.AI",
          "cs.CL"
        ]
      },
      "meta": {
        "created_at": "2025-01-20T07:22:12+00:00",
        "updated_at": "2025-01-20T07:22:15+00:00",
        "version": 2
      }
    },
    "paper:2412.06769": {
      "data": {
        "arxivId": "2412.06769",
        "url": "https://arxiv.org/abs/2412.06769",
        "title": "Training Large Language Models to Reason in a Continuous Latent Space",
        "authors": "Shibo Hao, Sainbayar Sukhbaatar, DiJia Su, Xian Li, Zhiting Hu, Jason Weston, Yuandong Tian",
        "abstract": "Large language models (LLMs) are restricted to reason in the \"language\nspace\", where they typically express the reasoning process with a\nchain-of-thought (CoT) to solve a complex reasoning problem. However, we argue\nthat language space may not always be optimal for reasoning. For example, most\nword tokens are primarily for textual coherence and not essential for\nreasoning, while some critical tokens require complex planning and pose huge\nchallenges to LLMs. To explore the potential of LLM reasoning in an\nunrestricted latent space instead of using natural language, we introduce a new\nparadigm Coconut (Chain of Continuous Thought). We utilize the last hidden\nstate of the LLM as a representation of the reasoning state (termed \"continuous\nthought\"). Rather than decoding this into a word token, we feed it back to the\nLLM as the subsequent input embedding directly in the continuous space.\nExperiments show that Coconut can effectively augment the LLM on several\nreasoning tasks. This novel latent reasoning paradigm leads to emergent\nadvanced reasoning patterns: the continuous thought can encode multiple\nalternative next reasoning steps, allowing the model to perform a breadth-first\nsearch (BFS) to solve the problem, rather than prematurely committing to a\nsingle deterministic path like CoT. Coconut outperforms CoT in certain logical\nreasoning tasks that require substantial backtracking during planning, with\nfewer thinking tokens during inference. These findings demonstrate the promise\nof latent reasoning and offer valuable insights for future research.",
        "timestamp": "2025-01-20T07:20:45.082Z",
        "rating": "novote",
        "published_date": "2024-12-09T18:55:56Z",
        "arxiv_tags": [
          "cs.CL"
        ]
      },
      "meta": {
        "created_at": "2025-01-20T07:20:45+00:00",
        "updated_at": "2025-01-20T07:20:48+00:00",
        "version": 2
      }
    },
    "interactions:2412.06769": {
      "data": {
        "paper_id": "2412.06769",
        "interactions": [
          {
            "type": "reading_session",
            "timestamp": "2025-01-20T07:21:08.269Z",
            "data": {
              "duration_seconds": 11
            }
          }
        ]
      },
      "meta": {
        "created_at": "2025-01-20T07:21:02+00:00",
        "updated_at": "2025-01-24T08:18:14+00:00",
        "version": 5
      }
    },
    "interactions:2501.09891": {
      "data": {
        "paper_id": "2501.09891",
        "interactions": [
          {
            "type": "reading_session",
            "timestamp": "2025-01-20T07:18:47.104Z",
            "data": {
              "duration_seconds": 50
            }
          }
        ]
      },
      "meta": {
        "created_at": "2025-01-20T07:17:51+00:00",
        "updated_at": "2025-01-24T08:18:22+00:00",
        "version": 4
      }
    },
    "paper:2501.09891": {
      "data": {
        "arxivId": "2501.09891",
        "url": "https://arxiv.org/abs/2501.09891",
        "title": "Evolving Deeper LLM Thinking",
        "authors": "Kuang-Huei Lee, Ian Fischer, Yueh-Hua Wu, Dave Marwood, Shumeet Baluja, Dale Schuurmans, Xinyun Chen",
        "abstract": "We explore an evolutionary search strategy for scaling inference time compute\nin Large Language Models. The proposed approach, Mind Evolution, uses a\nlanguage model to generate, recombine and refine candidate responses. The\nproposed approach avoids the need to formalize the underlying inference problem\nwhenever a solution evaluator is available. Controlling for inference cost, we\nfind that Mind Evolution significantly outperforms other inference strategies\nsuch as Best-of-N and Sequential Revision in natural language planning tasks.\nIn the TravelPlanner and Natural Plan benchmarks, Mind Evolution solves more\nthan 98% of the problem instances using Gemini 1.5 Pro without the use of a\nformal solver.",
        "timestamp": "2025-01-20T07:17:04.098Z",
        "rating": "novote",
        "published_date": "2025-01-17T00:41:44Z",
        "arxiv_tags": [
          "cs.AI"
        ]
      },
      "meta": {
        "created_at": "2025-01-20T07:17:04+00:00",
        "updated_at": "2025-01-20T07:17:07+00:00",
        "version": 2
      }
    },
    "interactions:2403.09635": {
      "data": {
        "paper_id": "2403.09635",
        "interactions": [
          {
            "type": "reading_session",
            "timestamp": "2025-01-20T07:13:23.907Z",
            "data": {
              "duration_seconds": 13
            }
          }
        ]
      },
      "meta": {
        "created_at": "2025-01-20T07:13:01+00:00",
        "updated_at": "2025-01-24T08:18:34+00:00",
        "version": 4
      }
    },
    "paper:2403.09635": {
      "data": {
        "arxivId": "2403.09635",
        "url": "https://arxiv.org/abs/2403.09635",
        "title": "Transformers Get Stable: An End-to-End Signal Propagation Theory for\n  Language Models",
        "authors": "Akhil Kedia, Mohd Abbas Zaidi, Sushil Khyalia, Jungho Jung, Harshith Goka, Haejun Lee",
        "abstract": "In spite of their huge success, transformer models remain difficult to scale\nin depth. In this work, we develop a unified signal propagation theory and\nprovide formulae that govern the moments of the forward and backward signal\nthrough the transformer model. Our framework can be used to understand and\nmitigate vanishing/exploding gradients, rank collapse, and instability\nassociated with high attention scores. We also propose DeepScaleLM, an\ninitialization and scaling scheme that conserves unit output/gradient moments\nthroughout the model, enabling the training of very deep models with 1000\nlayers. We find that transformer models could be much deeper - our deep models\nwith fewer parameters outperform shallow models in Language Modeling, Speech\nTranslation, and Image Classification, across encoder-only, decoder-only and\nencoder-decoder variants, for both Pre-LN and Post-LN transformers, for\nmultiple datasets and model sizes. These improvements also translate into\nimproved performance on downstream Question Answering tasks and improved\nrobustness for Image Classification.",
        "timestamp": "2025-01-20T07:12:49.004Z",
        "rating": "novote",
        "published_date": "2024-03-14T17:59:14Z",
        "arxiv_tags": [
          "cs.CL",
          "cs.AI",
          "cs.CV",
          "cs.LG",
          "I.2.7; I.2.10"
        ]
      },
      "meta": {
        "created_at": "2025-01-20T07:12:49+00:00",
        "updated_at": "2025-01-20T07:12:52+00:00",
        "version": 2
      }
    },
    "interactions:2006.08570": {
      "data": {
        "paper_id": "2006.08570",
        "interactions": [
          {
            "type": "reading_session",
            "timestamp": "2025-01-20T05:50:39.552Z",
            "data": {
              "duration_seconds": 32
            }
          }
        ]
      },
      "meta": {
        "created_at": "2025-01-20T05:50:00+00:00",
        "updated_at": "2025-01-24T08:18:48+00:00",
        "version": 8
      }
    },
    "paper:2006.08570": {
      "data": {
        "arxivId": "2006.08570",
        "url": "https://arxiv.org/abs/2006.08570",
        "title": "Cross-temporal forecast reconciliation: Optimal combination method and\n  heuristic alternatives",
        "authors": "Tommaso Di Fonzo, Daniele Girolimetto",
        "abstract": "Forecast reconciliation is a post-forecasting process aimed to improve the\nquality of the base forecasts for a system of hierarchical/grouped time series\n(Hyndman et al., 2011). Contemporaneous (cross-sectional) and temporal\nhierarchies have been considered in the literature, but - except for Kourentzes\nand Athanasopoulos (2019) - generally these two features have not been fully\nconsidered together. Adopting a notation able to simultaneously deal with both\nforecast reconciliation dimensions, the paper shows two new results: (i) an\niterative cross-temporal forecast reconciliation procedure which extends, and\novercomes some weaknesses of, the two-step procedure by Kourentzes and\nAthanasopoulos (2019), and (ii) the closed-form expression of the optimal (in\nleast squares sense) point forecasts which fulfill both contemporaneous and\ntemporal constraints. The feasibility of the proposed procedures, along with\nfirst evaluations of their performance as compared to the most performing\n`single dimension' (either cross-sectional or temporal) forecast reconciliation\nprocedures, is studied through a forecasting experiment on the 95 quarterly\ntime series of the Australian GDP from Income and Expenditure sides considered\nby Athanasopoulos et al. (2019).",
        "timestamp": "2025-01-20T05:49:19.264Z",
        "rating": "novote",
        "published_date": "2020-06-15T17:34:05Z",
        "arxiv_tags": [
          "stat.ME"
        ]
      },
      "meta": {
        "created_at": "2025-01-20T05:49:20+00:00",
        "updated_at": "2025-01-20T05:49:23+00:00",
        "version": 2
      }
    },
    "interactions:2006.02043": {
      "data": {
        "paper_id": "2006.02043",
        "interactions": []
      },
      "meta": {
        "created_at": "2025-01-20T00:20:33+00:00",
        "updated_at": "2025-01-20T00:20:36+00:00",
        "version": 2
      }
    },
    "paper:2006.02043": {
      "data": {
        "arxivId": "2006.02043",
        "url": "https://arxiv.org/pdf/2006.02043",
        "title": "Hierarchical forecast reconciliation with machine learning",
        "authors": "Evangelos Spiliotis, Mahdi Abolghasemi, Rob J Hyndman, Fotios Petropoulos, Vassilios Assimakopoulos",
        "abstract": "Hierarchical forecasting methods have been widely used to support aligned\ndecision-making by providing coherent forecasts at different aggregation\nlevels. Traditional hierarchical forecasting approaches, such as the bottom-up\nand top-down methods, focus on a particular aggregation level to anchor the\nforecasts. During the past decades, these have been replaced by a variety of\nlinear combination approaches that exploit information from the complete\nhierarchy to produce more accurate forecasts. However, the performance of these\ncombination methods depends on the particularities of the examined series and\ntheir relationships. This paper proposes a novel hierarchical forecasting\napproach based on machine learning that deals with these limitations in three\nimportant ways. First, the proposed method allows for a non-linear combination\nof the base forecasts, thus being more general than the linear approaches.\nSecond, it structurally combines the objectives of improved post-sample\nempirical forecasting accuracy and coherence. Finally, due to its non-linear\nnature, our approach selectively combines the base forecasts in a direct and\nautomated way without requiring that the complete information must be used for\nproducing reconciled forecasts for each series and level. The proposed method\nis evaluated both in terms of accuracy and bias using two different data sets\ncoming from the tourism and retail industries. Our results suggest that the\nproposed method gives superior point forecasts than existing approaches,\nespecially when the series comprising the hierarchy are not characterized by\nthe same patterns.",
        "timestamp": "2025-01-20T00:20:16.561Z",
        "rating": "novote",
        "published_date": "2020-06-03T04:49:39Z",
        "arxiv_tags": [
          "cs.LG",
          "stat.CO",
          "stat.ML"
        ]
      },
      "meta": {
        "created_at": "2025-01-20T00:20:17+00:00",
        "updated_at": "2025-01-20T00:20:20+00:00",
        "version": 2
      }
    },
    "paper:1801.02042": {
      "data": {
        "arxivId": "1801.02042",
        "url": "https://arxiv.org/pdf/1801.02042",
        "title": "Learning from Neighbors about a Changing State",
        "authors": "Krishna Dasaratha, Benjamin Golub, Nir Hak",
        "abstract": "Agents learn about a changing state using private signals and their\nneighbors' past estimates of the state. We present a model in which Bayesian\nagents in equilibrium use neighbors' estimates simply by taking weighted sums\nwith time-invariant weights. The dynamics thus parallel those of the tractable\nDeGroot model of learning in networks, but arise as an equilibrium outcome\nrather than a behavioral assumption. We examine whether information aggregation\nis nearly optimal as neighborhoods grow large. A key condition for this is\nsignal diversity: each individual's neighbors have private signals that not\nonly contain independent information, but also have sufficiently different\ndistributions. Without signal diversity $\\unicode{x2013}$ e.g., if private\nsignals are i.i.d. $\\unicode{x2013}$ learning is suboptimal in all networks and\nhighly inefficient in some. Turning to social influence, we find it is much\nmore sensitive to one's signal quality than to one's number of neighbors, in\ncontrast to standard models with exogenous updating rules.",
        "timestamp": "2025-01-19T20:59:30.013Z",
        "rating": "novote",
        "published_date": "2018-01-06T16:14:47Z",
        "arxiv_tags": [
          "econ.TH",
          "cs.GT",
          "cs.SI"
        ]
      },
      "meta": {
        "created_at": "2025-01-19T20:59:30+00:00",
        "updated_at": "2025-01-19T20:59:33+00:00",
        "version": 2
      }
    },
    "interactions:1710.06026": {
      "data": {
        "paper_id": "1710.06026",
        "interactions": []
      },
      "meta": {
        "created_at": "2025-01-19T20:57:30+00:00",
        "updated_at": "2025-01-19T20:57:33+00:00",
        "version": 2
      }
    },
    "paper:1710.06026": {
      "data": {
        "arxivId": "1710.06026",
        "url": "https://arxiv.org/abs/1710.06026",
        "title": "Targeting Interventions in Networks",
        "authors": "Andrea Galeotti, Benjamin Golub, Sanjeev Goyal",
        "abstract": "We study games in which a network mediates strategic spillovers and\nexternalities among the players. How does a planner optimally target\ninterventions that change individuals' private returns to investment? We\nanalyze this question by decomposing any intervention into orthogonal principal\ncomponents, which are determined by the network and are ordered according to\ntheir associated eigenvalues. There is a close connection between the nature of\nspillovers and the representation of various principal components in the\noptimal intervention. In games of strategic complements (substitutes),\ninterventions place more weight on the top (bottom) principal components, which\nreflect more global (local) network structure. For large budgets, optimal\ninterventions are simple -- they involve a single principal component.",
        "timestamp": "2025-01-19T20:56:52.926Z",
        "rating": "novote",
        "published_date": "2017-10-16T23:18:55Z",
        "arxiv_tags": [
          "cs.GT"
        ]
      },
      "meta": {
        "created_at": "2025-01-19T20:56:53+00:00",
        "updated_at": "2025-01-19T20:56:56+00:00",
        "version": 2
      }
    },
    "interactions:2307.13912": {
      "data": {
        "paper_id": "2307.13912",
        "interactions": [
          {
            "type": "reading_session",
            "timestamp": "2025-01-19T15:26:37.045Z",
            "data": {
              "duration_seconds": 9
            }
          }
        ]
      },
      "meta": {
        "created_at": "2025-01-19T15:26:37+00:00",
        "updated_at": "2025-01-24T08:19:20+00:00",
        "version": 3
      }
    },
    "paper:2307.13912": {
      "data": {
        "arxivId": "2307.13912",
        "url": "https://arxiv.org/abs/2307.13912",
        "title": "Embedding Democratic Values into Social Media AIs via Societal Objective\n  Functions",
        "authors": "Chenyan Jia, Michelle S. Lam, Minh Chau Mai, Jeff Hancock, Michael S. Bernstein",
        "abstract": "Can we design artificial intelligence (AI) systems that rank our social media\nfeeds to consider democratic values such as mitigating partisan animosity as\npart of their objective functions? We introduce a method for translating\nestablished, vetted social scientific constructs into AI objective functions,\nwhich we term societal objective functions, and demonstrate the method with\napplication to the political science construct of anti-democratic attitudes.\nTraditionally, we have lacked observable outcomes to use to train such models,\nhowever, the social sciences have developed survey instruments and qualitative\ncodebooks for these constructs, and their precision facilitates translation\ninto detailed prompts for large language models. We apply this method to create\na democratic attitude model that estimates the extent to which a social media\npost promotes anti-democratic attitudes, and test this democratic attitude\nmodel across three studies. In Study 1, we first test the attitudinal and\nbehavioral effectiveness of the intervention among US partisans (N=1,380) by\nmanually annotating (alpha=.895) social media posts with anti-democratic\nattitude scores and testing several feed ranking conditions based on these\nscores. Removal (d=.20) and downranking feeds (d=.25) reduced participants'\npartisan animosity without compromising their experience and engagement. In\nStudy 2, we scale up the manual labels by creating the democratic attitude\nmodel, finding strong agreement with manual labels (rho=.75). Finally, in Study\n3, we replicate Study 1 using the democratic attitude model instead of manual\nlabels to test its attitudinal and behavioral impact (N=558), and again find\nthat the feed downranking using the societal objective function reduced\npartisan animosity (d=.25). This method presents a novel strategy to draw on\nsocial science theory and methods to mitigate societal harms in social media\nAIs.",
        "timestamp": "2025-01-19T15:26:24.313Z",
        "rating": "novote",
        "published_date": "2023-07-26T02:27:24Z",
        "arxiv_tags": [
          "cs.HC",
          "cs.AI"
        ]
      },
      "meta": {
        "created_at": "2025-01-19T15:26:24+00:00",
        "updated_at": "2025-01-19T15:26:27+00:00",
        "version": 2
      }
    },
    "interactions:2410.05437": {
      "data": {
        "paper_id": "2410.05437",
        "interactions": [
          {
            "type": "reading_session",
            "timestamp": "2025-01-19T09:46:23.440Z",
            "data": {
              "duration_seconds": 17
            }
          }
        ]
      },
      "meta": {
        "created_at": "2025-01-19T09:46:19+00:00",
        "updated_at": "2025-01-24T08:19:25+00:00",
        "version": 4
      }
    },
    "paper:2410.05437": {
      "data": {
        "arxivId": "2410.05437",
        "url": "https://arxiv.org/abs/2410.05437",
        "title": "ESPACE: Dimensionality Reduction of Activations for Model Compression",
        "authors": "Charbel Sakr, Brucek Khailany",
        "abstract": "We propose ESPACE, an LLM compression technique based on dimensionality\nreduction of activations. Unlike prior works on weight-centric tensor\ndecomposition, ESPACE projects activations onto a pre-calibrated set of\nprincipal components. The activation-centrality of the approach enables\nretraining LLMs with no loss of expressivity; while at inference, weight\ndecomposition is obtained as a byproduct of matrix multiplication\nassociativity. Theoretical results on the construction of projection matrices\nwith optimal computational accuracy are provided. Experimentally, we find\nESPACE enables 50% compression of GPT3, Llama2, and Nemotron4 models with small\naccuracy degradation, as low as a 0.18 perplexity increase on GPT3-22B. At\nlower compression rates of 20% to 40%, ESPACE drives GPT3 models to\noutperforming their baseline, by up to a 0.38 decrease in perplexity for\nGPT3-8B. ESPACE also reduces GEMM execution time and prefill inference latency\non existing hardware. Comparison with related works on compressing Llama2-7B\nvia matrix factorization shows that ESPACE is a first step in advancing the\nstate-of-the-art in tensor decomposition compression of LLMs.",
        "timestamp": "2025-01-19T09:45:58.441Z",
        "rating": "novote",
        "published_date": "2024-10-07T18:59:22Z",
        "arxiv_tags": [
          "cs.LG"
        ]
      },
      "meta": {
        "created_at": "2025-01-19T09:45:58+00:00",
        "updated_at": "2025-01-19T09:46:01+00:00",
        "version": 2
      }
    },
    "interactions:2406.07522": {
      "data": {
        "paper_id": "2406.07522",
        "interactions": []
      },
      "meta": {
        "created_at": "2025-01-19T03:47:56+00:00",
        "updated_at": "2025-01-19T03:47:58+00:00",
        "version": 2
      }
    },
    "paper:2406.07522": {
      "data": {
        "arxivId": "2406.07522",
        "url": "https://arxiv.org/abs/2406.07522",
        "title": "Samba: Simple Hybrid State Space Models for Efficient Unlimited Context\n  Language Modeling",
        "authors": "Liliang Ren, Yang Liu, Yadong Lu, Yelong Shen, Chen Liang, Weizhu Chen",
        "abstract": "Efficiently modeling sequences with infinite context length has long been a\nchallenging problem. Previous approaches have either suffered from quadratic\ncomputational complexity or limited extrapolation ability in length\ngeneralization. In this work, we present Samba, a simple hybrid architecture\nthat layer-wise combines Mamba, a selective State Space Model (SSM), with\nSliding Window Attention (SWA). Samba selectively compresses a given sequence\ninto recurrent hidden states while still maintaining the ability to precisely\nrecall recent memories with the attention mechanism. We scale Samba up to 3.8B\nparameters with 3.2T training tokens and demonstrate that it significantly\noutperforms state-of-the-art models across a variety of benchmarks. Pretrained\non sequences of 4K length, Samba shows improved perplexity in context lengths\nof up to 1M in zero-shot. When finetuned on 4K-length sequences, Samba\nefficiently extrapolates to a 256K context length with perfect memory recall on\nthe Passkey Retrieval task, and exhibits superior retrieval extrapolation on\nthe challenging Phonebook task compared to full-attention models. As a\nlinear-time sequence model, Samba achieves a 3.73x higher throughput compared\nto Transformers with grouped-query attention for user prompts of 128K length,\nand a 3.64x speedup when generating 64K tokens with unlimited streaming. Our\ncode for training on open source data is publicly available at\nhttps://github.com/microsoft/Samba.",
        "timestamp": "2025-01-19T03:47:40.608Z",
        "rating": "novote",
        "published_date": "2024-06-11T17:50:51Z",
        "arxiv_tags": [
          "cs.CL",
          "cs.LG"
        ]
      },
      "meta": {
        "created_at": "2025-01-19T03:47:41+00:00",
        "updated_at": "2025-01-19T03:47:43+00:00",
        "version": 2
      }
    },
    "interactions:1503.03585": {
      "data": {
        "paper_id": "1503.03585",
        "interactions": [
          {
            "type": "reading_session",
            "timestamp": "2025-01-19T02:31:42.622Z",
            "data": {
              "duration_seconds": 13,
              "session_config": {
                "idle_threshold_seconds": 300,
                "min_duration_seconds": 3,
                "continuous_activity_required": true,
                "partial_sessions_logged": false
              }
            }
          }
        ]
      },
      "meta": {
        "created_at": "2025-01-19T02:31:20+00:00",
        "updated_at": "2025-01-24T08:19:55+00:00",
        "version": 4
      }
    },
    "paper:1503.03585": {
      "data": {
        "arxivId": "1503.03585",
        "url": "https://arxiv.org/abs/1503.03585",
        "title": "Deep Unsupervised Learning using Nonequilibrium Thermodynamics",
        "authors": "Jascha Sohl-Dickstein, Eric A. Weiss, Niru Maheswaranathan, Surya Ganguli",
        "abstract": "A central problem in machine learning involves modeling complex data-sets\nusing highly flexible families of probability distributions in which learning,\nsampling, inference, and evaluation are still analytically or computationally\ntractable. Here, we develop an approach that simultaneously achieves both\nflexibility and tractability. The essential idea, inspired by non-equilibrium\nstatistical physics, is to systematically and slowly destroy structure in a\ndata distribution through an iterative forward diffusion process. We then learn\na reverse diffusion process that restores structure in data, yielding a highly\nflexible and tractable generative model of the data. This approach allows us to\nrapidly learn, sample from, and evaluate probabilities in deep generative\nmodels with thousands of layers or time steps, as well as to compute\nconditional and posterior probabilities under the learned model. We\nadditionally release an open source reference implementation of the algorithm.",
        "timestamp": "2025-01-19T02:31:15.039Z",
        "rating": "novote",
        "published_date": "2015-03-12T04:51:37Z",
        "arxiv_tags": [
          "cs.LG",
          "cond-mat.dis-nn",
          "q-bio.NC",
          "stat.ML"
        ]
      },
      "meta": {
        "created_at": "2025-01-19T02:31:15+00:00",
        "updated_at": "2025-01-19T02:31:18+00:00",
        "version": 2
      }
    },
    "interactions:2405.07987": {
      "data": {
        "paper_id": "2405.07987",
        "interactions": [
          {
            "type": "reading_session",
            "timestamp": "2025-01-25T03:33:43.312Z",
            "data": {
              "session_id": "session_1737775995128_823e123",
              "duration_seconds": 23,
              "idle_seconds": 0,
              "start_time": "2025-01-25T03:33:15.128Z",
              "end_time": "2025-01-25T03:33:37.681Z",
              "total_elapsed_seconds": 23
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-01-25T03:34:26.731Z",
            "data": {
              "session_id": "session_1737776038591_jr5426l",
              "duration_seconds": 28,
              "idle_seconds": 0,
              "start_time": "2025-01-25T03:33:58.591Z",
              "end_time": "2025-01-25T03:34:26.720Z",
              "total_elapsed_seconds": 28
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-01-25T03:34:53.954Z",
            "data": {
              "session_id": "session_1737776069173_63927kh",
              "duration_seconds": 22,
              "idle_seconds": 0,
              "start_time": "2025-01-25T03:34:29.173Z",
              "end_time": "2025-01-25T03:34:51.012Z",
              "total_elapsed_seconds": 22
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-01-25T05:07:48.512Z",
            "data": {
              "session_id": "session_1737781656680_dfgmzhc",
              "duration_seconds": 12,
              "idle_seconds": 0,
              "start_time": "2025-01-25T05:07:36.680Z",
              "end_time": "2025-01-25T05:07:48.504Z",
              "total_elapsed_seconds": 12
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-01-25T05:20:22.857Z",
            "data": {
              "session_id": "session_1737782408397_970dbde",
              "duration_seconds": 14,
              "idle_seconds": 0,
              "start_time": "2025-01-25T05:20:08.397Z",
              "end_time": "2025-01-25T05:20:22.245Z",
              "total_elapsed_seconds": 14
            }
          },
          {
            "type": "reading_session",
            "timestamp": "2025-01-25T05:28:39.568Z",
            "data": {
              "session_id": "session_1737782910571_c1pwhng",
              "duration_seconds": 8,
              "idle_seconds": 0,
              "start_time": "2025-01-25T05:28:30.571Z",
              "end_time": "2025-01-25T05:28:38.176Z",
              "total_elapsed_seconds": 8
            }
          }
        ]
      },
      "meta": {
        "created_at": "2025-01-25T03:33:39+00:00",
        "updated_at": "2025-01-25T05:29:07+00:00",
        "version": 14
      }
    },
    "paper:2405.07987": {
      "data": {
        "arxivId": "2405.07987",
        "url": "https://arxiv.org/abs/2405.07987",
        "title": "The Platonic Representation Hypothesis",
        "authors": "Minyoung Huh, Brian Cheung, Tongzhou Wang, Phillip Isola",
        "abstract": "We argue that representations in AI models, particularly deep networks, are\nconverging. First, we survey many examples of convergence in the literature:\nover time and across multiple domains, the ways by which different neural\nnetworks represent data are becoming more aligned. Next, we demonstrate\nconvergence across data modalities: as vision models and language models get\nlarger, they measure distance between datapoints in a more and more alike way.\nWe hypothesize that this convergence is driving toward a shared statistical\nmodel of reality, akin to Plato's concept of an ideal reality. We term such a\nrepresentation the platonic representation and discuss several possible\nselective pressures toward it. Finally, we discuss the implications of these\ntrends, their limitations, and counterexamples to our analysis.",
        "timestamp": "2025-01-25T03:33:15.181Z",
        "rating": "thumbsup",
        "published_date": "2024-05-13T17:58:30Z",
        "arxiv_tags": [
          "cs.LG",
          "cs.AI",
          "cs.CV",
          "cs.NE"
        ]
      },
      "meta": {
        "created_at": "2025-01-25T03:33:15+00:00",
        "updated_at": "2025-01-25T05:08:15+00:00",
        "version": 4
      }
    }
  }
}