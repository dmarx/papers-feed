- **Key Concepts:**
  - Language models (LMs) often rely on surface-level heuristics early in training, resembling n-gram models.
  - Transition from surface-level heuristics to hierarchical syntactic representations is termed **structural grokking**.
  
- **Data Characteristics:**
  - **Data Diversity:** Variation in syntactic structure influences model behavior; low diversity leads to memorization, while high diversity promotes generalization.
  - **Data Complexity:** Complexity, measured by center-embedded sentences, induces hierarchical rules; simpler data leads to surface-level rules.

- **Generalization Behavior:**
  - Models exhibit stable in-distribution behavior but inconsistent out-of-distribution (OOD) performance across random seeds.
  - OOD performance stabilizes only when models commit to either a surface-level heuristic or a hierarchical rule.

- **Training Dynamics:**
  - Intermediate levels of data diversity can lead to greater instability than low or high diversity.
  - Competition between different generalization rules results in unstable training dynamics and inconsistent outcomes.

- **Experimental Tasks:**
  - **Question Formation (QF) Task:** 
    - Two strategies: linear rule (first auxiliary verb) vs. hierarchical rule (based on syntax tree).
    - OOD accuracy measures hierarchical generalization.
  - **Tense Inflection (TI) Task:**
    - Requires identification of subject for correct verb inflection.
    - Similar structure to QF task regarding ambiguous vs. unambiguous examples.

- **Model Architecture:**
  - Decoder-only Transformer with 8 heads, 512-dimensional embedding.
  - QF models: 6 layers; TI models: 4 layers.
  - Trained on causal language modeling objective for 300K steps using Adam optimizer.

- **Findings:**
  - Data composition critically shapes OOD generalization behavior.
  - Models trained on less diverse data may stabilize in a memorization regime without learning systematic rules.

- **References to Prior Work:**
  - Structural grokking parallels classic grokking, where models transition from memorization to generalization.
  - Previous studies highlight the role of data diversity in achieving OOD compositional generalization.

- **Code Repository:**
  - Available at [GitHub](https://github.com/sunnytqin/concept_comp.git).