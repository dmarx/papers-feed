
\section{Experimental Setup}
\label{sec:experiments}
The question formation task and the tense inflection task were first proposed by \citet{Frank2007-pn} and \citet{Linzen2016-vx} as canonical tests of language modeling ability. We use existing synthetic datasets for question formation from \citet{McCoy2018-uv} and tense inflection from \citet{McCoy2020-pj}.
\subsection{Question Formation Task}
\label{sec:qf_task}
\begin{table}[t]
    \centering
    {\renewcommand{\arraystretch}{1.12}
    \small
      \caption{\textbf{Examples from two grammar case studies.} \textit{Top}: In the question formation task, the model moves the main auxiliary verb to the front to form a question.
      \textit{Bottom}:  In the tense inflection task, the model inflects the main verb from past to present tense, while respecting subject-verb agreement. }  
    \label{tab:task_examples}
    \resizebox{\textwidth}{!}{
    \begin{tabular}{p{2.5cm} p{2.3cm} p{9cm}}
    \toprule
    \textbf{Dataset} & \textbf{Task Type} & \hspace{3.5cm} \textbf{Examples} \\ 
    \hline
    \multirow{2}{*}{Question Formation} & Quest  & \textbf{Input:} My unicorn \textcolor{ForestGreen}{does} move the dogs that \textcolor{red}{do} wait.  \\ 
                             &(Ambiguous)  &\textbf{Output:} \textcolor{ForestGreen}{Does} my unicorn move the dogs that \textcolor{red}{do} wait?     \\
                             \cline{2-3} 
                             & \multirow{2}{*}{Quest }   &\textbf{Input:} My unicorn who \textcolor{red}{doesn't} sing \textcolor{ForestGreen}{does} move.
 \\ 
                             & & \textbf{Linear Output:} \textcolor{red}{Doesn't} my unicorn who sing \textcolor{ForestGreen}{does} move?
 \\
                             & (Unambiguous)& \textbf{Hierarchical Output:} \textcolor{ForestGreen}{Does} my unicorn who \textcolor{red}{doesn't} sing move? \\
                              
                             % & \multirow{2}{*}{Decl}   & \textbf{Input:} My unicorn does move the dogs that do wait. \\ 
                             % & & \textbf{Output:} My unicorn does move the dogs that do wait.    \\
    \hline
    \multirow{5}{*}{Tense Inflection} & Present & \textbf{Input:} My zebra behind the peacock smiled. \\ 
                        & (Ambiguous) & \textbf{Output:} My \textcolor{cyan}{zebra} behind the \textcolor{cyan}{peacock}  \textcolor{ForestGreen}{smiles}.    \\
                        \cline{2-3} 
                        & \multirow{1.5}{*}{Present}   & \textbf{Input:} My zebra behind the peacocks smiled. \\ 
                        & & \textbf{Linear output:} My zebra behind the \textcolor{cyan}{peacocks} \textcolor{red}{smile}.     \\
                        &  (Unambiguous) & \textbf{Hierarchical output:} My \textcolor{red}{zebra} behind the peacocks \textcolor{ForestGreen}{smiles}.     \\
                        % & \multirow{2}{*}{Decl}   & Input: My unicorn does move the dogs that do wait. \\ 
                        % & & Output: My unicorn does move the dogs that do wait.    \\
    \bottomrule
    \end{tabular}
    \vspace{-5px}
    }}
\end{table}


In the \textbf{question formation (QF)} task, the model transforms a declarative sentence into a question (see Table~\ref{tab:task_examples}) by moving the main auxiliary verb (such as \textit{does} in \textit{does move}) to the front. Our training data (based on \citet{McCoy2018-uv}) permits two strategies for choosing which verb to move: (1) a linear rule that moves the first auxiliary verb (Figure \ref{fig:stability_demo} \textit{upper right}), or (2) a hierarchical rule---the correct rule in English grammar---based on the sentence's syntax tree (Figure \ref{fig:stability_demo} \textit{lower right}). The model leverages this tree representation to select the main auxiliary verb.

Examples of each rule are provided in Table \ref{tab:task_examples}. The first example is considered \textbf{ambiguous} because the hierarchical and linear rules produce the same correct outcome. In contrast, the second example is \textbf{unambiguous} because only the hierarchical rule produces the correct outcome. The training and in-distribution test data contain only ambiguous samples, while the OOD generalization set includes only unambiguous samples. Therefore, if a model uses the hierarchical rule, it will achieve $100\%$ accuracy on both the in-distribution (ambiguous questions) and OOD (unambiguous questions) sets. Conversely, if a model uses the linear rule, it will still achieve 100\% accuracy on the in-distribution set, but will score $0\%$ on the OOD set. 
We therefore use the model's accuracy on the OOD set to measure hierarchical generalization.


\subsection{Tense Inflection Task}
\label{sec:ti_task}

In the \textbf{tense inflection (TI)} task, the model transforms a past-tense sentence into the present tense by changing the inflection of its main verb. 
Since past-tense verbs in English have the same form in singular and plural, the model must identify the subject to determine whether the present-tense verb should be inflected as singular or plural. The TI model could follow either a hierarchical or linear rule for subject-verb agreement in the training data (based on \citet{McCoy2020-pj}). The linear rule inflects the verb based on the most recent noun, while the hierarchical rule correctly inflects the verb according to its subject. As in the QF task, the training and in-distribution test sets contain ambiguous examples, whereas the OOD set contains unambiguous examples. In the ambiguous example from Table \ref{tab:task_examples}, the subject noun \textit{zebra} and the most recent noun \textit{peacock} must share the same plurality and therefore either rule produces the correct answer. In the OOD unambiguous example, the subject and the most recent noun differ in plurality and therefore only the hierarchical rule produces the correct answer.
Similar to the QF task, we use the model's main-verb prediction accuracy on the OOD set as a metric for hierarchical generalization.


\subsection{Models, Data and Training}
\label{sec:model_and_training}
We run all experiments on the same 50 random seeds using hyperparameter settings from the existing literature \citep{Ahuja2024-ul, Murty2023-xp}. We use a decoder-only Transformer architecture where each layer has 8 heads with a 512-dimensional embedding. QF models have 6 layers and TI models have 4 layers. All models are trained from scratch on a causal language modeling objective for 300K steps. We use the Adam optimizer \citep{Kingma2014-he}, a learning rate of 1e-4, and a linear decay schedule. We use a word-level tokenizer with a vocabulary of size 72. 

We use the original training, validation and OOD generalization data proposed by \citet{McCoy2018-uv} and \citet{McCoy2020-pj}. To create variations on the training data, we mimic the data generation process used for the original QF and TI task. Specifically, the original TI and QF data are generated with Context-Free Grammars (CFGs) using a simplified set of grammatical rules; we reuse the same CFG rules to create variations of the training data. 

