\section{Discussion and Conclusions}
% \subsection{Conclusion}
% In conclusion, our study highlights the critical role of data composition in driving neural networks' generalization behaviors, particularly in language models. We show that complex gramwonmatical structures guide models toward hierarchical rules, while mixed data compositions lead to unstable dynamics and inconsistent rule commitment. These findings emphasize the importance of understanding how data diversity shapes both stability and generalization in neural networks.

% \subsection{Limitation and Discussion}
By exploring the role of data structure in determining OOD generalization rules, we have also revealed which settings render model behavior unpredictable. We can predict which rule is learned when diverse training data is composed of either hierarchy-inducing complex samples or linearity-inducing simple samples. However, a data mixture of complex and simple examples will lead to unstable dynamics and inconsistent rules across seeds. Likewise, we can predict that a model trained on low-diversity data will memorize and one trained on diverse data will learn a systematic generalization rule, but an intermediate level of data diversity leads to unstable training and inconsistent OOD generalization behavior. 
% These findings emphasize the importance of understanding how data diversity shapes both stability and generalization in neural networks.
% When different subsets of the data are in competition, we find that the resulting rules can be inconsistent across random /seeds and that training runs which fail to select a rule become unstable. 
Our findings have a number of implications across machine learning and even formal linguistics.


\paragraph{Inconsistent behavior across seeds.} While variation in model error is often treated as unimodal Gaussian noise in the theoretical literature \citep{Lakshminarayanan2016-fb}, our findings suggest that errors may only be distributed unimodally for a given compositional solution. Our work joins the growing literature that suggests random variation can create clusters of OOD behaviors. Previously, clustered distributions have been documented in text classification heuristics \citep{Juneja2022-hj} and training dynamics \citep{Hu2023-vh}. In our case, we note that generalization accuracy is only clearly multimodally distributed when we exclude unstable training runs. We suggest that research on compositional variation in training consider training stability in the future, which may expose addition behaviors as bimodal.


\paragraph{Implications for formal linguistics.}
% The learning theory field, although now seen primarily as an area of statistical machine learning, originated from formal linguistics. 
Our findings have potential implications for linguistics debates about the poverty of the stimulus \citep{McCoy2018-uv, Berwick2011-xb}. Linguists have extensively studied the question of what data is necessary and sufficient to learn grammatical rules. In particular, \citet{wexler1980formal} argue that all English syntactic rules are learnable given ``degree 2'' data: sentences with only one embedded clause nested within another clause. Our center embedding results confirm that without a stronger architectural inductive bias---the very subject of the poverty of the stimulus debate---degree 1 data alone cannot induce a preference for hierarchical structure. However, our work also supports the position of \citet{lightfoot1989child} that lower degree data is adequate for a child to learn a specific rule given sufficiently rich data outside of that rule, as the LM generalizes ID degree 1 QF rule examples to OOD degree 2 by using the hierarchical inductive bias induced by declaration examples. 

\paragraph{Grokking, instability, and latent structure.}
Classic grokking \citep{Power2022-hz} is different from structural grokking: rather than a transition between generalization rules, it describes a transition from memorization to generalization. Our findings clarify both scenarios. 
We link structural grokking to the instability formed by competition between linear- and hierarchical-inducing training subsets. Without competing subsets, the model immediately learns either the linear or the hierarchical rule without the gradual transition of structural grokking. This instability could represent the same phenomenon of circuit competition described by \citet{Ahuja2024-ul}.
We find a similar pattern of instability in our study of data diversity, with implications for classic grokking. In this case, the competition is not between two rules, but instead between memorized heuristics---sufficient for modeling syntactically homogeneous training data---and simple OOD rules---required to efficiently model diverse training data. Yet again, while a strict memorization regime is relatively stable, the regime between memorization and generalization is unstable, leading to potential grokking.

Our findings also suggest that memorization is just another rule that the model can adopt when it is the simplest way of capturing the training distribution. Such a framework unifies the grokking literature with other phenomena such as emergence \citep{Schaeffer2023-od} and benign interpolation \citep{Theunissen2020-pv}; both areas suggest a phase transition between generalization and memorization. Future work could develop a unified theory of data diversity and complexity, describing the Bayesian and information-theoretical optimal models prescribed by those data properties.



