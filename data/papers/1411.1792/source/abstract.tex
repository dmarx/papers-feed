% !TEX root = main.tex

Many deep neural networks trained on natural images exhibit a curious
phenomenon in common: on the first layer they learn features similar
to Gabor filters and color blobs.  Such first-layer features appear
not to be \emph{specific} to a particular dataset or task, but
\emph{general} in that they are applicable to many datasets and tasks.
Features must eventually transition from general to specific by the
last layer of the network, but this transition has not been studied
extensively.  In this paper we experimentally quantify the generality
versus specificity of neurons in each layer of a deep convolutional
neural network and report a few surprising results. Transferability is
negatively affected by two distinct issues: (1) the specialization of
higher layer neurons to their original task at the expense of
performance on the target task, which was expected, and (2)
optimization difficulties related to splitting networks between
co-adapted neurons, which was not expected.  In an example network
trained on ImageNet, we demonstrate that either of these two issues
may dominate, depending on whether features are transferred from the
bottom, middle, or top of the network.  We also document that the
transferability of features decreases as the distance between the base
task and target task increases, but that transferring features even
from distant tasks can be better than using random features. A final
surprising result is that initializing a network with transferred
features from almost any number of layers can produce a boost to
generalization that lingers even after fine-tuning to the target
dataset.

%\comment{Do we need a sentence like ``All told, these results will catalyze ongoing efforts to create ever more powerful deep neural networks.''}

% Or, Jeff's version:

%A high percentage of deep neural networks trained on
%natural images exhibit a curious aspect in common: they all learn
%features similar to Gabor filters on the first layer. Such features
%appear to be \emph{general}, as opposed to \emph{specific} for a
%particular task. Because higher layers are difficult to visualize, not
%as much is known about whether the are general or specific. In this
%paper we experimentally quantify the generality of neurons on each
%layer of a deep convolutional neural network trained on ImageNet. The experiments also reveal a
%few unexpected insights. First, we find that transferability is
%negatively affected by two distinct issues: (a) The higher the layer, the worse it transfers. This result, which is to be expected, occurs because higher-level layers are more specialized to their original task, which hurts performance on the new task. (b) Co-adaptation occurs during training at intermediate layers such that layers must be trained at the same time to maximize performance, even on the same data set, which is a novel finding. 
%%In an
%%example network , we demonstrate that either of
%%these two issues may dominate, depending on whether features are
%%transferred from the bottom, middle, or top of the network.  
%We also
%show how the benefits of transfer learning decrease as the similarity between the original task and the new task decreases, but how even transfer from dissimilar 
%tasks can be better than using random features. Finally, a
%new, surprising result is that initializing a network with transferred
%features can improve generalization, even if those features are further fine-tuned during training on a new task. 
