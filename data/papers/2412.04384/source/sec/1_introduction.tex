\section{Introduction}
\label{sec:intro}
In autonomous driving, vision-centric systems have been more cost-effective compared with the LiDAR-based counterparts.
However, their inability to capture obstacles with arbitrary shapes poses challenges for driving safety and reliability~\cite{li2022bevformer,hu2022uniad,jiang2023vad,li2022bevdepth}. 
The advent of 3D semantic occupancy prediction methods~\cite{cao2022monoscene,miao2023occdepth,zhang2023occformer,wei2023surroundocc,jiang2023symphonize,huang2023tri,li2023voxformer,li2023fb} alleviates this limitation by predicting the fine-grained geometry and semantics of the surrounding 3D environment. 
This advancement supports a range of emerging applications, including end-to-end autonomous driving~\cite{occnet,hu2022uniad}, 4D occupancy forecasting~\cite{occworld,wang2024occsora,yan2024renderworld}, and self-supervised 3D scene understanding~\cite{selfocc,wimbauer2023behind,cao2023scenerf}.

Despite the promising applications, 3D semantic occupancy prediction is essentially a dense three-dimensional segmentation task~\cite{cao2022monoscene,tian2023occ3d}, which necessitates a both efficient and effective representation of the 3D scene.
Voxel-based methods~\cite{li2023voxformer,wei2023surroundocc} use dense 3D voxels as representation to describe the scene with the finest detail.
However, they neglect the spatial redundancy of the 3D occupancy and suffer from high computational complexity.
As a workaround, planer representations, such as BEV~\cite{li2022bevformer,yu2023flashocc} and TPV~\cite{huang2023tri}, compress the 3D grid along one of the axes to derive 2D feature maps for reduction of the token number.
Nonetheless, they still take into account the empty region when modeling the environment, which compromises their model capacity and efficiency.
As a pioneer in object-centric sparse scene representations, 3D semantic Gaussians~\cite{huang2024gaussian} describe the 3D space in a sparse way with learnable mean, covariance, opacity and semantics for each Gaussian.
However, several limitations persist in the current 3D semantic Gaussian representation:
1) Each Gaussian can still describe the empty region, which renders most of the Gaussians useless in an object-centric formulation given the sptial sparsity of 3D occupancy.
2) The aggregation process ignores the overlapping issue and directly sums up the contribution of each Gaussian to produce occupancy prediction, which results in unbounded semantic logits and further increases the overlapping among Gaussians.
Thus, the proportion of effective Gaussians describing occupied regions independently could be extremely low, which undermines the efficiency of the 3D semantic Gaussian representation.

In this paper, we introduce a probabilistic Gaussian superposition model to resolve the above limitations of 3D semantic Gaussians and improve utilization and efficiency. 
To elaborate, we propose the probabilistic Gaussian representation, which assigns 3D Gaussians to exclusively model the non-empty area by interpreting each Gaussian as a probability distribution of its neighborhood being occupied.
We employ the multiplication theorem of probability to aggregate the independent probability distributions and derive the geometry predictions.
Furthermore, we integrate the Gaussian mixture model into out probabilistic Gaussian representation to generate normalized semantic predictions, which avoid unbounded logits and prevents Gaussians from unnecessary overlapping.
Since our representation only models the occupied region, we also design a distribution-based initialization module to effectively initialize Gaussians around the non-emtpy area, which learns the pixel-aligned occupancy distribution instead of depth values of surfaces~\cite{li2023voxformer,li2022bevdepth,huang2021bevdet}.
We conduct extensive experiments on the nuScenes~\cite{caesar2020nuscenes} and KITTI-360~\cite{Liao2022kitti360} datasets for surround-view and monocular 3D semantic occupancy prediction, respectively. 
Our GaussianFormer-2 outperforms state-of-the-art methods
with high efficiency. 
In addition, qualitative visualizations show that GaussianFormer-2 is able to generate a both holistic and realistic perception of the scene.

