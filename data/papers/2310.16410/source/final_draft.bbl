\begin{thebibliography}{}

\bibitem[Achtibat et~al., 2022]{achtibat2022where}
Achtibat, R., Dreyer, M., Eisenbraun, I., Bosse, S., Wiegand, T., Samek, W.,
  and Lapuschkin, S. (2022).
\newblock From "where" to "what": Towards human-understandable explanations
  through concept relevance propagation.

\bibitem[Adebayo et~al., 2018]{adebayo2018sanity}
Adebayo, J., Gilmer, J., Muelly, M., Goodfellow, I., Hardt, M., and Kim, B.
  (2018).
\newblock Sanity checks for saliency maps.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  9525--9536.

\bibitem[Agrawal et~al., 2018]{cvxpy2}
Agrawal, A., Verschueren, R., Diamond, S., and Boyd, S. (2018).
\newblock A rewriting system for convex optimization problems.
\newblock {\em Journal of Control and Decision}, 5(1):42--60.

\bibitem[Alharin et~al., 2020]{alharin2020reinforcement}
Alharin, A., Doan, T.-N., and Sartipi, M. (2020).
\newblock Reinforcement learning interpretation methods: A survey.
\newblock {\em IEEE Access}, 8:171058--171077.

\bibitem[{Alisa Melekhina}, 2014]{chuchelov_interview}
{Alisa Melekhina} (2014).
\newblock Interview with gm chuchelov - caruana's coach.
\newblock [Online; accessed 1-August-2023].

\bibitem[Alvarez-Melis and Jaakkola, 2018]{melis2018towards}
Alvarez-Melis, D. and Jaakkola, T.~S. (2018).
\newblock Towards robust interpretability with self-explaining neural networks.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  7786--7795.

\bibitem[Annasamy and Sycara, 2019]{annasamy2019towards}
Annasamy, R.~M. and Sycara, K. (2019).
\newblock Towards better interpretability in deep q-networks.
\newblock In {\em Proceedings of the AAAI conference on artificial
  intelligence}, volume~33, pages 4561--4569.

\bibitem[Atrey et~al., 2019]{atrey2019exploratory}
Atrey, A., Clary, K., and Jensen, D. (2019).
\newblock Exploratory not explanatory: Counterfactual analysis of saliency maps
  for deep reinforcement learning.
\newblock {\em arXiv preprint arXiv:1912.05743}.

\bibitem[Bahadori and Heckerman, 2020]{Bahadori2020}
Bahadori, M.~T. and Heckerman, D.~E. (2020).
\newblock Debiasing concept bottleneck models with instrumental variables.
\newblock {\em arXiv preprint arXiv:2007.11500}.

\bibitem[Bai et~al., 2022]{bai2022concept}
Bai, A., Yeh, C.-K., Ravikumar, P., Lin, N. Y.~C., and Hsieh, C.-J. (2022).
\newblock Concept gradient: Concept-based interpretation without linear
  assumption.

\bibitem[Bastani et~al., 2018]{bastani2018verifiable}
Bastani, O., Pu, Y., and Solar-Lezama, A. (2018).
\newblock Verifiable reinforcement learning via policy extraction.
\newblock {\em Advances in neural information processing systems}, 31.

\bibitem[Bau et~al., 2017]{bau2017network}
Bau, D., Zhou, B., Khosla, A., Oliva, A., and Torralba, A. (2017).
\newblock Network dissection: Quantifying interpretability of deep visual
  representations.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 6541--6549.

\bibitem[{Bilodeau} et~al., 2022]{bilodeau22impossibility}
{Bilodeau}, B., {Jaques}, N., {Koh}, P.~W., and {Kim}, B. (2022).
\newblock Impossibility theorems for feature attribution.
\newblock arXiv:2212.11870.

\bibitem[Bilodeau et~al., 2022]{bilodeau2022impossibility}
Bilodeau, B., Jaques, N., Koh, P.~W., and Kim, B. (2022).
\newblock Impossibility theorems for feature attribution.
\newblock {\em arXiv preprint arXiv:2212.11870}.

\bibitem[{Bojun Guo}, 2023]{tablebase}
{Bojun Guo} (2023).
\newblock Syzygy tablebase.
\newblock [Online; accessed 23-July-2023].

\bibitem[Bouchacourt and Denoyer, 2019]{bouchacourt2019educe}
Bouchacourt, D. and Denoyer, L. (2019).
\newblock {EDUCE}: {E}xplaining model {D}ecisions through {U}nsupervised
  {C}oncepts {E}xtraction.
\newblock {\em arXiv preprint arXiv:1905.11852}.

\bibitem[Brunia and van Wijgerden, 2021]{step_method}
Brunia, R. and van Wijgerden, C. (2021).
\newblock {\em Steps Method}.
\newblock Self-published.

\bibitem[Chen et~al., 2020]{chen2020concept}
Chen, Z., Bei, Y., and Rudin, C. (2020).
\newblock Concept whitening for interpretable image recognition.
\newblock {\em Nature Machine Intelligence}, 2(12):772--782.

\bibitem[ChessBase, 2021]{chessbase}
ChessBase (2021).
\newblock Chessbase {M}ega {D}atabase.
\newblock database.chessbase.com.

\bibitem[Clough et~al., 2019]{clough2019global}
Clough, J.~R., Oksuz, I., Puyol-Ant{\'o}n, E., Ruijsink, B., King, A.~P., and
  Schnabel, J.~A. (2019).
\newblock Global and local interpretability for cardiac {MRI} classification.
\newblock In {\em International Conference on Medical Image Computing and
  Computer-Assisted Intervention}, pages 656--664. Springer.

\bibitem[Conneau et~al., 2018]{conneau2018you}
Conneau, A., Kruszewski, G., Lample, G., Barrault, L., and Baroni, M. (2018).
\newblock What you can cram into a single vector: Probing sentence embeddings
  for linguistic properties.
\newblock {\em arXiv preprint arXiv:1805.01070}.

\bibitem[Coppens et~al., 2019]{coppens2019distilling}
Coppens, Y., Efthymiadis, K., Lenaerts, T., Now{\'e}, A., Miller, T., Weber,
  R., and Magazzeni, D. (2019).
\newblock Distilling deep reinforcement learning policies in soft decision
  trees.
\newblock In {\em Proceedings of the IJCAI 2019 workshop on explainable
  artificial intelligence}, pages 1--6.

\bibitem[Corbit et~al., 2014]{sts}
Corbit, D., Natarajan, S., and Mosca, F. (2014).
\newblock Strategic test suite.

\bibitem[Crabb\'{e} and van~der Schaar, 2022]{NEURIPS2022_11a7f429}
Crabb\'{e}, J. and van~der Schaar, M. (2022).
\newblock Concept activation regions: A generalized framework for concept-based
  explanations.
\newblock In Koyejo, S., Mohamed, S., Agarwal, A., Belgrave, D., Cho, K., and
  Oh, A., editors, {\em Advances in Neural Information Processing Systems},
  volume~35, pages 2590--2607. Curran Associates, Inc.

\bibitem[Das et~al., 2023]{das2023state2explanation}
Das, D., Chernova, S., and Kim, B. (2023).
\newblock State2explanation: Concept-based explanations to benefit agent
  learning and user understanding.
\newblock {\em Advances in Neural Information Processing Systems}.

\bibitem[d'Avila Garcez et~al., 2018]{garcez2018symbolic}
d'Avila Garcez, A., Dutra, A. R.~R., and Alonso, E. (2018).
\newblock Towards symbolic reinforcement learning with common sense.

\bibitem[Dazeley et~al., 2023]{dazeley2023explainable}
Dazeley, R., Vamplew, P., and Cruz, F. (2023).
\newblock Explainable reinforcement learning for broad-xai: a conceptual
  framework and survey.
\newblock {\em Neural Computing and Applications}, pages 1--24.

\bibitem[{DecodeChess}, 2017]{decodechess}
{DecodeChess} (2017).
\newblock {Understanding Chess with Explainable AI}.
\newblock \url{https://decodechess.com/about/},.

\bibitem[Deshmukh et~al., 2023]{deshmukh2023counterfactual}
Deshmukh, S.~V., R, S., Vijay, S., Subramanian, J., and Agarwal, C. (2023).
\newblock Counterfactual explanation policies in rl.

\bibitem[Diamond and Boyd, 2016]{cvxpy1}
Diamond, S. and Boyd, S. (2016).
\newblock {CVXPY}: {A} {P}ython-embedded modeling language for convex
  optimization.
\newblock {\em Journal of Machine Learning Research}, 17(83):1--5.

\bibitem[Ding et~al., 2008]{ding2008convex}
Ding, C.~H., Li, T., and Jordan, M.~I. (2008).
\newblock Convex and semi-nonnegative matrix factorizations.
\newblock {\em IEEE transactions on pattern analysis and machine intelligence},
  32(1):45--55.

\bibitem[Doncieux et~al., 2020]{doncieux2020dream}
Doncieux, S., Bredeche, N., Goff, L.~L., Girard, B., Coninx, A., Sigaud, O.,
  Khamassi, M., D\'{i}az-Rodr\'{i}guez, N., Filliat, D., Hospedales, T., Eiben,
  A., and Duro, R. (2020).
\newblock Dream architecture: a developmental approach to open-ended learning
  in robotics.

\bibitem[Doncieux et~al., 2018]{openendedlearning}
Doncieux, S., Filliat, D., D\'{i}az-Rodr\'{i}guez, N., Hospedales, T., Duro,
  R., Coninx, A., Roijers, D.~M., Girard, B., Perrin, N., and Sigaud, O.
  (2018).
\newblock Open-ended learning: A conceptual framework based on representational
  redescription.
\newblock {\em Frontiers in Neurorobotics}, 12:59.

\bibitem[Feng et~al., 2023]{feng2023chessgpt}
Feng, X., Luo, Y., Wang, Z., Tang, H., Yang, M., Shao, K., Mguni, D., Du, Y.,
  and Wang, J. (2023).
\newblock Chessgpt: Bridging policy learning and language modeling.

\bibitem[{FIDE}, 2019]{fide_handbook}
{FIDE} (2019).
\newblock Fide handbook c.02.
\newblock [Online; accessed 13-October-2023].

\bibitem[Fiekas, 2023]{chesspackage}
Fiekas, N. (2023).
\newblock {python-chess}.

\bibitem[Finkelstein et~al., 2022]{finkelstein2022explainable}
Finkelstein, M., Liu, L., Schlot, N.~L., Kolumbus, Y., Parkes, D.~C.,
  Rosenshein, J.~S., and Keren, S. (2022).
\newblock Explainable reinforcement learning via model transforms.

\bibitem[Forde et~al., 2022]{forde2022concepts}
Forde, J.~Z., Lovering, C., Konidaris, G., Pavlick, E., and Littman, M.~L.
  (2022).
\newblock Where, when \& which concepts does {AlphaZero} learn? {Lessons} from
  the game of {Hex}.
\newblock In {\em AAAI Workshop on Reinforcement Learning in Games}, volume~2.

\bibitem[Gajcin and Dusparic, 2022]{gajcin2022reccover}
Gajcin, J. and Dusparic, I. (2022).
\newblock Reccover: Detecting causal confusion for explainable reinforcement
  learning.

\bibitem[Garnelo et~al., 2016]{garnelo2016deep}
Garnelo, M., Arulkumaran, K., and Shanahan, M. (2016).
\newblock Towards deep symbolic reinforcement learning.

\bibitem[Ghandeharioun et~al., 2021]{ghandeharioun2021dissect}
Ghandeharioun, A., Kim, B., Li, C.-L., Jou, B., Eoff, B., and Picard, R.~W.
  (2021).
\newblock Dissect: Disentangled simultaneous explanations via concept
  traversals.
\newblock {\em arXiv preprint arXiv:2105.15164}.

\bibitem[Ghorbani et~al., 2019]{ghorbani2019towards}
Ghorbani, A., Wexler, J., Zou, J.~Y., and Kim, B. (2019).
\newblock Towards automatic concept-based explanations.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  9273--9282.

\bibitem[Glanois et~al., 2021]{glanois2021survey}
Glanois, C., Weng, P., Zimmer, M., Li, D., Yang, T., Hao, J., and Liu, W.
  (2021).
\newblock A survey on interpretable reinforcement learning.
\newblock {\em arXiv preprint arXiv:2112.13112}.

\bibitem[Goel et~al., 2018]{goel2018unsupervised}
Goel, V., Weng, J., and Poupart, P. (2018).
\newblock Unsupervised video object segmentation for deep reinforcement
  learning.
\newblock {\em Advances in neural information processing systems}, 31.

\bibitem[Gonz{\'a}lez-D{\'\i}az and Palacios-Huerta,
  2022]{gonzalez2022alphazero}
Gonz{\'a}lez-D{\'\i}az, J. and Palacios-Huerta, I. (2022).
\newblock Alphazero ideas.
\newblock {\em Available at SSRN 4140916}.

\bibitem[Goyal et~al., 2019]{goyal2019explaining}
Goyal, Y., Feder, A., Shalit, U., and Kim, B. (2019).
\newblock Explaining classifiers with causal concept effect ({CaCE}).
\newblock {\em arXiv preprint arXiv:1907.07165}.

\bibitem[Graziani et~al., 2018]{graziani2018regression}
Graziani, M., Andrearczyk, V., and M{\"u}ller, H. (2018).
\newblock Regression concept vectors for bidirectional explanations in
  histopathology.
\newblock In {\em Understanding and Interpreting Machine Learning in Medical
  Image Computing Applications}, pages 124--132. Springer.

\bibitem[Greydanus et~al., 2018]{greydanus2018visualizing}
Greydanus, S., Koul, A., Dodge, J., and Fern, A. (2018).
\newblock Visualizing and understanding atari agents.
\newblock In {\em International Conference on Machine Learning}, pages
  1792--1801. PMLR.

\bibitem[Gupta et~al., 2020]{puri2020explain}
Gupta, P., Puri, N., Verma, S., Kayastha, D., Deshmukh, S., Krishnamurthy, B.,
  and Singh, S. (2020).
\newblock Explain your move: understanding agent actions using specific and
  relevant feature attribution.
\newblock In {\em International Conference on Learning Representations (ICLR)}.

\bibitem[Gurnee et~al., 2023]{gurnee2023finding}
Gurnee, W., Nanda, N., Pauly, M., Harvey, K., Troitskii, D., and Bertsimas, D.
  (2023).
\newblock Finding neurons in a haystack: Case studies with sparse probing.
\newblock {\em arXiv preprint arXiv:2305.01610}.

\bibitem[Hansen, 2021]{openings_carsten}
Hansen, C. (2021).
\newblock {\em Back to Basics: Chess Openings}.
\newblock Russel Enterprises.

\bibitem[Hazra and De~Raedt, 2023]{hazra2023deep}
Hazra, R. and De~Raedt, L. (2023).
\newblock Deep explainable relational reinforcement learning: A neuro-symbolic
  approach.
\newblock {\em arXiv preprint arXiv:2304.08349}.

\bibitem[Heuillet et~al., 2020]{heuillet2020explainability}
Heuillet, A., Couthouis, F., and D\'{i}az-Rodr\'{i}guez, N. (2020).
\newblock Explainability in deep reinforcement learning.

\bibitem[Jaunet et~al., 2020]{jaunet2020drlviz}
Jaunet, T., Vuillemot, R., and Wolf, C. (2020).
\newblock Drlviz: Understanding decisions and memory in deep reinforcement
  learning.
\newblock In {\em Computer Graphics Forum}, volume~39, pages 49--61. Wiley
  Online Library.

\bibitem[Jhamtani et~al., 2018]{jhamtani2018acl}
Jhamtani, H., Gangal, V., Hovy, E., Neubig, G., and Berg-Kirkpatrick, T.
  (2018).
\newblock Learning to generate move-by-move commentary for chess games from
  large-scale social forum data.
\newblock In {\em The 56th Annual Meeting of the Association for Computational
  Linguistics (ACL)}, Melbourne, Australia.

\bibitem[Jia et~al., 2022]{jia2022role}
Jia, Y., McDermid, J., Lawton, T., and Habli, I. (2022).
\newblock The role of explainability in assuring safety of machine learning in
  healthcare.
\newblock {\em IEEE Transactions on Emerging Topics in Computing},
  10(4):1746--1760.

\bibitem[Kerner, 1995]{10.1007/3-540-60364-6_40}
Kerner, Y. (1995).
\newblock Case-based evaluation in computer chess.
\newblock In Haton, J.-P., Keane, M., and Manago, M., editors, {\em Advances in
  Case-Based Reasoning}, pages 240--254, Berlin, Heidelberg. Springer Berlin
  Heidelberg.

\bibitem[Kim, 2022]{iclrkeynote_been_2022}
Kim, B. (2022).
\newblock Beyond interpretability: developing a language to shape our
  relationships with ai.

\bibitem[Kim et~al., 2018]{kim2018interpretability}
Kim, B., Wattenberg, M., Gilmer, J., Cai, C., Wexler, J., Viegas, F., et~al.
  (2018).
\newblock Interpretability beyond feature attribution: Quantitative testing
  with concept activation vectors ({TCAV}).
\newblock In {\em International {C}onference on {M}achine {L}earning}, pages
  2668--2677. PMLR.

\bibitem[King, 2000]{10goldenrules}
King, D. (2000).
\newblock {\em How to Win at Chess}.
\newblock Everyman Chess.

\bibitem[Kingma and Ba, 2014]{kingma2014adam}
Kingma, D.~P. and Ba, J. (2014).
\newblock Adam: A method for stochastic optimization.
\newblock {\em arXiv preprint arXiv:1412.6980}.

\bibitem[Koh and Liang, 2017]{koh2017understanding}
Koh, P.~W. and Liang, P. (2017).
\newblock Understanding black-box predictions via influence functions.
\newblock In {\em International conference on machine learning}, pages
  1885--1894. PMLR.

\bibitem[Koh et~al., 2020]{koh2020concept}
Koh, P.~W., Nguyen, T., Tang, Y.~S., Mussmann, S., Pierson, E., Kim, B., and
  Liang, P. (2020).
\newblock Concept bottleneck models.
\newblock {\em arXiv preprint arXiv:2007.04612}.

\bibitem[Koul et~al., 2018]{koul2018learning}
Koul, A., Greydanus, S., and Fern, A. (2018).
\newblock Learning finite state representations of recurrent policy networks.
\newblock {\em arXiv preprint arXiv:1811.12530}.

\bibitem[Krajna et~al., 2022]{krajna2022explainability}
Krajna, A., Brcic, M., Lipic, T., and Doncevic, J. (2022).
\newblock Explainability in reinforcement learning: perspective and position.

\bibitem[Lan et~al., 2022]{lan2022alphazerolike}
Lan, L.-C., Zhang, H., Wu, T.-R., Tsai, M.-Y., Wu, I.-C., and Hsieh, C.-J.
  (2022).
\newblock Are alphazero-like agents robust to adversarial perturbations?

\bibitem[{LCZero Development Community}, 2018]{leela}
{LCZero Development Community} (2018).
\newblock {Leela Chess Zero}.
\newblock \url{lczero.org}.
\newblock Accessed: 20 November 2019.

\bibitem[Lesort et~al., 2019]{8852042}
Lesort, T., Seurin, M., Li, X., D\'{i}az-Rodr\'{i}guez, N., and Filliat, D.
  (2019).
\newblock Deep unsupervised state representation learning with robotic priors:
  a robustness analysis.
\newblock In {\em 2019 International Joint Conference on Neural Networks
  (IJCNN)}, pages 1--8.

\bibitem[Li et~al., 2018]{li2018object}
Li, Y., Sycara, K., and Iyer, R. (2018).
\newblock Object-sensitive deep reinforcement learning.
\newblock {\em arXiv preprint arXiv:1809.06064}.

\bibitem[{LiChess}, 2023]{eco}
{LiChess} (2023).
\newblock Encyclopedia of chess openings.
\newblock [Online; accessed 1-May-2023].

\bibitem[Liu et~al., 2019]{liu2019toward}
Liu, G., Schulte, O., Zhu, W., and Li, Q. (2019).
\newblock Toward interpretable deep reinforcement learning with linear model
  u-trees.
\newblock In {\em Machine Learning and Knowledge Discovery in Databases:
  European Conference, ECML PKDD 2018, Dublin, Ireland, September 10--14, 2018,
  Proceedings, Part II 18}, pages 414--429. Springer.

\bibitem[Lundberg and Lee, 2017]{lundberg2017unified}
Lundberg, S.~M. and Lee, S.-I. (2017).
\newblock A unified approach to interpreting model predictions.
\newblock In {\em Advances in Neural Information Processing Systems},
  volume~30.

\bibitem[Madumal et~al., 2020]{madumal2020distal}
Madumal, P., Miller, T., Sonenberg, L., and Vetere, F. (2020).
\newblock Distal explanations for explainable reinforcement learning agents.
\newblock {\em arXiv preprint arXiv:2001.10284}.

\bibitem[Mahinpei et~al., 2021]{pitfalls21}
Mahinpei, A., Clark, J., Lage, I., Doshi{-}Velez, F., and Pan, W. (2021).
\newblock Promises and pitfalls of black-box concept learning models.
\newblock {\em CoRR}, abs/2106.13314.

\bibitem[McGrath et~al., 2021]{mcgrath2021acquisition}
McGrath, T., Kapishnikov, A., Toma{\v{s}}ev, N., Pearce, A., Hassabis, D., Kim,
  B., Paquet, U., and Kramnik, V. (2021).
\newblock Acquisition of chess knowledge in alphazero.
\newblock {\em arXiv preprint arXiv:2111.09259}.

\bibitem[McGrath et~al., 2022]{mcgrath2022acquisition}
McGrath, T., Kapishnikov, A., Toma{\v{s}}ev, N., Pearce, A., Wattenberg, M.,
  Hassabis, D., Kim, B., Paquet, U., and Kramnik, V. (2022).
\newblock Acquisition of chess knowledge in alphazero.
\newblock {\em Proceedings of the National Academy of Sciences},
  119(47):e2206625119.

\bibitem[Meinshausen and B{\"u}hlmann, 2006]{meinshausen2006high}
Meinshausen, N. and B{\"u}hlmann, P. (2006).
\newblock High-dimensional graphs and variable selection with the lasso.

\bibitem[Milani et~al., 2022]{milani2022survey}
Milani, S., Topin, N., Veloso, M., and Fang, F. (2022).
\newblock A survey of explainable reinforcement learning.
\newblock {\em arXiv preprint arXiv:2202.08434}.

\bibitem[Mincu et~al., 2021]{mincu2021concept}
Mincu, D., Loreaux, E., Hou, S., Baur, S., Protsyuk, I., Seneviratne, M.,
  Mottram, A., Tomasev, N., Karthikesalingam, A., and Schrouff, J. (2021).
\newblock Concept-based model explanations for electronic health records.
\newblock In {\em Proceedings of the Conference on Health, Inference, and
  Learning}, pages 36--46.

\bibitem[Mundhenk et~al., 2020]{mundhenk2020efficient}
Mundhenk, T.~N., Chen, B.~Y., and Friedland, G. (2020).
\newblock Efficient saliency maps for explainable ai.

\bibitem[Nanda, 2023]{nanda_othello_2023}
Nanda, N. (2023).
\newblock Actually, othello-gpt has a linear emergent world model.

\bibitem[Nie et~al., 2018]{nie2018}
Nie, W., Zhang, Y., and Patel, A. (2018).
\newblock A theoretical explanation for perplexing behaviors of
  backpropagation-based visualizations.
\newblock {\em CoRR}.

\bibitem[Olson et~al., 2019]{olson2019counterfactual}
Olson, M.~L., Neal, L., Li, F., and Wong, W.-K. (2019).
\newblock Counterfactual states for atari agents via generative deep learning.
\newblock {\em arXiv preprint arXiv:1909.12969}.

\bibitem[Omidshafiei et~al., 2022]{omidshafiei2022beyond}
Omidshafiei, S., Kapishnikov, A., Assogba, Y., Dixon, L., and Kim, B. (2022).
\newblock Beyond rewards: a hierarchical perspective on offline multiagent
  behavioral analysis.
\newblock {\em Advances in Neural Information Processing Systems},
  35:3444--3460.

\bibitem[P{\'a}lsson and Bj{\"o}rnsson, 2023]{palssonunveiling}
P{\'a}lsson, A. and Bj{\"o}rnsson, Y. (2023).
\newblock Unveiling concepts learned by a world-class chess-playing agent.
\newblock In {\em International Joint Conference on Artificial Intelligence}.

\bibitem[Raffin et~al., 2018]{raffin2018srl}
Raffin, A., Hill, A., Traor\'{e}, R., Lesort, T., D\'{i}az-Rodr\'{i}guez, N.,
  and Filliat, D. (2018).
\newblock S-rl toolbox: Environments, datasets and evaluation metrics for state
  representation learning.

\bibitem[Raffin et~al., 2019]{raffin2019decoupling}
Raffin, A., Hill, A., Traor\'{e}, R., Lesort, T., D\'{i}az-Rodr\'{i}guez, N.,
  and Filliat, D. (2019).
\newblock Decoupling feature extraction from policy learning: assessing
  benefits of state representation learning in goal based robotics.

\bibitem[Ramaswamy et~al., 2023]{Ramaswamy_2023_CVPR}
Ramaswamy, V.~V., Kim, S. S.~Y., Fong, R., and Russakovsky, O. (2023).
\newblock Overlooked factors in concept-based explanations: Dataset choice,
  concept learnability, and human capability.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition (CVPR)}, pages 10932--10941.

\bibitem[Ribeiro et~al., 2016]{ribeiro2016should}
Ribeiro, M.~T., Singh, S., and Guestrin, C. (2016).
\newblock Why should {I} trust you?: Explaining the predictions of any
  classifier.
\newblock In {\em Proceedings of the 22nd ACM SIGKDD International Conference
  on Knowledge Discovery and Data Mining}, pages 1135--1144. ACM.

\bibitem[Robinson, 1974]{robinson1974fitting}
Robinson, P.~J. (1974).
\newblock Fitting equations to data: Computer analysis of multifactor data for
  scientists and engineers.
\newblock {\em JMR, Journal of Marketing Research (pre-1986)}, 11(000003):346.

\bibitem[Roth et~al., 2019]{roth2019conservative}
Roth, A.~M., Topin, N., Jamshidi, P., and Veloso, M. (2019).
\newblock Conservative q-improvement: Reinforcement learning for an
  interpretable decision-tree policy.
\newblock {\em arXiv preprint arXiv:1907.01180}.

\bibitem[Rupprecht et~al., 2019]{rupprecht2019finding}
Rupprecht, C., Ibrahim, C., and Pal, C.~J. (2019).
\newblock Finding and visualizing weaknesses of deep reinforcement learning
  agents.
\newblock {\em arXiv preprint arXiv:1904.01318}.

\bibitem[Sadler and Regan, 2019]{game_changer}
Sadler, M. and Regan, N. (2019).
\newblock {\em Game Changer: {A}lpha{Z}ero's Groundbreaking Chess Strategies
  and the Promise of {AI}}.
\newblock New In Chess.

\bibitem[Schrittwieser et~al., 2019]{schrittwieser2019mastering}
Schrittwieser, J., Antonoglou, I., Hubert, T., Simonyan, K., Sifre, L.,
  Schmitt, S., Guez, A., Lockhart, E., Hassabis, D., Graepel, T., Lillicrap,
  T., and Silver, D. (2019).
\newblock Mastering {A}tari, {G}o, chess and shogi by planning with a learned
  model.

\bibitem[Schwalbe and Schels, 2020]{schwalbe2020concept}
Schwalbe, G. and Schels, M. (2020).
\newblock Concept enforcement and modularization as methods for the iso 26262
  safety argumentation of neural networks.
\newblock {\em University of Bamberg}.

\bibitem[Selvaraju et~al., 2019]{Selvaraju_2019}
Selvaraju, R.~R., Cogswell, M., Das, A., Vedantam, R., Parikh, D., and Batra,
  D. (2019).
\newblock Grad-cam: Visual explanations from deep networks via gradient-based
  localization.
\newblock {\em International Journal of Computer Vision}, 128(2):336–359.

\bibitem[Silver et~al., 2017]{silver2017mastering}
Silver, D., Hubert, T., Schrittwieser, J., Antonoglou, I., Lai, M., Guez, A.,
  Lanctot, M., Sifre, L., Kumaran, D., Graepel, T., et~al. (2017).
\newblock Mastering chess and shogi by self-play with a general reinforcement
  learning algorithm.
\newblock {\em arXiv preprint arXiv:1712.01815}.

\bibitem[Silver et~al., 2018]{Silver1140}
Silver, D., Hubert, T., Schrittwieser, J., Antonoglou, I., Lai, M., Guez, A.,
  Lanctot, M., Sifre, L., Kumaran, D., Graepel, T., Lillicrap, T., Simonyan,
  K., and Hassabis, D. (2018).
\newblock A general reinforcement learning algorithm that masters chess, shogi,
  and {G}o through self-play.
\newblock {\em Science}, 362(6419):1140--1144.

\bibitem[Snee, 1973]{snee1973some}
Snee, R.~D. (1973).
\newblock Some aspects of nonorthogonal data analysis: Part i. developing
  prediction equations.
\newblock {\em Journal of Quality Technology}, 5(2):67--79.

\bibitem[Snee and Marquardt, 1984]{snee1984comment}
Snee, R.~D. and Marquardt, D.~W. (1984).
\newblock Comment: Collinearity diagnostics depend on the domain of prediction,
  the model, and the data.
\newblock {\em The American Statistician}, 38(2):83--87.

\bibitem[Soni et~al., 2020]{soni2020adversarial}
Soni, R., Shah, N., Seng, C.~T., and Moore, J.~D. (2020).
\newblock Adversarial tcav--robust and effective interpretation of intermediate
  layers in neural networks.
\newblock {\em arXiv preprint arXiv:2002.03549}.

\bibitem[Sprague et~al., 2019]{sprague2018interpretable}
Sprague, C., Wendoloski, E.~B., and Guch, I. (2019).
\newblock Interpretable {AI} for deep learning-based meteorological
  applications.
\newblock In {\em American Meteorological Society Annual Meeting}.

\bibitem[Sreedharan et~al., 2020a]{sreedharan2020bridging}
Sreedharan, S., Soni, U., Verma, M., Srivastava, S., and Kambhampati, S.
  (2020a).
\newblock Bridging the gap: Providing post-hoc symbolic explanations for
  sequential decision-making problems with black box simulators.
\newblock {\em arXiv preprint arXiv:2002.01080}.

\bibitem[Sreedharan et~al., 2020b]{sreedharan2020tldr}
Sreedharan, S., Srivastava, S., and Kambhampati, S. (2020b).
\newblock Tldr: Policy summarization for factored ssp problems using temporal
  abstractions.
\newblock In {\em Proceedings of the International Conference on Automated
  Planning and Scheduling}, volume~30, pages 272--280.

\bibitem[{Stockfish Community}, 2018]{stockfish}
{Stockfish Community} (2018).
\newblock {Stockfish Chess}.
\newblock \url{https://stockfishchess.org/}.
\newblock Accessed: 23 July 2023.

\bibitem[Sundararajan et~al., 2017]{integrated-gradients}
Sundararajan, M., Taly, A., and Yan, Q. (2017).
\newblock Axiomatic attribution for deep networks.
\newblock In {\em Proceedings of the 34th International Conference on Machine
  Learning - Volume 70}, pages 3319--3328.

\bibitem[Tenney et~al., 2019]{tenney2019bert}
Tenney, I., Das, D., and Pavlick, E. (2019).
\newblock Bert rediscovers the classical nlp pipeline.
\newblock {\em arXiv preprint arXiv:1905.05950}.

\bibitem[Tibshirani, 1996]{tibshirani1996regression}
Tibshirani, R. (1996).
\newblock Regression shrinkage and selection via the lasso.
\newblock {\em Journal of the Royal Statistical Society: Series B
  (Methodological)}, 58(1):267--288.

\bibitem[Toma{\v{s}}ev et~al., 2020]{az_variants_preprint}
Toma{\v{s}}ev, N., Paquet, U., Hassabis, D., and Kramnik, V. (2020).
\newblock Assessing game balance with {AlphaZero}: Exploring alternative rule
  sets in chess.
\newblock {\em arXiv preprint arXiv:2009.04374}.

\bibitem[Toma\v{s}ev et~al., 2022]{CACM-paper}
Toma\v{s}ev, N., Paquet, U., Hassabis, D., and Kramnik, V. (2022).
\newblock Reimagining chess with {A}lpha{Z}ero.
\newblock {\em Commun. ACM}, 65(2):60–66.

\bibitem[Tomlin et~al., 2022]{tomlin2022understanding}
Tomlin, N., He, A., and Klein, D. (2022).
\newblock Understanding game-playing agents with natural language annotations.
\newblock {\em arXiv preprint arXiv:2204.07531}.

\bibitem[Topin et~al., 2021]{topin2021iterative}
Topin, N., Milani, S., Fang, F., and Veloso, M. (2021).
\newblock Iterative bounding mdps: Learning interpretable policies via
  non-interpretable methods.
\newblock In {\em Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~35, pages 9923--9931.

\bibitem[Traor\'{e} et~al., 2019]{traore2019discorl}
Traor\'{e}, R., Caselles-Dupr\'{e}, H., Lesort, T., Sun, T., Cai, G.,
  D\'{i}az-Rodr\'{i}guez, N., and Filliat, D. (2019).
\newblock Discorl: Continual reinforcement learning via policy distillation.

\bibitem[Vasic et~al., 2019]{vasic2019moet}
Vasic, M., Petrovic, A., Wang, K., Nikolic, M., Singh, R., and Khurshid, S.
  (2019).
\newblock Mo{\"e}t: Interpretable and verifiable reinforcement learning via
  mixture of expert trees.
\newblock {\em Open Review}.

\bibitem[Vouros, 2022]{vouros2022explainable}
Vouros, G.~A. (2022).
\newblock Explainable deep reinforcement learning: state of the art and
  challenges.
\newblock {\em ACM Computing Surveys}, 55(5):1--39.

\bibitem[Wang et~al., 2016]{wang2016dueling}
Wang, Z., Schaul, T., Hessel, M., Hasselt, H., Lanctot, M., and Freitas, N.
  (2016).
\newblock Dueling network architectures for deep reinforcement learning.
\newblock In {\em International conference on machine learning}, pages
  1995--2003. PMLR.

\bibitem[{Wikipedia contributors}, 2023a]{wiki:elo}
{Wikipedia contributors} (2023a).
\newblock Chess rating system.
\newblock [Online; accessed 23-July-2023].

\bibitem[{Wikipedia contributors}, 2023b]{wiki:chess_strategy}
{Wikipedia contributors} (2023b).
\newblock Chess strategy.
\newblock [Online; accessed 13-October-2023].

\bibitem[{Wikipedia contributors}, 2023c]{wiki:chess_tactic}
{Wikipedia contributors} (2023c).
\newblock Chess tactic.
\newblock [Online; accessed 13-October-2023].

\bibitem[Wu et~al., 2023]{wu2023causal}
Wu, Z., D’Oosterlinck, K., Geiger, A., Zur, A., and Potts, C. (2023).
\newblock Causal proxy models for concept-based model explanations.
\newblock In {\em International Conference on Machine Learning}, pages
  37313--37334. PMLR.

\bibitem[Yang et~al., 2023]{yang2023leveraging}
Yang, Q., Wang, H., Tong, M., Shi, W., Huang, G., and Song, S. (2023).
\newblock Leveraging reward consistency for interpretable feature discovery in
  reinforcement learning.
\newblock {\em arXiv preprint arXiv:2309.01458}.

\bibitem[Yeche et~al., 2019]{yeche2019ubs}
Yeche, H., Harrison, J., and Berthier, T. (2019).
\newblock Ubs: A dimension-agnostic metric for concept vector interpretability
  applied to radiomics.
\newblock In {\em Interpretability of Machine Intelligence in Medical Image
  Computing and Multimodal Learning for Clinical Decision Support}, pages
  12--20. Springer.

\bibitem[Yeh et~al., 2020]{yeh2020completeness}
Yeh, C.-K., Kim, B., Arik, S., Li, C.-L., Pfister, T., and Ravikumar, P.
  (2020).
\newblock On completeness-aware concept-based explanations in deep neural
  networks.
\newblock {\em Advances in Neural Information Processing Systems},
  33:20554--20565.

\bibitem[Zahavy et~al., 2016]{zahavy2016graying}
Zahavy, T., Ben-Zrihem, N., and Mannor, S. (2016).
\newblock Graying the black box: Understanding dqns.
\newblock In {\em International conference on machine learning}, pages
  1899--1908. PMLR.

\bibitem[Zahavy et~al., 2023]{zahavy2023diversifying}
Zahavy, T., Veeriah, V., Hou, S., Waugh, K., Lai, M., Leurent, E., Tomasev, N.,
  Schut, L., Hassabis, D., and Singh, S. (2023).
\newblock Diversifying ai: Towards creative chess with alphazero.

\bibitem[Zambaldi et~al., 2018]{zambaldi2018relational}
Zambaldi, V., Raposo, D., Santoro, A., Bapst, V., Li, Y., Babuschkin, I.,
  Tuyls, K., Reichert, D., Lillicrap, T., Lockhart, E., Shanahan, M., Langston,
  V., Pascanu, R., Botvinick, M., Vinyals, O., and Battaglia, P. (2018).
\newblock Relational deep reinforcement learning.

\bibitem[Zrihem et~al., 2016]{zrihem2016visualizing}
Zrihem, N.~B., Zahavy, T., and Mannor, S. (2016).
\newblock Visualizing dynamics: from t-sne to semi-mdps.
\newblock {\em arXiv preprint arXiv:1606.07112}.

\end{thebibliography}
