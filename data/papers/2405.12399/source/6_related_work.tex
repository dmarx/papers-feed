\section{Related work}
\label{sec:related_work}

\textbf{World models.} The idea of reinforcement learning (RL) in the imagination of a neural network world model was introduced by \citet{ha2018world}. SimPLe \citep{kaiser2019atari100k} applied world models to Atari, and introduced the Atari 100k benchmark to focus on sample efficiency. Dreamer \citep{hafner2020dream} introduced RL from the latent space of a recurrent state space model (RSSM). DreamerV2 \citep{hafner2021mastering} demonstrated that using discrete latents could help to reduce compounding error, and DreamerV3 \citep{hafner2023dreamerv3} was able to achieve human-level performance on a wide range of domains with fixed hyperparameters. TWM \citep{robine2023transformer} adapts DreamerV2's RSSM to use a transformer architecture, while STORM \citep{zhang2023storm} adapts DreamerV3 in a similar way but with a different tokenization approach. Alternatively, IRIS \citep{iris2023} builds a language of image tokens with a discrete autoencoder, and composes these tokens over time with an autoregressive transformer. 

\textbf{Generative vision models.} There are parallels between these world models and image generation models which suggests that developments in generative vision models could provide benefits to world modeling. Following the rise of transformers in natural language processing \citep{vaswani2017attention,devlin2018bert,radford2019language}, VQGAN \citep{esser2021taming} and DALLÂ·E \citep{ramesh2021zero} convert images to discrete tokens with discrete autoencoders \citep{vqvae}, and leverage the sequence modeling abilities of autoregressive transformers to build powerful text-to-image generative models. Concurrently, diffusion models \citep{sohl2015difforigin,ho2020DDPM,song_sde} gained traction \citep{dhariwal2021diffbeatsgans,ldm_stable_diffusion}, and have become a dominant paradigm for high-resolution image generation \citep{saharia2022imagen,ramesh2022hierarchical,podell2023sdxl}.

The same trends have taken place in the recent developments of video generation methods. VideoGPT \citep{yan2021videogpt} provides a minimal video generation architecture by combining a discrete autoencoder with an autoregressive transformer. Godiva \citep{wu2021godiva} enables text conditioning with promising generalization. Phenaki \citep{phenaki} allows arbitrary length video generation with sequential prompt conditioning. TECO \citep{yan2023teco} improves upon autoregressive modeling by using MaskGit \citep{chang2022maskgit}, and enables longer temporal dependencies by compressing input sequence embeddings. Diffusion models have also seen a resurgence in video generation using 3D U-Nets to provide high quality but short-duration video \citep{singer2023make,bar2024lumiere}. 
Recently, transformer-based diffusion models such as DiT  \citep{dit2023} and Sora \citep{sora2024} have shown improved scalability for both image and video generation, respectively.

\textbf{Diffusion for reinforcement learning.} There has also been much interest in combining diffusion models with reinforcement learning. This includes taking advantage of the flexibility of diffusion models as a policy \citep{wang2022diffusion, ajay2022conditional,pearce2023imitating}, as planners \citep{janner2022planning, liang2023adaptdiffuser}, as reward models \citep{nuti2023extracting}, and trajectory modeling for data augmentation in offline RL \citep{lu2023synthetic,ding2024diffusion,jackson2024policyguided}. \textsc{diamond} represents the first use of diffusion models as world models for learning online in imagination. 

\textbf{Generative game engines.} Playable games running entirely on neural networks have recently been growing in scope. \textit{GameGAN} \citep{gameGAN2020} learns generative models of games using a GAN \citep{goodfellow2014GAN} while \citet{bamford2020neural} use a Neural GPU \citep{kaiser2015neural}. Concurrent work includes \textit{Genie} \citep{bruce2024genie}, which generates playable platformer environments from image prompts, and \textit{GameNGen} \citep{valevski2024diffusionmodelsrealtimegame}, which similarly leverages a diffusion model to obtain a high resolution simulator of the game DOOM, but at a larger scale.