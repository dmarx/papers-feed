\vspace{-2mm}
\section{Conclusion and Broader Impact}
\label{sec:conclusion}

We have introduced \textsc{diamond}, a reinforcement learning agent trained in a diffusion world model. 
We explained the key design choices we made to adapt diffusion for world modeling and to make our world model stable over long time horizons with a low number of denoising steps.
\textsc{diamond} achieves a mean human normalized score of $1.46$ on the well-established Atari 100k benchmark; a new best among agents trained entirely within a world model. 
We analyzed our improved performance in some games and found that it likely follows from better modeling of critical visual details.
We further demonstrated \textsc{diamond}'s diffusion world model can successfully model 3D environments and serve as a real-time neural game engine by training on static \textit{Counter-Strike: Global Offensive} gameplay.

World models constitute a promising direction to address sample efficiency and safety concerns associated with training agents in the real world. However, imperfections in the world model may lead to suboptimal or unexpected agent behaviors. We hope that the development of more faithful and interactive world models will contribute to broader efforts to further reduce these risks.

%The development of more visually faithful world models such as \textsc{diamond} provides a promising avenue to further reduce these risks.% associated with deploying agents trained in simulation. 

%hope that developing more visually faithful world models such as \textsc{diamond} constitutes a promising avenue to further reduce these risks. 

%In general, the deployment of agents in the real world raises safety concerns. Training in a world model reduces these risks by minimizing the time spent in the real environment, but imperfect world models may lead to unexpected agent behaviors. The development of more visually faithful world models such as \textsc{diamond} provides a promising avenue to further reduce the risks associated with deploying agents trained in simulation. 



%Our work considers the training of autonomous agents using a world model. 

%Taking a step back, the deployment of autonomous agents in the real world raises safety concerns regarding the potential harm they may cause, and training in a world model reduces these risks by minimizing the time the agent spends interacting with the environment. However, imperfect world models may lead to unexpected behaviors upon deployment of agents in the real-world, and the development of more realistic world models such as \textsc{diamond} provides a promising avenue to further reduce the risks associated with deploying agents trained in simulation.

%Additionally, as with all advances in the field of Machine Learning, there are many other potential societal consequences of our work, but none of which we feel must be specifically highlighted here.

% We have introduced \textsc{diamond}, a visually faithful diffusion world model for training agents in imagination. We explained key design choices for \textsc{diamond}'s diffusion world model that enables our implementation to remain stable over long time horizons with a low number of denoising steps. We demonstrate that this improved visual quality translates into improved agent performance on the well-established Atari 100k benchmark. As a result, \textsc{diamond} achieves a new state of the art among world model agents on this benchmark, with a mean human normalized score of $1.46$. The performance improvements are particularly evident for visually challenging environments, which is a promising sign that \textsc{diamond} could scale to visually complex real-world environments.
% % which is promising for scaling \textsc{diamond} to more visually complex real-world environments.

% This paper considers the training of autonomous agents using a world model. The deployment of autonomous agents in the real world raises safety concerns regarding the potential harm that may be caused by an agent's actions. Training in simulation reduces these risks by reducing the time the agent spends interacting with the environment. However, imperfect world models may lead to unexpected behaviors in the real world. The development of more realistic world models should therefore reduce the risk associated with deploying agents trained in this manner. Additionally, as with all advances in the field of Machine Learning, there are many other potential societal consequences of our work, but none of which we feel must be specifically highlighted here.