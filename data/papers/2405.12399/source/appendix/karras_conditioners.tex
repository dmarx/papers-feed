\section{\textsc{EDM} network preconditioners and training}
\label{appendix:karras_conditioners}

\citet{karras2022elucidating} use the following preconditioners for normalization and rescaling purposes (as mentioned in Section \ref{subsec:practical_dwm}) to improve network training:

\begin{equation}
    c_{in}^\tau = \frac{1}{\sqrt{\sigma(\tau)^2 + \sigma_{data}^2}}
\end{equation}
\begin{equation}
    c_{out}^\tau = \frac{\sigma(\tau)\sigma_{data}}{\sqrt{\sigma(\tau)^2 + \sigma_{data}^2}}
\end{equation}
\begin{equation}
    c_{noise}^\tau = \frac{1}{4}\log(\sigma(\tau))
\end{equation}
\begin{equation}
    c_{skip}^\tau = \frac{\sigma_{data}^2}{\sigma_{data}^2 + \sigma^2(\tau)},
\end{equation}
where $\sigma_{data}=0.5$.

The noise parameter $\sigma(\tau)$ is sampled to maximize the effectiveness of training as follows:
\begin{equation}
\log(\sigma(\tau))\sim \mathcal{N}(P_{mean}, P_{std}^2),
\end{equation}
where $P_{mean}=-0.4, P_{std}=1.2$. Refer to \citet{karras2022elucidating} for an in-depth analysis.