@article{deit,
  title={Training data-efficient image transformers \& distillation through attention},
  author={Touvron, Hugo and Cord, Matthieu and Douze, Matthijs and Massa, Francisco and Sablayrolles, Alexandre and J{\'e}gou, Herv{\'e}},
  journal={arXiv preprint arXiv:2012.12877},
  year={2020}
}

@inproceedings{Kolesnikov2020,
  author={Kolesnikov, A. and Beyer, L. and Zhai, X. and Puigcerver, J. and Yung, J. and Gelly, S. and Houlsby, N.},
  title={Big transfer (BiT): General visual representation learning},
  booktitle={ECCV},
  year={2020}
}

@inproceedings{Dosovitskiy2021,
  author={Dosovitskiy, A. and Beyer, L. and Kolesnikov, A. and Weissenborn, D. and Zhai, X. and Unterthiner, T. and Dehghani, M. and Minderer, M. and Heigold, G. and Gelly, S. and Uszkoreit, J. and Houlsby, N.},
  title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  booktitle={ICLR},
  year={2021}
}

@inproceedings{wu2019lightcnn,
  author={Wu, F. and Fan, A. and Baevski, A. and Dauphin, Y. and Auli, M.},
  title={Pay Less Attention with Lightweight and Dynamic Convolutions},
  booktitle={ICLR},
  year={2019}
}

@inproceedings{lin2016mlp,
  author={Lin, Z. and Memisevic, R. and Konda, K.},
  title={How far can we go without convolution: Improving fullyconnected networks},
  booktitle={ICLR, Workshop Track},
  year={2016}
}

@inproceedings{Sandler2019,
  author={Sandler, M. and Baccash, J. and Zhmoginov, A. and Howard},
  title={Non-discriminative data or weak model? {On} the relative importance of data and model resolution},
  booktitle={ICCV Workshop on Real-World Recognition from Low-Quality Images and Videos},
  year={2019}
}

@inproceedings{simonyan2014very,
  title={Very deep convolutional networks for large-scale image recognition},
  author={Simonyan, Karen and Zisserman, Andrew},
  booktitle={ICLR},
  year={2015}
}

@article{Xie2016,
  title={Aggregated Residual Transformations for Deep Neural Networks},
  author={Saining Xie and Ross Girshick and Piotr Doll√°r and Zhuowen Tu and Kaiming He},
  journal={arXiv preprint arXiv:1611.05431},
  year={2016}
}

@article{howard2017mobilenets,
  title={Mobilenets: Efficient convolutional neural networks for mobile vision applications},
  author={Howard, Andrew G and Zhu, Menglong and Chen, Bo and Kalenichenko, Dmitry and Wang, Weijun and Weyand, Tobias and Andreetto, Marco and Adam, Hartwig},
  journal={arXiv preprint arXiv:1704.04861},
  year={2017}
}
@inproceedings{hu2018squeeze,
  title={Squeeze-and-excitation networks},
  author={Hu, Jie and Shen, Li and Sun, Gang},
  booktitle={CVPR},
  year={2018}
}

@inproceedings{szegedy15inception,
  title={Going deeper with convolutions},
  author={Szegedy, C. and Liu, W. and Jia, Y. and Sermanet, P. and Reed, S. and Anguelov, D. and Erhan, D. and Vanhoucke, V. and Rabinovich, A.},
  booktitle={CVPR},
  year={2015}
}


@inproceedings{neyshabur2020towards,
 author = {Neyshabur, Behnam},
 title = {Towards Learning Convolutions from Scratch},
 booktitle = {NeurIPS},
 year = {2020}
}

@article{wang2021pyramid,
  title={Pyramid vision transformer: A versatile backbone for dense prediction without convolutions},
  author={Wang, Wenhai and Xie, Enze and Li, Xiang and Fan, Deng-Ping and Song, Kaitao and Liang, Ding and Lu, Tong and Luo, Ping and Shao, Ling},
  journal={arXiv preprint arXiv:2102.12122},
  year={2021}
}

@inproceedings{chollet2017xception,
  title={Xception: Deep learning with depthwise separable convolutions},
  author={Chollet, Fran{\c{c}}ois},
  booktitle={CVPR},
  year={2017}
}

@article{vaswani2021scaling,
  title={Scaling Local Self-Attention For Parameter Efficient Visual Backbones},
  author={Vaswani, Ashish and Ramachandran, Prajit and Srinivas, Aravind and Parmar, Niki and Hechtman, Blake and Shlens, Jonathon},
  journal={arXiv preprint arXiv:2103.12731},
  year={2021}
}

@article{jia2021scaling,
  title={Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision},
  author={Chao Jia and Yinfei Yang and Ye Xia and Yi-Ting Chen and Zarana Parekh and Hieu Pham and Quoc V. Le and Yunhsuan Sung and Zhen Li and Tom Duerig},
  journal={arXiv preprint arXiv:2102.05918},
  year={2021}
}

@InProceedings{cubuk2020rand,
author = {Cubuk, Ekin D. and Zoph, Barret and Shlens, Jonathon and Le, Quoc V.},
title = {{RandAugment}: Practical Automated Data Augmentation With a Reduced Search Space},
booktitle = {CVPR Workshops},
monthComment = {June},
year = {2020}
}

@inproceedings{zhang2018mixup,
  title={mixup: Beyond empirical risk minimization},
  author={Zhang, Hongyi and Cisse, Moustapha and Dauphin, Yann N and Lopez-Paz, David},
  booktitle={ICLR},
  year={2018}
}

@article{srivastava14dropout,
  author  = {Nitish Srivastava and Geoffrey Hinton and Alex Krizhevsky and Ilya Sutskever and Ruslan Salakhutdinov},
  title   = {Dropout: A Simple Way to Prevent Neural Networks from Overfitting},
  journal = {JMLR},
  year    = {2014},
  volume  = {15},
  number  = {56},
  pagesComment   = {1929-1958},
  urlComment     = {http://jmlr.org/papers/v15/srivastava14a.html}
}

@inproceedings{huang2016deep,
  title={Deep networks with stochastic depth},
  author={Huang, Gao and Sun, Yu and Liu, Zhuang and Sedra, Daniel and Weinberger, Kilian Q},
  booktitle={ECCV},
  year={2016},
}

@misc{rw2019timm,
  author = {Ross Wightman},
  title = {PyTorch Image Models},
  year = {2019},
  publisher = {GitHub},
  journal = {GitHub repository},
  doi = {10.5281/zenodo.4414861},
  howpublished = {\url{https://github.com/rwightman/pytorch-image-models}}
}

@article{touvron2020training,
  title={Training data-efficient image transformers \& distillation through attention},
  author={Touvron, Hugo and Cord, Matthieu and Douze, Matthijs and Massa, Francisco and Sablayrolles, Alexandre and J{\'e}gou, Herv{\'e}},
  journal={arXiv preprint arXiv:2012.12877},
  year={2020}
}

@article{pinz2006object,
year = {2006},
volume = {1},
journal = {Foundations and Trends in Computer Graphics and Vision},
title = {Object Categorization},
issnComment = {1572-2740},
number = {4},
author = {Axel Pinz}
}

@article{srinivas2021bottleneck,
  title={Bottleneck transformers for visual recognition},
  author={Srinivas, Aravind and Lin, Tsung-Yi and Parmar, Niki and Shlens, Jonathon and Abbeel, Pieter and Vaswani, Ashish},
  journal={arXiv preprint arXiv:2101.11605},
  year={2021}
}

@phdthesis{Sifre2014phd,
  author       = {Laurent Sifre}, 
  title        = {Rigid-Motion Scattering For Image
Classification},
  school       = {Ecole Polytechnique},
  year         = 2014,
  addressComment      = {CMAP},
  monthCOmment        = 10,
}

% Use NeurIPS version instead: ramachandran19-sasa
@article{ramachandran2019stand,
  title={Stand-alone self-attention in vision models},
  author={Ramachandran, Prajit and Parmar, Niki and Vaswani, Ashish and Bello, Irwan and Levskaya, Anselm and Shlens, Jonathon},
  journal={arXiv preprint arXiv:1906.05909},
  year={2019}
}

@article{li2021involution,
  title={Involution: Inverting the Inherence of Convolution for Visual Recognition},
  author={Li, Duo and Hu, Jie and Wang, Changhu and Li, Xiangtai and She, Qi and Zhu, Lei and Zhang, Tong and Chen, Qifeng},
  journal={CVPR},
  year={2021}
}

@article{bello2021lambdanetworks,
  title={{LambdaNetworks}: Modeling long-range interactions without attention},
  author={Bello, Irwan},
  journal={arXiv preprint arXiv:2102.08602},
  year={2021}
}

@article{ba2016layer,
  title={Layer normalization},
  author={Ba, Jimmy Lei and Kiros, Jamie Ryan and Hinton, Geoffrey E},
  journal={arXiv preprint arXiv:1607.06450},
  year={2016}
}

%%%% References from ViT %%%%%

@incollection{Bengio+chapter2007,
  author = {Bengio, Yoshua and LeCun, Yann},
  booktitle = {Large Scale Kernel Machines},
  publisher = {MIT Press},
  title = {Scaling Learning Algorithms Towards {AI}},
  year = {2007}
}

@article{Hinton06,
  author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee Whye},
  journal = {Neural Computation},
  pages = {1527--1554},
  title = {A Fast Learning Algorithm for Deep Belief Nets},
  volume = {18},
  year = {2006}
}

@article{Hendrycks2016GaussianEL,
  title={Gaussian Error Linear Units (GELUs).},
  author={Dan Hendrycks and Kevin Gimpel},
  journal={arXiv},
  year={2016}
}

@article{tay20synthesizer,
  title={Synthesizer: Rethinking Self-Attention in Transformer Models},
  author={Tay, Yi and Bahri, Dara and Metzler, Donald and Juan, Da-Cheng and Zhao, Zhe and Zheng, Che},
  journal={arXiv},
  year={2020}
}

@article{vitg,
  title={Scaling Vision Transformers},
  author={Zhai, Xiaohua and Kolesnikov, Alexander and Houlsby, Neil and Beyer, Lucas},
  journal={arXiv preprint arXiv:2106.04560},
  year={2021}
}

@book{goodfellow2016deep,
  title={Deep learning},
  author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
  volume={1},
  year={2016},
  publisher={MIT Press}
}

@inproceedings{Baevski2019Adaptive,
  title={Adaptive Input Representations for Neural Language Modeling},
  author={Alexei Baevski and Michael Auli},
  booktitle={ICLR},
  year={2019},
}

@inproceedings{glorot2011deep,
  title={Deep sparse rectifier neural networks},
  author={Glorot, Xavier and Bordes, Antoine and Bengio, Yoshua},
  booktitle={AISTATS},
  year={2011}
}

@inproceedings{kolesnikov2020-bit,
    title={Big Transfer {(BiT)}: General Visual Representation Learning},
    author={Alexander Kolesnikov and Lucas Beyer and Xiaohua Zhai and Joan Puigcerver and Jessica Yung and Sylvain Gelly and Neil Houlsby},
    year={2020},
    booktitle={ECCV}
}

@inproceedings{vaswani2017,
title = {Attention is All you Need},
author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
booktitle = {NeurIPS},
year = {2017},
}

@InProceedings{parmar18-imagetransformer,
title = {Image Transformer},
author = {Parmar, Niki and Vaswani, Ashish and Uszkoreit, Jakob and Kaiser, Lukasz and Shazeer, Noam and Ku, Alexander and Tran, Dustin},
booktitle = {ICML},
year = {2018}
}

@inproceedings{chen20-igpt,
  title={Generative Pretraining from Pixels},
  author={Chen, Mark and Radford, Alec and Child, Rewon and Wu, Jeff and Jun, Heewoo},
  booktitle = {ICML},
  year = {2020}
}

@inproceedings{ramachandran19-sasa,
title = {Stand-Alone Self-Attention in Vision Models},
author = {Ramachandran, Prajit and Parmar, Niki and Vaswani, Ashish and Bello, Irwan and Levskaya, Anselm and Shlens, Jon},
booktitle = {NeurIPS},
year = {2019},
}

@inproceedings{carion20-detr,
    title={End-to-End Object Detection with Transformers},
    author={Nicolas Carion and Francisco Massa and Gabriel Synnaeve and Nicolas Usunier and Alexander Kirillov and Sergey Zagoruyko},
    year={2020},
    booktitle = {ECCV},
}

@inproceedings{cordonnier2020-sacnn,
  title={On the Relationship between Self-Attention and Convolutional Layers},
  author={Jean-Baptiste Cordonnier and Andreas Loukas and Martin Jaggi},
  booktitle={ICLR},
  year={2020},
}

@inproceedings{devlin19-bert,
    title = "{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    author = "Devlin, Jacob  and
      Chang, Ming-Wei  and
      Lee, Kenton  and
      Toutanova, Kristina",
    booktitle = "{NAACL}",
    year = "2019",
}
    
@article{radford2018-gpt,
  title={Improving language understanding with unsupervised learning},
  author={Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya},
  journal={Technical Report},
  year={2018}
}

@article{radford2019-gpt2,
  title={Language Models are Unsupervised Multitask Learners},
  author={Radford, Alec and Wu, Jeff and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
  journal={Technical Report},  
  year={2019}
}

@article{brown2020-gpt3,
  title={Language models are few-shot learners},
  author={Brown, Tom B and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={arXiv},
  year={2020}
}

@article{child2019-sparsetransformers,
  title={Generating long sequences with sparse transformers},
  author={Child, Rewon and Gray, Scott and Radford, Alec and Sutskever, Ilya},
  journal={arXiv preprint arXiv:1904.10509},
  year={2019}
}

@inproceedings{bello2019-attentionaugmentedcnn,
  author={I. {Bello} and B. {Zoph} and Q. {Le} and A. {Vaswani} and J. {Shlens}},
  booktitle={ICCV}, 
  title={Attention Augmented Convolutional Networks}, 
  year={2019},
}

@article{locatello2020-slotattention,
    title={Object-Centric Learning with Slot Attention},
    author={Francesco Locatello and Dirk Weissenborn and Thomas Unterthiner and Aravindh Mahendran and Georg Heigold and Jakob Uszkoreit and Alexey Dosovitskiy and Thomas Kipf},
    year={2020},
    journal={arXiv},
}

@article{ho2019-axialattention,
  title={Axial Attention in Multidimensional Transformers},
  author={Ho, Jonathan and Kalchbrenner, Nal and Weissenborn, Dirk and Salimans, Tim},
  journal={arXiv},
  year={2019}
}

@inproceedings{weissenborn2019-savm,
  title={Scaling Autoregressive Video Models},
  author={Weissenborn, Dirk and T{\"a}ckstr{\"o}m, Oscar and Uszkoreit, Jakob},
  booktitle={ICLR},
  year={2019}
}

@inproceedings{huang2020ccnet,
  title={CCNet: Criss-Cross Attention for Semantic Segmentation}, 
  author={Zilong Huang and Xinggang Wang and Yunchao Wei and Lichao Huang and Humphrey Shi and Wenyu Liu and Thomas S. Huang},
  year={2020},
  booktitle={ICCV},
}

@inproceedings{wang2020-axialdeeplab,
    title={Axial-DeepLab: Stand-Alone Axial-Attention for Panoptic Segmentation},
    author={Huiyu Wang and Yukun Zhu and Bradley Green and Hartwig Adam and Alan Yuille and Liang-Chieh Chen},
    year={2020},
    booktitle = {ECCV},
}

@inproceedings{hu2018-relationnetworks,
  author    = {Han Hu and
               Jiayuan Gu and
               Zheng Zhang and
               Jifeng Dai and
               Yichen Wei},
  title     = {Relation Networks for Object Detection},
  booktitle = {CVPR},
  year      = {2018},
}

@InProceedings{wang2018-nonlocalnn,
author = {Wang, Xiaolong and Girshick, Ross and Gupta, Abhinav and He, Kaiming},
title = {Non-Local Neural Networks},
booktitle = {CVPR},
year = {2018}
}

@article{wu2020-visualtransformer,
  author={Bichen Wu and Chenfeng Xu and Xiaoliang Dai and Alvin Wan and Peizhao Zhang and Masayoshi Tomizuka and Kurt Keutzer and Peter Vajda},
  title={Visual Transformers: Token-based Image Representation and Processing for Computer Vision},
  year={2020},
  journal={arxiv},
}

@article{beyer2020-imagenet,
    title={Are we done with {ImageNet}?},
    author={Lucas Beyer and Olivier J. H√©naff and Alexander Kolesnikov and Xiaohua Zhai and A√§ron van den Oord},
    year={2020},
    journal={arXiv preprint arXiv:2006.07159},
}

@article{djolonga2020-robustness,
    title={On Robustness and Transferability of Convolutional Neural Networks},
    author={Josip Djolonga and Jessica Yung and Michael Tschannen and Rob Romijnders and Lucas Beyer and Alexander Kolesnikov and Joan Puigcerver and Matthias Minderer and Alexander D'Amour and Dan Moldovan and Sylvan Gelly and Neil Houlsby and Xiaohua Zhai and Mario Lucic},
    year={2020},
    journal={arXiv},
}

@InProceedings{xie2020-noisystudent,
author = {Xie, Qizhe and Luong, Minh-Thang and Hovy, Eduard and Le, Quoc V.},
title = {Self-Training With Noisy Student Improves ImageNet Classification},
booktitle = {CVPR},
year = {2020}
}

@InProceedings{mahajan2018,
author = {Mahajan, Dhruv and Girshick, Ross and Ramanathan, Vignesh and He, Kaiming and Paluri, Manohar and Li, Yixuan and Bharambe, Ashwin and van der Maaten, Laurens},
title = {Exploring the Limits of Weakly Supervised Pretraining},
booktitle = {ECCV},
year = {2018}
}

@inproceedings{touvron2019,
title = {Fixing the train-test resolution discrepancy},
author = {Touvron, Hugo and Vedaldi, Andrea and Douze, Matthijs and Jegou, Herve},
booktitle = {NeurIPS},
year = {2019},
}

@article{touvron2020,
      title={Fixing the train-test resolution discrepancy: FixEfficientNet}, 
      author={Hugo Touvron and Andrea Vedaldi and Matthijs Douze and Herve Jegou},
      year={2020},
      journal={arXiv preprint arXiv:2003.08237},
}

@InProceedings{zhao2020-san,
author = {Zhao, Hengshuang and Jia, Jiaya and Koltun, Vladlen},
title = {Exploring Self-Attention for Image Recognition},
booktitle = {CVPR},
year = {2020}
}
@InProceedings{sun2019-videobert,
author = {Sun, Chen and Myers, Austin and Vondrick, Carl and Murphy, Kevin and Schmid, Cordelia},
title = {VideoBERT: A Joint Model for Video and Language Representation Learning},
booktitle = {ICCV},
year = {2019}
}

@InProceedings{sun2017-jft,
author = {Sun, Chen and Shrivastava, Abhinav and Singh, Saurabh and Gupta, Abhinav},
title = {Revisiting Unreasonable Effectiveness of Data in Deep Learning Era},
booktitle = {ICCV},
year = {2017}
}

@InProceedings{deng2009-imagenet,
  author={J. {Deng} and W. {Dong} and R. {Socher} and L. {Li} and  {Kai Li} and  {Li Fei-Fei}},
  booktitle={CVPR}, 
  title={{ImageNet}: A large-scale hierarchical image database}, 
  year={2009},
}

@InProceedings{parkhi2012-pets,
  author       = "Omkar M. Parkhi and Andrea Vedaldi and Andrew Zisserman and C. V. Jawahar",
  title        = "Cats and Dogs",
  booktitle    = "CVPR",
  year         = "2012",
}

@techreport{Krizhevsky2009-cifar,
    author = {Alex Krizhevsky},
    title = {Learning multiple layers of features from tiny images},
    year = {2009},
    institution = {University of Toronto},
}

@INPROCEEDINGS{Nilsback2008-flowers,
  author={M. {Nilsback} and A. {Zisserman}},
  booktitle={ICVGIP}, 
  title={Automated Flower Classification over a Large Number of Classes}, 
  year={2008},
}


@article{gencoglu2019-hark,
      title={HARK Side of Deep Learning -- From Grad Student Descent to Automated Machine Learning}, 
      author={Oguzhan Gencoglu and Mark van Gils and Esin Guldogan and Chamin Morikawa and Mehmet S√ºzen and Mathias Gruber and Jussi Leinonen and Heikki Huttunen},
      year={2019},
      journal={arXiv},
}

@inproceedings{wang2019-preLN,
    title = "Learning Deep Transformer Models for Machine Translation",
    author = "Wang, Qiang  and
      Li, Bei  and
      Xiao, Tong  and
      Zhu, Jingbo  and
      Li, Changliang  and
      Wong, Derek F.  and
      Chao, Lidia S.",
    booktitle = "ACL",
    year = "2019",
}

@inproceedings{abnar2020quantifying,
    title={Quantifying Attention Flow in Transformers}, 
    author={Samira Abnar and Willem Zuidema},
    year={2020},
    booktitle = "ACL",
}

@inproceedings{KrizhevskyNIPS12,
  author    = {Alex Krizhevsky and
               Ilya Sutskever and
               Geoffrey E. Hinton},
  title     = {{ImageNet} Classification with Deep Convolutional Neural Networks},
  booktitle = {NeurIPS},
  year      = {2012},
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={CVPR},
  year={2016}
}


@inproceedings{Chen2020simclr,
  title={A Simple Framework for Contrastive Learning of Visual Representations},
  author={Ting Chen and Simon Kornblith and Mohammad Norouzi and Geoffrey E. Hinton},
  booktitle={ICML},
  year={2020}
}

@inproceedings{he2020moco,
  title={Momentum Contrast for Unsupervised Visual Representation Learning},  
  author={Kaiming He and Haoqi Fan and Yuxin Wu and Saining Xie and Ross Girshick},
  booktitle={CVPR},
  year={2020}
}

@inproceedings{henaff2020cpc,
  title={Data-Efficient Image Recognition with Contrastive Predictive Coding}, 
  author={Olivier J. H√©naff and Aravind Srinivas and Jeffrey De Fauw and Ali Razavi and Carl Doersch and S. M. Ali Eslami and Aaron van den Oord},
  booktitle={ICML},
  year={2020}
}

@inproceedings{bachman2019amdim,
  title={Learning Representations by Maximizing Mutual Information Across Views}, 
  author={Philip Bachman and R Devon Hjelm and William Buchwalter},
  booktitle={NeurIPS},
  year={2019}
}

@inproceedings{grill2020byol,
  title={Bootstrap your own latent: A new approach to self-supervised Learning}, 
  author={Jean-Bastien Grill and Florian Strub and Florent Altch√© and Corentin Tallec and Pierre H. Richemond and Elena Buchatskaya and Carl Doersch and Bernardo Avila Pires and Zhaohan Daniel Guo and Mohammad Gheshlaghi Azar and Bilal Piot and Koray Kavukcuoglu and R√©mi Munos and Michal Valko},
  booktitle={NeurIPS},
  year={2020}
}

@InProceedings{vivi,
author = {Tschannen, Michael and Djolonga, Josip and Ritter, Marvin and Mahendran, Aravindh and Houlsby, Neil and Gelly, Sylvain and Lucic, Mario},
title = {Self-Supervised Learning of Video-Induced Visual Invariances},
booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2020}
}

@inproceedings{zhai2019s4l,
  title={{S$^\mathbf{4}$L: Self-Supervised Semi-Supervised Learning}},
  author={Zhai, Xiaohua and Oliver, Avital and Kolesnikov, Alexander and Beyer, Lucas},
  booktitle={ICCV},
  year={2019}
}

@article{vtab,
  title={A Large-scale Study of Representation Learning with the Visual Task Adaptation Benchmark},
  author={Zhai, Xiaohua and Puigcerver, Joan and Kolesnikov, Alexander and Ruyssen, Pierre and Riquelme, Carlos and Lucic, Mario and Djolonga, Josip and Pinto, Andre Susano and Neumann, Maxim and Dosovitskiy, Alexey and others},
  journal={arXiv preprint arXiv:1910.04867},
  year={2019}
}

@article{wang2020axial,
  title={Axial-DeepLab: Stand-Alone Axial-Attention for Panoptic Segmentation},
  author={Wang, Huiyu and Zhu, Yukun and Green, Bradley and Adam, Hartwig and Yuille, Alan and Chen, Liang-Chieh},
  journal={arXiv preprint arXiv:2003.07853},
  year={2020}
}

@article{polyak,
    author = {Polyak, B. T. and Juditsky, A. B.},
    title = {Acceleration of Stochastic Approximation by Averaging},
    journal = {SIAM Journal on Control and Optimization},
    volume = {30},
    number = {4},
    pages = {838-855},
    year = {1992},
    doiComment = {10.1137/0330046},
    URLComment = {https://doi.org/10.1137/0330046},
    eprint = {https://doi.org/10.1137/0330046}
}

@inproceedings{chenuniter,
  title={{UNITER: UNiversal Image-TExt Representation Learning}},
  author={Chen, Yen-Chun and Li, Linjie and Yu, Licheng and Kholy, Ahmed El and Ahmed, Faisal and Gan, Zhe and Cheng, Yu and Liu, Jingjing},
  booktitle={ECCV},
  year={2020}
}

@incollection{vilbert,
title = {{ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks}},
author = {Lu, Jiasen and Batra, Dhruv and Parikh, Devi and Lee, Stefan},
booktitle = {NeurIPS},
year = {2019},
}

@inproceedings{visualbert,
  author = {Li, Liunian Harold and Yatskar, Mark and Yin, Da and Hsieh, Cho-Jui and Chang, Kai-Wei},
  title = {{VisualBERT: A Simple and Performant Baseline for Vision and Language}},
  booktitle = {Arxiv},
  year = {2019}
}

@article{LeCun1989BackpropagationAT,
  title={Backpropagation Applied to Handwritten Zip Code Recognition},
  author={Y. LeCun and B. Boser and J. Denker and D. Henderson and R. Howard and W. Hubbard and L. Jackel},
  journal={Neural Computation},
  year={1989},
  volume={1},
  pages={541-551}
}

@inproceedings{ioffe2015batch,
title	= {Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift},
author	= {Sergey Ioffe and Christian Szegedy},
year	= {2015},
booktitle  = {ICML},
}

@inproceedings{wu2018group,
  title={Group normalization},
  author={Wu, Yuxin and He, Kaiming},
  booktitle={ECCV},
  year={2018}
}

@inproceedings{salimans2016weight,
  title={Weight normalization: A simple reparameterization to accelerate training of deep neural networks},
  author={Salimans, Tim and Kingma, Durk P},
  booktitle={NeurIPS},
  year={2016}
}

@inproceedings{kingma2015adam,
  author    = {Diederik P. Kingma and
               Jimmy Ba},
  title     = {Adam: {A} Method for Stochastic Optimization},
  booktitle = {{ICLR}},
  year      = {2015},
}

@article{qiao2019ws,
  author    = {Siyuan Qiao and Huiyu Wang and Chenxi Liu and Wei Shen and Alan Yuille},
  title     = {Weight Standardization},
  journal   = {arXiv preprint arXiv:1903.10520},
  year      = {2019},
}

@inproceedings{hu2019local,
	title={Local Relation Networks for Image Recognition},
	author={Hu, Han and Zhang, Zheng and Xie, Zhenda and Lin, Stephen},
	booktitle={ICCV},
	year={2019}
}

@article{lepikhin2020gshard,
      title={GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding}, 
      author={Dmitry Lepikhin and HyoukJoong Lee and Yuanzhong Xu and Dehao Chen and Orhan Firat and Yanping Huang and Maxim Krikun and Noam Shazeer and Zhifeng Chen},
      year={2020},
      eprint={2006.16668},
      journal={arXiv},
}

@article{brock2021high,
  title={High-Performance Large-Scale Image Recognition Without Normalization},
  author={Brock, Andrew and De, Soham and Smith, Samuel L and Simonyan, Karen},
  journal={arXiv preprint arXiv:2102.06171},
  year={2021}
}

@inproceedings{pham2020meta,
  title={Meta pseudo labels},
  author={Pham, Hieu and Dai, Zihang and Xie, Qizhe and Luong, Minh-Thang and Le, Quoc V},
  journalComment={arXiv preprint arXiv:2003.10580 --> year=2020},
  booktitle={CVPR},
  year={2021},
}

@article{bello2021revisiting,
  title={Revisiting {ResNets}: Improved training and scaling strategies},
  author={Bello, Irwan and Fedus, William and Du, Xianzhi and Cubuk, Ekin D and Srinivas, Aravind and Lin, Tsung-Yi and Shlens, Jonathon and Zoph, Barret},
  journal={arXiv preprint arXiv:2103.07579},
  year={2021}
}

@inproceedings{inception,
author = {Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jon and Wojna, Zbigniew},
year = {2016},
booktitle = {CVPR},
title = {Rethinking the Inception Architecture for Computer Vision},
doiComment = {10.1109/CVPR.2016.308}
}

@inproceedings{autoaugment,
title	= {{AutoAugment}: Learning Augmentation Policies from Data},
author	= {Ekin Dogus Cubuk and Barret Zoph and Dandelion Mane and Vijay Vasudevan and Quoc V. Le},
year	= {2019},
booktitle={CVPR},
}

@article{araujo2019computing,
  author = {Araujo, Andr√© and Norris, Wade and Sim, Jack},
  title = {Computing Receptive Fields of Convolutional Neural Networks},
  journal = {Distill},
  year = {2019},
  url = {https://distill.pub/2019/computing-receptive-fields},
  doi = {10.23915/distill.00021}
}

@inproceedings{luo2017understanding,
  title={Understanding the effective receptive field in deep convolutional neural networks},
  author={Luo, Wenjie and Li, Yujia and Urtasun, Raquel and Zemel, Richard},
  arXivComment={arXiv preprint arXiv:1701.04128},
  booktitle = {NeurIPS},
  year={2016}
}

@inproceedings{shang2016crelu,
author = {Shang, Wenling and Sohn, Kihyuk and Almeida, Diogo and Lee, Honglak},
title = {Understanding and Improving Convolutional Neural Networks via Concatenated Rectified Linear Units},
year = {2016},
booktitle = {ICML}
}

@article{bhojanapalli2021understanding,
  title={Understanding Robustness of Transformers for Image Classification},
  author={Bhojanapalli, Srinadh and Chakrabarti, Ayan and Glasner, Daniel and Li, Daliang and Unterthiner, Thomas and Veit, Andreas},
  journal={arXiv preprint arXiv:2103.14586},
  year={2021}
}

@inproceedings{yun2019transformers,
  title={Are Transformers universal approximators of sequence-to-sequence functions?},
  author={Yun, Chulhee and Bhojanapalli, Srinadh and Rawat, Ankit Singh and Reddi, Sashank and Kumar, Sanjiv},
  booktitle={ICLR},
  year={2019}
}

@article{hendrycks2016gelu,
  title={Gaussian Error Linear Units {(GELUs)}},
  author={Hendrycks, Dan and Gimpel, Kevin},
  journal={arXiv preprint arXiv:1606.08415},
  year={2016}
}

@article{kaplan2020scaling,
  title={Scaling laws for neural language models},
  author={Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  journal={arXiv preprint arXiv:2001.08361},
  year={2020}
}
