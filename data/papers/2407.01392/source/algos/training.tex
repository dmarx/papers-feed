\begin{algorithm}[H]
\footnotesize
\caption{\algo{} Training}
\label{alg:diffusion_forcing_training}
\begin{algorithmic}[1]
\LOOP
    \STATE Sample tajectory of observations $(\bx_1, ..., \bx_T)$.
    \FOR{$t = 1, ..., T$}
        \STATE Sample independent noise level $k_t \in \{0,1, ... ,K\}$
        \STATE $\xtk=\ $ForwardDiffuse$(\bx_t, k_t)$
        \STATE Define $\epsilon_t = \frac{\xtk-\sqrt{\bar{\alpha}_{k_t}} \bx_t}{\sqrt{1-\bar{\alpha}_{k_t}}}$ 
         \STATE Update $\bz_t \sim p_\theta(\bz_t|\bz_{t-1}, \xtk, k_t)$.
        \STATE Set $\hat{\epsilon}_t = \epsilon_\theta(\bz_{t-1},\xtk,k_t)$
    \ENDFOR
    \STATE $L=$MSELoss$(\left[\hat{\epsilon}_1, ..., \hat{\epsilon}_n\right], \left[\epsilon_1, ..., \epsilon_n\right])$ 
    \STATE Backprop with $L$ and update $\theta$
\ENDLOOP
\end{algorithmic}
\end{algorithm}
