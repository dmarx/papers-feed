\begin{algorithm}[H]
\footnotesize
\caption{\algshort{} Sampling with Guidance}
\label{alg:diffusion_forcing_sampling}
\begin{algorithmic}[1]
\STATE \textbf{Input:} Model  $\theta$, scheduling matrix $\cK$, initial latent $\bz_0$, guidance cost $c(\cdot)$.
\STATE \textbf{Initialize} $\bx_1,\dots,\bx_T \sim \cN(0,\sigma_K^2 I)$. 
    \FOR{row $m = M-1, ..., 0$}
    \FOR{$t = 1,\dots,T$}
        \STATE $\bz_t^{\mathrm{new}} \sim p_{\theta}(\bz_t \mid \bz_{t-1}, \bx_t,\cK_{m+1,t})$.  \label{line:latent_infernece}
        \STATE $k \gets \cK_{m,t}$, $\mathbf{w} \sim \cN(0,\mathbf{I})$.
        \STATE $ \bx_t^{\mathrm{new}} \gets \frac{1}{\sqrt{\alpha_k}}(\bx_t - \frac{1-\alpha_k}{\sqrt{1-\bar{\alpha}_k}}\epsilon_{\theta}(\bz_t^{\mathrm{new}},\bx_t,k)) + \sigma_k \mathbf{w}$ 
        \label{alg:line_backward}
        \STATE \textbf{Update} $\bz_t \gets \bz_t^{\mathrm{new}}$.
    \ENDFOR
    \STATE
    $\bx_{1:H} \leftarrow$AddGuidance$(\bx_{1:H}^{\mathrm{new}}, \nabla_{\bx}\log c({\bx}_{1:H}^{\mathrm{new}} ))$
    \ENDFOR
    \STATE \textbf{Return} $\bx_{1:T}$.
    \vspace{1.5pt}
\end{algorithmic}
\end{algorithm}
