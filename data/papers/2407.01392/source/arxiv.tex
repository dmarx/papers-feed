
\documentclass{article}



\usepackage{bm,verbatim}
\usepackage{algorithmic,algorithm}

\usepackage[final, nonatbib]{neurips_2024}





\usepackage{microtype}
\usepackage{wrapfig}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{booktabs} %
\usepackage[colorlinks,citecolor=blue]{hyperref}
\newcommand{\theHalgorithm}{\arabic{algorithm}}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{relsize}
\usepackage{physics}
\usepackage[normalem]{ulem}

\newcommand{\bx}{\mathbf{x}}
\newcommand{\bs}{\mathbf{s}}
\newcommand{\ba}{\mathbf{a}}
\newcommand{\bo}{\mathbf{o}}
\newcommand{\br}{\mathbf{r}}
\newcommand{\xtk}{\bx_t^{k_t}}
\newcommand{\bz}{\mathbf{z}}
\newcommand{\by}{\mathbf{y}}
\newcommand{\Exp}{\mathop{\mathlarger{\mathbb{E}}}}
\newcommand{\cN}{\mathcal{N}}
\newcommand{\cK}{\mathcal{K}}
\newcommand{\R}{\mathbb{R}}

\usepackage[capitalize,noabbrev]{cleveref}

\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{claim}{Claim}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}{Remark}

\usepackage{color,verbatim}
\usepackage{color-edits}
\usepackage{titlesec}
\addauthor{ms}{magenta}
\addauthor{bc}{cyan}
\addauthor{dmm}{olive}
\addauthor{russt}{orange}
\addauthor{vs}{blue}
\newcommand{\yd}[1]{\textcolor{red}{#1}}

\usepackage[textsize=tiny]{todonotes}
\usepackage{ctable}%

\title{Diffusion Forcing: Next-token Prediction\\Meets Full-Sequence Diffusion}

\author{%
  Boyuan Chen \\
  MIT CSAIL\\
  \texttt{boyuanc@mit.edu} \\
  \And
  Diego Marti Monso\thanks{Work done as a visiting student at MIT.} \\
  Technical University of Munich\\
  \texttt{diego.marti@tum.de} \\
  \And
  Yilun Du \\
  MIT CSAIL\\
  \texttt{yilundu@mit.edu} \\
  \And
  Max Simchowitz \\
  MIT CSAIL\\
  \texttt{msimchow@mit.edu} \\
  \And
  Russ Tedrake \\
  MIT CSAIL\\
  \texttt{russt@mit.edu} \\
  \And
  Vincent Sitzmann \\
  MIT CSAIL\\
  \texttt{sitzmann@mit.edu} \\
}

\newcommand{\algo}{{Diffusion Forcing}}
\newcommand{\algoseq}{{Causal Diffusion Forcing}}
\newcommand{\algons}{Diffusion Forcing}
\newcommand{\algshort}{DF}
\newcommand{\algshortseq}{CDF}
\newcommand{\algopar}{(Causal) Diffusion Forcing}

\makeatletter
\renewcommand{\paragraph}{%
  \@startsection{paragraph}{4}%
  {\z@}{0ex \@plus 0ex \@minus 0.ex}{-0.5em}%
  {\normalfont\normalsize\bfseries}%
}
\makeatother


\begin{document}
\maketitle
\numberwithin{equation}{section}

\begin{abstract}
This paper presents \algons{}, a new training paradigm where a diffusion model is trained to denoise a set of tokens with \emph{independent} per-token noise levels.
We apply \algons{} to sequence generative modeling by training a causal next-token prediction model to generate one or several future tokens without fully diffusing past ones. Our approach is shown to combine the strengths of next-token prediction models, such as variable-length generation, with the strengths of full-sequence diffusion models, such as the ability to guide sampling to desirable trajectories. Our method offers a range of additional capabilities, such as (1) rolling-out sequences of continuous tokens, such as video, with lengths past the training horizon, where baselines diverge and (2) new sampling and guiding schemes that uniquely profit from \algons{}'s variable-horizon and causal architecture,  and which lead to marked performance gains in decision-making and planning tasks. In addition to its empirical success, our method is proven to optimize a variational lower bound on the likelihoods of all subsequences of tokens drawn from the true joint distribution. Project website: \url{https://boyuan.space/diffusion-forcing}

\end{abstract}

\input{tex/intro}
\input{tex/related_work}
\input{tex/method_new}


\input{tex/theory}
\input{tex/experiment}
\input{tex/conclusion}

\small\paragraph{Acknowledgements.} This work was supported by the National Science Foundation under Grant No. 2211259, by the Singapore DSTA under DST00OECI20300823 (3D Self-Supervised Learning for Label-Efficient Vision), by the Intelligence Advanced Research Projects Activity (IARPA) via Department of Interior/ Interior Business Center (DOI/IBC) under 140D0423C0075, and by the Amazon Science Hub.



\bibliographystyle{abbrv} 
\bibliography{arxiv}


\newpage
\appendix
\input{tex/app_theory_new}
\input{tex/app_intuition}
\input{tex/app_extended_related}
\input{tex/app_method}
\input{tex/app_experiments}
\input{tex/app_dataset}




\end{document}
