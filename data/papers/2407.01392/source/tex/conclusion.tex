\section{Discussion}
\label{sec:discussion}
\paragraph{Limitations.} Our current causal implementation is based on an RNN. Applications to higher-resolution video or more complex distributions likely require large transformer models following instructions in Appendix~\ref{app:transformer}. We do not investigate the scaling behavior of \algo{} to internet-scale datasets and tasks. 
\paragraph{Conclusion.} In this paper, we introduced \algo{}, a new training paradigm where a model is trained to denoise sets of tokens with independent, per-token noise levels.
Applied to time series data, we show how a next-token prediction model trained with \algo{} combines the benefits of both next-token models and full-sequence diffusion models.
We introduced new sampling and guidance schemes that lead to dramatic performance gains when applied to tasks in sequential decision making.
Future work may investigate the application of \algo{} to domains other than time series generative modeling, and scale up \algo{} to larger datasets.
