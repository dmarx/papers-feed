---
abstract: |
  This paper presents Diffusion Forcing, a new training paradigm where a diffusion model is trained to denoise a set of tokens with *independent* per-token noise levels. We apply Diffusion Forcing to sequence generative modeling by training a causal next-token prediction model to generate one or several future tokens without fully diffusing past ones. Our approach is shown to combine the strengths of next-token prediction models, such as variable-length generation, with the strengths of full-sequence diffusion models, such as the ability to guide sampling to desirable trajectories. Our method offers a range of additional capabilities, such as (1) rolling-out sequences of continuous tokens, such as video, with lengths past the training horizon, where baselines diverge and (2) new sampling and guiding schemes that uniquely profit from Diffusion Forcingâ€™s variable-horizon and causal architecture, and which lead to marked performance gains in decision-making and planning tasks. In addition to its empirical success, our method is proven to optimize a variational lower bound on the likelihoods of all subsequences of tokens drawn from the true joint distribution. Project website: <https://boyuan.space/diffusion-forcing>
author:
- |
  Boyuan Chen  
  MIT CSAIL  
  `boyuanc@mit.edu`  
  Diego Marti Monso[^1]  
  Technical University of Munich  
  `diego.marti@tum.de`  
  Yilun Du  
  MIT CSAIL  
  `yilundu@mit.edu`  
  Max Simchowitz  
  MIT CSAIL  
  `msimchow@mit.edu`  
  Russ Tedrake  
  MIT CSAIL  
  `russt@mit.edu`  
  Vincent Sitzmann  
  MIT CSAIL  
  `sitzmann@mit.edu`  
bibliography:
- arxiv.bib
citation-style: ieee
header-includes:
- 
- 
link-citations: true
reference-section-title: References
title: |
  Diffusion Forcing: Next-token Prediction  
  Meets Full-Sequence Diffusion
---





0ex 0ex 0.ex-0.5em Acknowledgements. This work was supported by the National Science Foundation under Grant No. 2211259, by the Singapore DSTA under DST00OECI20300823 (3D Self-Supervised Learning for Label-Efficient Vision), by the Intelligence Advanced Research Projects Activity (IARPA) via Department of Interior/ Interior Business Center (DOI/IBC) under 140D0423C0075, and by the Amazon Science Hub.

[^1]: Work done as a visiting student at MIT.
