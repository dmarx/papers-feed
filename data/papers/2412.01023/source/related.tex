\section{Related Work}
\label{sec:related}

\subparagraph{Learning with Label Hierarchy.} Several recent works have explored how to leverage hierarchical information between classes for various purposes such as relational consistency 
 \citep{DengHEX}, designing specific hierarchical classification architectures \citep{HDCNN,guoCNNRNN, noor2022capsule}, hierarchical conditioning of the logits \citep{davis2021hierarchical}, learning order preserving embeddings \citep{dhall2020hierarchical}, and improving classification accuracy \citep{iclr16CL, taherkhani2019weakly, lei2017weakly, semantivisualHierarchy, ZHENG201797, hoffmann2022ranking}. The proposed structural regularization framework in \citep{zeng2022learning} offers an interesting approach to embed a tree metric to learn structured representations through an \emph{explicit} objective term, although they rely on the $\ell_2$ distance, which is less than ideal for learning hierarchies. 
 
\subparagraph{Hyperbolic Geometry.}
\citep{nickel2017poincare} first proposed using the hyperbolic space to learn hierarchical representations of symbolic data such as text and graphs by embedding them into a \Poincare ball. Since then, the use of hyperbolic geometry has been explored in several different applications. \citet{khrulkov2020hyperbolic} proposed a hyperbolic image embedding for few-shot learning and person re-identification. \citep{ganea2018hyperbolic} proposed hyperbolic neural network layers, enabling the development of hybrid architectures such as hyperbolic convolutional neural networks \citep{shimizu2020hyperbolic}, graph convolutional networks \citep{dai2021hyperbolic}, hyperbolic variational autoencoders \citep{mathieu2019continuous} and hyperbolic attention networks \citep{gulcehre2018hyperbolic}. Additionally, these hybrid architectures have also been explored for different tasks such as deep metric learning \citep{ermolov2022hyperbolic, yan2021unsupervised}, object detection \citep{lang2022hyperbolic} and natural language processing \citep{dhingra2018embedding}. There have also been several investigations into the properties of hyperbolic spaces and models such as low distortion \citep{Sarkar_2012}, small generalization error \citep{suzuki2021generalization} and representation capacity \citep{mishne2023numerical}. However, none of these works have leveraged  hyperbolic geometry for \emph{explicitly} embedding a hierarchy in the representation space via structured regularization, and usually attempt to leverage the underlying hierarchy \emph{implicitly} using hyperbolic models. 