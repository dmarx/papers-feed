@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})



@misc{Authors14,
 author = {FirstName LastName},
 title = {The frobnicatable foo filter},
 note = {Face and Gesture submission ID 324. Supplied as supplemental material {\tt fg324.pdf}},
 year = 2014
}

@misc{Authors14b,
 author = {FirstName LastName},
 title = {Frobnication tutorial},
 note = {Supplied as supplemental material {\tt tr.pdf}},
 year = 2014
}



@article{dhariwal2021diffusion,
  title={Diffusion models beat gans on image synthesis},
  author={Dhariwal, Prafulla and Nichol, Alexander},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={8780--8794},
  year={2021}
}

@article{ho2020denoising,
  title={Denoising diffusion probabilistic models},
  author={Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={6840--6851},
  year={2020}
}

@inproceedings{sohl2015deep,
  title={Deep unsupervised learning using nonequilibrium thermodynamics},
  author={Sohl-Dickstein, Jascha and Weiss, Eric and Maheswaranathan, Niru and Ganguli, Surya},
  booktitle={International conference on machine learning},
  pages={2256--2265},
  year={2015},
  organization={PMLR}
}

@article{song2019generative,
  title={Generative modeling by estimating gradients of the data distribution},
  author={Song, Yang and Ermon, Stefano},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{ramesh2022hierarchical,
  title={Hierarchical text-conditional image generation with clip latents},
  author={Ramesh, Aditya and Dhariwal, Prafulla and Nichol, Alex and Chu, Casey and Chen, Mark},
  journal={arXiv preprint arXiv:2204.06125},
  volume={1},
  number={2},
  pages={3},
  year={2022}
}

@article{saharia2022photorealistic,
  title={Photorealistic text-to-image diffusion models with deep language understanding},
  author={Saharia, Chitwan and Chan, William and Saxena, Saurabh and Li, Lala and Whang, Jay and Denton, Emily L and Ghasemipour, Kamyar and Gontijo Lopes, Raphael and Karagol Ayan, Burcu and Salimans, Tim and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={36479--36494},
  year={2022}
}

@article{chen2023pixart,
  title={Pixart-alpha: Fast training of diffusion transformer for photorealistic text-to-image synthesis},
  author={Chen, Junsong and Yu, Jincheng and Ge, Chongjian and Yao, Lewei and Xie, Enze and Wu, Yue and Wang, Zhongdao and Kwok, James and Luo, Ping and Lu, Huchuan and others},
  journal={arXiv preprint arXiv:2310.00426},
  year={2023}
}

@inproceedings{peebles2023scalable,
  title={Scalable diffusion models with transformers},
  author={Peebles, William and Xie, Saining},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={4195--4205},
  year={2023}
}



@article{li2024snapfusion,
  title={Snapfusion: Text-to-image diffusion model on mobile devices within two seconds},
  author={Li, Yanyu and Wang, Huan and Jin, Qing and Hu, Ju and Chemerys, Pavlo and Fu, Yun and Wang, Yanzhi and Tulyakov, Sergey and Ren, Jian},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{shih2024parallel,
  title={Parallel sampling of diffusion models},
  author={Shih, Andy and Belkhale, Suneel and Ermon, Stefano and Sadigh, Dorsa and Anari, Nima},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{yang2024cogvideox,
  title={Cogvideox: Text-to-video diffusion models with an expert transformer},
  author={Yang, Zhuoyi and Teng, Jiayan and Zheng, Wendi and Ding, Ming and Huang, Shiyu and Xu, Jiazheng and Yang, Yuanming and Hong, Wenyi and Zhang, Xiaohan and Feng, Guanyu and others},
  journal={arXiv preprint arXiv:2408.06072},
  year={2024}
}

@article{chen2024pixart,
  title={Pixart-sigma: Weak-to-strong training of diffusion transformer for 4k text-to-image generation},
  author={Chen, Junsong and Ge, Chongjian and Xie, Enze and Wu, Yue and Yao, Lewei and Ren, Xiaozhe and Wang, Zhongdao and Luo, Ping and Lu, Huchuan and Li, Zhenguo},
  journal={arXiv preprint arXiv:2403.04692},
  year={2024}
}

@article{sauer2023adversarial,
  title={Adversarial diffusion distillation},
  author={Sauer, Axel and Lorenz, Dominik and Blattmann, Andreas and Rombach, Robin},
  journal={arXiv preprint arXiv:2311.17042},
  year={2023}
}

@article{ma2024learning,
  title={Learning-to-Cache: Accelerating Diffusion Transformer via Layer Caching},
  author={Ma, Xinyin and Fang, Gongfan and Mi, Michael Bi and Wang, Xinchao},
  journal={arXiv preprint arXiv:2406.01733},
  year={2024}
}

@article{chen2024q,
  title={Q-dit: Accurate post-training quantization for diffusion transformers},
  author={Chen, Lei and Meng, Yuan and Tang, Chen and Ma, Xinzhu and Jiang, Jingyan and Wang, Xin and Wang, Zhi and Zhu, Wenwu},
  journal={arXiv preprint arXiv:2406.17343},
  year={2024}
}

@article{wang2023videolcm,
  title={Videolcm: Video latent consistency model},
  author={Wang, Xiang and Zhang, Shiwei and Zhang, Han and Liu, Yu and Zhang, Yingya and Gao, Changxin and Sang, Nong},
  journal={arXiv preprint arXiv:2312.09109},
  year={2023}
}

@inproceedings{meng2023distillation,
  title={On distillation of guided diffusion models},
  author={Meng, Chenlin and Rombach, Robin and Gao, Ruiqi and Kingma, Diederik and Ermon, Stefano and Ho, Jonathan and Salimans, Tim},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={14297--14306},
  year={2023}
}

@article{smith1982cache,
  title={Cache memories},
  author={Smith, Alan Jay},
  journal={ACM Computing Surveys (CSUR)},
  volume={14},
  number={3},
  pages={473--530},
  year={1982},
  publisher={ACM New York, NY, USA}
}

@inproceedings{goodman1983using,
  title={Using cache memory to reduce processor-memory traffic},
  author={Goodman, James R},
  booktitle={Proceedings of the 10th annual international symposium on Computer architecture},
  pages={124--131},
  year={1983}
}

@inproceedings{albonesi1999selective,
  title={Selective cache ways: On-demand cache resource allocation},
  author={Albonesi, David H},
  booktitle={MICRO-32. Proceedings of the 32nd Annual ACM/IEEE International Symposium on Microarchitecture},
  pages={248--259},
  year={1999},
  organization={IEEE}
}

@inproceedings{xu2018deepcache,
  title={Deepcache: Principled cache for mobile deep vision},
  author={Xu, Mengwei and Zhu, Mengze and Liu, Yunxin and Lin, Felix Xiaozhu and Liu, Xuanzhe},
  booktitle={Proceedings of the 24th annual international conference on mobile computing and networking},
  pages={129--144},
  year={2018}
}

@article{selvaraju2024fora,
  title={Fora: Fast-forward caching in diffusion transformer acceleration},
  author={Selvaraju, Pratheba and Ding, Tianyu and Chen, Tianyi and Zharkov, Ilya and Liang, Luming},
  journal={arXiv preprint arXiv:2407.01425},
  year={2024}
}

@article{zhao2024real,
  title={Real-Time Video Generation with Pyramid Attention Broadcast},
  author={Zhao, Xuanlei and Jin, Xiaolong and Wang, Kai and You, Yang},
  journal={arXiv preprint arXiv:2408.12588},
  year={2024}
}

@misc{Open-Sora,
    title = {Open-sora: Democratizing efficient video production for all},
    note = {https://github.com/hpcaitech/Open-Sora},
    author = {Zheng, Zangwei and Peng, Xiangyu and  Yang, Tianji and Shen, Chenhui and Li, Shenggui and Liu, Hongxin and Zhou, Yukun and Li, Tianyi and You, Yang},
    year = {2024},
}

@misc{Open-Sora-Plan,
    title = {Open-sora: Democratizing efficient video production for all},
    note = {https://doi.org/10. 5281/zenodo.10948109},
    author = {PKU-Yuan Lab and Tuzhan AI etc.},
    year = {2024},
}
@misc{Sora,
    title = {Sora},
    note = {https://openai.com/index/sora/},
    author = {OpenAI},
    year = {2024},
}

@misc{Vchitect,
    title = {Vchitect. Vchitect-2.0: Parallel transformer for scaling up video diffusion models},
    note = {https://github.com/Vchitect/Vchitect-2.0},
    author = {},
    year = {2024},
}

@misc{Mochi,
    title = {Mochi 1},
    note = {https://www.genmo.ai},
    author = {},
    year = {2024},
}

@article{ma2024latte,
  title={Latte: Latent diffusion transformer for video generation},
  author={Ma, Xin and Wang, Yaohui and Jia, Gengyun and Chen, Xinyuan and Liu, Ziwei and Li, Yuan-Fang and Chen, Cunjian and Qiao, Yu},
  journal={arXiv preprint arXiv:2401.03048},
  year={2024}
}

@article{sun2024t2v,
  title={T2V-CompBench: A Comprehensive Benchmark for Compositional Text-to-video Generation},
  author={Sun, Kaiyue and Huang, Kaiyi and Liu, Xian and Wu, Yue and Xu, Zihan and Li, Zhenguo and Liu, Xihui},
  journal={arXiv preprint arXiv:2407.14505},
  year={2024}
}

@misc{yu2022parti,
  title={Parti: Pathways Autoregressive Text-to-Image Model},
  author={Yu, Jiahui and Xu, Yuanzhong and Koh, Jing Yu and Luong, Thang and Baid, Gunjan and Wang, Zirui and Vasudevan, Vijay and Ku, Alexander and Yang, Yinfei and Ayan, Burcu Karagol and others},
  year={2022}
}

@inproceedings{wimbauer2024cache,
  title={Cache me if you can: Accelerating diffusion models through block caching},
  author={Wimbauer, Felix and Wu, Bichen and Schoenfeld, Edgar and Dai, Xiaoliang and Hou, Ji and He, Zijian and Sanakoyeu, Artsiom and Zhang, Peizhao and Tsai, Sam and Kohler, Jonas and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6211--6220},
  year={2024}
}

@inproceedings{rombach2022high,
  title={High-resolution image synthesis with latent diffusion models},
  author={Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\"o}rn},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={10684--10695},
  year={2022}
}

@article{ho2022video,
  title={Video diffusion models},
  author={Ho, Jonathan and Salimans, Tim and Gritsenko, Alexey and Chan, William and Norouzi, Mohammad and Fleet, David J},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={8633--8646},
  year={2022}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, A},
  journal={Advances in Neural Information Processing Systems},
  year={2017}
}

@article{song2020denoising,
  title={Denoising diffusion implicit models},
  author={Song, Jiaming and Meng, Chenlin and Ermon, Stefano},
  journal={arXiv preprint arXiv:2010.02502},
  year={2020}
}

@article{jolicoeur2021gotta,
  title={Gotta go fast when generating data with score-based models},
  author={Jolicoeur-Martineau, Alexia and Li, Ke and Pich{\'e}-Taillefer, R{\'e}mi and Kachman, Tal and Mitliagkas, Ioannis},
  journal={arXiv preprint arXiv:2105.14080},
  year={2021}
}

@article{lu2022dpm,
  title={Dpm-solver: A fast ode solver for diffusion probabilistic model sampling in around 10 steps},
  author={Lu, Cheng and Zhou, Yuhao and Bao, Fan and Chen, Jianfei and Li, Chongxuan and Zhu, Jun},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={5775--5787},
  year={2022}
}

@article{karras2022elucidating,
  title={Elucidating the design space of diffusion-based generative models},
  author={Karras, Tero and Aittala, Miika and Aila, Timo and Laine, Samuli},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={26565--26577},
  year={2022}
}

@article{lu2022dpm++,
  title={Dpm-solver++: Fast solver for guided sampling of diffusion probabilistic models},
  author={Lu, Cheng and Zhou, Yuhao and Bao, Fan and Chen, Jianfei and Li, Chongxuan and Zhu, Jun},
  journal={arXiv preprint arXiv:2211.01095},
  year={2022}
}

@article{salimans2022progressive,
  title={Progressive distillation for fast sampling of diffusion models},
  author={Salimans, Tim and Ho, Jonathan},
  journal={arXiv preprint arXiv:2202.00512},
  year={2022}
}

@article{li2024q,
  title={Q-dm: An efficient low-bit quantized diffusion model},
  author={Li, Yanjing and Xu, Sheng and Cao, Xianbin and Sun, Xiao and Zhang, Baochang},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{he2024ptqd,
  title={Ptqd: Accurate post-training quantization for diffusion models},
  author={He, Yefei and Liu, Luping and Liu, Jing and Wu, Weijia and Zhou, Hong and Zhuang, Bohan},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{so2024temporal,
  title={Temporal dynamic quantization for diffusion models},
  author={So, Junhyuk and Lee, Jungwon and Ahn, Daehyun and Kim, Hyungjun and Park, Eunhyeok},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{shang2023post,
  title={Post-training quantization on diffusion models},
  author={Shang, Yuzhang and Yuan, Zhihang and Xie, Bin and Wu, Bingzhe and Yan, Yan},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={1972--1981},
  year={2023}
}

@inproceedings{li2024distrifusion,
  title={Distrifusion: Distributed parallel inference for high-resolution diffusion models},
  author={Li, Muyang and Cai, Tianle and Cao, Jiaxin and Zhang, Qinsheng and Cai, Han and Bai, Junjie and Jia, Yangqing and Li, Kai and Han, Song},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={7183--7193},
  year={2024}
}

@inproceedings{bolya2023token,
  title={Token merging for fast stable diffusion},
  author={Bolya, Daniel and Hoffman, Judy},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={4599--4603},
  year={2023}
}

@inproceedings{wang2024attention,
  title={Attention-Driven Training-Free Efficiency Enhancement of Diffusion Models},
  author={Wang, Hongjie and Liu, Difan and Kang, Yan and Li, Yijun and Lin, Zhe and Jha, Niraj K and Liu, Yuchen},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={16080--16089},
  year={2024}
}

@article{so2023frdiff,
  title={FRDiff: Feature Reuse for Universal Training-free Acceleration of Diffusion Models},
  author={So, Junhyuk and Lee, Jungwon and Park, Eunhyeok},
  journal={arXiv preprint arXiv:2312.03517},
  year={2023}
}

@article{zhang2024cross,
  title={Cross-attention makes inference cumbersome in text-to-image diffusion models},
  author={Zhang, Wentian and Liu, Haozhe and Xie, Jinheng and Faccio, Francesco and Shou, Mike Zheng and Schmidhuber, J{\"u}rgen},
  journal={arXiv preprint arXiv:2404.02747},
  year={2024}
}

@article{li2023faster,
  title={Faster diffusion: Rethinking the role of unet encoder in diffusion models},
  author={Li, Senmao and Hu, Taihang and Shahbaz Khan, Fahad and Li, Linxuan and Yang, Shiqi and Wang, Yaxing and Cheng, Ming-Ming and Yang, Jian},
  journal={arXiv e-prints},
  pages={arXiv--2312},
  year={2023}
}

@article{chen2024delta,
  title={Delta DiT: A Training-Free Acceleration Method Tailored for Diffusion Transformers},
  author={Chen, Pengtao and Shen, Mingzhu and Ye, Peng and Cao, Jianjian and Tu, Chongjun and Bouganis, Christos-Savvas and Zhao, Yiren and Chen, Tao},
  journal={arXiv preprint arXiv:2406.01125},
  year={2024}
}

@inproceedings{huang2024vbench,
  title={Vbench: Comprehensive benchmark suite for video generative models},
  author={Huang, Ziqi and He, Yinan and Yu, Jiashuo and Zhang, Fan and Si, Chenyang and Jiang, Yuming and Zhang, Yuanhan and Wu, Tianxing and Jin, Qingyang and Chanpaisit, Nattapol and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={21807--21818},
  year={2024}
}

@inproceedings{zhang2018unreasonable,
  title={The unreasonable effectiveness of deep features as a perceptual metric},
  author={Zhang, Richard and Isola, Phillip and Efros, Alexei A and Shechtman, Eli and Wang, Oliver},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={586--595},
  year={2018}
}

@article{dao2022flashattention,
  title={Flashattention: Fast and memory-efficient exact attention with io-awareness},
  author={Dao, Tri and Fu, Dan and Ermon, Stefano and Rudra, Atri and R{\'e}, Christopher},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={16344--16359},
  year={2022}
}

@article{blattmann2023stable,
  title={Stable video diffusion: Scaling latent video diffusion models to large datasets},
  author={Blattmann, Andreas and Dockhorn, Tim and Kulal, Sumith and Mendelevitch, Daniel and Kilian, Maciej and Lorenz, Dominik and Levi, Yam and English, Zion and Voleti, Vikram and Letts, Adam and others},
  journal={arXiv preprint arXiv:2311.15127},
  year={2023}
}

@inproceedings{wei2024dreamvideo,
  title={Dreamvideo: Composing your dream videos with customized subject and motion},
  author={Wei, Yujie and Zhang, Shiwei and Qing, Zhiwu and Yuan, Hangjie and Liu, Zhiheng and Liu, Yu and Zhang, Yingya and Zhou, Jingren and Shan, Hongming},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6537--6549},
  year={2024}
}

@article{wei2024dreamvideo2,
  title={DreamVideo-2: Zero-Shot Subject-Driven Video Customization with Precise Motion Control},
  author={Wei, Yujie and Zhang, Shiwei and Yuan, Hangjie and Wang, Xiang and Qiu, Haonan and Zhao, Rui and Feng, Yutong and Liu, Feng and Huang, Zhizhong and Ye, Jiaxin and others},
  journal={arXiv preprint arXiv:2410.13830},
  year={2024}
}

@article{wang2023modelscope,
  title={Modelscope text-to-video technical report},
  author={Wang, Jiuniu and Yuan, Hangjie and Chen, Dayou and Zhang, Yingya and Wang, Xiang and Zhang, Shiwei},
  journal={arXiv preprint arXiv:2308.06571},
  year={2023}
}

@article{chen2023videocrafter1,
  title={Videocrafter1: Open diffusion models for high-quality video generation},
  author={Chen, Haoxin and Xia, Menghan and He, Yingqing and Zhang, Yong and Cun, Xiaodong and Yang, Shaoshu and Xing, Jinbo and Liu, Yaofang and Chen, Qifeng and Wang, Xintao and others},
  journal={arXiv preprint arXiv:2310.19512},
  year={2023}
}

@inproceedings{chen2024videocrafter2,
  title={Videocrafter2: Overcoming data limitations for high-quality video diffusion models},
  author={Chen, Haoxin and Zhang, Yong and Cun, Xiaodong and Xia, Menghan and Wang, Xintao and Weng, Chao and Shan, Ying},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={7310--7320},
  year={2024}
}