\begin{thebibliography}{60}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Moc(2024)]{Mochi}
Mochi 1, 2024.
\newblock https://www.genmo.ai.

\bibitem[Vch(2024)]{Vchitect}
Vchitect. vchitect-2.0: Parallel transformer for scaling up video diffusion models, 2024.
\newblock https://github.com/Vchitect/Vchitect-2.0.

\bibitem[Albonesi(1999)]{albonesi1999selective}
David~H Albonesi.
\newblock Selective cache ways: On-demand cache resource allocation.
\newblock In \emph{MICRO-32. Proceedings of the 32nd Annual ACM/IEEE International Symposium on Microarchitecture}, pages 248--259. IEEE, 1999.

\bibitem[Blattmann et~al.(2023)Blattmann, Dockhorn, Kulal, Mendelevitch, Kilian, Lorenz, Levi, English, Voleti, Letts, et~al.]{blattmann2023stable}
Andreas Blattmann, Tim Dockhorn, Sumith Kulal, Daniel Mendelevitch, Maciej Kilian, Dominik Lorenz, Yam Levi, Zion English, Vikram Voleti, Adam Letts, et~al.
\newblock Stable video diffusion: Scaling latent video diffusion models to large datasets.
\newblock \emph{arXiv preprint arXiv:2311.15127}, 2023.

\bibitem[Bolya and Hoffman(2023)]{bolya2023token}
Daniel Bolya and Judy Hoffman.
\newblock Token merging for fast stable diffusion.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 4599--4603, 2023.

\bibitem[Chen et~al.(2023{\natexlab{a}})Chen, Xia, He, Zhang, Cun, Yang, Xing, Liu, Chen, Wang, et~al.]{chen2023videocrafter1}
Haoxin Chen, Menghan Xia, Yingqing He, Yong Zhang, Xiaodong Cun, Shaoshu Yang, Jinbo Xing, Yaofang Liu, Qifeng Chen, Xintao Wang, et~al.
\newblock Videocrafter1: Open diffusion models for high-quality video generation.
\newblock \emph{arXiv preprint arXiv:2310.19512}, 2023{\natexlab{a}}.

\bibitem[Chen et~al.(2024{\natexlab{a}})Chen, Zhang, Cun, Xia, Wang, Weng, and Shan]{chen2024videocrafter2}
Haoxin Chen, Yong Zhang, Xiaodong Cun, Menghan Xia, Xintao Wang, Chao Weng, and Ying Shan.
\newblock Videocrafter2: Overcoming data limitations for high-quality video diffusion models.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 7310--7320, 2024{\natexlab{a}}.

\bibitem[Chen et~al.(2023{\natexlab{b}})Chen, Yu, Ge, Yao, Xie, Wu, Wang, Kwok, Luo, Lu, et~al.]{chen2023pixart}
Junsong Chen, Jincheng Yu, Chongjian Ge, Lewei Yao, Enze Xie, Yue Wu, Zhongdao Wang, James Kwok, Ping Luo, Huchuan Lu, et~al.
\newblock Pixart-alpha: Fast training of diffusion transformer for photorealistic text-to-image synthesis.
\newblock \emph{arXiv preprint arXiv:2310.00426}, 2023{\natexlab{b}}.

\bibitem[Chen et~al.(2024{\natexlab{b}})Chen, Ge, Xie, Wu, Yao, Ren, Wang, Luo, Lu, and Li]{chen2024pixart}
Junsong Chen, Chongjian Ge, Enze Xie, Yue Wu, Lewei Yao, Xiaozhe Ren, Zhongdao Wang, Ping Luo, Huchuan Lu, and Zhenguo Li.
\newblock Pixart-sigma: Weak-to-strong training of diffusion transformer for 4k text-to-image generation.
\newblock \emph{arXiv preprint arXiv:2403.04692}, 2024{\natexlab{b}}.

\bibitem[Chen et~al.(2024{\natexlab{c}})Chen, Meng, Tang, Ma, Jiang, Wang, Wang, and Zhu]{chen2024q}
Lei Chen, Yuan Meng, Chen Tang, Xinzhu Ma, Jingyan Jiang, Xin Wang, Zhi Wang, and Wenwu Zhu.
\newblock Q-dit: Accurate post-training quantization for diffusion transformers.
\newblock \emph{arXiv preprint arXiv:2406.17343}, 2024{\natexlab{c}}.

\bibitem[Chen et~al.(2024{\natexlab{d}})Chen, Shen, Ye, Cao, Tu, Bouganis, Zhao, and Chen]{chen2024delta}
Pengtao Chen, Mingzhu Shen, Peng Ye, Jianjian Cao, Chongjun Tu, Christos-Savvas Bouganis, Yiren Zhao, and Tao Chen.
\newblock Delta dit: A training-free acceleration method tailored for diffusion transformers.
\newblock \emph{arXiv preprint arXiv:2406.01125}, 2024{\natexlab{d}}.

\bibitem[Dao et~al.(2022)Dao, Fu, Ermon, Rudra, and R{\'e}]{dao2022flashattention}
Tri Dao, Dan Fu, Stefano Ermon, Atri Rudra, and Christopher R{\'e}.
\newblock Flashattention: Fast and memory-efficient exact attention with io-awareness.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 16344--16359, 2022.

\bibitem[Dhariwal and Nichol(2021)]{dhariwal2021diffusion}
Prafulla Dhariwal and Alexander Nichol.
\newblock Diffusion models beat gans on image synthesis.
\newblock \emph{Advances in neural information processing systems}, 34:\penalty0 8780--8794, 2021.

\bibitem[Goodman(1983)]{goodman1983using}
James~R Goodman.
\newblock Using cache memory to reduce processor-memory traffic.
\newblock In \emph{Proceedings of the 10th annual international symposium on Computer architecture}, pages 124--131, 1983.

\bibitem[He et~al.(2024)He, Liu, Liu, Wu, Zhou, and Zhuang]{he2024ptqd}
Yefei He, Luping Liu, Jing Liu, Weijia Wu, Hong Zhou, and Bohan Zhuang.
\newblock Ptqd: Accurate post-training quantization for diffusion models.
\newblock \emph{Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem[Ho et~al.(2020)Ho, Jain, and Abbeel]{ho2020denoising}
Jonathan Ho, Ajay Jain, and Pieter Abbeel.
\newblock Denoising diffusion probabilistic models.
\newblock \emph{Advances in neural information processing systems}, 33:\penalty0 6840--6851, 2020.

\bibitem[Ho et~al.(2022)Ho, Salimans, Gritsenko, Chan, Norouzi, and Fleet]{ho2022video}
Jonathan Ho, Tim Salimans, Alexey Gritsenko, William Chan, Mohammad Norouzi, and David~J Fleet.
\newblock Video diffusion models.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 8633--8646, 2022.

\bibitem[Huang et~al.(2024)Huang, He, Yu, Zhang, Si, Jiang, Zhang, Wu, Jin, Chanpaisit, et~al.]{huang2024vbench}
Ziqi Huang, Yinan He, Jiashuo Yu, Fan Zhang, Chenyang Si, Yuming Jiang, Yuanhan Zhang, Tianxing Wu, Qingyang Jin, Nattapol Chanpaisit, et~al.
\newblock Vbench: Comprehensive benchmark suite for video generative models.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 21807--21818, 2024.

\bibitem[Jolicoeur-Martineau et~al.(2021)Jolicoeur-Martineau, Li, Pich{\'e}-Taillefer, Kachman, and Mitliagkas]{jolicoeur2021gotta}
Alexia Jolicoeur-Martineau, Ke Li, R{\'e}mi Pich{\'e}-Taillefer, Tal Kachman, and Ioannis Mitliagkas.
\newblock Gotta go fast when generating data with score-based models.
\newblock \emph{arXiv preprint arXiv:2105.14080}, 2021.

\bibitem[Karras et~al.(2022)Karras, Aittala, Aila, and Laine]{karras2022elucidating}
Tero Karras, Miika Aittala, Timo Aila, and Samuli Laine.
\newblock Elucidating the design space of diffusion-based generative models.
\newblock \emph{Advances in neural information processing systems}, 35:\penalty0 26565--26577, 2022.

\bibitem[Lab and etc.(2024)]{Open-Sora-Plan}
PKU-Yuan Lab and Tuzhan~AI etc.
\newblock Open-sora: Democratizing efficient video production for all, 2024.
\newblock https://doi.org/10. 5281/zenodo.10948109.

\bibitem[Li et~al.(2024{\natexlab{a}})Li, Cai, Cao, Zhang, Cai, Bai, Jia, Li, and Han]{li2024distrifusion}
Muyang Li, Tianle Cai, Jiaxin Cao, Qinsheng Zhang, Han Cai, Junjie Bai, Yangqing Jia, Kai Li, and Song Han.
\newblock Distrifusion: Distributed parallel inference for high-resolution diffusion models.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 7183--7193, 2024{\natexlab{a}}.

\bibitem[Li et~al.(2023)Li, Hu, Shahbaz~Khan, Li, Yang, Wang, Cheng, and Yang]{li2023faster}
Senmao Li, Taihang Hu, Fahad Shahbaz~Khan, Linxuan Li, Shiqi Yang, Yaxing Wang, Ming-Ming Cheng, and Jian Yang.
\newblock Faster diffusion: Rethinking the role of unet encoder in diffusion models.
\newblock \emph{arXiv e-prints}, pages arXiv--2312, 2023.

\bibitem[Li et~al.(2024{\natexlab{b}})Li, Wang, Jin, Hu, Chemerys, Fu, Wang, Tulyakov, and Ren]{li2024snapfusion}
Yanyu Li, Huan Wang, Qing Jin, Ju Hu, Pavlo Chemerys, Yun Fu, Yanzhi Wang, Sergey Tulyakov, and Jian Ren.
\newblock Snapfusion: Text-to-image diffusion model on mobile devices within two seconds.
\newblock \emph{Advances in Neural Information Processing Systems}, 36, 2024{\natexlab{b}}.

\bibitem[Li et~al.(2024{\natexlab{c}})Li, Xu, Cao, Sun, and Zhang]{li2024q}
Yanjing Li, Sheng Xu, Xianbin Cao, Xiao Sun, and Baochang Zhang.
\newblock Q-dm: An efficient low-bit quantized diffusion model.
\newblock \emph{Advances in Neural Information Processing Systems}, 36, 2024{\natexlab{c}}.

\bibitem[Lu et~al.(2022{\natexlab{a}})Lu, Zhou, Bao, Chen, Li, and Zhu]{lu2022dpm}
Cheng Lu, Yuhao Zhou, Fan Bao, Jianfei Chen, Chongxuan Li, and Jun Zhu.
\newblock Dpm-solver: A fast ode solver for diffusion probabilistic model sampling in around 10 steps.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 5775--5787, 2022{\natexlab{a}}.

\bibitem[Lu et~al.(2022{\natexlab{b}})Lu, Zhou, Bao, Chen, Li, and Zhu]{lu2022dpm++}
Cheng Lu, Yuhao Zhou, Fan Bao, Jianfei Chen, Chongxuan Li, and Jun Zhu.
\newblock Dpm-solver++: Fast solver for guided sampling of diffusion probabilistic models.
\newblock \emph{arXiv preprint arXiv:2211.01095}, 2022{\natexlab{b}}.

\bibitem[Ma et~al.(2024{\natexlab{a}})Ma, Fang, Mi, and Wang]{ma2024learning}
Xinyin Ma, Gongfan Fang, Michael~Bi Mi, and Xinchao Wang.
\newblock Learning-to-cache: Accelerating diffusion transformer via layer caching.
\newblock \emph{arXiv preprint arXiv:2406.01733}, 2024{\natexlab{a}}.

\bibitem[Ma et~al.(2024{\natexlab{b}})Ma, Wang, Jia, Chen, Liu, Li, Chen, and Qiao]{ma2024latte}
Xin Ma, Yaohui Wang, Gengyun Jia, Xinyuan Chen, Ziwei Liu, Yuan-Fang Li, Cunjian Chen, and Yu Qiao.
\newblock Latte: Latent diffusion transformer for video generation.
\newblock \emph{arXiv preprint arXiv:2401.03048}, 2024{\natexlab{b}}.

\bibitem[Meng et~al.(2023)Meng, Rombach, Gao, Kingma, Ermon, Ho, and Salimans]{meng2023distillation}
Chenlin Meng, Robin Rombach, Ruiqi Gao, Diederik Kingma, Stefano Ermon, Jonathan Ho, and Tim Salimans.
\newblock On distillation of guided diffusion models.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 14297--14306, 2023.

\bibitem[OpenAI(2024)]{Sora}
OpenAI.
\newblock Sora, 2024.
\newblock https://openai.com/index/sora/.

\bibitem[Peebles and Xie(2023)]{peebles2023scalable}
William Peebles and Saining Xie.
\newblock Scalable diffusion models with transformers.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 4195--4205, 2023.

\bibitem[Ramesh et~al.(2022)Ramesh, Dhariwal, Nichol, Chu, and Chen]{ramesh2022hierarchical}
Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen.
\newblock Hierarchical text-conditional image generation with clip latents.
\newblock \emph{arXiv preprint arXiv:2204.06125}, 1\penalty0 (2):\penalty0 3, 2022.

\bibitem[Rombach et~al.(2022)Rombach, Blattmann, Lorenz, Esser, and Ommer]{rombach2022high}
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj{\"o}rn Ommer.
\newblock High-resolution image synthesis with latent diffusion models.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 10684--10695, 2022.

\bibitem[Saharia et~al.(2022)Saharia, Chan, Saxena, Li, Whang, Denton, Ghasemipour, Gontijo~Lopes, Karagol~Ayan, Salimans, et~al.]{saharia2022photorealistic}
Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily~L Denton, Kamyar Ghasemipour, Raphael Gontijo~Lopes, Burcu Karagol~Ayan, Tim Salimans, et~al.
\newblock Photorealistic text-to-image diffusion models with deep language understanding.
\newblock \emph{Advances in neural information processing systems}, 35:\penalty0 36479--36494, 2022.

\bibitem[Salimans and Ho(2022)]{salimans2022progressive}
Tim Salimans and Jonathan Ho.
\newblock Progressive distillation for fast sampling of diffusion models.
\newblock \emph{arXiv preprint arXiv:2202.00512}, 2022.

\bibitem[Sauer et~al.(2023)Sauer, Lorenz, Blattmann, and Rombach]{sauer2023adversarial}
Axel Sauer, Dominik Lorenz, Andreas Blattmann, and Robin Rombach.
\newblock Adversarial diffusion distillation.
\newblock \emph{arXiv preprint arXiv:2311.17042}, 2023.

\bibitem[Selvaraju et~al.(2024)Selvaraju, Ding, Chen, Zharkov, and Liang]{selvaraju2024fora}
Pratheba Selvaraju, Tianyu Ding, Tianyi Chen, Ilya Zharkov, and Luming Liang.
\newblock Fora: Fast-forward caching in diffusion transformer acceleration.
\newblock \emph{arXiv preprint arXiv:2407.01425}, 2024.

\bibitem[Shang et~al.(2023)Shang, Yuan, Xie, Wu, and Yan]{shang2023post}
Yuzhang Shang, Zhihang Yuan, Bin Xie, Bingzhe Wu, and Yan Yan.
\newblock Post-training quantization on diffusion models.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 1972--1981, 2023.

\bibitem[Shih et~al.(2024)Shih, Belkhale, Ermon, Sadigh, and Anari]{shih2024parallel}
Andy Shih, Suneel Belkhale, Stefano Ermon, Dorsa Sadigh, and Nima Anari.
\newblock Parallel sampling of diffusion models.
\newblock \emph{Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem[Smith(1982)]{smith1982cache}
Alan~Jay Smith.
\newblock Cache memories.
\newblock \emph{ACM Computing Surveys (CSUR)}, 14\penalty0 (3):\penalty0 473--530, 1982.

\bibitem[So et~al.(2023)So, Lee, and Park]{so2023frdiff}
Junhyuk So, Jungwon Lee, and Eunhyeok Park.
\newblock Frdiff: Feature reuse for universal training-free acceleration of diffusion models.
\newblock \emph{arXiv preprint arXiv:2312.03517}, 2023.

\bibitem[So et~al.(2024)So, Lee, Ahn, Kim, and Park]{so2024temporal}
Junhyuk So, Jungwon Lee, Daehyun Ahn, Hyungjun Kim, and Eunhyeok Park.
\newblock Temporal dynamic quantization for diffusion models.
\newblock \emph{Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem[Sohl-Dickstein et~al.(2015)Sohl-Dickstein, Weiss, Maheswaranathan, and Ganguli]{sohl2015deep}
Jascha Sohl-Dickstein, Eric Weiss, Niru Maheswaranathan, and Surya Ganguli.
\newblock Deep unsupervised learning using nonequilibrium thermodynamics.
\newblock In \emph{International conference on machine learning}, pages 2256--2265. PMLR, 2015.

\bibitem[Song et~al.(2020)Song, Meng, and Ermon]{song2020denoising}
Jiaming Song, Chenlin Meng, and Stefano Ermon.
\newblock Denoising diffusion implicit models.
\newblock \emph{arXiv preprint arXiv:2010.02502}, 2020.

\bibitem[Song and Ermon(2019)]{song2019generative}
Yang Song and Stefano Ermon.
\newblock Generative modeling by estimating gradients of the data distribution.
\newblock \emph{Advances in neural information processing systems}, 32, 2019.

\bibitem[Sun et~al.(2024)Sun, Huang, Liu, Wu, Xu, Li, and Liu]{sun2024t2v}
Kaiyue Sun, Kaiyi Huang, Xian Liu, Yue Wu, Zihan Xu, Zhenguo Li, and Xihui Liu.
\newblock T2v-compbench: A comprehensive benchmark for compositional text-to-video generation.
\newblock \emph{arXiv preprint arXiv:2407.14505}, 2024.

\bibitem[Vaswani(2017)]{vaswani2017attention}
A Vaswani.
\newblock Attention is all you need.
\newblock \emph{Advances in Neural Information Processing Systems}, 2017.

\bibitem[Wang et~al.(2024)Wang, Liu, Kang, Li, Lin, Jha, and Liu]{wang2024attention}
Hongjie Wang, Difan Liu, Yan Kang, Yijun Li, Zhe Lin, Niraj~K Jha, and Yuchen Liu.
\newblock Attention-driven training-free efficiency enhancement of diffusion models.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 16080--16089, 2024.

\bibitem[Wang et~al.(2023{\natexlab{a}})Wang, Yuan, Chen, Zhang, Wang, and Zhang]{wang2023modelscope}
Jiuniu Wang, Hangjie Yuan, Dayou Chen, Yingya Zhang, Xiang Wang, and Shiwei Zhang.
\newblock Modelscope text-to-video technical report.
\newblock \emph{arXiv preprint arXiv:2308.06571}, 2023{\natexlab{a}}.

\bibitem[Wang et~al.(2023{\natexlab{b}})Wang, Zhang, Zhang, Liu, Zhang, Gao, and Sang]{wang2023videolcm}
Xiang Wang, Shiwei Zhang, Han Zhang, Yu Liu, Yingya Zhang, Changxin Gao, and Nong Sang.
\newblock Videolcm: Video latent consistency model.
\newblock \emph{arXiv preprint arXiv:2312.09109}, 2023{\natexlab{b}}.

\bibitem[Wei et~al.(2024{\natexlab{a}})Wei, Zhang, Qing, Yuan, Liu, Liu, Zhang, Zhou, and Shan]{wei2024dreamvideo}
Yujie Wei, Shiwei Zhang, Zhiwu Qing, Hangjie Yuan, Zhiheng Liu, Yu Liu, Yingya Zhang, Jingren Zhou, and Hongming Shan.
\newblock Dreamvideo: Composing your dream videos with customized subject and motion.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 6537--6549, 2024{\natexlab{a}}.

\bibitem[Wei et~al.(2024{\natexlab{b}})Wei, Zhang, Yuan, Wang, Qiu, Zhao, Feng, Liu, Huang, Ye, et~al.]{wei2024dreamvideo2}
Yujie Wei, Shiwei Zhang, Hangjie Yuan, Xiang Wang, Haonan Qiu, Rui Zhao, Yutong Feng, Feng Liu, Zhizhong Huang, Jiaxin Ye, et~al.
\newblock Dreamvideo-2: Zero-shot subject-driven video customization with precise motion control.
\newblock \emph{arXiv preprint arXiv:2410.13830}, 2024{\natexlab{b}}.

\bibitem[Wimbauer et~al.(2024)Wimbauer, Wu, Schoenfeld, Dai, Hou, He, Sanakoyeu, Zhang, Tsai, Kohler, et~al.]{wimbauer2024cache}
Felix Wimbauer, Bichen Wu, Edgar Schoenfeld, Xiaoliang Dai, Ji Hou, Zijian He, Artsiom Sanakoyeu, Peizhao Zhang, Sam Tsai, Jonas Kohler, et~al.
\newblock Cache me if you can: Accelerating diffusion models through block caching.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 6211--6220, 2024.

\bibitem[Xu et~al.(2018)Xu, Zhu, Liu, Lin, and Liu]{xu2018deepcache}
Mengwei Xu, Mengze Zhu, Yunxin Liu, Felix~Xiaozhu Lin, and Xuanzhe Liu.
\newblock Deepcache: Principled cache for mobile deep vision.
\newblock In \emph{Proceedings of the 24th annual international conference on mobile computing and networking}, pages 129--144, 2018.

\bibitem[Yang et~al.(2024)Yang, Teng, Zheng, Ding, Huang, Xu, Yang, Hong, Zhang, Feng, et~al.]{yang2024cogvideox}
Zhuoyi Yang, Jiayan Teng, Wendi Zheng, Ming Ding, Shiyu Huang, Jiazheng Xu, Yuanming Yang, Wenyi Hong, Xiaohan Zhang, Guanyu Feng, et~al.
\newblock Cogvideox: Text-to-video diffusion models with an expert transformer.
\newblock \emph{arXiv preprint arXiv:2408.06072}, 2024.

\bibitem[Zhang et~al.(2018)Zhang, Isola, Efros, Shechtman, and Wang]{zhang2018unreasonable}
Richard Zhang, Phillip Isola, Alexei~A Efros, Eli Shechtman, and Oliver Wang.
\newblock The unreasonable effectiveness of deep features as a perceptual metric.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and pattern recognition}, pages 586--595, 2018.

\bibitem[Zhang et~al.(2024)Zhang, Liu, Xie, Faccio, Shou, and Schmidhuber]{zhang2024cross}
Wentian Zhang, Haozhe Liu, Jinheng Xie, Francesco Faccio, Mike~Zheng Shou, and J{\"u}rgen Schmidhuber.
\newblock Cross-attention makes inference cumbersome in text-to-image diffusion models.
\newblock \emph{arXiv preprint arXiv:2404.02747}, 2024.

\bibitem[Zhao et~al.(2024)Zhao, Jin, Wang, and You]{zhao2024real}
Xuanlei Zhao, Xiaolong Jin, Kai Wang, and Yang You.
\newblock Real-time video generation with pyramid attention broadcast.
\newblock \emph{arXiv preprint arXiv:2408.12588}, 2024.

\bibitem[Zheng et~al.(2024)Zheng, Peng, Yang, Shen, Li, Liu, Zhou, Li, and You]{Open-Sora}
Zangwei Zheng, Xiangyu Peng, Tianji Yang, Chenhui Shen, Shenggui Li, Hongxin Liu, Yukun Zhou, Tianyi Li, and Yang You.
\newblock Open-sora: Democratizing efficient video production for all, 2024.
\newblock https://github.com/hpcaitech/Open-Sora.

\end{thebibliography}
