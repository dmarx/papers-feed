\vspace{-3pt}
\section{Conclusion}
We propose CausalFusion, a decoder-only transformer that unifies AR and diffusion paradigms through a dual-factorized framework across sequential tokens and diffusion noise levels. This approach achieves state-of-the-art performance on the ImageNet generation benchmark, supports arbitrary-length token generation, and enables smooth transitions between AR and diffusion modes. CausalFusion also demonstrates multimodal capabilities, including joint image generation and captioning, as well as zero-shot image manipulations. Our framework offers a new perspective on unified learning of diffusion and AR models.

