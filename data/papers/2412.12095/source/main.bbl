\begin{thebibliography}{75}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Bao et~al.(2023)Bao, Nie, Xue, Cao, Li, Su, and Zhu]{bao2023all}
Fan Bao, Shen Nie, Kaiwen Xue, Yue Cao, Chongxuan Li, Hang Su, and Jun Zhu.
\newblock All are worth words: A vit backbone for diffusion models.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 22669--22679, 2023.

\bibitem[Bao et~al.(2021)Bao, Dong, Piao, and Wei]{beit}
Hangbo Bao, Li Dong, Songhao Piao, and Furu Wei.
\newblock Beit: Bert pre-training of image transformers.
\newblock In \emph{International Conference on Learning Representations}, 2021.

\bibitem[Bengio et~al.(2015)Bengio, Vinyals, Jaitly, and Shazeer]{bengio2015scheduled}
Samy Bengio, Oriol Vinyals, Navdeep Jaitly, and Noam Shazeer.
\newblock Scheduled sampling for sequence prediction with recurrent neural networks.
\newblock \emph{Advances in neural information processing systems}, 28, 2015.

\bibitem[Brooks et~al.(2024)Brooks, Peebles, Holmes, DePue, Guo, Jing, Schnurr, Taylor, Luhman, and Luhman]{sora}
Tim Brooks, Bill Peebles, Connor Holmes, Will DePue, Yufei Guo, Li Jing, David Schnurr, Joe Taylor, Troy Luhman, and Eric Luhman.
\newblock Video generation models as world simulators.
\newblock \emph{OpenAI Blog}, 2024.

\bibitem[Brown et~al.(2020)Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal, Neelakantan, Shyam, Sastry, Askell, Agarwal, Herbert-Voss, Krueger, Henighan, Child, Ramesh, Ziegler, Wu, Winter, Hesse, Chen, Sigler, Litwin, Gray, Chess, Clark, Berner, McCandlish, Radford, Sutskever, and Amodei]{gpt3}
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared~D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei.
\newblock Language models are few-shot learners.
\newblock \emph{Advances in neural information processing systems}, 33:\penalty0 1877--1901, 2020.

\bibitem[Chang et~al.(2022)Chang, Zhang, Jiang, Liu, and Freeman]{chang2022maskgit}
Huiwen Chang, Han Zhang, Lu Jiang, Ce Liu, and William~T Freeman.
\newblock Maskgit: Masked generative image transformer.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 11315--11325, 2022.

\bibitem[Chang et~al.(2023)Chang, Zhang, Barber, Maschinot, Lezama, Jiang, Yang, Murphy, Freeman, Rubinstein, et~al.]{muse}
Huiwen Chang, Han Zhang, Jarred Barber, AJ Maschinot, Jos{\'e} Lezama, Lu Jiang, Ming-Hsuan Yang, Kevin Murphy, William~T Freeman, Michael Rubinstein, et~al.
\newblock Muse: Text-to-image generation via masked generative transformers.
\newblock In \emph{Proceedings of the 40th International Conference on Machine Learning}, pages 4055--4075, 2023.

\bibitem[Chen et~al.(2024)Chen, Ge, Xie, Wu, Yao, Ren, Wang, Luo, Lu, and Li]{chen2024pixart}
Junsong Chen, Chongjian Ge, Enze Xie, Yue Wu, Lewei Yao, Xiaozhe Ren, Zhongdao Wang, Ping Luo, Huchuan Lu, and Zhenguo Li.
\newblock Pixart-$\backslash$sigma: Weak-to-strong training of diffusion transformer for 4k text-to-image generation.
\newblock \emph{arXiv preprint arXiv:2403.04692}, 2024.

\bibitem[Clark et~al.(2020)Clark, Luong, Le, and Manning]{electra}
Kevin Clark, Minh-Thang Luong, Quoc~V. Le, and Christopher~D. Manning.
\newblock Electra: Pre-training text encoders as discriminators rather than generators.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Cubuk et~al.(2020)Cubuk, Zoph, Shlens, and Le]{randaugment}
Ekin~D Cubuk, Barret Zoph, Jonathon Shlens, and Quoc~V Le.
\newblock Randaugment: Practical automated data augmentation with a reduced search space.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition workshops}, pages 702--703, 2020.

\bibitem[Dehghani et~al.(2023)Dehghani, Djolonga, Mustafa, Padlewski, Heek, Gilmer, Steiner, Caron, Geirhos, Alabdulmohsin, et~al.]{dehghani2023vit22b}
Mostafa Dehghani, Josip Djolonga, Basil Mustafa, Piotr Padlewski, Jonathan Heek, Justin Gilmer, Andreas~Peter Steiner, Mathilde Caron, Robert Geirhos, Ibrahim Alabdulmohsin, et~al.
\newblock Scaling vision transformers to 22 billion parameters.
\newblock In \emph{International Conference on Machine Learning}, pages 7480--7512. PMLR, 2023.

\bibitem[Deng et~al.(2009)Deng, Dong, Socher, Li, Li, and Fei-Fei]{deng2009imagenet}
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In \emph{2009 IEEE conference on computer vision and pattern recognition}, pages 248--255. Ieee, 2009.

\bibitem[Dhariwal and Nichol(2021)]{adm}
Prafulla Dhariwal and Alexander Nichol.
\newblock Diffusion models beat gans on image synthesis.
\newblock \emph{Advances in neural information processing systems}, 34:\penalty0 8780--8794, 2021.

\bibitem[Ding et~al.(2021)Ding, Yang, Hong, Zheng, Zhou, Yin, Lin, Zou, Shao, Yang, and Tang]{ding2021cogview}
Ming Ding, Zhuoyi Yang, Wenyi Hong, Wendi Zheng, Chang Zhou, Da Yin, Junyang Lin, Xu Zou, Zhou Shao, Hongxia Yang, and Jie Tang.
\newblock Cogview: Mastering text-to-image generation via transformers.
\newblock \emph{Advances in neural information processing systems}, 34:\penalty0 19822--19835, 2021.

\bibitem[Dosovitskiy et~al.(2021)Dosovitskiy, Beyer, Kolesnikov, Weissenborn, Zhai, Unterthiner, Dehghani, Minderer, Heigold, Gelly, Uszkoreit, and Houlsby]{vit}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby.
\newblock An image is worth 16x16 words: Transformers for image recognition at scale.
\newblock In \emph{International Conference on Learning Representations}, 2021.

\bibitem[Dubey et~al.(2024)Dubey, Jauhri, Pandey, Kadian, Al-Dahle, Letman, Mathur, Schelten, Yang, Fan, et~al.]{llama3}
Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Amy Yang, Angela Fan, et~al.
\newblock The llama 3 herd of models.
\newblock \emph{arXiv:2407.21783}, 2024.

\bibitem[Esser et~al.(2024)Esser, Kulal, Blattmann, Entezari, M{\"u}ller, Saini, Levi, Lorenz, Sauer, Boesel, et~al.]{li2023scaling}
Patrick Esser, Sumith Kulal, Andreas Blattmann, Rahim Entezari, Jonas M{\"u}ller, Harry Saini, Yam Levi, Dominik Lorenz, Axel Sauer, Frederic Boesel, et~al.
\newblock Scaling rectified flow transformers for high-resolution image synthesis.
\newblock In \emph{Forty-first International Conference on Machine Learning}, 2024.

\bibitem[Fei et~al.(2024)Fei, Fan, Yu, Li, and Huang]{fei2024scaling}
Zhengcong Fei, Mingyuan Fan, Changqian Yu, Debang Li, and Junshi Huang.
\newblock Scaling diffusion transformers to 16 billion parameters.
\newblock \emph{arXiv preprint arXiv:2407.11633}, 2024.

\bibitem[Gafni et~al.(2022)Gafni, Polyak, Ashual, Sheynin, Parikh, and Taigman]{gafni2022make}
Oran Gafni, Adam Polyak, Oron Ashual, Shelly Sheynin, Devi Parikh, and Yaniv Taigman.
\newblock Make-a-scene: Scene-based text-to-image generation with human priors.
\newblock In \emph{European Conference on Computer Vision}, pages 89--106. Springer, 2022.

\bibitem[Gao et~al.(2024)Gao, Zhuo, Lin, Liu, Chen, Du, Xie, Luo, Qiu, Zhang, et~al.]{gao2024lumina}
Peng Gao, Le Zhuo, Ziyi Lin, Chris Liu, Junsong Chen, Ruoyi Du, Enze Xie, Xu Luo, Longtian Qiu, Yuhang Zhang, et~al.
\newblock Lumina-t2x: Transforming text into any modality, resolution, and duration via flow-based large diffusion transformers.
\newblock \emph{arXiv preprint arXiv:2405.05945}, 2024.

\bibitem[Gu et~al.(2024)Gu, Wang, Zhang, Zhang, Zhang, Jaitly, Susskind, and Zhai]{dart}
Jiatao Gu, Yuyang Wang, Yizhe Zhang, Qihang Zhang, Dinghuai Zhang, Navdeep Jaitly, Josh Susskind, and Shuangfei Zhai.
\newblock Dart: Denoising autoregressive transformer for scalable text-to-image generation.
\newblock \emph{arXiv preprint arXiv:2410.08159}, 2024.

\bibitem[Hang et~al.(2023)Hang, Gu, Li, Bao, Chen, Hu, Geng, and Guo]{minsnr}
Tiankai Hang, Shuyang Gu, Chen Li, Jianmin Bao, Dong Chen, Han Hu, Xin Geng, and Baining Guo.
\newblock Efficient diffusion training via min-snr weighting strategy.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 7441--7451, 2023.

\bibitem[Hao et~al.(2024)Hao, Liu, Qi, Zhao, Zi, Xiao, Han, and Wong]{bigr}
Shaozhe Hao, Xuantong Liu, Xianbiao Qi, Shihao Zhao, Bojia Zi, Rong Xiao, Kai Han, and Kwan-Yee~K Wong.
\newblock Bigr: Harnessing binary latent codes for image generation and improved visual representation capabilities.
\newblock \emph{arXiv preprint arXiv:2410.14672}, 2024.

\bibitem[He et~al.(2022)He, Chen, Xie, Li, Doll{\'a}r, and Girshick]{he2022masked}
Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Doll{\'a}r, and Ross Girshick.
\newblock Masked autoencoders are scalable vision learners.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 16000--16009, 2022.

\bibitem[Ho and Salimans(2022)]{ho2022classifier}
Jonathan Ho and Tim Salimans.
\newblock Classifier-free diffusion guidance.
\newblock \emph{arXiv preprint arXiv:2207.12598}, 2022.

\bibitem[Ho et~al.(2020)Ho, Jain, and Abbeel]{ddpm}
Jonathan Ho, Ajay Jain, and Pieter Abbeel.
\newblock Denoising diffusion probabilistic models.
\newblock \emph{Advances in neural information processing systems}, 33:\penalty0 6840--6851, 2020.

\bibitem[Hoogeboom et~al.(2023)Hoogeboom, Heek, and Salimans]{hoogeboom2023simple}
Emiel Hoogeboom, Jonathan Heek, and Tim Salimans.
\newblock simple diffusion: End-to-end diffusion for high resolution images.
\newblock In \emph{International Conference on Machine Learning}, pages 13213--13232. PMLR, 2023.

\bibitem[Huang et~al.(2016)Huang, Sun, Liu, Sedra, and Weinberger]{droppath}
Gao Huang, Yu Sun, Zhuang Liu, Daniel Sedra, and Kilian~Q Weinberger.
\newblock Deep networks with stochastic depth.
\newblock In \emph{Computer Vision--ECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October 11--14, 2016, Proceedings, Part IV 14}, pages 646--661. Springer, 2016.

\bibitem[Karras et~al.(2022)Karras, Aittala, Aila, and Laine]{edm}
Tero Karras, Miika Aittala, Timo Aila, and Samuli Laine.
\newblock Elucidating the design space of diffusion-based generative models.
\newblock \emph{Advances in neural information processing systems}, 35:\penalty0 26565--26577, 2022.

\bibitem[Kingma and Gao(2024)]{kingma2024understanding}
Diederik Kingma and Ruiqi Gao.
\newblock Understanding diffusion objectives as the elbo with simple data augmentation.
\newblock \emph{Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem[Kondratyuk et~al.(2024)Kondratyuk, Yu, Gu, Lezama, Huang, Schindler, Hornung, Birodkar, Yan, Chiu, et~al.]{kondratyukvideopoet}
Dan Kondratyuk, Lijun Yu, Xiuye Gu, Jose Lezama, Jonathan Huang, Grant Schindler, Rachel Hornung, Vighnesh Birodkar, Jimmy Yan, Ming-Chang Chiu, et~al.
\newblock Videopoet: A large language model for zero-shot video generation.
\newblock In \emph{Forty-first International Conference on Machine Learning}, 2024.

\bibitem[Kynk{\"a}{\"a}nniemi et~al.(2024)Kynk{\"a}{\"a}nniemi, Aittala, Karras, Laine, Aila, and Lehtinen]{kynkaanniemi2024applying}
Tuomas Kynk{\"a}{\"a}nniemi, Miika Aittala, Tero Karras, Samuli Laine, Timo Aila, and Jaakko Lehtinen.
\newblock Applying guidance in a limited interval improves sample and distribution quality in diffusion models.
\newblock \emph{arXiv preprint arXiv:2404.07724}, 2024.

\bibitem[Labs(2024)]{flux}
Black~Forest Labs.
\newblock Flux, 2024.

\bibitem[Li et~al.(2024)Li, Tian, Li, Deng, and He]{mar}
Tianhong Li, Yonglong Tian, He Li, Mingyang Deng, and Kaiming He.
\newblock Autoregressive image generation without vector quantization.
\newblock \emph{arXiv preprint arXiv:2406.11838}, 2024.

\bibitem[Li et~al.(2023)Li, Fan, Hu, Feichtenhofer, and He]{flip}
Yanghao Li, Haoqi Fan, Ronghang Hu, Christoph Feichtenhofer, and Kaiming He.
\newblock Scaling language-image pre-training via masking.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 23390--23400, 2023.

\bibitem[Lin et~al.(2014)Lin, Maire, Belongie, Hays, Perona, Ramanan, Doll{\'a}r, and Zitnick]{lin2014microsoft}
Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Doll{\'a}r, and C~Lawrence Zitnick.
\newblock Microsoft coco: Common objects in context.
\newblock In \emph{Computer Vision--ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part V 13}, pages 740--755. Springer, 2014.

\bibitem[Lipman et~al.(2023)Lipman, Chen, Ben-Hamu, Nickel, and Le]{lipman2023flow}
Yaron Lipman, Ricky~TQ Chen, Heli Ben-Hamu, Maximilian Nickel, and Matthew Le.
\newblock Flow matching for generative modeling.
\newblock In \emph{The Eleventh International Conference on Learning Representations}, 2023.

\bibitem[Liu et~al.(2024)Liu, Zeng, He, Yu, Shen, and Chen]{liu2024alleviating}
Qihao Liu, Zhanpeng Zeng, Ju He, Qihang Yu, Xiaohui Shen, and Liang-Chieh Chen.
\newblock Alleviating distortion in image generation via multi-resolution diffusion models.
\newblock \emph{arXiv preprint arXiv:2406.09416}, 2024.

\bibitem[Loshchilov(2017)]{loshchilov2017decoupled}
I Loshchilov.
\newblock Decoupled weight decay regularization.
\newblock \emph{arXiv preprint arXiv:1711.05101}, 2017.

\bibitem[Lu et~al.(2024)Lu, Clark, Lee, Zhang, Khosla, Marten, Hoiem, and Kembhavi]{io2}
Jiasen Lu, Christopher Clark, Sangho Lee, Zichen Zhang, Savya Khosla, Ryan Marten, Derek Hoiem, and Aniruddha Kembhavi.
\newblock Unified-io 2: Scaling autoregressive multimodal models with vision language audio and action.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 26439--26455, 2024.

\bibitem[Luo et~al.(2024)Luo, Shi, Ge, Yang, Wang, and Shan]{luo2024open}
Zhuoyan Luo, Fengyuan Shi, Yixiao Ge, Yujiu Yang, Limin Wang, and Ying Shan.
\newblock Open-magvit2: An open-source project toward democratizing auto-regressive visual generation.
\newblock \emph{arXiv preprint arXiv:2409.04410}, 2024.

\bibitem[Ma et~al.(2024)Ma, Goldstein, Albergo, Boffi, Vanden-Eijnden, and Xie]{sit}
Nanye Ma, Mark Goldstein, Michael~S Albergo, Nicholas~M Boffi, Eric Vanden-Eijnden, and Saining Xie.
\newblock Sit: Exploring flow and diffusion-based generative models with scalable interpolant transformers.
\newblock \emph{arXiv preprint arXiv:2401.08740}, 2024.

\bibitem[Nichol et~al.(2021)Nichol, Dhariwal, Ramesh, Shyam, Mishkin, McGrew, Sutskever, and Chen]{nichol2021glide}
Alex Nichol, Prafulla Dhariwal, Aditya Ramesh, Pranav Shyam, Pamela Mishkin, Bob McGrew, Ilya Sutskever, and Mark Chen.
\newblock Glide: Towards photorealistic image generation and editing with text-guided diffusion models.
\newblock \emph{arXiv preprint arXiv:2112.10741}, 2021.

\bibitem[Peebles and Xie(2023)]{dit}
William Peebles and Saining Xie.
\newblock Scalable diffusion models with transformers.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 4195--4205, 2023.

\bibitem[Podell et~al.(2024)Podell, English, Lacey, Blattmann, Dockhorn, M{\"u}ller, Penna, and Rombach]{sdxl}
Dustin Podell, Zion English, Kyle Lacey, Andreas Blattmann, Tim Dockhorn, Jonas M{\"u}ller, Joe Penna, and Robin Rombach.
\newblock Sdxl: Improving latent diffusion models for high-resolution image synthesis.
\newblock In \emph{The Twelfth International Conference on Learning Representations}, 2024.

\bibitem[Radford and Narasimhan(2018)]{gpt1}
Alec Radford and Karthik Narasimhan.
\newblock Improving language understanding by generative pre-training.
\newblock \emph{OpenAI blog}, 2018.

\bibitem[Radford et~al.(2019)Radford, Wu, Child, Luan, Amodei, Sutskever, et~al.]{gpt2}
Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et~al.
\newblock Language models are unsupervised multitask learners.
\newblock \emph{OpenAI blog}, 2019.

\bibitem[Ramesh et~al.(2021)Ramesh, Pavlov, Goh, Gray, Voss, Radford, Chen, and Sutskever]{dalle1}
Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray, Chelsea Voss, Alec Radford, Mark Chen, and Ilya Sutskever.
\newblock Zero-shot text-to-image generation.
\newblock In \emph{International conference on machine learning}, pages 8821--8831. Pmlr, 2021.

\bibitem[Ramesh et~al.(2022)Ramesh, Dhariwal, Nichol, Chu, and Chen]{dalle2}
Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen.
\newblock Hierarchical text-conditional image generation with clip latents.
\newblock \emph{arXiv:2204.06125}, 2022.

\bibitem[Rombach et~al.(2022)Rombach, Blattmann, Lorenz, Esser, and Ommer]{rombach2022high}
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj{\"o}rn Ommer.
\newblock High-resolution image synthesis with latent diffusion models.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 10684--10695, 2022.

\bibitem[Sohl-Dickstein et~al.(2015{\natexlab{a}})Sohl-Dickstein, Weiss, Maheswaranathan, and Ganguli]{dpm}
Jascha Sohl-Dickstein, Eric Weiss, Niru Maheswaranathan, and Surya Ganguli.
\newblock Deep unsupervised learning using nonequilibrium thermodynamics.
\newblock In \emph{International conference on machine learning}, pages 2256--2265. PMLR, 2015{\natexlab{a}}.

\bibitem[Sohl-Dickstein et~al.(2015{\natexlab{b}})Sohl-Dickstein, Weiss, Maheswaranathan, and Ganguli]{sohl2015deep}
Jascha Sohl-Dickstein, Eric Weiss, Niru Maheswaranathan, and Surya Ganguli.
\newblock Deep unsupervised learning using nonequilibrium thermodynamics.
\newblock In \emph{International conference on machine learning}, pages 2256--2265. PMLR, 2015{\natexlab{b}}.

\bibitem[Song and Ermon(2019)]{song0}
Yang Song and Stefano Ermon.
\newblock Generative modeling by estimating gradients of the data distribution.
\newblock \emph{Advances in neural information processing systems}, 32, 2019.

\bibitem[Song et~al.(2021)Song, Sohl-Dickstein, Kingma, Kumar, Ermon, and Poole]{songscore}
Yang Song, Jascha Sohl-Dickstein, Diederik~P Kingma, Abhishek Kumar, Stefano Ermon, and Ben Poole.
\newblock Score-based generative modeling through stochastic differential equations.
\newblock In \emph{International Conference on Learning Representations}, 2021.

\bibitem[StabilityAI(2024)]{SD-vae}
StabilityAI.
\newblock \url{https://huggingface.co/stabilityai/sd-vae-ft-ema}, 2024.

\bibitem[Sun et~al.(2024{\natexlab{a}})Sun, Jiang, Chen, Zhang, Peng, Luo, and Yuan]{sun2024autoregressive}
Peize Sun, Yi Jiang, Shoufa Chen, Shilong Zhang, Bingyue Peng, Ping Luo, and Zehuan Yuan.
\newblock Autoregressive model beats diffusion: Llama for scalable image generation.
\newblock \emph{arXiv preprint arXiv:2406.06525}, 2024{\natexlab{a}}.

\bibitem[Sun et~al.(2024{\natexlab{b}})Sun, Cui, Zhang, Zhang, Yu, Wang, Rao, Liu, Huang, and Wang]{emu2}
Quan Sun, Yufeng Cui, Xiaosong Zhang, Fan Zhang, Qiying Yu, Yueze Wang, Yongming Rao, Jingjing Liu, Tiejun Huang, and Xinlong Wang.
\newblock Generative multimodal models are in-context learners.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 14398--14409, 2024{\natexlab{b}}.

\bibitem[Szegedy et~al.(2016)Szegedy, Vanhoucke, Ioffe, Shlens, and Wojna]{label_smooth}
Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jon Shlens, and Zbigniew Wojna.
\newblock Rethinking the inception architecture for computer vision.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and pattern recognition}, pages 2818--2826, 2016.

\bibitem[Teng et~al.(2023)Teng, Zheng, Ding, Hong, Wangni, Yang, and Tang]{teng2023relay}
Jiayan Teng, Wendi Zheng, Ming Ding, Wenyi Hong, Jianqiao Wangni, Zhuoyi Yang, and Jie Tang.
\newblock Relay diffusion: Unifying diffusion process across resolutions for image synthesis.
\newblock \emph{arXiv preprint arXiv:2309.03350}, 2023.

\bibitem[Tian et~al.(2024)Tian, Jiang, Yuan, Peng, and Wang]{tian2024visual}
Keyu Tian, Yi Jiang, Zehuan Yuan, Bingyue Peng, and Liwei Wang.
\newblock Visual autoregressive modeling: Scalable image generation via next-scale prediction.
\newblock \emph{arXiv preprint arXiv:2404.02905}, 2024.

\bibitem[Touvron et~al.(2023{\natexlab{a}})Touvron, Lavril, Izacard, Martinet, Lachaux, Lacroix, Rozi{\`e}re, Goyal, Hambro, Azhar, et~al.]{llama1}
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timoth{\'e}e Lacroix, Baptiste Rozi{\`e}re, Naman Goyal, Eric Hambro, Faisal Azhar, et~al.
\newblock Llama: Open and efficient foundation language models.
\newblock \emph{arXiv:2302.13971}, 2023{\natexlab{a}}.

\bibitem[Touvron et~al.(2023{\natexlab{b}})Touvron, Martin, Stone, Albert, Almahairi, Babaei, Bashlykov, Batra, Bhargava, Bhosale, et~al.]{llama2}
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et~al.
\newblock Llama 2: Open foundation and fine-tuned chat models.
\newblock \emph{arXiv:2307.09288}, 2023{\natexlab{b}}.

\bibitem[Tschannen et~al.(2025)Tschannen, Eastwood, and Mentzer]{tschannen2025givt}
Michael Tschannen, Cian Eastwood, and Fabian Mentzer.
\newblock Givt: Generative infinite-vocabulary transformers.
\newblock In \emph{European Conference on Computer Vision}, pages 292--309. Springer, 2025.

\bibitem[Wang et~al.(2024{\natexlab{a}})Wang, Bai, Tan, Wang, Fan, Bai, Chen, Liu, Wang, Ge, Fan, Dang, Du, Ren, Men, Liu, Zhou, Zhou, and Lin]{qwen2vl}
Peng Wang, Shuai Bai, Sinan Tan, Shijie Wang, Zhihao Fan, Jinze Bai, Keqin Chen, Xuejing Liu, Jialin Wang, Wenbin Ge, Yang Fan, Kai Dang, Mengfei Du, Xuancheng Ren, Rui Men, Dayiheng Liu, Chang Zhou, Jingren Zhou, and Junyang Lin.
\newblock Qwen2-vl: Enhancing vision-language model's perception of the world at any resolution.
\newblock \emph{arXiv:2409.12191}, 2024{\natexlab{a}}.

\bibitem[Wang et~al.(2018)Wang, Girshick, Gupta, and He]{wang2018non}
Xiaolong Wang, Ross Girshick, Abhinav Gupta, and Kaiming He.
\newblock Non-local neural networks.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and pattern recognition}, pages 7794--7803, 2018.

\bibitem[Wang et~al.(2024{\natexlab{b}})Wang, Lu, Huang, Zhou, Ouyang, et~al.]{wang2024fitv2}
ZiDong Wang, Zeyu Lu, Di Huang, Cai Zhou, Wanli Ouyang, et~al.
\newblock Fitv2: Scalable and improved flexible vision transformer for diffusion model.
\newblock \emph{arXiv preprint arXiv:2410.13925}, 2024{\natexlab{b}}.

\bibitem[Wei et~al.(2022)Wei, Fan, Xie, Wu, Yuille, and Feichtenhofer]{maskedpredict}
Chen Wei, Haoqi Fan, Saining Xie, Chao-Yuan Wu, Alan Yuille, and Christoph Feichtenhofer.
\newblock Masked feature prediction for self-supervised visual pre-training.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 14668--14678, 2022.

\bibitem[Yu et~al.(2022)Yu, Xu, Koh, Luong, Baid, Wang, Vasudevan, Ku, Yang, Ayan, et~al.]{parti}
Jiahui Yu, Yuanzhong Xu, Jing~Yu Koh, Thang Luong, Gunjan Baid, Zirui Wang, Vijay Vasudevan, Alexander Ku, Yinfei Yang, Burcu~Karagol Ayan, et~al.
\newblock Scaling autoregressive models for content-rich text-to-image generation.
\newblock \emph{Transactions on Machine Learning Research}, 2022.

\bibitem[Yun et~al.(2019)Yun, Han, Oh, Chun, Choe, and Yoo]{cutmix}
Sangdoo Yun, Dongyoon Han, Seong~Joon Oh, Sanghyuk Chun, Junsuk Choe, and Youngjoon Yoo.
\newblock Cutmix: Regularization strategy to train strong classifiers with localizable features.
\newblock In \emph{Proceedings of the IEEE/CVF international conference on computer vision}, pages 6023--6032, 2019.

\bibitem[Zhan et~al.(2024)Zhan, Dai, Ye, Zhou, Zhang, Liu, Zhang, Yuan, Zhang, Li, et~al.]{anygpt}
Jun Zhan, Junqi Dai, Jiasheng Ye, Yunhua Zhou, Dong Zhang, Zhigeng Liu, Xin Zhang, Ruibin Yuan, Ge Zhang, Linyang Li, et~al.
\newblock Anygpt: Unified multimodal llm with discrete sequence modeling.
\newblock \emph{arXiv:2402.12226}, 2024.

\bibitem[Zhang et~al.(2018)Zhang, Cisse, Dauphin, and Lopez-Paz]{mixup}
Hongyi Zhang, Moustapha Cisse, Yann~N. Dauphin, and David Lopez-Paz.
\newblock mixup: Beyond empirical risk minimization.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Zhao et~al.(2024)Zhao, Song, Wang, Feng, Ding, Sun, Xiao, and Wang]{monoformer}
Chuyang Zhao, Yuxing Song, Wenhao Wang, Haocheng Feng, Errui Ding, Yifan Sun, Xinyan Xiao, and Jingdong Wang.
\newblock Monoformer: One transformer for both diffusion and autoregression.
\newblock \emph{arXiv:2409.16280}, 2024.

\bibitem[Zheng et~al.(2023)Zheng, Nie, Vahdat, and Anandkumar]{zheng2023fast}
Hongkai Zheng, Weili Nie, Arash Vahdat, and Anima Anandkumar.
\newblock Fast training of diffusion models with masked transformers.
\newblock \emph{arXiv preprint arXiv:2306.09305}, 2023.

\bibitem[Zhong et~al.(2020)Zhong, Zheng, Kang, Li, and Yang]{erasing}
Zhun Zhong, Liang Zheng, Guoliang Kang, Shaozi Li, and Yi Yang.
\newblock Random erasing data augmentation.
\newblock In \emph{Proceedings of the AAAI conference on artificial intelligence}, pages 13001--13008, 2020.

\bibitem[Zhou et~al.(2024)Zhou, Yu, Babu, Tirumala, Yasunaga, Shamis, Kahn, Ma, Zettlemoyer, and Levy]{transfusion}
Chunting Zhou, Lili Yu, Arun Babu, Kushal Tirumala, Michihiro Yasunaga, Leonid Shamis, Jacob Kahn, Xuezhe Ma, Luke Zettlemoyer, and Omer Levy.
\newblock Transfusion: Predict the next token and diffuse images with one multi-modal model.
\newblock \emph{arXiv:2408.11039}, 2024.

\end{thebibliography}
