\begin{thebibliography}{62}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Altekrüger et~al.(2023)Altekrüger, Denker, Hagemann, Hertrich,
  Maass, and Steidl]{Altekruger_2023}
Fabian Altekrüger, Alexander Denker, Paul Hagemann, Johannes Hertrich, Peter
  Maass, and Gabriele Steidl.
\newblock Patch{NR}: learning from very few images by patch normalizing flow
  regularization.
\newblock \emph{Inverse Problems}, 39\penalty0 (6):\penalty0 064006, 2023.

\bibitem[Ambrosio et~al.(2008)Ambrosio, Gigli, and Savaré]{ambrosio2008}
Luigi Ambrosio, Nicola Gigli, and Giuseppe Savaré.
\newblock \emph{Gradient Flows in Metric Spaces and in the Space of Probability
  Measures}.
\newblock Lectures in Mathematics {{ETH Zürich}}. {Birkhäuser}, 2nd edition,
  2008.

\bibitem[Asim et~al.(2020)Asim, Daniels, Leong, Ahmed, and
  Hand]{pmlr-v119-asim20a}
Muhammad Asim, Max Daniels, Oscar Leong, Ali Ahmed, and Paul Hand.
\newblock Invertible generative models for inverse problems: mitigating
  representation error and dataset bias.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2020.

\bibitem[Ben-Hamu et~al.(2024)Ben-Hamu, Puny, Gat, Karrer, Singer, and
  Lipman]{ben2024dflow}
Heli Ben-Hamu, Omri Puny, Itai Gat, Brian Karrer, Uriel Singer, and Yaron
  Lipman.
\newblock D-{F}low: Differentiating through flows for controlled generation.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2024.

\bibitem[Benton et~al.(2024)Benton, Deligiannidis, and Doucet]{benton2024error}
Joe Benton, George Deligiannidis, and Arnaud Doucet.
\newblock Error bounds for flow matching methods.
\newblock \emph{Transactions on Machine Learning Research}, 2024.

\bibitem[Blau \& Michaeli(2018)Blau and Michaeli]{Blau_2018}
Yochai Blau and Tomer Michaeli.
\newblock The perception-distortion tradeoff.
\newblock In \emph{IEEE/CVF Conference on Computer Vision and Pattern
  Recognition (CVPR)}. IEEE, 2018.

\bibitem[Boll et~al.(2024)Boll, Gonzalez-Alvarado, Petra, and
  Schnörr]{boll2024}
Bastian Boll, Daniel Gonzalez-Alvarado, Stefania Petra, and Christoph Schnörr.
\newblock Generative assignment flows for representing and learning joint
  distributions of discrete data.
\newblock \emph{arXiv preprint arXiv:2406.04527}, 2024.

\bibitem[Bora et~al.(2017)Bora, Jalal, Price, and Dimakis]{bora2017compressed}
Ashish Bora, Ajil Jalal, Eric Price, and Alexandros~G Dimakis.
\newblock Compressed sensing using generative models.
\newblock In \emph{International Conference on Machine Learning (ICML)}, pp.\
  537--546, 2017.

\bibitem[Boyd et~al.(2011)Boyd, Parikh, Chu, Peleato, Eckstein,
  et~al.]{boyd2011distributed}
Stephen Boyd, Neal Parikh, Eric Chu, Borja Peleato, Jonathan Eckstein, et~al.
\newblock Distributed optimization and statistical learning via the alternating
  direction method of multipliers.
\newblock \emph{Foundations and Trends{\textregistered} in Machine learning},
  3\penalty0 (1):\penalty0 1--122, 2011.

\bibitem[Chan et~al.(2016)Chan, Wang, and Elgendy]{chan2016plug}
Stanley~H Chan, Xiran Wang, and Omar~A Elgendy.
\newblock Plug-and-play admm for image restoration: Fixed-point convergence and
  applications.
\newblock \emph{IEEE Transactions on Computational Imaging}, 3\penalty0
  (1):\penalty0 84--98, 2016.

\bibitem[Chemseddine et~al.(2024)Chemseddine, Hagemann, Steidl, and
  Wald]{CHSW2024}
Jannis Chemseddine, Paul Hagemann, Gabriele Steidl, and Christian Wald.
\newblock Conditional {W}asserstein distances with applications in {B}ayesian
  {OT} flow matching.
\newblock \emph{arXiv preprint arXiv:2024}, 2024.

\bibitem[Chen et~al.(2018)Chen, Rubanova, Bettencourt, and
  Duvenaud]{chen2018neural}
Ricky T.~Q. Chen, Yulia Rubanova, Jesse Bettencourt, and David~K. Duvenaud.
\newblock Neural ordinary differential equations.
\newblock \emph{Advances in Neural Information Processing Systems (NeurIPS)},
  2018.

\bibitem[Choi et~al.(2021)Choi, Kim, Jeong, Gwon, and Yoon]{choi2021ilvr}
Jooyoung Choi, Sungwon Kim, Yonghyun Jeong, Youngjune Gwon, and Sungroh Yoon.
\newblock Ilvr: Conditioning method for denoising diffusion probabilistic
  models.
\newblock In \emph{CVF International Conference on Computer Vision (ICCV)},
  volume~1, pp.\ ~2, 2021.

\bibitem[Choi et~al.(2020)Choi, Uh, Yoo, and Ha]{choi2020stargan}
Yunjey Choi, Youngjung Uh, Jaejun Yoo, and Jung-Woo Ha.
\newblock Star{GAN} v2: Diverse image synthesis for multiple domains.
\newblock In \emph{IEEE/CVF Conference on Computer Vision and Pattern
  Recognition (CVPR)}, pp.\  8188--8197, 2020.

\bibitem[Chung et~al.(2023)Chung, Kim, Mccann, Klasky, and
  Ye]{chung2023diffusion}
Hyungjin Chung, Jeongsol Kim, Michael~Thompson Mccann, Marc~Louis Klasky, and
  Jong~Chul Ye.
\newblock Diffusion posterior sampling for general noisy inverse problems.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2023.

\bibitem[Combettes \& Wajs(2005)Combettes and Wajs]{combettes2005signal}
Patrick~L Combettes and Val{\'e}rie~R Wajs.
\newblock Signal recovery by proximal forward-backward splitting.
\newblock \emph{Multiscale Modeling \& Simulation}, 4\penalty0 (4):\penalty0
  1168--1200, 2005.

\bibitem[Davis et~al.(2024)Davis, Kessler, Petrache, İsmail~İlkan Ceylan,
  Bronstein, and Bose]{davis2024}
Oscar Davis, Samuel Kessler, Mircea Petrache, İsmail~İlkan Ceylan, Michael
  Bronstein, and Avishek~Joey Bose.
\newblock Fisher flow matching for generative modeling over discrete data.
\newblock \emph{arXiv preprint arXiv:2405.14664}, 2024.

\bibitem[Dinh et~al.(2017)Dinh, Sohl-Dickstein, and Bengio]{dinh2017density}
Laurent Dinh, Jascha Sohl-Dickstein, and Samy Bengio.
\newblock Density estimation using real {NVP}.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2017.

\bibitem[Gat et~al.(2024)Gat, Remez, Shaul, Kreuk, Chen, Synnaeve, Adi, and
  Lipman]{gat2024discreteflowmatching}
Itai Gat, Tal Remez, Neta Shaul, Felix Kreuk, Ricky T.~Q. Chen, Gabriel
  Synnaeve, Yossi Adi, and Yaron Lipman.
\newblock Discrete flow matching.
\newblock \emph{arXiv preprint arXiv:2407.15595}, 2024.

\bibitem[Graikos et~al.(2022)Graikos, Malkin, Jojic, and
  Samaras]{graikos2022diffusion}
Alexandros Graikos, Nikolay Malkin, Nebojsa Jojic, and Dimitris Samaras.
\newblock Diffusion models as plug-and-play priors.
\newblock In Alice~H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho
  (eds.), \emph{Advances in Neural Information Processing Systems (NeurIPS)},
  2022.

\bibitem[Guo et~al.(2016)Guo, Qi, Xu, Chen, Li, and Zhou]{guo2016iterative}
Jingyu Guo, Hongliang Qi, Yuan Xu, Zijia Chen, Shulong Li, and Linghong Zhou.
\newblock Iterative image reconstruction for limited-angle {CT} using optimized
  initial image.
\newblock \emph{Computational and Mathematical Methods in Medicine},
  2016\penalty0 (1):\penalty0 5836410, 2016.

\bibitem[Hertrich et~al.(2021)Hertrich, Neumayer, and Steidl]{HNS2021}
Johannes Hertrich, Sebastian Neumayer, and Gabriele Steidl.
\newblock Convolutional proximal neural networks and plug-and-play algorithms.
\newblock \emph{Linear Algebra and its Applications}, 631:\penalty0
  203–--234, 2021.

\bibitem[Ho et~al.(2020)Ho, Jain, and Abbeel]{ho2020}
Jonathan Ho, Ajay Jain, and Pieter Abbeel.
\newblock Denoising diffusion probabilistic models.
\newblock In H.~Larochelle, M.~Ranzato, R.~Hadsell, M.F. Balcan, and H.~Lin
  (eds.), \emph{Advances in Neural Information Processing Systems (NeurIPS)},
  volume~33, pp.\  6840--6851, 2020.

\bibitem[Huang et~al.(2021)Huang, Lim, and Courville]{huang2021}
Chin-Wei Huang, Jae~Hyun Lim, and Aaron~C Courville.
\newblock A variational perspective on diffusion-based generative models and
  score matching.
\newblock In M.~Ranzato, A.~Beygelzimer, Y.~Dauphin, P.S. Liang, and J.~Wortman
  Vaughan (eds.), \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, volume~34, pp.\  22863--22876, 2021.

\bibitem[Hurault et~al.(2022{\natexlab{a}})Hurault, Leclaire, and
  Papadakis]{hurault2022gradient}
Samuel Hurault, Arthur Leclaire, and Nicolas Papadakis.
\newblock Gradient step denoiser for convergent plug-and-play.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2022{\natexlab{a}}.

\bibitem[Hurault et~al.(2022{\natexlab{b}})Hurault, Leclaire, and
  Papadakis]{hurault2022prox}
Samuel Hurault, Arthur Leclaire, and Nicolas Papadakis.
\newblock Proximal denoiser for convergent plug-and-play optimization with
  nonconvex regularization.
\newblock In \emph{International Conference on Machine Learning (ICML)},
  2022{\natexlab{b}}.

\bibitem[Hurault et~al.(2023)Hurault, Kamilov, Leclaire, and
  Papadakis]{hurault23poission}
Samuel Hurault, Ulugbek Kamilov, Arthur Leclaire, and Nicolas Papadakis.
\newblock Convergent bregman plug-and-play image restoration for poisson
  inverse problems.
\newblock In A.~Oh, T.~Naumann, A.~Globerson, K.~Saenko, M.~Hardt, and
  S.~Levine (eds.), \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, volume~36, pp.\  27251--27280, 2023.

\bibitem[Karras et~al.(2018)Karras, Aila, Laine, and
  Lehtinen]{karras2018progressive}
Tero Karras, Timo Aila, Samuli Laine, and Jaakko Lehtinen.
\newblock Progressive growing of gans for improved quality, stability, and
  variation.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2018.

\bibitem[Karras et~al.(2019)Karras, Laine, and Aila]{karras2019style}
Tero Karras, Samuli Laine, and Timo Aila.
\newblock A style-based generator architecture for generative adversarial
  networks.
\newblock In \emph{IEEE/CVF Conference on Computer Vision and Pattern
  Recognition (CVPR)}, pp.\  4401--4410, 2019.

\bibitem[Kornilov et~al.(2024)Kornilov, Gasnikov, and
  Korotin]{kornilov2024optimal}
Nikita Kornilov, Alexander Gasnikov, and Alexander Korotin.
\newblock Optimal flow matching: Learning straight trajectories in just one
  step.
\newblock \emph{arXiv preprint arXiv:2403.13117}, 2024.

\bibitem[LeCun et~al.(1998)LeCun, Bottou, Bengio, and Haffner]{mnist}
Yann LeCun, L\'eon Bottou, Yoshua Bengio, and Patrick Haffner.
\newblock Gradient-based learning applied to document recognition.
\newblock \emph{Proceedings of the IEEE}, 86\penalty0 (11):\penalty0
  2278--2324, 1998.
\newblock \doi{10.1109/5.726791}.

\bibitem[Lee et~al.(2023)Lee, Kim, and Ye]{pmlr-v202-lee23j}
Sangyun Lee, Beomsu Kim, and Jong~Chul Ye.
\newblock Minimizing trajectory curvature of {ODE}-based generative models.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2023.

\bibitem[Lipman et~al.(2023)Lipman, Chen, Ben-Hamu, Nickel, and
  Le]{lipman2023flow}
Yaron Lipman, Ricky T.~Q. Chen, Heli Ben-Hamu, Maximilian Nickel, and Matthew
  Le.
\newblock Flow matching for generative modeling.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2023.

\bibitem[Liu(2022)]{liu2022Ot}
Qiang Liu.
\newblock Rectified flow: A marginal preserving approach to optimal transport.
\newblock \emph{arXiv preprint arXiv:2209.14577}, 2022.

\bibitem[Liu et~al.(2023)Liu, Gong, and Liu]{liu2023flow}
Xingchao Liu, Chengyue Gong, and Qiang Liu.
\newblock Flow straight and fast: Learning to generate and transfer data with
  rectified flow.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2023.

\bibitem[Manekar et~al.(2020)Manekar, Zhuang, Tayal, Kumar, and
  Sun]{manekar2020deep}
Raunak Manekar, Zhong Zhuang, Kshitij Tayal, Vipin Kumar, and Ju~Sun.
\newblock Deep learning initialized phase retrieval.
\newblock In \emph{Neural Information Processing Systems (NeurIPS) Workshop},
  2020.

\bibitem[Mardani et~al.(2024)Mardani, Song, Kautz, and
  Vahdat]{mardani2024variational}
Morteza Mardani, Jiaming Song, Jan Kautz, and Arash Vahdat.
\newblock A variational perspective on solving inverse problems with diffusion
  models.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2024.

\bibitem[Meinhardt et~al.(2017)Meinhardt, Moeller, Hazirbas, and
  Cremers]{meinhardt17learnprox}
Tim Meinhardt, Michael Moeller, Caner Hazirbas, and Daniel Cremers.
\newblock Learning proximal operators: Using denoising networks for
  regularizing inverse imaging problems.
\newblock In \emph{IEEE International Conference on Computer Vision (ICCV)},
  pp.\  1799--1808. IEEE Computer Society, 2017.

\bibitem[Pesquet et~al.(2021)Pesquet, Repetti, Terris, and
  Wiaux]{pesquet2021learning}
Jean-Christophe Pesquet, Audrey Repetti, Matthieu Terris, and Yves Wiaux.
\newblock Learning maximally monotone operators for image recovery.
\newblock \emph{SIAM Journal on Imaging Sciences}, 14\penalty0 (3):\penalty0
  1206--1237, 2021.

\bibitem[Pokle et~al.(2024)Pokle, Muckley, Chen, and
  Karrer]{pokle2024trainingfree}
Ashwini Pokle, Matthew~J. Muckley, Ricky T.~Q. Chen, and Brian Karrer.
\newblock Training-free linear image inverses via flows.
\newblock \emph{Transactions on Machine Learning Research}, 2024.

\bibitem[Pooladian et~al.(2023)Pooladian, Ben-Hamu, Domingo-Enrich, Amos,
  Lipman, and Chen]{pooladian2023multisample}
Aram-Alexandre Pooladian, Heli Ben-Hamu, Carles Domingo-Enrich, Brandon Amos,
  Yaron Lipman, and Ricky T.~Q. Chen.
\newblock Multisample flow matching: Straightening flows with minibatch
  couplings.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2023.

\bibitem[Ronneberger et~al.(2015)Ronneberger, Fischer, and
  Brox]{ronneberger2015u}
Olaf Ronneberger, Philipp Fischer, and Thomas Brox.
\newblock U-net: Convolutional networks for biomedical image segmentation.
\newblock In \emph{Medical Image Computing and Computer-Assisted Intervention
  (MICCAI)}, pp.\  234--241. Springer, 2015.

\bibitem[Ryu et~al.(2019)Ryu, Liu, Wang, Chen, Wang, and Yin]{ryu19prox}
Ernest Ryu, Jialin Liu, Sicheng Wang, Xiaohan Chen, Zhangyang Wang, and Wotao
  Yin.
\newblock Plug-and-play methods provably converge with properly trained
  denoisers.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2019.

\bibitem[Sohl-Dickstein et~al.(2015)Sohl-Dickstein, Weiss, Maheswaranathan, and
  Ganguli]{pmlr-v37-sohl-dickstein15}
Jascha Sohl-Dickstein, Eric Weiss, Niru Maheswaranathan, and Surya Ganguli.
\newblock Deep unsupervised learning using nonequilibrium thermodynamics.
\newblock In Francis Bach and David Blei (eds.), \emph{Proceedings of the 32nd
  International Conference on Machine Learning}, volume~37 of \emph{Proceedings
  of Machine Learning Research}, pp.\  2256--2265, 2015.

\bibitem[Sommerhoff et~al.(2019)Sommerhoff, Kolb, and Moeller]{SKM2019}
Hendrik Sommerhoff, Andreas Kolb, and Michael Moeller.
\newblock Energy dissipation with plug-and-play priors.
\newblock In \emph{Advances in Neural Information Processing Systems (NeurIPS)
  Workshop}, 2019.

\bibitem[Song et~al.(2023)Song, Vahdat, Mardani, and
  Kautz]{song2023pseudoinverse}
Jiaming Song, Arash Vahdat, Morteza Mardani, and Jan Kautz.
\newblock Pseudoinverse-guided diffusion models for inverse problems.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2023.

\bibitem[Song et~al.(2021)Song, Sohl-Dickstein, Kingma, Kumar, Ermon, and
  Poole]{song2021scorebased}
Yang Song, Jascha Sohl-Dickstein, Diederik~P Kingma, Abhishek Kumar, Stefano
  Ermon, and Ben Poole.
\newblock Score-based generative modeling through stochastic differential
  equations.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2021.

\bibitem[Stark et~al.(2024)Stark, Jing, Wang, Corso, Berger, Barzilay, and
  Jaakkola]{stark2024dirichlet}
Hannes Stark, Bowen Jing, Chenyu Wang, Gabriele Corso, Bonnie Berger, Regina
  Barzilay, and Tommi Jaakkola.
\newblock Dirichlet flow matching with applications to {DNA} sequence design.
\newblock In \emph{International Conference on Machine Learning (ICLR)}, 2024.

\bibitem[Sun et~al.(2019)Sun, Wohlberg, and Kamilov]{SWK2019}
Yu~Sun, Brendt Wohlberg, and Ulugbek~S Kamilov.
\newblock An online plug-and-play algorithm for regularized image
  reconstruction.
\newblock \emph{IEEE Transactions on Computational Imaging}, 5\penalty0
  (3):\penalty0 395--408, 2019.

\bibitem[Tachella et~al.(2023)Tachella, Chen, Hurault, Terris, and
  Wang]{Tachella_DeepInverse_A_deep_2023}
Julian Tachella, Dongdong Chen, Samuel Hurault, Matthieu Terris, and Andrew
  Wang.
\newblock {DeepInverse: A deep learning framework for inverse problems in
  imaging}, 2023.

\bibitem[Tan et~al.(2024)Tan, Mukherjee, Tang, and
  Sch{\"o}nlieb]{tan2024provably}
Hong~Ye Tan, Subhadip Mukherjee, Junqi Tang, and Carola-Bibiane Sch{\"o}nlieb.
\newblock Provably convergent plug-and-play quasi-{N}ewton methods.
\newblock \emph{SIAM Journal on Imaging Sciences}, 17\penalty0 (2):\penalty0
  785--819, 2024.

\bibitem[Terris et~al.(2020)Terris, Repetti, Pesquet, and
  Wiaux]{terris20firmly}
Matthieu Terris, Audrey Repetti, Jean-Christophe Pesquet, and Yves Wiaux.
\newblock Building firmly nonexpansive convolutional neural networks.
\newblock In \emph{IEEE International Conference on Acoustics, Speech and
  Signal Processing (ICASSP)}, 2020.

\bibitem[Tong et~al.(2024)Tong, Fatras, Malkin, Huguet, Zhang, Rector-Brooks,
  Wolf, and Bengio]{tong2024improving}
Alexander Tong, Kilian Fatras, Nikolay Malkin, Guillaume Huguet, Yanlei Zhang,
  Jarrid Rector-Brooks, Guy Wolf, and Yoshua Bengio.
\newblock Improving and generalizing flow-based generative models with
  minibatch optimal transport.
\newblock \emph{Transactions on Machine Learning Research}, 2024.

\bibitem[Venkatakrishnan et~al.(2013)Venkatakrishnan, Bouman, and
  Wohlberg]{venkatakrishnan13pnp}
{Singanallur V.} Venkatakrishnan, {Charles A.} Bouman, and Brendt Wohlberg.
\newblock Plug-and-play priors for model based reconstruction.
\newblock In \emph{IEEE Global Conference on Signal and Information Processing
  (GlobalSIP)}, pp.\  945--948, 2013.

\bibitem[Villani(2008)]{villani}
Cédric Villani.
\newblock \emph{Optimal Transport -- Old and New}, volume 338.
\newblock Springer, 2008.

\bibitem[Wei et~al.(2022)Wei, van Gorp, Gonzalez-Carabarin, Freedman, Eldar,
  and van Sloun]{Wei_2022}
Xinyi Wei, Hans van Gorp, Lizeth Gonzalez-Carabarin, Daniel Freedman, Yonina~C.
  Eldar, and Ruud J.~G. van Sloun.
\newblock Deep unfolding with normalizing flow priors for inverse problems.
\newblock \emph{IEEE Transactions on Signal Processing}, 70:\penalty0
  2962–2971, 2022.

\bibitem[Yang et~al.(2024)Yang, Zhang, Zhang, Liu, Xu, Zhang, Meng, Ermon, and
  Cui]{yang2024consistencyflowmatchingdefining}
Ling Yang, Zixiang Zhang, Zhilong Zhang, Xingchao Liu, Minkai Xu, Wentao Zhang,
  Chenlin Meng, Stefano Ermon, and Bin Cui.
\newblock Consistency flow matching: Defining straight flows with velocity
  consistency.
\newblock \emph{arXiv preprint arXiv:2407.02398}, 2024.

\bibitem[Yang et~al.(2015)Yang, Luo, Loy, and Tang]{yang2015facial}
Shuo Yang, Ping Luo, Chen-Change Loy, and Xiaoou Tang.
\newblock From facial parts responses to face detection: A deep learning
  approach.
\newblock In \emph{IEEE International Conference on Computer Vision (ICCV)},
  pp.\  3676--3684, 2015.

\bibitem[Zhang et~al.(2017)Zhang, Zuo, Chen, Meng, and Zhang]{zhang2017beyond}
Kai Zhang, Wangmeng Zuo, Yunjin Chen, Deyu Meng, and Lei Zhang.
\newblock Beyond a {Gaussian} denoiser: Residual learning of deep {CNN} for
  image denoising.
\newblock \emph{IEEE Transactions on Image Processing}, 26\penalty0
  (7):\penalty0 3142--3155, 2017.

\bibitem[Zhang et~al.(2021)Zhang, Li, Zuo, Zhang, Van~Gool, and
  Timofte]{zhang2021plug}
Kai Zhang, Yawei Li, Wangmeng Zuo, Lei Zhang, Luc Van~Gool, and Radu Timofte.
\newblock Plug-and-play image restoration with deep denoiser prior.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine
  Intelligence}, 44\penalty0 (10):\penalty0 6360--6376, 2021.

\bibitem[Zhang et~al.(2024)Zhang, Yu, Zhu, Chang, Gao, Wu, and
  Leong]{zhang2024flow}
Yasi Zhang, Peiyu Yu, Yaxuan Zhu, Yingshan Chang, Feng Gao, Ying~Nian Wu, and
  Oscar Leong.
\newblock Flow priors for linear inverse problems via iterative corrupted
  trajectory matching.
\newblock \emph{arXiv preprint arXiv:2405.18816}, 2024.

\bibitem[Zhu et~al.(2023)Zhu, Zhang, Liang, Cao, Wen, Timofte, and
  Van~Gool]{zhu2023denoising}
Yuanzhi Zhu, Kai Zhang, Jingyun Liang, Jiezhang Cao, Bihan Wen, Radu Timofte,
  and Luc Van~Gool.
\newblock Denoising diffusion models for plug-and-play image restoration.
\newblock In \emph{IEEE/CVF Conference on Computer Vision and Pattern
  Recognition (CVPR)}, pp.\  1219--1229, 2023.

\end{thebibliography}
