@article{Woelfle2011OpenSI,
  title = {Open science is a research accelerator.},
  author = {Michael Woelfle and Piero L Olliaro and Matthew H. Todd},
  year = 2011,
  journal = {Nature chemistry},
  volume = {3 10},
  pages = {745--8},
  url = {https://api.semanticscholar.org/CorpusID:205289283},
}
@article{cacm-2018-software-heritage,
  title = {Building the Universal Archive of Source Code},
  author = {Jean-François Abramatic and Roberto Di Cosmo and Stefano Zacchiroli},
  year = 2018,
  journal = {Communications of the ACM},
  volume = 61,
  number = 10,
  pages = {29--31},
  doi = {10.1145/3183558},
  url = {https://cacm.acm.org/magazines/2018/10/231366-building-the-universal-archive-of-source-code/fulltext},
}
@article{conneau2019unsupervised,
  title = {Unsupervised cross-lingual representation learning at scale},
  author = {Conneau, Alexis and Khandelwal, Kartikay and Goyal, Naman and Chaudhary, Vishrav and Wenzek, Guillaume and Guzm{\'a}n, Francisco and Grave, Edouard and Ott, Myle and Zettlemoyer, Luke and Stoyanov, Veselin},
  year = 2019,
  journal = {arXiv preprint arXiv:1911.02116},
}
@article{shazeer2019mqa,
  title = {Fast Transformer Decoding: One Write-Head is All You Need},
  author = {Noam Shazeer},
  year = 2019,
  journal = {CoRR},
  volume = {abs/1911.02150},
  url = {http://arxiv.org/abs/1911.02150},
  eprint = {1911.02150},
  eprinttype = {arXiv},
  timestamp = {Mon, 11 Nov 2019 18:38:09 +0100},
  biburl = {https://dblp.org/rec/journals/corr/abs-1911-02150.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
}
@inproceedings{reimers2019sentence,
    title = "Sentence-{BERT}: Sentence Embeddings using Siamese {BERT}-Networks",
    author = "Reimers, Nils  and
      Gurevych, Iryna",
    editor = "Inui, Kentaro  and
      Jiang, Jing  and
      Ng, Vincent  and
      Wan, Xiaojun",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-1410",
    doi = "10.18653/v1/D19-1410",
    pages = "3982--3992",
    abstract = "BERT (Devlin et al., 2018) and RoBERTa (Liu et al., 2019) has set a new state-of-the-art performance on sentence-pair regression tasks like semantic textual similarity (STS). However, it requires that both sentences are fed into the network, which causes a massive computational overhead: Finding the most similar pair in a collection of 10,000 sentences requires about 50 million inference computations ({\textasciitilde}65 hours) with BERT. The construction of BERT makes it unsuitable for semantic similarity search as well as for unsupervised tasks like clustering. In this publication, we present Sentence-BERT (SBERT), a modification of the pretrained BERT network that use siamese and triplet network structures to derive semantically meaningful sentence embeddings that can be compared using cosine-similarity. This reduces the effort for finding the most similar pair from 65 hours with BERT / RoBERTa to about 5 seconds with SBERT, while maintaining the accuracy from BERT. We evaluate SBERT and SRoBERTa on common STS tasks and transfer learning tasks, where it outperforms other state-of-the-art sentence embeddings methods.",
}

@inproceedings{sheng2019woman,
    title = "The Woman Worked as a Babysitter: On Biases in Language Generation",
    author = "Sheng, Emily  and
      Chang, Kai-Wei  and
      Natarajan, Premkumar  and
      Peng, Nanyun",
    editor = "Inui, Kentaro  and
      Jiang, Jing  and
      Ng, Vincent  and
      Wan, Xiaojun",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-1339",
    doi = "10.18653/v1/D19-1339",
    pages = "3407--3412",
    abstract = "We present a systematic study of biases in natural language generation (NLG) by analyzing text generated from prompts that contain mentions of different demographic groups. In this work, we introduce the notion of the regard towards a demographic, use the varying levels of regard towards different demographics as a defining metric for bias in NLG, and analyze the extent to which sentiment scores are a relevant proxy metric for regard. To this end, we collect strategically-generated text from language models and manually annotate the text with both sentiment and regard scores. Additionally, we build an automatic regard classifier through transfer learning, so that we can analyze biases in unseen text. Together, these methods reveal the extent of the biased nature of language model generations. Our analysis provides a study of biases in NLG, bias metrics and correlated human judgments, and empirical evidence on the usefulness of our annotated dataset.",
}

@article{sholler2019ten,
  title = {Ten simple rules for helping newcomers become contributors to open projects},
  author = {Sholler, Dan and Steinmacher, Igor and Ford, Denise and Averick, Mara and Hoye, Mike and Wilson, Greg},
  year = 2019,
  journal = {PLoS Computational Biology},
  publisher = {Public Library of Science},
  volume = 15,
  number = 9,
  pages = {e1007296},
  doi = {10.1371/journal.pcbi.1007296},
  url = {https://doi.org/10.1371/journal.pcbi.1007296},
}
@article{arivazhagan2019massively,
  title = {Massively Multilingual Neural Machine Translation in the Wild: Findings and Challenges},
  author = {Naveen Arivazhagan and Ankur Bapna and Orhan Firat and Dmitry Lepikhin and Melvin Johnson and Maxim Krikun and Mia Xu Chen and Yuan Cao and George Foster and Colin Cherry and Wolfgang Macherey and Zhifeng Chen and Yonghui Wu},
  year = 2019,
  month = jul,
  journal = {arXiv preprint},
  url = {https://arxiv.org/abs/1907.05019},
  eprint = {1907.05019},
  archiveprefix = {arXiv},
  primaryclass = {cs.CL},
}
@article{lacoste2019quantifying,
  title = {Quantifying the Carbon Emissions of Machine Learning},
  author = {Lacoste, Alexandre and Luccioni, Alexandra and Schmidt, Victor and Dandres, Thomas},
  year = 2019,
  month = oct,
  journal = {arXiv preprint},
  url = {https://arxiv.org/abs/1910.09700},
}
@article{cosmo2020referencing,
  title = {Referencing Source Code Artifacts: A Separate Concern in Software Citation},
  author = {Roberto Di Cosmo and Morane Gruenpeter and Stefano Zacchiroli},
  year = 2020,
  journal = {Computing in Science \& Engineering},
  volume = 22,
  number = 2,
  pages = {33--43},
  doi = {10.1109/MCSE.2019.2963148},
}
@inproceedings{
sanh2021multitask,
title={Multitask Prompted Training Enables Zero-Shot Task Generalization},
author={Victor Sanh and Albert Webson and Colin Raffel and Stephen Bach and Lintang Sutawika and Zaid Alyafeai and Antoine Chaffin and Arnaud Stiegler and Arun Raja and Manan Dey and M Saiful Bari and Canwen Xu and Urmish Thakker and Shanya Sharma Sharma and Eliza Szczechla and Taewoon Kim and Gunjan Chhablani and Nihal Nayak and Debajyoti Datta and Jonathan Chang and Mike Tian-Jian Jiang and Han Wang and Matteo Manica and Sheng Shen and Zheng Xin Yong and Harshit Pandey and Rachel Bawden and Thomas Wang and Trishala Neeraj and Jos Rozen and Abheesht Sharma and Andrea Santilli and Thibault Fevry and Jason Alan Fries and Ryan Teehan and Teven Le Scao and Stella Biderman and Leo Gao and Thomas Wolf and Alexander M Rush},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=9Vrb9D0WI4}
}
@article{su2021roformer,
  title = {{RoFormer}: Enhanced transformer with rotary position embedding},
  author = {Su, Jianlin and Lu, Yu and Pan, Shengfeng and Murtadha, Ahmed and Wen, Bo and Liu, Yunfeng},
  year = 2021,
  month = apr,
  journal = {arXiv preprint},
  url = {https://arxiv.org/abs/2104.09864},
  eprint = {2104.09864},
  archiveprefix = {arXiv},
  primaryclass = {cs.CL},
}
@article{chen2021evaluating,
  title = {Evaluating Large Language Models Trained on Code},
  author = {Mark Chen and Jerry Tworek and Heewoo Jun and Qiming Yuan and Henrique Ponde de Oliveira Pinto and Jared Kaplan and Harri Edwards and Yuri Burda and Nicholas Joseph and Greg Brockman and Alex Ray and Raul Puri and Gretchen Krueger and Michael Petrov and Heidy Khlaaf and Girish Sastry and Pamela Mishkin and Brooke Chan and Scott Gray and Nick Ryder and Mikhail Pavlov and Alethea Power and Lukasz Kaiser and Mohammad Bavarian and Clemens Winter and Philippe Tillet and Felipe Petroski Such and Dave Cummings and Matthias Plappert and Fotios Chantzis and Elizabeth Barnes and Ariel Herbert-Voss and William Hebgen Guss and Alex Nichol and Alex Paino and Nikolas Tezak and Jie Tang and Igor Babuschkin and Suchir Balaji and Shantanu Jain and William Saunders and Christopher Hesse and Andrew N. Carr and Jan Leike and Josh Achiam and Vedant Misra and Evan Morikawa and Alec Radford and Matthew Knight and Miles Brundage and Mira Murati and Katie Mayer and Peter Welinder and Bob McGrew and Dario Amodei and Sam McCandlish and Ilya Sutskever and Wojciech Zaremba},
  year = 2021,
  month = jul,
  journal = {arXiv preprint},
  url = {https://arxiv.org/abs/2107.03374},
  eprint = {2107.03374},
  archiveprefix = {arXiv},
  primaryclass = {cs.LG},
}
@article{austin:mbpp,
  title = {Program Synthesis with Large Language Models},
  author = {Jacob Austin and Augustus Odena and Maxwell Nye and Maarten Bosma and Henryk Michalewski and David Dohan and Ellen Jiang and Carrie Cai and Michael Terry and Quoc V. Le and Charles Sutton},
  year = 2021,
  month = aug,
  journal = {arXiv preprint},
  url = {https://arxiv.org/abs/2108.07732},
  eprint = {2108.07732},
  archiveprefix = {arXiv},
  primaryclass = {cs.PL},
}
@article{cobbe2021gsm8k,
  title = {Training Verifiers to Solve Math Word Problems},
  author = {Karl Cobbe and Vineet Kosaraju and Mohammad Bavarian and Mark Chen and Heewoo Jun and Lukasz Kaiser and Matthias Plappert and Jerry Tworek and Jacob Hilton and Reiichiro Nakano and Christopher Hesse and John Schulman},
  year = 2021,
  month = oct,
  journal = {arXiv preprint},
  url = {https://arxiv.org/abs/2110.14168},
  eprint = {2110.14168},
  archiveprefix = {arXiv},
  primaryclass = {cs.LG},
}
@article{muennighoff2022mteb,
  title = {MTEB: Massive Text Embedding Benchmark},
  author = {Muennighoff, Niklas and Tazi, Nouamane and Magne, Lo{\"\i}c and Reimers, Nils},
  year = 2022,
  journal = {arXiv preprint arXiv:2210.07316},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.2210.07316},
  url = {https://arxiv.org/abs/2210.07316},
}
@misc{muennighoff2022crosslingual,
    title={Crosslingual Generalization through Multitask Finetuning},
    author={Niklas Muennighoff and Thomas Wang and Lintang Sutawika and Adam Roberts and Stella Biderman and Teven Le Scao and M Saiful Bari and Sheng Shen and Zheng-Xin Yong and Hailey Schoelkopf and Xiangru Tang and Dragomir Radev and Alham Fikri Aji and Khalid Almubarak and Samuel Albanie and Zaid Alyafeai and Albert Webson and Edward Raff and Colin Raffel},
    year={2022},
    eprint={2211.01786},
    archivePrefix={arXiv},
    primaryClass={cs.CL},
  journal = {arXiv preprint},
url={https://arxiv.org/abs/2211.01786}
}
@article{scao2022language,
  title = {What language model to train if you have one million gpu hours?},
  author = {Scao, Teven Le and Wang, Thomas and Hesslow, Daniel and Saulnier, Lucile and Bekman, Stas and Bari, M Saiful and Biderman, Stella and Elsahar, Hady and Muennighoff, Niklas and Phang, Jason and others},
  year = 2022,
  journal = {arXiv preprint arXiv:2210.15424},
}
@article{scao-bloom,
  title = {{BLOOM:} {A} 176B-Parameter Open-Access Multilingual Language Model},
  author = {Teven Le Scao and Angela Fan and Christopher Akiki and Ellie Pavlick and Suzana Ilic and Daniel Hesslow and Roman Castagn{\'{e}} and Alexandra Sasha Luccioni and Fran{\c{c}}ois Yvon and Matthias Gall{\'{e}} and Jonathan Tow and Alexander M. Rush and Stella Biderman and Albert Webson and Pawan Sasanka Ammanamanchi and Thomas Wang and Beno{\^{\i}}t Sagot and Niklas Muennighoff and Albert Villanova del Moral and Olatunji Ruwase and Rachel Bawden and Stas Bekman and Angelina McMillan{-}Major and Iz Beltagy and Huu Nguyen and Lucile Saulnier and Samson Tan and Pedro Ortiz Suarez and Victor Sanh and Hugo Lauren{\c{c}}on and Yacine Jernite and Julien Launay and Margaret Mitchell and Colin Raffel and Aaron Gokaslan and Adi Simhi and Aitor Soroa and Alham Fikri Aji and Amit Alfassy and Anna Rogers and Ariel Kreisberg Nitzav and Canwen Xu and Chenghao Mou and Chris Emezue and Christopher Klamm and Colin Leong and Daniel van Strien and David Ifeoluwa Adelani and et al.},
  year = 2022,
  journal = {CoRR},
  volume = {abs/2211.05100},
  doi = {10.48550/ARXIV.2211.05100},
  url = {https://doi.org/10.48550/arXiv.2211.05100},
  eprint = {2211.05100},
  eprinttype = {arXiv},
  timestamp = {Mon, 28 Aug 2023 21:26:22 +0200},
  biburl = {https://dblp.org/rec/journals/corr/abs-2211-05100.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
}
@article{yong2022bloom+,
  title = {Bloom+ 1: Adding language support to bloom for zero-shot prompting},
  author = {Yong, Zheng-Xin and Schoelkopf, Hailey and Muennighoff, Niklas and Aji, Alham Fikri and Adelani, David Ifeoluwa and Almubarak, Khalid and Bari, M Saiful and Sutawika, Lintang and Kasai, Jungo and Baruwa, Ahmed and others},
  year = 2022,
  journal = {arXiv preprint arXiv:2212.09535},
}
@article{doi:10.1126/science.abq1158,
  title = {Competition-level code generation with AlphaCode},
  author = {Yujia Li  and David Choi  and Junyoung Chung  and Nate Kushman  and Julian Schrittwieser  and R{\'e}mi Leblond  and Tom Eccles  and James Keeling  and Felix Gimeno  and Agustin Dal Lago  and Thomas Hubert  and Peter Choy  and Cyprien de Masson d’Autume  and Igor Babuschkin  and Xinyun Chen  and Po-Sen Huang  and Johannes Welbl  and Sven Gowal  and Alexey Cherepanov  and James Molloy  and Daniel J. Mankowitz  and Esme Sutherland Robson  and Pushmeet Kohli  and Nando de Freitas  and Koray Kavukcuoglu  and Oriol Vinyals},
  year = 2022,
  journal = {Science},
  volume = 378,
  number = 6624,
  pages = {1092--1097},
  doi = {10.1126/science.abq1158},
  url = {https://www.science.org/doi/abs/10.1126/science.abq1158},
  eprint = {https://www.science.org/doi/pdf/10.1126/science.abq1158},
  abstract = {Programming is a powerful and ubiquitous problem-solving tool. Systems that can assist programmers or even generate programs themselves could make programming more productive and accessible. Recent transformer-based neural network models show impressive code generation abilities yet still perform poorly on more complex tasks requiring problem-solving skills, such as competitive programming problems. Here, we introduce AlphaCode, a system for code generation that achieved an average ranking in the top 54.3\% in simulated evaluations on recent programming competitions on the Codeforces platform. AlphaCode solves problems by generating millions of diverse programs using specially trained transformer-based networks and then filtering and clustering those programs to a maximum of just 10 submissions. This result marks the first time an artificial intelligence system has performed competitively in programming competitions. Computer programming competitions are popular tests among programmers that require critical thinking informed by experience and creating solutions to unforeseen problems, both of which are key aspects of human intelligence but challenging to mimic by machine learning models. Using self-supervised learning and an encoder-decoder transformer architecture, Li et al. developed AlphaCode, a deep-learning model that can achieve approximately human-level performance on the Codeforces platform, which regularly hosts these competitions and attracts numerous participants worldwide (see the Perspective by Kolter). The development of such coding platforms could have a huge impact on programmers’ productivity. It may even change the culture of programming by shifting human work to formulating problems, with machine learning being the main one responsible for generating and executing codes. —YS Modern machine learning systems can achieve average human-level performance in popular competitive programming contests.},
}
@article{bavarian2022fim,
  title = {Efficient Training of Language Models to Fill in the Middle},
  author = {Mohammad Bavarian and Heewoo Jun and Nikolas Tezak and John Schulman and Christine McLeavey and Jerry Tworek and Mark Chen},
  year = 2022,
  month = jul,
  journal = {arXiv preprint},
  url = {https://arxiv.org/abs/2207.14255},
  eprint = {2207.14255},
  archiveprefix = {arXiv},
  primaryclass = {cs.CL},
}
@article{palm,
  title = {PaLM: Scaling Language Modeling with Pathways},
  author = {Aakanksha Chowdhery and Sharan Narang and Jacob Devlin and Maarten Bosma and Gaurav Mishra and Adam Roberts and Paul Barham and Hyung Won Chung and Charles Sutton and Sebastian Gehrmann and Parker Schuh and Kensen Shi and Sasha Tsvyashchenko and Joshua Maynez and Abhishek Rao and Parker Barnes and Yi Tay and Noam Shazeer and Vinodkumar Prabhakaran and Emily Reif and Nan Du and Ben Hutchinson and Reiner Pope and James Bradbury and Jacob Austin and Michael Isard and Guy Gur-Ari and Pengcheng Yin and Toju Duke and Anselm Levskaya and Sanjay Ghemawat and Sunipa Dev and Henryk Michalewski and Xavier Garcia and Vedant Misra and Kevin Robinson and Liam Fedus and Denny Zhou and Daphne Ippolito and David Luan and Hyeontaek Lim and Barret Zoph and Alexander Spiridonov and Ryan Sepassi and David Dohan and Shivani Agrawal and Mark Omernick and Andrew M. Dai and Thanumalayan Sankaranarayana Pillai and Marie Pellat and Aitor Lewkowycz and Erica Moreira and Rewon Child and Oleksandr Polozov and Katherine Lee and Zongwei Zhou and Xuezhi Wang and Brennan Saeta and Mark Diaz and Orhan Firat and Michele Catasta and Jason Wei and Kathy Meier-Hellstern and Douglas Eck and Jeff Dean and Slav Petrov and Noah Fiedel},
  year = 2023,
  journal = {Journal of Machine Learning Research},
  volume = 24,
  number = 240,
  pages = {1--113},
  url = {http://jmlr.org/papers/v24/22-1144.html},
}
@article{jiang2023mistral,
  title = {Mistral {7B}},
  author = {Albert Q. Jiang and Alexandre Sablayrolles and Arthur Mensch and Chris Bamford and Devendra Singh Chaplot and Diego de las Casas and Florian Bressand and Gianna Lengyel and Guillaume Lample and Lucile Saulnier and Lélio Renard Lavaud and Marie-Anne Lachaux and Pierre Stock and Teven Le Scao and Thibaut Lavril and Thomas Wang and Timothée Lacroix and William El Sayed},
  year = 2023,
  journal = {arXiv preprint},
  url = {https://arxiv.org/abs/2310.06825},
  eprint = {2310.06825},
  archiveprefix = {arXiv},
  primaryclass = {cs.CL},
}
@article{cassano:multipl-e,
  title = {{MultiPL-E:} A Scalable and Polyglot Approach to Benchmarking Neural Code Generation},
  author = {Cassano, Federico and Gouwar, John and Nguyen, Daniel and Nguyen, Sydney and Phipps-Costin, Luna and Pinckney, Donald and Yee, Ming-Ho and Zi, Yangtian and Anderson, Carolyn Jane and Feldman, Molly Q. and Guha, Arjun and Greenberg, Michael and Jangda, Abhinav},
  year = 2023,
  journal = {IEEE Transactions on Software Engineering},
  volume = 49,
  number = 7,
  pages = {3675--3691},
  doi = {10.1109/TSE.2023.3267446},
  url = {https://www.computer.org/csdl/journal/ts/2023/07/10103177/1MpWUtj7Rwk},
  keywords = {Codes;Benchmark testing;Python;Programming;Natural languages;Task analysis;Syntactics;B.2.3 reliability, testing, and fault-tolerance;I.5.1.D neural nets},
}
@article{kocetkov2023stack,
  title = {The Stack: 3 {TB} of permissively licensed source code},
  author = {Denis Kocetkov and Raymond Li and Loubna Ben allal and Jia LI and Chenghao Mou and Yacine Jernite and Margaret Mitchell and Carlos Mu{\~n}oz Ferrandis and Sean Hughes and Thomas Wolf and Dzmitry Bahdanau and Leandro Von Werra and Harm de Vries},
  year = 2023,
  journal = {Transactions on Machine Learning Research},
  issn = {2835-8856},
  url = {https://openreview.net/forum?id=pxpbTdUEpD},
  note = {},
}
@article{huang2024bias,
  title = {Bias Testing and Mitigation in {LLM}-based Code Generation},
  author = {Dong Huang and Qingwen Bu and Jie Zhang and Xiaofei Xie and Junjie Chen and Heming Cui},
  year = 2023,
  journal = {arXiv preprint},
  url = {https://arxiv.org/abs/2309.14345},
  eprint = {2309.14345},
  archiveprefix = {arXiv},
  primaryclass = {cs.SE},
}
@article{tang2023PII,
  title = {Helping Code Reviewer Prioritize: Pinpointing Personal Data and Its Processing},
  author = {Feiyang Tang and Bjarte M. Østvold and Magiel Bruntink},
  year = 2023,
  journal = {Frontiers in Artificial Intelligence and Applications},
  series = {New Trends in Intelligent Software Methodologies, Tools and Techniques},
  volume = 371,
  pages = {109--124},
  doi = {10.3233/FAIA230228},
}
@article{gupta2023malware,
  title = {From {ChatGPT} to {ThreatGPT:} Impact of Generative {AI} in Cybersecurity and Privacy},
  author = {Gupta, Maanak and Akiri, Charankumar and Aryal, Kshitiz and Parker, Eli and Praharaj, Lopamudra},
  year = 2023,
  journal = {IEEE Access},
  publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
  volume = 11,
  pages = {80218–80245},
  doi = {10.1109/access.2023.3300381},
  issn = {2169-3536},
  url = {http://dx.doi.org/10.1109/ACCESS.2023.3300381},
}
@article{touvron2023llama,
  title = {Llama 2: Open Foundation and Fine-Tuned Chat Models},
  author = {Hugo Touvron and Louis Martin and Kevin Stone and Peter Albert and Amjad Almahairi and Yasmine Babaei and Nikolay Bashlykov and Soumya Batra and Prajjwal Bhargava and Shruti Bhosale and Dan Bikel and Lukas Blecher and Cristian Canton Ferrer and Moya Chen and Guillem Cucurull and David Esiobu and Jude Fernandes and Jeremy Fu and Wenyin Fu and Brian Fuller and Cynthia Gao and Vedanuj Goswami and Naman Goyal and Anthony Hartshorn and Saghar Hosseini and Rui Hou and Hakan Inan and Marcin Kardas and Viktor Kerkez and Madian Khabsa and Isabel Kloumann and Artem Korenev and Punit Singh Koura and Marie-Anne Lachaux and Thibaut Lavril and Jenya Lee and Diana Liskovich and Yinghai Lu and Yuning Mao and Xavier Martinet and Todor Mihaylov and Pushkar Mishra and Igor Molybog and Yixin Nie and Andrew Poulton and Jeremy Reizenstein and Rashi Rungta and Kalyan Saladi and Alan Schelten and Ruan Silva and Eric Michael Smith and Ranjan Subramanian and Xiaoqing Ellen Tan and Binh Tang and Ross Taylor and Adina Williams and Jian Xiang Kuan and Puxin Xu and Zheng Yan and Iliyan Zarov and Yuchen Zhang and Angela Fan and Melanie Kambadur and Sharan Narang and Aurelien Rodriguez and Robert Stojnic and Sergey Edunov and Thomas Scialom},
  year = 2023,
  journal = {arXiv preprint},
  url = {https://arxiv.org/abs/2307.09288},
  eprint = {2307.09288},
  archiveprefix = {arXiv},
  primaryclass = {cs.CL},
}
@article{solaiman2023gradient,
  title = {The Gradient of Generative {AI} Release: Methods and Considerations},
  author = {Irene Solaiman},
  year = 2023,
  journal = {arXiv preprint},
  url = {https://arxiv.org/abs/2302.04844},
  eprint = {2302.04844},
  archiveprefix = {arXiv},
  primaryclass = {cs.CY},
}
@article{luo2023wizardcoder,
  title = {WizardCoder: Empowering Code Large Language Models with Evol-Instruct},
  author = {Luo, Ziyang and Xu, Can and Zhao, Pu and Sun, Qingfeng and Geng, Xiubo and Hu, Wenxiang and Tao, Chongyang and Ma, Jing and Lin, Qingwei and Jiang, Daxin},
  year = 2023,
  journal = {arXiv preprint arXiv:2306.08568},
}
@article{luukkonen2023fingpt,
  title = {Fingpt: Large generative models for a small language},
  author = {Luukkonen, Risto and Komulainen, Ville and Luoma, Jouni and Eskelinen, Anni and Kanerva, Jenna and Kupari, Hanna-Mari and Ginter, Filip and Laippala, Veronika and Muennighoff, Niklas and Piktus, Aleksandra and others},
  year = 2023,
  journal = {arXiv preprint arXiv:2311.05640},
  url = {https://arxiv.org/abs/2311.05640},
}
@article{mozes2023use,
  title = {Use of {LLMs} for Illicit Purposes: Threats, Prevention Measures, and Vulnerabilities},
  author = {Maximilian Mozes and Xuanli He and Bennett Kleinberg and Lewis D. Griffin},
  year = 2023,
  journal = {arXiv preprint},
  url = {https://arxiv.org/abs/2308.12833},
  eprint = {2308.12833},
  archiveprefix = {arXiv},
  primaryclass = {cs.CL},
}
@article{mokander2023auditing,
  title = {Auditing Large Language Models: A Three-Layered Approach},
  author = {Mökander, J. and Schuett, J. and Kirk, H.R. and others},
  year = 2023,
  journal = {AI Ethics},
  url = {https://doi.org/10.1007/s43681-023-00289-2},
}
@inproceedings{muennighoff2023octopack,
title={{OctoPack:} Instruction Tuning Code Large Language Models},
author={Niklas Muennighoff and Qian Liu and Armel Randy Zebaze and Qinkai Zheng and Binyuan Hui and Terry Yue Zhuo and Swayam Singh and Xiangru Tang and Leandro Von Werra and Shayne Longpre},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=mw1PWNSWZP}
}
@article{longpre2023data,
  title = {The Data Provenance Initiative: A Large Scale Audit of Dataset Licensing \& Attribution in {AI}},
  author = {Shayne Longpre and Robert Mahari and Anthony Chen and Naana Obeng-Marnu and Damien Sileo and William Brannon and Niklas Muennighoff and Nathan Khazam and Jad Kabbara and Kartik Perisetla and Xinyi Wu and Enrico Shippole and Kurt Bollacker and Tongshuang Wu and Luis Villa and Sandy Pentland and Sara Hooker},
  year = 2023,
  journal = {arXiv preprint},
  url = {https://arxiv.org/abs/2310.16787},
  eprint = {2310.16787},
  archiveprefix = {arXiv},
  primaryclass = {cs.CL},
}
@article{peng2023impact,
  title = {The Impact of {AI} on Developer Productivity: Evidence from {GitHub Copilot}},
  author = {Sida Peng and Eirini Kalliamvakou and Peter Cihon and Mert Demirer},
  year = 2023,
  journal = {arXiv preprint},
  url = {https://arxiv.org/abs/2302.06590},
  eprint = {2302.06590},
  archiveprefix = {arXiv},
  primaryclass = {cs.SE},
}
@article{team2023gemini,
  title = {Gemini: a family of highly capable multimodal models},
  author = {{Gemini Team}  and others},
  year = 2023,
  journal = {arXiv preprint},
url={https://arxiv.org/abs/2312.11805}
}
@article{zhuo2023red,
  title = {Red teaming {ChatGPT} via Jailbreaking: Bias, Robustness, Reliability and Toxicity},
  author = {Terry Yue Zhuo and Yujin Huang and Chunyang Chen and Zhenchang Xing},
  year = 2023,
  journal = {arXiv preprint},
  url = {https://arxiv.org/abs/2301.12867},
  eprint = {2301.12867},
  archiveprefix = {arXiv},
  primaryclass = {cs.CL},
}
@article{wei2023magic,
  title = {Magicoder: Source Code Is All You Need},
  author = {Wei, Yuxiang and Wang, Zhe and Liu, Jiawei and Ding, Yifeng and Zhang, Lingming},
  year = 2023,
  journal = {arXiv preprint arXiv:2312.02120},
}
@article{yang2023gotcha,
  title = {Gotcha! This Model Uses My Code! Evaluating Membership Leakage Risks in Code Models},
  author = {Zhou Yang and Zhipeng Zhao and Chenyu Wang and Jieke Shi and Dongsum Kim and Donggyun Han and David Lo},
  year = 2023,
  journal = {arXiv preprint},
  url = {https://arxiv.org/abs/2310.01166},
  eprint = {2310.01166},
  archiveprefix = {arXiv},
  primaryclass = {cs.SE},
}
@article{achiam2023gpt,
  title = {{GPT-4} Technical Report},
  author = {{OpenAI} and others},
  year = 2023,
  month = mar,
  journal = {arXiv preprint},
  url = {https://arxiv.org/abs/2303.08774},
  eprint = {2303.08774},
  archiveprefix = {arXiv},
  primaryclass = {cs.CL},
}
@article{li2023starcoder,
  title = {{StarCoder:} may the source be with you!},
  author = {Raymond Li and Ben Allal, Loubna and Yangtian Zi and Niklas Muennighoff and Denis Kocetkov and Chenghao Mou and Marc Marone and Christopher Akiki and Jia Li and Jenny Chim and Qian Liu and Evgenii Zheltonozhskii and Terry Yue Zhuo and Thomas Wang and Olivier Dehaene and Mishig Davaadorj and Joel Lamy-Poirier and João Monteiro and Oleh Shliazhko and Nicolas Gontier and Nicholas Meade and Armel Zebaze and Ming-Ho Yee and Logesh Kumar Umapathi and Jian Zhu and Benjamin Lipkin and Muhtasham Oblokulov and Zhiruo Wang and Rudra Murthy and Jason Stillerman and Siva Sankalp Patel and Dmitry Abulkhanov and Marco Zocca and Manan Dey and Zhihan Zhang and Nour Fahmy and Urvashi Bhattacharyya and Wenhao Yu and Swayam Singh and Sasha Luccioni and Paulo Villegas and Maxim Kunakov and Fedor Zhdanov and Manuel Romero and Tony Lee and Nadav Timor and Jennifer Ding and Claire Schlesinger and Hailey Schoelkopf and Jan Ebert and Tri Dao and Mayank Mishra and Alex Gu and Jennifer Robinson and Carolyn Jane Anderson and Brendan Dolan-Gavitt and Danish Contractor and Siva Reddy and Daniel Fried and Dzmitry Bahdanau and Yacine Jernite and Carlos Muñoz Ferrandis and Sean Hughes and Thomas Wolf and Arjun Guha and von Werra, Leandro  and de Vries, Harm},
  year = 2023,
  month = may,
  journal = {arXiv preprint},
  url = {https://arxiv.org/abs/2305.06161},
  eprint = {2305.06161},
  archiveprefix = {arXiv},
  primaryclass = {cs.CL},
}
@article{zhuo2023data,
  title = {Source Code Data Augmentation for Deep Learning: A Survey},
  author = {Zhuo, Terry Yue and Yang, Zhou and Sun, Zhensu and Wang, Yufei and Li, Li and Du, Xiaoning and Xing, Zhenchang and Lo, David},
  year = 2023,
  month = may,
  journal = {arXiv preprint},
  url = {https://arxiv.org/abs/2305.19915},
  eprint = {2305.19915},
  archiveprefix = {arXiv},
  primaryclass = {cs.CL},
}
@article{liu2023repobench,
  title = {{RepoBench}: Benchmarking Repository-Level Code Auto-Completion Systems},
  author = {Tianyang Liu and Canwen Xu and Julian McAuley},
  year = 2023,
  month = jun,
  journal = {arXiv preprint},
  url = {https://arxiv.org/abs/2306.03091},
  eprint = {2306.03091},
  archiveprefix = {arXiv},
  primaryclass = {cs.CL},
}
@article{roziere2023code,
  title = {Code Llama: Open Foundation Models for Code},
  author = {Baptiste Rozière and Jonas Gehring and Fabian Gloeckle and Sten Sootla and Itai Gat and Xiaoqing Ellen Tan and Yossi Adi and Jingyu Liu and Tal Remez and Jérémy Rapin and Artyom Kozhevnikov and Ivan Evtimov and Joanna Bitton and Manish Bhatt and Cristian Canton Ferrer and Aaron Grattafiori and Wenhan Xiong and Alexandre Défossez and Jade Copet and Faisal Azhar and Hugo Touvron and Louis Martin and Nicolas Usunier and Thomas Scialom and Gabriel Synnaeve},
  year = 2023,
  month = aug,
  journal = {arXiv preprint},
  url = {https://arxiv.org/abs/2308.12950},
  eprint = {2308.12950},
  archiveprefix = {arXiv},
  primaryclass = {cs.CL},
}
@article{allal2023santacoder,
  title = {{SantaCoder:} don't reach for the stars!},
  author = {Ben Allal, Loubna  and Raymond Li and Denis Kocetkov and Chenghao Mou and Christopher Akiki and Carlos Munoz Ferrandis and Niklas Muennighoff and Mayank Mishra and Alex Gu and Manan Dey and Logesh Kumar Umapathi and Carolyn Jane Anderson and Yangtian Zi and Joel Lamy Poirier and Hailey Schoelkopf and Sergey Troshin and Dmitry Abulkhanov and Manuel Romero and Michael Lappert and Francesco De Toni and Bernardo García del Río and Qian Liu and Shamik Bose and Urvashi Bhattacharyya and Terry Yue Zhuo and Ian Yu and Paulo Villegas and Marco Zocca and Sourab Mangrulkar and David Lansky and Huu Nguyen and Danish Contractor and Luis Villa and Jia Li and Dzmitry Bahdanau and Yacine Jernite and Sean Hughes and Daniel Fried and Arjun Guha and de Vries, Harm  and von Werra, Leandro},
  year = 2023,
  month = aug,
  journal = {arXiv preprint},
  url = {https://arxiv.org/abs/2301.03988},
  eprint = {2301.03988},
  archiveprefix = {arXiv},
  primaryclass = {cs.SE},
}
@article{cassano2023knowledge,
  title = {Knowledge Transfer from High-Resource to Low-Resource Programming Languages for Code {LLMs}},
  author = {Federico Cassano and John Gouwar and Francesca Lucchetti and Claire Schlesinger and Carolyn Jane Anderson and Michael Greenberg and Abhinav Jangda and Arjun Guha},
  year = 2023,
  month = aug,
  journal = {arXiv preprint},
  url = {https://arxiv.org/abs/2308.09895},
  eprint = {2308.09895},
  archiveprefix = {arXiv},
  primaryclass = {cs.PL},
}
@inproceedings{chai2023ernie-code,
  url = {https://aclanthology.org/2023.findings-acl.676},
  title = {{ERNIE}-Code: Beyond {E}nglish-Centric Cross-lingual Pretraining for Programming Languages},
  author = {Chai, Yekun and Wang, Shuohuan and Pang, Chao and Sun, Yu and Tian, Hao and Wu, Hua},
  editor = {Rogers, Anna and Boyd-Graber, Jordan and Okazaki, Naoaki},
  booktitle = {Findings of the Association for Computational Linguistics: ACL 2023},
  month = jul,
  year = {2023},
  address = {Toronto, Canada},
  publisher = {Association for Computational Linguistics},
  doi = {10.18653/v1/2023.findings-acl.676},
  pages = {10628--10650}
}
@article{chen2023jobs,
  title = {Large Language Models at Work in {China}'s Labor Market},
  author = {Qin Chen and Jinfeng Ge and Huaqing Xie and Xingcheng Xu and Yanqing Yang},
  year = 2023,
  month = aug,
  journal = {arXiv preprint},
  url = {https://arxiv.org/abs/2308.08776},
  eprint = {2308.08776},
  archiveprefix = {arXiv},
  primaryclass = {econ.GN},
}
@article{hou2023large,
  title = {Large Language Models for Software Engineering: A Systematic Literature Review},
  author = {Xinyi Hou and Yanjie Zhao and Yue Liu and Zhou Yang and Kailong Wang and Li Li and Xiapu Luo and David Lo and John Grundy and Haoyu Wang},
  year = 2023,
  month = aug,
  journal = {arXiv preprint},
  url = {https://arxiv.org/abs/2308.10620},
  eprint = {2308.10620},
  archiveprefix = {arXiv},
  primaryclass = {cs.SE},
}
@article{yuan2023scaling,
  title = {Scaling Relationship on Learning Mathematical Reasoning with Large Language Models},
  author = {Zheng Yuan and Hongyi Yuan and Chengpeng Li and Guanting Dong and Keming Lu and Chuanqi Tan and Chang Zhou and Jingren Zhou},
  year = 2023,
  month = aug,
  journal = {arXiv preprint},
  url = {https://arxiv.org/abs/2308.01825},
  eprint = {2308.01825},
  archiveprefix = {arXiv},
  primaryclass = {cs.CL},
}
@article{grossman2023compile,
  title = {{ComPile:} A Large {IR} Dataset from Production Sources},
  author = {Grossman, Aiden and Paehler, Ludger and Parasyris, Konstantinos and Ben-Nun, Tal and Hegna, Jacob and Moses, William and Diaz, Jose M. Monsalve and Trofin, Mircea and Doerfert, Johannes},
  year = 2023,
  month = sep,
  journal = {arXiv preprint},
  url = {https://arxiv.org/abs/2309.15432},
  eprint = {2305.06161},
  archiveprefix = {arXiv},
  primaryclass = PL,
}
@article{fan2023large,
  title = {Large Language Models for Software Engineering: Survey and Open Problems},
  author = {Angela Fan and Beliz Gokkaya and Mark Harman and Mitya Lyubarskiy and Shubho Sengupta and Shin Yoo and Jie M. Zhang},
  year = 2023,
  month = oct,
  journal = {arXiv preprint},
  url = {https://arxiv.org/abs/2310.03533},
  eprint = {2310.03533},
  archiveprefix = {arXiv},
  primaryclass = {cs.SE},
}
@article{paster2023openwebmath,
  title = {{OpenWebMath:} An Open Dataset of High-Quality Mathematical Web Text},
  author = {Keiran Paster and Marco Dos Santos and Zhangir Azerbayev and Jimmy Ba},
  year = 2023,
  month = oct,
  journal = {arXiv preprint},
  url = {https://arxiv.org/abs/2310.06786},
  eprint = {2310.06786},
  archiveprefix = {arXiv},
  primaryclass = {cs.AI},
}
@article{bigcodecollaboration2023bigcode,
  title = {The {BigCode} Project Governance Card},
  author = {{BigCode collaboration} and Sean Hughes and Harm de Vries and Jennifer Robinson and Carlos Muñoz Ferrandis and Loubna Ben Allal and Leandro von Werra and Jennifer Ding and Sebastien Paquet and Yacine Jernite},
  year = 2023,
  month = dec,
  journal = {arXiv preprint},
  url = {https://arxiv.org/abs/2312.03872},
  eprint = {2312.03872},
  archiveprefix = {arXiv},
  primaryclass = {cs.CY},
}
@article{bhatt2023purple,
  title = {Purple Llama {CyberSecEval}: A Secure Coding Benchmark for Language Models},
  author = {Manish Bhatt and Sahana Chennabasappa and Cyrus Nikolaidis and Shengye Wan and Ivan Evtimov and Dominik Gabi and Daniel Song and Faizan Ahmad and Cornelius Aschermann and Lorenzo Fontana and Sasha Frolov and Ravi Prakash Giri and Dhaval Kapil and Yiannis Kozyrakis and David LeBlanc and James Milazzo and Aleksandar Straumann and Gabriel Synnaeve and Varun Vontimitta and Spencer Whitman and Joshua Saxe},
  year = 2023,
  month = dec,
  journal = {arXiv preprint},
  url = {https://arxiv.org/abs/2312.04724},
  eprint = {2312.04724},
  archiveprefix = {arXiv},
  primaryclass = {cs.CR},
}
@article{ustun2024aya,
  title = {Aya Model: An Instruction Finetuned Open-Access Multilingual Language Model},
  author = {{\"U}st{\"u}n, Ahmet  and Viraat Aryabumi and Zheng-Xin Yong and Wei-Yin Ko and Daniel D'souza and Gbemileke Onilude and Neel Bhandari and Shivalika Singh and Hui-Lee Ooi and Amr Kayid and Freddie Vargus and Phil Blunsom and Shayne Longpre and Niklas Muennighoff and Marzieh Fadaee and Julia Kreutzer and Sara Hooker},
  year = 2024,
  journal = {arXiv preprint},
  url = {https://arxiv.org/abs/2402.07827},
  eprint = {2402.07827},
  archiveprefix = {arXiv},
  primaryclass = {cs.CL},
}
@article{soldaini2024dolma,
  title = {Dolma: an Open Corpus of Three Trillion Tokens for Language Model Pretraining Research},
  author = {Luca Soldaini and Rodney Kinney and Akshita Bhagia and Dustin Schwenk and David Atkinson and Russell Authur and Ben Bogin and Khyathi Chandu and Jennifer Dumas and Yanai Elazar and Valentin Hofmann and Ananya Harsh Jha and Sachin Kumar and Li Lucy and Xinxi Lyu and Nathan Lambert and Ian Magnusson and Jacob Morrison and Niklas Muennighoff and Aakanksha Naik and Crystal Nam and Matthew E. Peters and Abhilasha Ravichander and Kyle Richardson and Zejiang Shen and Emma Strubell and Nishant Subramani and Oyvind Tafjord and Pete Walsh and Luke Zettlemoyer and Noah A. Smith and Hannaneh Hajishirzi and Iz Beltagy and Dirk Groeneveld and Jesse Dodge and Kyle Lo},
  year = 2024,
  journal = {arXiv preprint},
  url = {https://arxiv.org/abs/2402.00159},
  eprint = {2402.00159},
  archiveprefix = {arXiv},
  primaryclass = {cs.CL},
}
@inproceedings{muennighoff2024scaling,
title={Scaling Data-Constrained Language Models},
author={Niklas Muennighoff and Alexander M Rush and Boaz Barak and Teven Le Scao and Nouamane Tazi and Aleksandra Piktus and Sampo Pyysalo and Thomas Wolf and Colin Raffel},
booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
year={2023},
url={https://openreview.net/forum?id=j5BuTrEj35}
}
@article{muennighoff2024generative,
    title={Generative Representational Instruction Tuning},
    author={Niklas Muennighoff and Hongjin Su and Liang Wang and Nan Yang and Furu Wei and Tao Yu and Amanpreet Singh and Douwe Kiela},
    year={2024},
    eprint={2402.09906},
    archivePrefix={arXiv},
    primaryClass={cs.CL},
  journal = {arXiv preprint},
url={https://arxiv.org/abs/2402.09906}
}
@article{singh2024aya,
    title={Aya Dataset: An Open-Access Collection for Multilingual Instruction Tuning},
    author={Shivalika Singh and Freddie Vargus and Daniel Dsouza and Börje F. Karlsson and Abinaya Mahendiran and Wei-Yin Ko and Herumb Shandilya and Jay Patel and Deividas Mataciunas and Laura OMahony and Mike Zhang and Ramith Hettiarachchi and Joseph Wilson and Marina Machado and Luisa Souza Moura and Dominik Krzemiński and Hakimeh Fadaei and Irem Ergün and Ifeoma Okoh and Aisha Alaagib and Oshan Mudannayake and Zaid Alyafeai and Vu Minh Chien and Sebastian Ruder and Surya Guthikonda and Emad A. Alghamdi and Sebastian Gehrmann and Niklas Muennighoff and Max Bartolo and Julia Kreutzer and Ahmet Üstün and Marzieh Fadaee and Sara Hooker},
    year={2024},
    eprint={2402.06619},
    archivePrefix={arXiv},
    primaryClass={cs.CL},
 journal = {arXiv preprint },
url={https://arxiv.org/abs/2402.06619}
}
@article{wang2023software,
  title = {Software Testing with Large Language Models: Survey, Landscape, and Vision},
  author = {Wang, Junjie and Huang, Yuchao and Chen, Chunyang and Liu, Zhe and Wang, Song and Wang, Qing},
  year = 2024,
  journal = {IEEE Transactions on Software Engineering},
  volume = {},
  number = {},
  pages = {1--27},
  doi = {10.1109/TSE.2024.3368208},
  url = {https://arxiv.org/abs/2307.07221},
  keywords = {Software testing;Task analysis;Computational modeling;Codes;Software systems;Natural language processing;Reviews;Pre-trained Large Language Model;Software Testing;LLM;GPT},
}
@article{ziegler2024measuring,
  title = {Measuring {GitHub Copilot}'s Impact on Productivity},
  author = {Ziegler, Albert and Kalliamvakou, Eirini and Li, X. Alice and Rice, Andrew and Rifkin, Devon and Simister, Shawn and Sittampalam, Ganesh and Aftandilian, Edward},
  year = 2024,
  month = {feb},
  journal = {Commun. ACM},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = 67,
  number = 3,
  pages = {54–63},
  numpages = 10,
  doi = {10.1145/3633453},
  issn = {0001-0782},
  url = {https://doi.org/10.1145/3633453},
  issue_date = {March 2024},
  abstract = {Case study asks Copilot users about its impact on their productivity, and seeks to find their perceptions mirrored in user data.},
}
@article{gu2024cruxeval,
  title = {{CRUXEval:} A Benchmark for Code Reasoning, Understanding and Execution},
  author = {Alex Gu and Baptiste Rozière and Hugh Leather and Armando Solar-Lezama and Gabriel Synnaeve and Sida I. Wang},
  year = 2024,
  month = jan,
  journal = {arXiv preprint},
  url = {https://arxiv.org/abs/2401.03065},
  eprint = {2401.03065},
  archiveprefix = {arXiv},
  primaryclass = {cs.SE},
}
@article{albalak2024survey,
  title = {A Survey on Data Selection for Language Models},
  author = {Alon Albalak and Yanai Elazar and Sang Michael Xie and Shayne Longpre and Nathan Lambert and Xinyi Wang and Niklas Muennighoff and Bairu Hou and Liangming Pan and Haewon Jeong and Colin Raffel and Shiyu Chang and Tatsunori Hashimoto and William Yang Wang},
  year = 2024,
  month = feb,
  journal = {arXiv preprint},
  url = {https://arxiv.org/abs/2402.16827},
  eprint = {2402.16827},
  archiveprefix = {arXiv},
  primaryclass = {cs.CL},
}
@article{groeneveld2024olmo,
  title = {{OLMo:} Accelerating the Science of Language Models},
  author = {Dirk Groeneveld and Iz Beltagy and Pete Walsh and Akshita Bhagia and Rodney Kinney and Oyvind Tafjord and Ananya Harsh Jha and Hamish Ivison and Ian Magnusson and Yizhong Wang and Shane Arora and David Atkinson and Russell Authur and Khyathi Raghavi Chandu and Arman Cohan and Jennifer Dumas and Yanai Elazar and Yuling Gu and Jack Hessel and Tushar Khot and William Merrill and Jacob Morrison and Niklas Muennighoff and Aakanksha Naik and Crystal Nam and Matthew E. Peters and Valentina Pyatkin and Abhilasha Ravichander and Dustin Schwenk and Saurabh Shah and Will Smith and Emma Strubell and Nishant Subramani and Mitchell Wortsman and Pradeep Dasigi and Nathan Lambert and Kyle Richardson and Luke Zettlemoyer and Jesse Dodge and Kyle Lo and Luca Soldaini and Noah A. Smith and Hannaneh Hajishirzi},
  year = 2024,
  month = feb,
  journal = {arXiv preprint},
  url = {https://arxiv.org/abs/2402.00838},
  eprint = {2402.00838},
  archiveprefix = {arXiv},
  primaryclass = {cs.CL},
}
@article{ethayarajh2024kto,
  title = {{KTO:} Model Alignment as Prospect Theoretic Optimization},
  author = {Kawin Ethayarajh and Winnie Xu and Niklas Muennighoff and Dan Jurafsky and Douwe Kiela},
  year = 2024,
  month = feb,
  journal = {arXiv preprint},
  url = {https://arxiv.org/abs/2402.01306},
  eprint = {2402.01306},
  archiveprefix = {arXiv},
  primaryclass = {cs.LG},
}
@article{dong2024guardrails,
  title = {Building Guardrails for Large Language Models},
  author = {Yi Dong and Ronghui Mu and Gaojie Jin and Yi Qi and Jinwei Hu and Xingyu Zhao and Jie Meng and Wenjie Ruan and Xiaowei Huang},
  year = 2024,
  month = feb,
  journal = {arXiv preprint},
  url = {https://arxiv.org/abs/2402.01822},
  eprint = {2402.01822},
  archiveprefix = {arXiv},
  primaryclass = {cs.CL},
}
@article{alyafeai2024cidar,
  title = {{CIDAR:} Culturally Relevant Instruction Dataset For {Arabic}},
  author = {Zaid Alyafeai and Khalid Almubarak and Ahmed Ashraf and Deema Alnuhait and Saied Alshahrani and Gubran A. Q. Abdulrahman and Gamil Ahmed and Qais Gawah and Zead Saleh and Mustafa Ghaleb and Yousef Ali and Maged S. Al-Shaibani},
  year = 2024,
  month = feb,
  journal = {arXiv preprint},
  url = {https://arxiv.org/abs/2402.03177},
  eprint = {2402.03177},
  archiveprefix = {arXiv},
  primaryclass = {cs.CL},
}
@article{zhuo2024astraios,
  title = {Astraios: Parameter-Efficient Instruction Tuning Code Large Language Models},
  author = {Zhuo, Terry Yue and Zebaze, Armel and Suppattarachai, Nitchakarn and von Werra, Leandro and de Vries, Harm and Liu, Qian and Muennighoff, Niklas},
  year = 2024,
  month = aug,
  journal = {arXiv preprint},
  url = {https://arxiv.org/abs/2401.00788},
}
@inbook{mendez2020openscience,
  title = {Open Science in Software Engineering},
  author = {Daniel Mendez and Daniel Graziotin and Stefan Wagner and Heidi Seibold},
  year = 2020,
  booktitle = {Contemporary Empirical Methods in Software Engineering},
  publisher = {Springer International Publishing},
  pages = {477--501},
  doi = {10.1007/978-3-030-32489-6_17},
  url = {http://dx.doi.org/10.1007/978-3-030-32489-6_17},
}
@inproceedings{broder2000identifying,
  title = {Identifying and filtering near-duplicate documents},
  author = {Broder, Andrei Z.},
  year = 2000,
  booktitle = {Annual symposium on combinatorial pattern matching},
  pages = {1--10},
  url = {https://link.springer.com/chapter/10.1007/3-540-45123-4_1},
  organization = {Springer},
}
@inproceedings{lattner2004llvm,
  title = {{LLVM:} A compilation framework for lifelong program analysis \& transformation},
  author = {Lattner, Chris and Adve, Vikram},
  year = 2004,
  booktitle = {International symposium on code generation and optimization, 2004. CGO 2004.},
  pages = {75--86},
  url = {https://ieeexplore.ieee.org/document/1281665},
  organization = {IEEE},
}
@inproceedings{DBLP:journals/corr/KingmaB14,
  title = {Adam: {A} Method for Stochastic Optimization},
  author = {Diederik P. Kingma and Jimmy Ba},
  year = 2015,
  booktitle = {3rd International Conference on Learning Representations, {ICLR} 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings},
  url = {http://arxiv.org/abs/1412.6980},
  editor = {Yoshua Bengio and Yann LeCun},
  timestamp = {Thu, 25 Jul 2019 14:25:37 +0200},
  biburl = {https://dblp.org/rec/journals/corr/KingmaB14.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
}
@inproceedings{nanz2015comparative,
  title = {A comparative study of programming languages in {Rosetta} code},
  author = {Nanz, Sebastian and Furia, Carlo A.},
  year = 2015,
  booktitle = {2015 IEEE/ACM 37th IEEE International Conference on Software Engineering},
  volume = 1,
  pages = {778--788},
  url = {https://ieeexplore.ieee.org/document/7194625},
  organization = {IEEE},
}
@inproceedings{christiano2017deep,
  title = {Deep Reinforcement Learning from Human Preferences},
  author = {Christiano, Paul F. and Leike, Jan and Brown, Tom and Martic, Miljan and Legg, Shane and Amodei, Dario},
  year = 2017,
  booktitle = {Advances in Neural Information Processing Systems},
  publisher = {Curran Associates, Inc.},
  volume = 30,
  pages = {},
  url = {https://proceedings.neurips.cc/paper_files/paper/2017/hash/d5e2c0adad503c91f91df240d0cd4e49-Abstract.html},
  editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
}
@inproceedings{dicosmo:hal-01590958,
  title = {Software Heritage: Why and How to Preserve Software Source Code},
  author = {Roberto Di Cosmo and Stefano Zacchiroli},
  year = 2017,
  booktitle = {iPRES 2017: 14th International Conference on Digital Preservation},
  address = {Kyoto, Japan},
  url = {https://www.softwareheritage.org/wp-content/uploads/2020/01/ipres-2017-swh.pdf},
  note = {https://hal.archives-ouvertes.fr/hal-01590958},
}
@inproceedings{winobias,
  title = {Gender Bias in Coreference Resolution: Evaluation and Debiasing Methods},
  author = {Zhao, Jieyu  and Wang, Tianlu  and Yatskar, Mark  and Ordonez, Vicente  and Chang, Kai-Wei},
  year = 2018,
  month = jun,
  booktitle = {Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)},
  publisher = {Association for Computational Linguistics},
  address = {New Orleans, Louisiana},
  pages = {15--20},
  doi = {10.18653/v1/N18-2003},
  url = {https://aclanthology.org/N18-2003},
  editor = {Walker, Marilyn  and Ji, Heng  and Stent, Amanda},
  abstract = {In this paper, we introduce a new benchmark for co-reference resolution focused on gender bias, WinoBias. Our corpus contains Winograd-schema style sentences with entities corresponding to people referred by their occupation (e.g. the nurse, the doctor, the carpenter). We demonstrate that a rule-based, a feature-rich, and a neural coreference system all link gendered pronouns to pro-stereotypical entities with higher accuracy than anti-stereotypical entities, by an average difference of 21.1 in F1 score. Finally, we demonstrate a data-augmentation approach that, in combination with existing word-embedding debiasing techniques, removes the bias demonstrated by these systems in WinoBias without significantly affecting their performance on existing datasets.},
}
@inproceedings{saxton2019analysing,
  title = {Analysing Mathematical Reasoning Abilities of Neural Models},
  author = {David Saxton and Edward Grefenstette and Felix Hill and Pushmeet Kohli},
  year = 2019,
  booktitle = {International Conference on Learning Representations},
  url = {https://openreview.net/forum?id=H1gR5iR5FX},
}
@inproceedings{OSCAR2019,
  title = {Asynchronous pipelines for processing huge corpora on medium to low resource infrastructures},
  author = {Pedro Javier {Ortiz Su{\'a}rez} and Beno{\^i}t Sagot and Laurent Romary},
  year = 2019,
  month = jul,
  booktitle = {Proceedings of the Workshop on Challenges in the Management of Large Corpora},
  publisher = {Leibniz-Institut f{\"u}r Deutsche Sprache},
  address = {Mannheim},
  pages = {9 -- 16},
  doi = {10.14618/ids-pub-9021},
  url = {http://nbn-resolving.de/urn:nbn:de:bsz:mh39-90215},
  editor = {Piotr Bański and Adrien Barbaresi and Hanno Biber and Evelyn Breiteneder and Simon Clematide and Marc Kupietz and Harald L{\"u}ngen and Caroline Iliadi},
  abstract = {Common Crawl is a considerably large, heterogeneous multilingual corpus comprised of crawled documents from the internet, surpassing 20TB of data and distributed as a set of more than 50 thousand plain text files where each contains many documents written in a wide variety of languages. Even though each document has a metadata block associated to it, this data lacks any information about the language in which each document is written, making it extremely difficult to use Common Crawl for monolingual applications. We propose a general, highly parallel, multithreaded pipeline to clean and classify Common Crawl by language; we specifically design it so that it runs efficiently on medium to low resource infrastructures where I/O speeds are the main constraint. We develop the pipeline so that it can be easily reapplied to any kind of heterogeneous corpus and so that it can be parameterised to a wide range of infrastructures. We also distribute a 6.3TB version of Common Crawl, filtered, classified by language, shuffled at line level in order to avoid copyright issues, and ready to be used for NLP applications.},
  language = {en},
}
@inproceedings{msr-2020-challenge,
  title = {The Software Heritage Graph Dataset: Large-scale Analysis of Public Software Development History},
  author = {Antoine Pietri and Diomidis Spinellis and Stefano Zacchiroli},
  year = 2020,
  booktitle = {MSR 2020: The 17th International Conference on Mining Software Repositories},
  publisher = {IEEE},
  pages = {1--5},
  doi = {10.1145/3379597.3387510},
  url = {https://arxiv.org/abs/2011.07824 https://www.softwareheritage.org/wp-content/uploads/2021/03/msr-2020-challenge.pdf},
  date = {2020-05-01},
  abstract = {Software Heritage is the largest existing public archive of software source code and accompanying development history. It spans more than five billion unique source code files and one billion unique commits, coming from more than 80 million software projects. These software artifacts were retrieved from major collaborative development platforms (e.g., GitHub, GitLab) and package repositories (e.g., PyPI, Debian, NPM), and stored in a uniform representation linking together source code files, directories, commits, and full snapshots of version control systems (VCS) repositories as observed by Software Heritage during periodic crawls. This dataset is unique in terms of accessibility and scale, and allows to explore a number of research questions on the long tail of public software development, instead of solely focusing on "most starred" repositories as it often happens.},
  keywords = {},
  pubstate = {published},
  tppubtype = {inproceedings},
}
@inproceedings{The_mathlib_Community_2020,
  title = {The lean mathematical library},
  author = {The mathlib Community},
  year = 2020,
  month = jan,
  booktitle = {Proceedings of the 9th ACM SIGPLAN International Conference on Certified Programs and Proofs},
  publisher = {ACM},
  series = {POPL ’20},
  doi = {10.1145/3372885.3373824},
  url = {http://dx.doi.org/10.1145/3372885.3373824},
  collection = {POPL ’20},
}
@inproceedings{conneau-etal-2020-unsupervised,
  title = {Unsupervised Cross-lingual Representation Learning at Scale},
  author = {Conneau, Alexis  and Khandelwal, Kartikay  and Goyal, Naman  and Chaudhary, Vishrav  and Wenzek, Guillaume  and Guzm{\'a}n, Francisco  and Grave, Edouard  and Ott, Myle  and Zettlemoyer, Luke  and Stoyanov, Veselin},
  year = 2020,
  month = jul,
  booktitle = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  publisher = {Association for Computational Linguistics},
  address = {Online},
  pages = {8440--8451},
  doi = {10.18653/v1/2020.acl-main.747},
  url = {https://aclanthology.org/2020.acl-main.747},
  editor = {Jurafsky, Dan  and Chai, Joyce  and Schluter, Natalie  and Tetreault, Joel},
  abstract = {This paper shows that pretraining multilingual language models at scale leads to significant performance gains for a wide range of cross-lingual transfer tasks. We train a Transformer-based masked language model on one hundred languages, using more than two terabytes of filtered CommonCrawl data. Our model, dubbed XLM-R, significantly outperforms multilingual BERT (mBERT) on a variety of cross-lingual benchmarks, including +14.6{\%} average accuracy on XNLI, +13{\%} average F1 score on MLQA, and +2.4{\%} F1 score on NER. XLM-R performs particularly well on low-resource languages, improving 15.7{\%} in XNLI accuracy for Swahili and 11.4{\%} for Urdu over previous XLM models. We also present a detailed empirical analysis of the key factors that are required to achieve these gains, including the trade-offs between (1) positive transfer and capacity dilution and (2) the performance of high and low resource languages at scale. Finally, we show, for the first time, the possibility of multilingual modeling without sacrificing per-language performance; XLM-R is very competitive with strong monolingual models on the GLUE and XNLI benchmarks. We will make our code and models publicly available.},
}
@inproceedings{toxicprompts,
  title = {{RealToxicityPrompts:} Evaluating Neural Toxic Degeneration in Language Models},
  author = {Gehman, Samuel  and Gururangan, Suchin  and Sap, Maarten  and Choi, Yejin  and Smith, Noah A.},
  year = 2020,
  month = nov,
  booktitle = {Findings of the Association for Computational Linguistics: EMNLP 2020},
  publisher = {Association for Computational Linguistics},
  address = {Online},
  pages = {3356--3369},
  doi = {10.18653/v1/2020.findings-emnlp.301},
  url = {https://aclanthology.org/2020.findings-emnlp.301},
  editor = {Cohn, Trevor  and He, Yulan  and Liu, Yang},
  abstract = {Pretrained neural language models (LMs) are prone to generating racist, sexist, or otherwise toxic language which hinders their safe deployment. We investigate the extent to which pretrained LMs can be prompted to generate toxic language, and the effectiveness of controllable text generation algorithms at preventing such toxic degeneration. We create and release RealToxicityPrompts, a dataset of 100K naturally occurring, sentence-level prompts derived from a large corpus of English web text, paired with toxicity scores from a widely-used toxicity classifier. Using RealToxicityPrompts, we find that pretrained LMs can degenerate into toxic text even from seemingly innocuous prompts. We empirically assess several controllable generation methods, and find that while data- or compute-intensive methods (e.g., adaptive pretraining on non-toxic data) are more effective at steering away from toxicity than simpler solutions (e.g., banning {``}bad{''} words), no current method is failsafe against neural toxic degeneration. To pinpoint the potential cause of such persistent toxic degeneration, we analyze two web text corpora used to pretrain several LMs (including GPT-2; Radford et. al, 2019), and find a significant amount of offensive, factually unreliable, and otherwise toxic content. Our work provides a test bed for evaluating toxic generations by LMs and stresses the need for better data selection processes for pretraining.},
}
@inproceedings{bold_2021,
  title = {{BOLD:} Dataset and Metrics for Measuring Biases in Open-Ended Language Generation},
  author = {Dhamala, Jwala and Sun, Tony and Kumar, Varun and Krishna, Satyapriya and Pruksachatkun, Yada and Chang, Kai-Wei and Gupta, Rahul},
  year = 2021,
  booktitle = {Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency},
  location = {Virtual Event, Canada},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  series = {FAccT '21},
  pages = {862–872},
  numpages = 11,
  doi = {10.1145/3442188.3445924},
  isbn = 9781450383097,
  url = {https://doi.org/10.1145/3442188.3445924},
  keywords = {natural language generation, Fairness},
}
@inproceedings{hendrycksapps2021,
  title = {Measuring Coding Challenge Competence With APPS},
  author = {Hendrycks, Dan and Basart, Steven and Kadavath, Saurav and Mazeika, Mantas and Arora, Akul and Guo, Ethan and Burns, Collin and Puranik, Samir and He, Horace and Song, Dawn and Steinhardt, Jacob},
  year = 2021,
  booktitle = {Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmarks},
  publisher = {Curran},
  volume = 1,
  pages = {},
  url = {https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/hash/c24cd76e1ce41366a4bbe8a49b02a028-Abstract-round2.html},
  editor = {J. Vanschoren and S. Yeung},
}
@inproceedings{jiang2021lisa,
  title = {{LISA:} Language models of {ISAbelle} proofs},
  author = {Jiang, Albert Qiaochu and Li, Wenda and Han, Jesse Michael and Wu, Yuhuai},
  year = 2021,
  booktitle = {6th Conference on Artificial Intelligence and Theorem Proving},
  pages = {378--392},
  url = {http://aitp-conference.org/2021/abstract/paper_17.pdf},
}
@inproceedings{puri2021codenet,
  title = {{CodeNet:} A Large-Scale {AI} for Code Dataset for Learning a Diversity of Coding Tasks},
  author = {Ruchir Puri and David S Kung and Geert Janssen and Wei Zhang and Giacomo Domeniconi and Vladimir Zolotov and Julian Dolby and Jie Chen and Mihir Choudhury and Lindsey Decker and Veronika Thost and Luca Buratti and Saurabh Pujar and Shyam Ramji and Ulrich Finkler and Susan Malaika and Frederick Reiss},
  year = 2021,
  booktitle = {Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2)},
  url = {https://openreview.net/forum?id=6vZVBkCDrHT},
}
@inproceedings{nozza-etal-2021-honest,
  title = {{HONEST}: Measuring Hurtful Sentence Completion in Language Models},
  author = {Nozza, Debora  and Bianchi, Federico  and Hovy, Dirk},
  year = 2021,
  month = jun,
  booktitle = {Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  publisher = {Association for Computational Linguistics},
  address = {Online},
  pages = {2398--2406},
  doi = {10.18653/v1/2021.naacl-main.191},
  url = {https://aclanthology.org/2021.naacl-main.191},
  editor = {Toutanova, Kristina  and Rumshisky, Anna  and Zettlemoyer, Luke  and Hakkani-Tur, Dilek  and Beltagy, Iz  and Bethard, Steven  and Cotterell, Ryan  and Chakraborty, Tanmoy  and Zhou, Yichao},
  abstract = {Language models have revolutionized the field of NLP. However, language models capture and proliferate hurtful stereotypes, especially in text generation. Our results show that 4.3{\%} of the time, language models complete a sentence with a hurtful word. These cases are not random, but follow language and gender-specific patterns. We propose a score to measure hurtful sentence completions in language models (HONEST). It uses a systematic template- and lexicon-based bias evaluation methodology for six languages. Our findings suggest that these models replicate and amplify deep-seated societal stereotypes about gender roles. Sentence completions refer to sexual promiscuity when the target is female in 9{\%} of the time, and in 4{\%} to homosexuality when the target is male. The results raise questions about the use of these models in production settings.},
}
@inproceedings{vidgen2021lftw,
  title = {Learning from the Worst: Dynamically Generated Datasets to Improve Online Hate Detection},
  author = {Vidgen, Bertie  and Thrush, Tristan  and Waseem, Zeerak  and Kiela, Douwe},
  year = 2021,
  month = aug,
  booktitle = {Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)},
  publisher = {Association for Computational Linguistics},
  address = {Online},
  pages = {1667--1682},
  doi = {10.18653/v1/2021.acl-long.132},
  url = {https://aclanthology.org/2021.acl-long.132},
  editor = {Zong, Chengqing  and Xia, Fei  and Li, Wenjie  and Navigli, Roberto},
  abstract = {We present a human-and-model-in-the-loop process for dynamically generating datasets and training better performing and more robust hate detection models. We provide a new dataset of 40,000 entries, generated and labelled by trained annotators over four rounds of dynamic data creation. It includes 15,000 challenging perturbations and each hateful entry has fine-grained labels for the type and target of hate. Hateful entries make up 54{\%} of the dataset, which is substantially higher than comparable datasets. We show that model performance is substantially improved using this approach. Models trained on later rounds of data collection perform better on test sets and are harder for annotators to trick. They also have better performance on HateCheck, a suite of functional tests for online hate detection. We provide the code, dataset and annotation guidelines for other researchers to use.},
}
@inproceedings{gutiérrezfandiño2022escorpius,
  title = {{esCorpius:} A Massive Spanish Crawling Corpus},
  author = {Asier Gutiérrez-Fandiño and David Pérez-Fernández and Jordi Armengol-Estapé and David Griol and Zoraida Callejas},
  year = 2022,
  booktitle = {IberSPEECH 2022},
  pages = {126--130},
  doi = {10.21437/IberSPEECH.2022-26},
  url = {https://www.isca-speech.org/archive/pdfs/iberspeech_2022/gutierrezfandino22_iberspeech.pdf},
  eprint = {2206.15147},
  archiveprefix = {arXiv},
  primaryclass = {cs.CL},
}
@inproceedings{akiki2022bigscience,
  title = {{BigScience:} A Case Study in the Social Construction of a Multilingual Large Language Model},
  author = {Christopher Akiki and Giada Pistilli and Margot Mieskes and Matthias Gall{\'e} and Thomas Wolf and Suzana Ilic and Yacine Jernite},
  year = 2022,
  booktitle = {Workshop on Broadening Research Collaborations 2022},
  url = {https://openreview.net/forum?id=2e346l2PPOm},
}
@inproceedings{dao2022flashattention,
  title = {{FlashAttention:} Fast and Memory-Efficient Exact Attention with {IO}-Awareness},
  author = {Dao, Tri and Fu, Dan and Ermon, Stefano and Rudra, Atri and R\'{e}, Christopher},
  year = 2022,
  booktitle = {Advances in Neural Information Processing Systems},
  publisher = {Curran Associates, Inc.},
  volume = 35,
  pages = {16344--16359},
  url = {https://proceedings.neurips.cc/paper_files/paper/2022/hash/67d57c32e20fd0a7a302cb81d36e40d5-Abstract-Conference.html},
  editor = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
}
@inproceedings{wei2021finetuned,
  title = {Finetuned Language Models are Zero-Shot Learners},
  author = {Jason Wei and Maarten Bosma and Vincent Zhao and Kelvin Guu and Adams Wei Yu and Brian Lester and Nan Du and Andrew M. Dai and Quoc V. Le},
  year = 2022,
  booktitle = {International Conference on Learning Representations},
  url = {https://openreview.net/forum?id=gEZrGCozdqR},
}
@inproceedings{ding2022towards,
  title = {Towards Openness Beyond Open Access: User Journeys through 3 Open {AI} Collaboratives},
  author = {Jennifer Ding and Christopher Akiki and Yacine Jernite and Anne Lee Steele and Temi Popo},
  year = 2022,
  booktitle = {Workshop on Broadening Research Collaborations 2022},
  url = {https://openreview.net/forum?id=slU-5h8rrCz},
}
@inproceedings{pearce2022asleep,
  title = {Asleep at the keyboard? assessing the security of github copilot’s code contributions},
  author = {Pearce, Hammond and Ahmad, Baleegh and Tan, Benjamin and Dolan-Gavitt, Brendan and Karri, Ramesh},
  year = 2022,
  booktitle = {2022 IEEE Symposium on Security and Privacy (SP)},
  pages = {754--768},
  organization = {IEEE},
}
@inproceedings{haviv2022transformer,
  title = {Transformer Language Models without Positional Encodings Still Learn Positional Information},
  author = {Haviv, Adi  and Ram, Ori  and Press, Ofir  and Izsak, Peter  and Levy, Omer},
  year = 2022,
  month = dec,
  booktitle = {Findings of the Association for Computational Linguistics: EMNLP 2022},
  publisher = {Association for Computational Linguistics},
  address = {Abu Dhabi, United Arab Emirates},
  pages = {1382--1390},
  doi = {10.18653/v1/2022.findings-emnlp.99},
  url = {https://aclanthology.org/2022.findings-emnlp.99},
  eprint = {2203.16634},
  archiveprefix = {arXiv},
  primaryclass = {cs.CL},
  editor = {Goldberg, Yoav  and Kozareva, Zornitsa  and Zhang, Yue},
  abstract = {Causal transformer language models (LMs), such as GPT-3, typically require some form of positional encoding, such as positional embeddings. However, we show that LMs without any explicit positional encoding are still competitive with standard models and that this phenomenon is robust across different datasets, model sizes, and sequence lengths. Probing experiments reveal that such models acquire an implicit notion of absolute positions throughout the network, effectively compensating for the missing information. We conjecture that causal attention enables the model to infer the number of predecessors that each token can attend to, thereby approximating its absolute position. Our findings indicate that causal LMs might derive positional awareness not only from the explicit positioning mechanism but also from the effects of the causal mask.},
}
@inproceedings{sinha2022curious,
  title = {The Curious Case of Absolute Position Embeddings},
  author = {Sinha, Koustuv  and Kazemnejad, Amirhossein  and Reddy, Siva  and Pineau, Joelle  and Hupkes, Dieuwke  and Williams, Adina},
  year = 2022,
  month = dec,
  booktitle = {Findings of the Association for Computational Linguistics: EMNLP 2022},
  publisher = {Association for Computational Linguistics},
  address = {Abu Dhabi, United Arab Emirates},
  pages = {4449--4472},
  doi = {10.18653/v1/2022.findings-emnlp.326},
  url = {https://aclanthology.org/2022.findings-emnlp.326},
  eprint = {2210.12574},
  archiveprefix = {arXiv},
  primaryclass = {cs.CL},
  editor = {Goldberg, Yoav  and Kozareva, Zornitsa  and Zhang, Yue},
  abstract = {Transformer language models encode the notion of word order using positional information. Most commonly, this positional information is represented by absolute position embeddings (APEs), that are learned from the pretraining data. However, in natural language, it is not absolute position that matters, but relative position, and the extent to which APEs can capture this type of information has not been studied. In this work, we observe that models trained with APE over-rely on positional information to the point that they break-down when subjected to sentences with shifted position information. Specifically, when models are subjected to sentences starting from a non-zero position (excluding the effect of priming), they exhibit noticeably degraded performance on zero- to full-shot tasks, across a range of model families and model sizes. Our findings raise questions about the efficacy of APEs to model the relativity of position information, and invite further introspection on the sentence and word order processing strategies employed by these models.},
}
@inproceedings{biderman2023pythia,
  title = {Pythia: A Suite for Analyzing Large Language Models Across Training and Scaling},
  author = {Biderman, Stella and Schoelkopf, Hailey and Anthony, Quentin Gregory and Bradley, Herbie and O'Brien, Kyle and Hallahan, Eric and Khan, Mohammad Aflah and Purohit, Shivanshu and Prashanth, Usvsn Sai and Raff, Edward and Skowron, Aviya and Sutawika, Lintang and Van Der Wal, Oskar},
  year = 2023,
  month = {23--29 Jul},
  booktitle = {Proceedings of the 40th International Conference on Machine Learning},
  publisher = {PMLR},
  series = {Proceedings of Machine Learning Research},
  volume = 202,
  pages = {2397--2430},
  url = {https://proceedings.mlr.press/v202/biderman23a.html},
  editor = {Krause, Andreas and Brunskill, Emma and Cho, Kyunghyun and Engelhardt, Barbara and Sabato, Sivan and Scarlett, Jonathan},
  pdf = {https://proceedings.mlr.press/v202/biderman23a/biderman23a.pdf},
  abstract = {How do large language models (LLMs) develop and evolve over the course of training? How do these patterns change as models scale? To answer these questions, we introduce <em>Pythia</em>, a suite of 16 LLMs all trained on public data seen in the exact same order and ranging in size from 70M to 12B parameters. We provide public access to 154 checkpoints for each one of the 16 models, alongside tools to download and reconstruct their exact training dataloaders for further study. We intend <em>Pythia</em> to facilitate research in many areas, and we present several case studies including novel results in memorization, term frequency effects on few-shot performance, and reducing gender bias. We demonstrate that this highly controlled setup can be used to yield novel insights toward LLMs and their training dynamics. Trained models, analysis code, training code, and training data can be found at https://github.com/EleutherAI/pythia.},
}
@inproceedings{nijkamp:codegen,
  title = {{CodeGen:} An Open Large Language Model for Code with Multi-Turn Program Synthesis},
  author = {Erik Nijkamp and Bo Pang and Hiroaki Hayashi and Lifu Tu and Huan Wang and Yingbo Zhou and Silvio Savarese and Caiming Xiong},
  year = 2023,
  booktitle = {The Eleventh International Conference on Learning Representations},
  url = {https://openreview.net/forum?id=iaYcJKpY2B_},
}
@inproceedings{gao2023pal,
  title = {{PAL}: Program-aided Language Models},
  author = {Gao, Luyu and Madaan, Aman and Zhou, Shuyan and Alon, Uri and Liu, Pengfei and Yang, Yiming and Callan, Jamie and Neubig, Graham},
  year = 2023,
  month = {23--29 Jul},
  booktitle = {Proceedings of the 40th International Conference on Machine Learning},
  publisher = {PMLR},
  series = {Proceedings of Machine Learning Research},
  volume = 202,
  pages = {10764--10799},
  url = {https://proceedings.mlr.press/v202/gao23f.html},
  editor = {Krause, Andreas and Brunskill, Emma and Cho, Kyunghyun and Engelhardt, Barbara and Sabato, Sivan and Scarlett, Jonathan},
  pdf = {https://proceedings.mlr.press/v202/gao23f/gao23f.pdf},
  abstract = {Large language models (LLMs) have demonstrated an impressive ability to perform arithmetic and symbolic reasoning tasks, when provided with a few examples at test time ("few-shot prompting"). Much of this success can be attributed to prompting methods such as "chain-of-thought", which employ LLMs for both understanding the problem description by decomposing it into steps, as well as solving each step of the problem. While LLMs seem to be adept at this sort of step-by-step decomposition, LLMs often make logical and arithmetic mistakes in the solution part, even when the problem is decomposed correctly. In this paper, we present Program-Aided Language models (PAL): a novel approach that uses the LLM to read natural language problems and generate programs as the intermediate reasoning steps, but offloads the solution step to a runtime such as a Python interpreter. With PAL, decomposing the natural language problem into runnable steps remains the only learning task for the LLM, while solving is delegated to the interpreter. We demonstrate this synergy between a neural LLM and a symbolic interpreter across 13 mathematical, symbolic, and algorithmic reasoning tasks from BIG-Bench Hard and others. In all these natural language reasoning tasks, generating code using an LLM and reasoning using a Python interpreter leads to more accurate results than much larger models. For example, PAL using Codex achieves state-of-the-art few-shot accuracy on GSM8K, surpassing PaLM which uses chain-of-thought by absolute 15% top-1.},
}
@inproceedings{penedo2023refinedweb,
  title = {The {RefinedWeb} Dataset for {Falcon LLM}: Outperforming Curated Corpora with Web Data Only},
  author = {Guilherme Penedo and Quentin Malartic and Daniel Hesslow and Ruxandra Cojocaru and Hamza Alobeidli and Alessandro Cappelli and Baptiste Pannier and Ebtesam Almazrouei and Julien Launay},
  year = 2023,
  booktitle = {Thirty-seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
  url = {https://openreview.net/forum?id=kM5eGcdCzq},
}
@inproceedings{pmlr-v202-lai23b,
  title = {{DS}-1000: A Natural and Reliable Benchmark for Data Science Code Generation},
  author = {Lai, Yuhang and Li, Chengxi and Wang, Yiming and Zhang, Tianyi and Zhong, Ruiqi and Zettlemoyer, Luke and Yih, Wen-Tau and Fried, Daniel and Wang, Sida and Yu, Tao},
  year = 2023,
  month = {23--29 Jul},
  booktitle = {Proceedings of the 40th International Conference on Machine Learning},
  publisher = {PMLR},
  series = {Proceedings of Machine Learning Research},
  volume = 202,
  pages = {18319--18345},
  url = {https://proceedings.mlr.press/v202/lai23b.html},
  editor = {Krause, Andreas and Brunskill, Emma and Cho, Kyunghyun and Engelhardt, Barbara and Sabato, Sivan and Scarlett, Jonathan},
  pdf = {https://proceedings.mlr.press/v202/lai23b/lai23b.pdf},
  abstract = {We introduce DS-1000, a code generation benchmark with a thousand data science problems spanning seven Python libraries, such as Numpy and Pandas. Compared to prior works, DS-1000 incorporates three core features. First, our problems reflect diverse, realistic, and practical use cases since we collected them from StackOverflow. Second, our automatic evaluation is highly specific (reliable) – across all Codex-002-predicted solutions that our evaluation accepts, only 1.8% of them are incorrect; we achieve this with multi-criteria metrics, checking both functional correctness by running test cases and surface-form constraints by restricting API usages or keywords. Finally, we proactively defend against memorization by slightly modifying our problems to be different from the original StackOverflow source; consequently, models cannot answer them correctly by memorizing the solutions from pre-training. The current best public system (Codex-002) achieves 43.3% accuracy, leaving ample room for improvement. We release our benchmark at https://ds1000-code-gen.github.io.},
}
@inproceedings{liu2023is,
  title = {Is Your Code Generated by Chat{GPT} Really Correct? Rigorous Evaluation of Large Language Models for Code Generation},
  author = {Liu, Jiawei and Xia, Chunqiu Steven and Wang, Yuyao and Zhang, Lingming},
  year = 2023,
  booktitle = {Thirty-seventh Conference on Neural Information Processing Systems},
  url = {https://openreview.net/forum?id=1qvx610Cu7},
}
@inproceedings{marone2023data,
  title = {Data Portraits: Recording Foundation Model Training Data},
  author = {Marc Marone and Benjamin {Van Durme}},
  year = 2023,
  booktitle = {Thirty-seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
  url = {https://arxiv.org/abs/2303.03919},
}
@inproceedings{szafraniec2023code,
  title = {Code Translation with Compiler Representations},
  author = {Marc Szafraniec and Baptiste Roziere and Hugh James Leather and Patrick Labatut and Francois Charton and Gabriel Synnaeve},
  year = 2023,
  booktitle = {The Eleventh International Conference on Learning Representations},
  url = {https://openreview.net/forum?id=XomEU3eNeSQ},
}
@inproceedings{ding2023crosscodeeval,
  title = {{CrossCodeEval:} A Diverse and Multilingual Benchmark for Cross-File Code Completion},
  author = {Yangruibo Ding and Zijian Wang and Wasi Uddin Ahmad and Hantian Ding and Ming Tan and Nihal Jain and Murali Krishna Ramanathan and Ramesh Nallapati and Parminder Bhatia and Dan Roth and Bing Xiang},
  year = 2023,
  booktitle = {Thirty-seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
  url = {https://openreview.net/forum?id=wgDcbBMSfh},
}
@inproceedings{piktus-etal-2023-roots,
  title = {The {ROOTS} Search Tool: Data Transparency for {LLM}s},
  author = {Piktus, Aleksandra  and Akiki, Christopher  and Villegas, Paulo  and Lauren{\c{c}}on, Hugo  and Dupont, G{\'e}rard  and Luccioni, Sasha  and Jernite, Yacine  and Rogers, Anna},
  year = 2023,
  month = jul,
  booktitle = {Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 3: System Demonstrations)},
  publisher = {Association for Computational Linguistics},
  address = {Toronto, Canada},
  pages = {304--314},
  doi = {10.18653/v1/2023.acl-demo.29},
  url = {https://aclanthology.org/2023.acl-demo.29},
  editor = {Bollegala, Danushka  and Huang, Ruihong  and Ritter, Alan},
}
@inproceedings{piktus-etal-2023-gaia,
  title = {{GAIA} Search: {Hugging Face} and Pyserini Interoperability for {NLP} Training Data Exploration},
  author = {Piktus, Aleksandra  and Ogundepo, Odunayo  and Akiki, Christopher  and Oladipo, Akintunde  and Zhang, Xinyu  and Schoelkopf, Hailey  and Biderman, Stella  and Potthast, Martin  and Lin, Jimmy},
  year = 2023,
  month = jul,
  booktitle = {Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 3: System Demonstrations)},
  publisher = {Association for Computational Linguistics},
  address = {Toronto, Canada},
  pages = {588--598},
  doi = {10.18653/v1/2023.acl-demo.57},
  url = {https://aclanthology.org/2023.acl-demo.57},
  editor = {Bollegala, Danushka  and Huang, Ruihong  and Ritter, Alan},
}
@inproceedings{ainslie2023gqa,
  title = {{GQA}: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints},
  author = {Ainslie, Joshua  and Lee-Thorp, James  and de Jong, Michiel  and Zemlyanskiy, Yury  and Lebron, Federico  and Sanghai, Sumit},
  year = 2023,
  month = dec,
  booktitle = {Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
  publisher = {Association for Computational Linguistics},
  address = {Singapore},
  pages = {4895--4901},
  doi = {10.18653/v1/2023.emnlp-main.298},
  url = {https://aclanthology.org/2023.emnlp-main.298},
  editor = {Bouamor, Houda  and Pino, Juan  and Bali, Kalika},
  abstract = {Multi-query attention (MQA), which only uses a single key-value head, drastically speeds up decoder inference. However, MQA can lead to quality degradation, and moreover it may not be desirable to train a separate model just for faster inference. We (1) propose a recipe for uptraining existing multi-head language model checkpoints into models with MQA using 5{\%} of original pre-training compute, and (2) introduce grouped-query attention (GQA), a generalization of multi-query attention which uses an intermediate (more than one, less than number of query heads) number of key-value heads. We show that uptrained GQA achieves quality close to multi-head attention with comparable speed to MQA.},
}
@inproceedings{akiki-etal-2023-spacerini,
  title = {Spacerini: Plug-and-play Search Engines with Pyserini and {Hugging Face}},
  author = {Akiki, Christopher  and Ogundepo, Odunayo  and Piktus, Aleksandra  and Zhang, Xinyu  and Oladipo, Akintunde  and Lin, Jimmy  and Potthast, Martin},
  year = 2023,
  month = dec,
  booktitle = {Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: System Demonstrations},
  publisher = {Association for Computational Linguistics},
  address = {Singapore},
  pages = {140--148},
  doi = {10.18653/v1/2023.emnlp-demo.12},
  url = {https://aclanthology.org/2023.emnlp-demo.12},
  editor = {Feng, Yansong  and Lefever, Els},
  abstract = {We present Spacerini, a tool that integrates the Pyserini toolkit for reproducible information retrieval research with Hugging Face to enable the seamless construction and deployment of interactive search engines. Spacerini makes state-of-the-art sparse and dense retrieval models more accessible to non-IR practitioners while minimizing deployment effort. This is useful for NLP researchers who want to better understand and validate their research by performing qualitative analyses of training corpora, for IR researchers who want to demonstrate new retrieval models integrated into the growing Pyserini ecosystem, and for third parties reproducing the work of other researchers. Spacerini is open source and includes utilities for loading, preprocessing, indexing, and deploying search engines locally and remotely. We demonstrate a portfolio of 13 search engines created with Spacerini for different use cases.},
}
@inproceedings{cassano2023edit,
  title = {Can It Edit? Evaluating the Ability of Large Language Models to Follow Code Editing Instructions},
  author = {Federico Cassano and Luisa Li and Akul Sethi and Noah Shinn and Abby Brennan-Jones and Anton Lozhkov and Carolyn Jane Anderson and Arjun Guha},
  year = 2024,
  booktitle = {The First International Workshop on Large Language Model for Code},
  url = {https://arxiv.org/abs/2312.12450},
}
@inproceedings{dao2023flashattention2,
  title = {{FlashAttention-2:} Faster Attention with Better Parallelism and Work Partitioning},
  author = {Tri Dao},
  year = 2024,
  booktitle = {The Twelfth International Conference on Learning Representations},
  url = {https://openreview.net/forum?id=mZn2Xyh9Ec},
}
@inproceedings{xu2024lemur,
  title = {Lemur: Harmonizing Natural Language and Code for Language Agents},
  author = {Yiheng Xu and Hongjin Su and Chen Xing and Boyu Mi and Qian Liu and Weijia Shi and Binyuan Hui and Fan Zhou and Yitao Liu and Tianbao Xie and Zhoujun Cheng and Siheng Zhao and Lingpeng Kong and Bailin Wang and Caiming Xiong and Tao Yu},
  year = 2024,
  booktitle = {The Twelfth International Conference on Learning Representations},
  url = {https://openreview.net/forum?id=hNhwSmtXRh},
}
@inproceedings{azerbayev2023llemma,
  title = {Llemma: An Open Language Model for Mathematics},
  author = {Zhangir Azerbayev and Hailey Schoelkopf and Keiran Paster and Marco Dos Santos and Stephen Marcus McAleer and Albert Q. Jiang and Jia Deng and Stella Biderman and Sean Welleck},
  year = 2024,
  booktitle = {The Twelfth International Conference on Learning Representations},
  url = {https://openreview.net/forum?id=4WnqRR915j},
}
@misc{Caballero_Description2Code_Dataset_2016,
  title = {{Description2Code} Dataset},
  author = {Caballero, Ethan and OpenAI and Sutskever, Ilya},
  year = 2016,
  month = aug,
  doi = {10.5281/zenodo.5665051},
  url = {https://github.com/ethancaballero/description2code},
}
@misc{codeforces2020,
  title = {Codeforces: Results of 2020 [Annual Report]},
  author = {Mirzayanov, Mike},
  year = 2020,
  howpublished = {\url{https://codeforces.com/blog/entry/89502}},
}
@article{ren2020codebleu,
  title = {CodeBLEU: a Method for Automatic Evaluation of Code Synthesis},
  author = {Shuo Ren and Daya Guo and Shuai Lu and Long Zhou and Shujie Liu and Duyu Tang and Neel Sundaresan and Ming Zhou and Ambrosio Blanco and Shuai Ma},
  year = 2020,
  eprint = {2009.10297},
  archiveprefix = {arXiv},
  primaryclass = {cs.SE},
journal={arXiv preprint},
url={https://arxiv.org/abs/2009.10297}
}
@misc{bigscience_workshop_2022,
  title = {{BLOOM} (Revision 4ab0472)},
  author = {{BigScience Workshop}},
  year = 2022,
  publisher = {Hugging Face},
  doi = {10.57967/hf/0003},
  url = {https://huggingface.co/bigscience/bloom},
}
@misc{bigcode-evaluation-harness,
  title = {A framework for the evaluation of code generation models},
  author = {Ben Allal, Loubna and Muennighoff, Niklas and Kumar Umapathi, Logesh and Lipkin, Ben and von Werra, Leandro},
  year = 2022,
  journal = {GitHub repository},
  publisher = {GitHub},
  howpublished = {\url{https://github.com/bigcode-project/bigcode-evaluation-harness}},
}
@article{khlaaf2022hazard,
  title = {A Hazard Analysis Framework for Code Synthesis Large Language Models},
  author = {Heidy Khlaaf and Pamela Mishkin and Joshua Achiam and Gretchen Krueger and Miles Brundage},
  year = 2022,
  eprint = {2207.14157},
  archiveprefix = {arXiv},
  primaryclass = {cs.SE},
journal={arXiv preprint},
url={https://arxiv.org/abs/2207.14157}
}
@misc{bigcode2023openrailfaq,
  title = {{BigCode} Open {RAIL}: Responsible {AI} Licensing Framework},
  author = {{BigCode Project}},
  year = 2023,
  url = {https://www.bigcode-project.org/docs/pages/bigcode-openrail/},
  note = {Accessed: 2023},
}
@misc{bigcode2023modellicense,
  title = {BigCode Model License Agreement},
  author = {{BigCode Project}},
  year = 2023,
  url = {https://huggingface.co/spaces/bigcode/bigcode-model-license-agreement},
  note = {Accessed: 2023},
}
@misc{rosetta-code,
  title = {},
  author = {{Rosetta Code}},
  year = 2023,
  url = {https://rosettacode.org/},
}
@misc{softwareheritage2023archival,
  title = {Archival of Software Metadata},
  author = {{Software Heritage}},
  year = 2023,
  url = {https://www.softwareheritage.org/2023/08/24/archival-of-software-metadata/},
}
@misc{softwareheritage2023swhstatement,
  title = {SWH Statement on LLM for Code},
  author = {{Software Heritage}},
  year = 2023,
  url = {https://www.softwareheritage.org/2023/10/19/swh-statement-on-llm-for-code/},
}
@misc{allalBigCodeModels,
  title = {Big Code Models Leaderboard},
  author = {Ben Allal, Loubna},
  year = 2023,
  url = {https://huggingface.co/spaces/bigcode/bigcode-models-leaderboard},
  urldate = {2024-02-27},
}
@misc{harms_law,
  title = {Go smol or go home},
  author = {de Vries, Harm},
  year = 2023,
  howpublished = {\url{https://www.harmdevries.com/post/model-size-vs-compute-overhead/}},
}
@article{lamalfa2023language,
  title = {Language Models as a Service: Overview of a New Paradigm and its Challenges},
  author = {Emanuele La Malfa and Aleksandar Petrov and Simon Frieder and Christoph Weinhuber and Ryan Burnell and Raza Nazar and Anthony G. Cohn and Nigel Shadbolt and Michael Wooldridge},
  year = 2023,
  url = {https://arxiv.org/abs/2309.16573},
journal={arXiv preprint},
}
@misc{together2023redpajama,
  title = {{RedPajama:} an Open Dataset for Training Large Language Models},
  author = {{Together Computer}},
  year = 2023,
  month = oct,
  url = {https://github.com/togethercomputer/RedPajama-Data},
}
@misc{arxiv_dump,
  title = {},
  author = {{Arxiv}},
  year = 2024,
  url = {https://info.arxiv.org/help/bulk_data_s3.html},
}
@misc{blueoak_list,
  title = {},
  author = {{Blue Oak Council}},
  year = 2024,
  url = {https://blueoakcouncil.org/list},
}
@misc{clamav,
  title = {},
  author = {{ClamAV}},
  year = 2024,
  url = {https://www.clamav.net/},
}
@misc{crowdstrike2024polymorphicvirus,
  title = {Polymorphic Virus},
  author = {{CrowdStrike}},
  year = 2024,
  note = {Accessed: 2024},
  howpublished = {\url{https://www.crowdstrike.com/cybersecurity-101/malware/polymorphic-virus/}},
}
@misc{cyberark2024chatting,
  title = {Chatting Our Way Into Creating a Polymorphic Malware},
  author = {{CyberArk}},
  year = 2024,
  note = {Accessed: 2024},
  howpublished = {\url{https://www.cyberark.com/resources/threat-research-blog/chatting-our-way-into-creating-a-polymorphic-malware}},
}
@misc{cisa2024securebydesign,
  title = {Secure by Design},
  author = {{Cybersecurity \& Infrastructure Security Agency}},
  year = 2024,
  url = {https://www.cisa.gov/resources-tools/resources/secure-by-design},
  note = {Accessed: 2024},
}
@misc{gharchive,
  title = {},
  author = {{Github Archive}},
  year = 2024,
  url = {https://gharchive.org},
}
@misc{go_enry,
  title = {},
  author = {{go-enry}},
  year = 2024,
  url = {https://github.com/go-enry/go-enry},
}
@misc{goldmansachs2024generativeworld,
  title = {The Generative World Order: {AI,} Geopolitics, and Power},
  author = {{Goldman Sachs}},
  year = 2024,
  url = {https://www.goldmansachs.com/intelligence/pages/the-generative-world-order-ai-geopolitics-and-power.html},
}
@misc{governanceai2024opensourcing,
  title = {Open Sourcing Highly Capable Foundation Models},
  author = {{Governance AI}},
  year = 2024,
  url = {https://www.governance.ai/research-paper/open-sourcing-highly-capable-foundation-models},
  note = {Accessed: 2024},
}
@misc{huggingface2024starchatalpha,
  title = {Introducing StarChat Alpha: A New Milestone in Conversational AI},
  author = {{Hugging Face}},
  year = 2024,
  howpublished = {\url{https://huggingface.co/blog/starchat-alpha}},
}
@misc{msft_q2_2024,
  title = {},
  author = {{MSFT Q2 Earning Call}},
  year = 2024,
  url = {https://www.microsoft.com/en-us/investor/events/fy-2024/earnings-fy-2024-q2.aspx},
}
@misc{redpajama_wiki,
  title = {},
  author = {{RedPajama Wiki}},
  year = 2024,
  url = {https://github.com/togethercomputer/RedPajama-Data/tree/rp_v1/data_prep/wiki},
}
@misc{sanesecurity,
  title = {},
  author = {{Sane Security}},
  year = 2024,
  url = {https://sanesecurity.com/usage/signatures},
}
@misc{scancode_license_categories,
  author = {{ScanCode License Categories}},
  year = 2024,
  url = {https://scancode-licensedb.aboutcode.org/help.html##license-categories},
}
@misc{scancode,
  title = {},
  author = {{ScanCode}},
  year = 2024,
  url = {https://github.com/nexB/scancode-toolkit},
}
@misc{servicenow2024summarization,
  title = {Summarization LLM: Enhancing Document Summarization with Large Language Models},
  author = {{ServiceNow}},
  year = 2024,
  url = {https://downloads.docs.servicenow.com/resource/enus/infocard/summarization-llm.pdf},
}
@misc{servicenow2024texttocode,
  title = {Text-to-Code {LLM:} Transforming Natural Language into Executable Code},
  author = {{ServiceNow}},
  year = 2024,
  url = {https://downloads.docs.servicenow.com/resource/enus/infocard/text-to-code-llm.pdf},
}
@misc{servicenow2024text2flow,
  title = {Text2Flow {LLM}: Automating Workflow Generation from Descriptive Text},
  author = {{ServiceNow}},
  year = 2024,
  howpublished = {\url{https://downloads.docs.servicenow.com/resource/enus/infocard/text2flow-llm.pdf}},
}
@misc{swh_graph_dataset,
  title = {},
  author = {{SHW Graph Dataset}},
  year = 2024,
  url = {https://docs.softwareheritage.org/devel/swh-dataset/graph/dataset.html},
}
@misc{swh,
  title = {},
  author = {{Software Heritage}},
  year = 2024,
  url = {https://www.softwareheritage.org},
}
@misc{softwareheritage2024bulk,
  title = {Bulk Access Terms of Use},
  author = {{Software Heritage}},
  year = 2024,
  url = {https://www.softwareheritage.org/legal/bulk-access-terms-of-use/},
}
@misc{stackoverflow_archive,
  title = {},
  author = {{StackExchange Archive}},
  year = 2024,
  url = {https://archive.org/details/stackexchange},
}
@misc{techcircle2024llmadoption,
  title = {How LLM Adoption Has Impacted AI Job Roles},
  author = {{TechCircle}},
  year = 2024,
  howpublished = {\url{https://www.techcircle.in/2024/02/08/how-llm-adoption-has-impacted-ai-job-roles}},
}
@misc{swhidspecification2024,
  title = {The {SWHID} Specification},
  author = {{The SWHID Specification Project}},
  year = 2024,
  url = {https://www.swhid.org/},
}
@misc{weforum2024jobsoftomorrow,
  title = {Jobs of Tomorrow: Large Language Models and Jobs},
  author = {{World Economic Forum}},
  year = 2024,
  url = {https://www.weforum.org/publications/jobs-of-tomorrow-large-language-models-and-jobs/},
}
@misc{servicenow2024q4earnings,
  title = {{ServiceNow Inc (NYSE: NOW) Q4} Earnings: What to Expect},
  author = {{Yahoo Finance}},
  year = 2024,
  url = {https://finance.yahoo.com/news/servicenow-inc-nyse-now-q4-154816487.html},
}
@misc{bigcode2024thestackv2,
  title = {The Stack V2},
  author = {BigCode Project},
  year = 2024,
  url = {https://huggingface.co/datasets/bigcode/the-stack-v2/},
  note = {Accessed: 2024},
}
@misc{bigcode2024models,
  title = {Models by {BigCode} on {Hugging Face}},
  author = {BigCode},
  year = 2024,
  url = {https://huggingface.co/api/models?author=bigcode&expand[]=downloadsAllTime},
  note = {Accessed: 2024},
}
@article{guo2024deepseek,
  title = {{DeepSeek-Coder:} When the Large Language Model Meets Programming -- The Rise of Code Intelligence},
  author = {Daya Guo and Qihao Zhu and Dejian Yang and Zhenda Xie and Kai Dong and Wentao Zhang and Guanting Chen and Xiao Bi and Y. Wu and Y. K. Li and Fuli Luo and Yingfei Xiong and Wenfeng Liang},
  year = 2024,
  journal = {arXiv preprint},
  url = {https://arxiv.org/abs/2401.14196},
  eprint = {2401.14196},
  archiveprefix = {arXiv},
  primaryclass = {cs.SE},
}
@article{tang2024privacy,
  title = {Finding Privacy-relevant Source Code},
  author = {Feiyang Tang and Bjarte M. Østvold},
  year = 2024,
  eprint = {2401.07316},
  archiveprefix = {arXiv},
  primaryclass = {cs.SE},
  journal = {arXiv preprint},
  url = {https://arxiv.org/abs/2401.07316},
}
@article{mirakhorli2024landscape,
  title = {A Landscape Study of Open Source and Proprietary Tools for Software Bill of Materials (SBOM)},
  author = {Mehdi Mirakhorli and Derek Garcia and Schuyler Dillon and Kevin Laporte and Matthew Morrison and Henry Lu and Viktoria Koscinski and Christopher Enoch},
  year = 2024,
  journal = {arXiv preprint},
  url = {https://arxiv.org/abs/2402.11151},
  eprint = {2402.11151},
  archiveprefix = {arXiv},
  primaryclass = {cs.SE},
}
@article{stablecode3b,
  title = {Stable Code {3B}: Coding on the Edge},
  shorttitle = {Stable {{Code 3B}}},
  author = {Pinnaparaju, Nikhil and Adithyan, Reshinth and Phung, Duy and Tow, Jonathan and Baicoianu, James and  and Cooper, Nathan},
  year = 2024,
  journal = {Stability AI},
  urldate = {2024-02-27},
  abstract = {Stable Code, an upgrade from Stable Code Alpha 3B, specializes in code completion and outperforms predecessors in efficiency and multi-language support. It is compatible with standard laptops, including non-GPU models, and features capabilities like FIM and expanded context size.},
  url = {https://stability.ai/news/stable-code-2024-llm-code-completion-release},
  langid = {british},
}
@misc{softwareheritage2024community,
  title = {Software Heritage Community},
  author = {Software Heritage},
  year = 2024,
  note = {Accessed: 2024},
  howpublished = {\url{https://www.softwareheritage.org/community/}},
}
@techreport{autor2022newfrontiers,
  title = {New Frontiers: The Origins and Content of New Work, 1940–2018},
  author = {Autor, David and Chin, Caroline and Salomons, Anna M and Seegmiller, Bryan},
  year = 2022,
  month = {August},
  number = 30389,
  doi = {10.3386/w30389},
  url = {http://www.nber.org/papers/w30389},
  institution = {National Bureau of Economic Research},
}

@inproceedings{merkle1987digital,
  title={A digital signature based on a conventional encryption function},
  author={Merkle, Ralph C.},
  booktitle={Conference on the theory and application of cryptographic techniques},
  pages={369--378},
  year={1987},
  organization={Springer}
}
