\newpage
\appendix
\onecolumn

% \startcontents[sections]
% \printcontents[sections]{l}{1}{\setcounter{tocdepth}{2}}
% \addcontentsline{toc}{section}{Appendix} % Add the appendix text to the document TOC
% \renewcommand \thepart{} % make "Part" text invisible
% \renewcommand \partname{}
% \newpage
% \part{Appendix} % Start the appendix part
% \parttoc % Insert the appendix TOC


% \section{Appendix}

% \Zhao{Write a roadmap here to summarize all of our theory sections} 
\textbf{Contents:} In Section \ref{appendix:related_work}, we present an extended discussion on LLM inference and related works. In Section \ref{sec:appendix-obs}, we provide more observation plots for slowly changing activation and further observation on the possibility of sparsifying LLMs via layer skipping. In Section \ref{sec:appendix-exp}, we provide experiment details. In Section~\ref{appendix:method}, we demonstrate implementation details. In Section \ref{sec:mlp_attn_benchmarks}, we provide detailed benchmarks regarding our implementation. 
In Section \ref{sec:notation_definition}, we define some basic notations and definitions.
In Section \ref{sec:subspace_embedding}, we define subspace embedding and show the norm preserving.
In Section \ref{sec:distances_angles}, we introduce  distances, angles, and inner product.
In Section \ref{sec:function_approx}, we provide the distance between different functions.
In Section \ref{sec:nearest_neighbor}, we provide the Near-neighbor Search data structure.
 In Section \ref{sec:clustering understanding}, we discuss self-attention as a clustering algorithm in depth.

\input{A02_Relatedwork.tex}
\input{A01_observation.tex}
\input{A04_method}
\input{A03_benchmarks.tex}
\input{08_theory.tex}
\input{09_understanding.tex}

