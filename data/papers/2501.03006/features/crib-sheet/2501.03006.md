- **Title**: TransPixar: Advancing Text-to-Video Generation with Transparency
- **Objective**: Develop a framework for RGBA video generation from text using DiT-based models, enabling realistic visual effects with transparency.
- **Key Contributions**:
  - Introduced a novel alpha channel adaptive attention mechanism.
  - Achieved simultaneous generation of RGB and alpha channels, enhancing RGBA video quality.
  - Utilized LoRA layers for fine-tuning, maintaining RGB generation quality while adapting to alpha tokens.
- **Method Overview**:
  - **Model Architecture**: Extends pretrained DiT models to generate RGB and alpha channels together.
  - **Token Structure**: Sequence includes text, RGB, and alpha tokens; employs a 3x3 grouped attention matrix.
  - **Attention Mechanisms**:
    - **Text-attend-to-RGB**: Original model's generation capabilities.
    - **RGB-attend-to-Alpha**: Necessary for refining RGB tokens based on alpha information.
    - **Text-attend-to-Alpha**: Removed to mitigate performance degradation risks.
- **Positional Encoding**:
  - **Absolute Positional Encoding**: 
    - RGB tokens: \( f_z(x_{video}) = W_z(x_{m_{video}} + p_m) \)
    - Alpha tokens: \( f_z(x_{video}) = W^*_z(x_{m_{video}} + p_{m-L} + d) \)
  - **Domain Embedding**: Learnable parameter to differentiate between RGB and alpha tokens.
- **Attention Formula**: 
  \[
  Attention(Q, K, V) = softmax\left(\frac{QK^T}{\sqrt{d_k}} + M\right)V
  \]
- **LoRA Fine-Tuning**: 
  - Applied only to alpha tokens to control residual strength with parameter \( \gamma \).
  - Attention mask defined to block unwanted computations.
- **Challenges Addressed**:
  - Limited RGBA video data availability.
  - Need for effective alpha channel generation without compromising RGB quality.
- **Experimental Validation**: Demonstrated effectiveness across various challenging scenarios, achieving diverse RGBA generation with limited training data.