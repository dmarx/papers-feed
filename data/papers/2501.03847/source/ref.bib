
% Journals

% First the Full Name is given, then the abbreviation used in the AMS Math
% Reviews, with an indication if it could not be found there.
% Note the 2nd overwrites the 1st, so swap them if you want the full name.

 %{AMS}
 @String{AMSTrans = "American Mathematical Society Translations" }
 @String{AMSTrans = "Amer. Math. Soc. Transl." }
 @String{BullAMS = "Bulletin of the American Mathematical Society" }
 @String{BullAMS = "Bull. Amer. Math. Soc." }
 @String{ProcAMS = "Proceedings of the American Mathematical Society" }
 @String{ProcAMS = "Proc. Amer. Math. Soc." }
 @String{TransAMS = "Transactions of the American Mathematical Society" }
 @String{TransAMS = "Trans. Amer. Math. Soc." }

 %ACM
 @String{CACM = "Communications of the {ACM}" }
 @String{CACM = "Commun. {ACM}" }
 @String{CompServ = "Comput. Surveys" }
 @String{JACM = "J. ACM" }
 @String{ACMMathSoft = "{ACM} Transactions on Mathematical Software" }
 @String{ACMMathSoft = "{ACM} Trans. Math. Software" }
 @String{SIGNUM = "{ACM} {SIGNUM} Newsletter" }
 @String{SIGNUM = "{ACM} {SIGNUM} Newslett." }

 @String{AmerSocio = "American Journal of Sociology" }
 @String{AmerStatAssoc = "Journal of the American Statistical Association" }
 @String{AmerStatAssoc = "J. Amer. Statist. Assoc." }
 @String{ApplMathComp = "Applied Mathematics and Computation" }
 @String{ApplMathComp = "Appl. Math. Comput." }
 @String{AmerMathMonthly = "American Mathematical Monthly" }
 @String{AmerMathMonthly = "Amer. Math. Monthly" }
 @String{BIT = "{BIT}" }
 @String{BritStatPsych = "British Journal of Mathematical and Statistical
          Psychology" }
 @String{BritStatPsych = "Brit. J. Math. Statist. Psych." }
 @String{CanMathBull = "Canadian Mathematical Bulletin" }
 @String{CanMathBull = "Canad. Math. Bull." }
 @String{CompApplMath = "Journal of Computational and Applied Mathematics" }
 @String{CompApplMath = "J. Comput. Appl. Math." }
 @String{CompPhys = "Journal of Computational Physics" }
 @String{CompPhys = "J. Comput. Phys." }
 @String{CompStruct = "Computers and Structures" }
 @String{CompStruct = "Comput. \& Structures" }
 @String{CompJour = "The Computer Journal" }
 @String{CompJour = "Comput. J." }
 @String{CompSysSci = "Journal of Computer and System Sciences" }
 @String{CompSysSci = "J. Comput. System Sci." }
 @String{Computing = "Computing" }
 @String{ContempMath = "Contemporary Mathematics" }
 @String{ContempMath = "Contemp. Math." }
 @String{Crelle = "Crelle's Journal" }
 @String{GiornaleMath = "Giornale di Mathematiche" }
 @String{GiornaleMath = "Giorn. Mat." } % didn't find in AMS MR., ibid.

 %IEEE
 @String{Computer = "{IEEE} Computer" }
 @String{IEEETransComp = "{IEEE} Transactions on Computers" }
 @String{IEEETransComp = "{IEEE} Trans. Comput." }
 @String{IEEETransAC = "{IEEE} Transactions on Automatic Control" }
 @String{IEEETransAC = "{IEEE} Trans. Automat. Control" }
 @String{IEEESpec = "{IEEE} Spectrum" } % didn't find in AMS MR
 @String{ProcIEEE = "Proceedings of the {IEEE}" }
 @String{ProcIEEE = "Proc. {IEEE}" } % didn't find in AMS MR
 @String{IEEETransAeroElec = "{IEEE} Transactions on Aerospace and Electronic
     Systems" }
 @String{IEEETransAeroElec = "{IEEE} Trans. Aerospace Electron. Systems" }

 @String{IMANumerAna = "{IMA} Journal of Numerical Analysis" }
 @String{IMANumerAna = "{IMA} J. Numer. Anal." }
 @String{InfProcLet = "Information Processing Letters" }
 @String{InfProcLet = "Inform. Process. Lett." }
 @String{InstMathApp = "Journal of the Institute of Mathematics and
     its Applications" }
 @String{InstMathApp = "J. Inst. Math. Appl." }
 @String{IntControl = "International Journal of Control" }
 @String{IntControl = "Internat. J. Control" }
 @String{IntNumerEng = "International Journal for Numerical Methods in
     Engineering" }
 @String{IntNumerEng = "Internat. J. Numer. Methods Engrg." }
 @String{IntSuper = "International Journal of Supercomputing Applications" }
 @String{IntSuper = "Internat. J. Supercomputing Applic." } % didn't find
%% in AMS MR
 @String{Kibernetika = "Kibernetika" }
 @String{JResNatBurStand = "Journal of Research of the National Bureau
     of Standards" }
 @String{JResNatBurStand = "J. Res. Nat. Bur. Standards" }
 @String{LinAlgApp = "Linear Algebra and its Applications" }
 @String{LinAlgApp = "Linear Algebra Appl." }
 @String{MathAnaAppl = "Journal of Mathematical Analysis and Applications" }
 @String{MathAnaAppl = "J. Math. Anal. Appl." }
 @String{MathAnnalen = "Mathematische Annalen" }
 @String{MathAnnalen = "Math. Ann." }
 @String{MathPhys = "Journal of Mathematical Physics" }
 @String{MathPhys = "J. Math. Phys." }
 @String{MathComp = "Mathematics of Computation" }
 @String{MathComp = "Math. Comp." }
 @String{MathScand = "Mathematica Scandinavica" }
 @String{MathScand = "Math. Scand." }
 @String{TablesAidsComp = "Mathematical Tables and Other Aids to Computation" }
 @String{TablesAidsComp = "Math. Tables Aids Comput." }
 @String{NumerMath = "Numerische Mathematik" }
 @String{NumerMath = "Numer. Math." }
 @String{PacificMath = "Pacific Journal of Mathematics" }
 @String{PacificMath = "Pacific J. Math." }
 @String{ParDistComp = "Journal of Parallel and Distributed Computing" }
 @String{ParDistComp = "J. Parallel and Distrib. Comput." } % didn't find
%% in AMS MR
 @String{ParComputing = "Parallel Computing" }
 @String{ParComputing = "Parallel Comput." }
 @String{PhilMag = "Philosophical Magazine" }
 @String{PhilMag = "Philos. Mag." }
 @String{ProcNAS = "Proceedings of the National Academy of Sciences
                    of the USA" }
 @String{ProcNAS = "Proc. Nat. Acad. Sci. U. S. A." }
 @String{Psychometrika = "Psychometrika" }
 @String{QuartMath = "Quarterly Journal of Mathematics, Oxford, Series (2)" }
 @String{QuartMath = "Quart. J. Math. Oxford Ser. (2)" }
 @String{QuartApplMath = "Quarterly of Applied Mathematics" }
 @String{QuartApplMath = "Quart. Appl. Math." }
 @String{RevueInstStat = "Review of the International Statisical Institute" }
 @String{RevueInstStat = "Rev. Inst. Internat. Statist." }

 %SIAM
 @String{JSIAM = "Journal of the Society for Industrial and Applied
     Mathematics" }
 @String{JSIAM = "J. Soc. Indust. Appl. Math." }
 @String{JSIAMB = "Journal of the Society for Industrial and Applied
     Mathematics, Series B, Numerical Analysis" }
 @String{JSIAMB = "J. Soc. Indust. Appl. Math. Ser. B Numer. Anal." }
 @String{SIAMAlgMeth = "{SIAM} Journal on Algebraic and Discrete Methods" }
 @String{SIAMAlgMeth = "{SIAM} J. Algebraic Discrete Methods" }
 @String{SIAMAppMath = "{SIAM} Journal on Applied Mathematics" }
 @String{SIAMAppMath = "{SIAM} J. Appl. Math." }
 @String{SIAMComp = "{SIAM} Journal on Computing" }
 @String{SIAMComp = "{SIAM} J. Comput." }
 @String{SIAMMatrix = "{SIAM} Journal on Matrix Analysis and Applications" }
 @String{SIAMMatrix = "{SIAM} J. Matrix Anal. Appl." }
 @String{SIAMNumAnal = "{SIAM} Journal on Numerical Analysis" }
 @String{SIAMNumAnal = "{SIAM} J. Numer. Anal." }
 @String{SIAMReview = "{SIAM} Review" }
 @String{SIAMReview = "{SIAM} Rev." }
 @String{SIAMSciStat = "{SIAM} Journal on Scientific and Statistical
     Computing" }
 @String{SIAMSciStat = "{SIAM} J. Sci. Statist. Comput." }

 @String{SoftPracExp = "Software Practice and Experience" }
 @String{SoftPracExp = "Software Prac. Experience" } % didn't find in AMS MR
 @String{StatScience = "Statistical Science" }
 @String{StatScience = "Statist. Sci." }
 @String{Techno = "Technometrics" }
 @String{USSRCompMathPhys = "{USSR} Computational Mathematics and Mathematical
     Physics" }
 @String{USSRCompMathPhys = "{U. S. S. R.} Comput. Math. and Math. Phys." }
 @String{VLSICompSys = "Journal of {VLSI} and Computer Systems" }
 @String{VLSICompSys = "J. {VLSI} Comput. Syst." }
 @String{ZAngewMathMech = "Zeitschrift fur Angewandte Mathematik und
     Mechanik" }
 @String{ZAngewMathMech = "Z. Angew. Math. Mech." }
 @String{ZAngewMathPhys = "Zeitschrift fur Angewandte Mathematik und Physik" }
 @String{ZAngewMathPhys = "Z. Angew. Math. Phys." }

% Publishers % ================================================= |

 @String{Academic = "Academic Press" }
 @String{ACMPress = "{ACM} Press" }
 @String{AdamHilger = "Adam Hilger" }
 @String{AddisonWesley = "Addison-Wesley" }
 @String{AllynBacon = "Allyn and Bacon" }
 @String{AMS = "American Mathematical Society" }
 @String{Birkhauser = "Birkha{\"u}ser" }
 @String{CambridgePress = "Cambridge University Press" }
 @String{Chelsea = "Chelsea" }
 @String{ClaredonPress = "Claredon Press" }
 @String{DoverPub = "Dover Publications" }
 @String{Eyolles = "Eyolles" }
 @String{HoltRinehartWinston = "Holt, Rinehart and Winston" }
 @String{Interscience = "Interscience" }
 @String{JohnsHopkinsPress = "The Johns Hopkins University Press" }
 @String{JohnWileySons = "John Wiley and Sons" }
 @String{Macmillan = "Macmillan" }
 @String{MathWorks = "The Math Works Inc." }
 @String{McGrawHill = "McGraw-Hill" }
 @String{NatBurStd = "National Bureau of Standards" }
 @String{NorthHolland = "North-Holland" }
 @String{OxfordPress = "Oxford University Press" }  %address Oxford or London?
 @String{PergamonPress = "Pergamon Press" }
 @String{PlenumPress = "Plenum Press" }
 @String{PrenticeHall = "Prentice-Hall" }
 @String{SIAMPub = "{SIAM} Publications" }
 @String{Springer = "Springer-Verlag" }
 @String{TexasPress = "University of Texas Press" }
 @String{VanNostrand = "Van Nostrand" }
 @String{WHFreeman = "W. H. Freeman and Co." }


@inproceedings{rombach2022high,
  title={High-resolution image synthesis with latent diffusion models},
  author={Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\"o}rn},
  booktitle={CVPR},
  year={2022}
}
@article{ho2020denoising,
  title={Denoising diffusion probabilistic models},
  author={Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  journal={NeurIPS},
  year={2020}
}
@inproceedings{peebles2023scalable,
  title={Scalable diffusion models with transformers},
  author={Peebles, William and Xie, Saining},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={4195--4205},
  year={2023}
}

@article{ho2022video,
  title={Video diffusion models},
  author={Ho, Jonathan and Salimans, Tim and Gritsenko, Alexey and Chan, William and Norouzi, Mohammad and Fleet, David J},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={8633--8646},
  year={2022}
}
@article{blattmann2023stable,
  title={Stable video diffusion: Scaling latent video diffusion models to large datasets},
  author={Blattmann, Andreas and Dockhorn, Tim and Kulal, Sumith and Mendelevitch, Daniel and Kilian, Maciej and Lorenz, Dominik and Levi, Yam and English, Zion and Voleti, Vikram and Letts, Adam and others},
  journal={arXiv preprint arXiv:2311.15127},
  year={2023}
}
@misc{brooks2024video,
  title={Video generation models as world simulators},
  author={Brooks, Tim and Peebles, Bill and Holmes, Connor and DePue, Will and Guo, Yufei and Jing, Li and Schnurr, David and Taylor, Joe and Luhman, Troy and Luhman, Eric and others},
  url={https://openai. com/research/video-generation-models-as-world-simulators},
  year={2024}
}
@article{yang2024cogvideox,
  title={Cogvideox: Text-to-video diffusion models with an expert transformer},
  author={Yang, Zhuoyi and Teng, Jiayan and Zheng, Wendi and Ding, Ming and Huang, Shiyu and Xu, Jiazheng and Yang, Yuanming and Hong, Wenyi and Zhang, Xiaohan and Feng, Guanyu and others},
  journal={arXiv preprint arXiv:2408.06072},
  year={2024}
}
@misc{keling,
title={Keling},
author={Kuaishou},
url={https://kling.kuaishou.com/},
year={2024}
}
@article{kong2024hunyuanvideo,
  title={HunyuanVideo: A Systematic Framework For Large Video Generative Models},
  author={Kong, Weijie and Tian, Qi and Zhang, Zijian and Min, Rox and Dai, Zuozhuo and others},
  journal={arXiv preprint arXiv:2412.03603},
  year={2024}
}
@article{lin2024open,
  title={Open-Sora Plan: Open-Source Large Video Generation Model},
  author={Lin, Bin and Ge, Yunyang and Cheng, Xinhua and Li, Zongjian and Zhu, Bin and Wang, Shaodong and He, Xianyi and Ye, Yang and Yuan, Shenghai and Chen, Liuhan and others},
  journal={arXiv preprint arXiv:2412.00131},
  year={2024}
}
@software{opensora,
  author = {Zangwei Zheng and Xiangyu Peng and Tianji Yang and Chenhui Shen and Shenggui Li and Hongxin Liu and Yukun Zhou and Tianyi Li and Yang You},
  title = {Open-Sora: Democratizing Efficient Video Production for All},
  month = {March},
  year = {2024},
  url = {https://github.com/hpcaitech/Open-Sora}
}

% camera
@inproceedings{wang2024motionctrl,
  title={Motionctrl: A unified and flexible motion controller for video generation},
  author={Wang, Zhouxia and Yuan, Ziyang and Wang, Xintao and Li, Yaowei and Chen, Tianshui and Xia, Menghan and Luo, Ping and Shan, Ying},
  booktitle={SIGGRAPH},
  year={2024}
}
@article{he2024cameractrl,
  title={Cameractrl: Enabling camera control for text-to-video generation},
  author={He, Hao and Xu, Yinghao and Guo, Yuwei and Wetzstein, Gordon and Dai, Bo and Li, Hongsheng and Yang, Ceyuan},
  journal={arXiv preprint arXiv:2404.02101},
  year={2024}
}
@article{zheng2024cami2v,
  title={CamI2V: Camera-Controlled Image-to-Video Diffusion Model},
  author={Zheng, Guangcong and Li, Teng and Jiang, Rui and Lu, Yehao and Wu, Tao and Li, Xi},
  journal={arXiv preprint arXiv:2410.15957},
  year={2024}
}
@article{yu2024viewcrafter,
  title={Viewcrafter: Taming video diffusion models for high-fidelity novel view synthesis},
  author={Yu, Wangbo and Xing, Jinbo and Yuan, Li and Hu, Wenbo and Li, Xiaoyu and Huang, Zhipeng and Gao, Xiangjun and Wong, Tien-Tsin and Shan, Ying and Tian, Yonghong},
  journal={arXiv preprint arXiv:2409.02048},
  year={2024}
}
@article{bahmani2024ac3d,
  title={AC3D: Analyzing and Improving 3D Camera Control in Video Diffusion Transformers},
  author={Bahmani, Sherwin and Skorokhodov, Ivan and Qian, Guocheng and Siarohin, Aliaksandr and Menapace, Willi and Tagliasacchi, Andrea and Lindell, David B and Tulyakov, Sergey},
  journal={arXiv preprint arXiv:2411.18673},
  year={2024}
}
@article{xiao2024trajectory,
  title={Trajectory Attention for Fine-grained Video Motion Control},
  author={Xiao, Zeqi and Ouyang, Wenqi and Zhou, Yifan and Yang, Shuai and Yang, Lei and Si, Jianlou and Pan, Xingang},
  journal={arXiv preprint arXiv:2411.19324},
  year={2024}
}
@article{wang2024cpa,
  title={CPA: Camera-pose-awareness Diffusion Transformer for Video Generation},
  author={Wang, Yuelei and Zhang, Jian and Jiang, Pengtao and Zhang, Hao and Chen, Jinwei and Li, Bo},
  journal={arXiv preprint arXiv:2412.01429},
  year={2024}
}
@article{wang2024objctrl,
  title={ObjCtrl-2.5 D: Training-free Object Control with Camera Poses},
  author={Wang, Zhouxia and Lan, Yushi and Zhou, Shangchen and Loy, Chen Change},
  journal={arXiv preprint arXiv:2412.07721},
  year={2024}
}
@inproceedings{zhou2018stereo,
    Author = {Zhou, Tinghui and Tucker, Richard and Flynn, John and Fyffe, Graham and Snavely, Noah},
    Title = {Stereo Magnification: Learning View Synthesis using Multiplane Images},
    Booktitle = {SIGGRAPH},
    Year = {2018}
}
@article{ng2003sift,
  title={SIFT: Predicting amino acid changes that affect protein function},
  author={Ng, Pauline C and Henikoff, Steven},
  journal={Nucleic acids research},
  volume={31},
  number={13},
  pages={3812--3814},
  year={2003},
  publisher={Oxford University Press}
}

% identity
@article{he2024id,
  title={Id-animator: Zero-shot identity-preserving human video generation},
  author={He, Xuanhua and Liu, Quande and Qian, Shengju and Wang, Xin and Hu, Tao and Cao, Ke and Yan, Keyu and Zhang, Jie},
  journal={arXiv preprint arXiv:2404.15275},
  year={2024}
}
@article{polyak2024movie,
  title={Movie gen: A cast of media foundation models},
  author={Polyak, Adam and Zohar, Amit and Brown, Andrew and Tjandra, Andros and Sinha, Animesh and Lee, Ann and Vyas, Apoorv and Shi, Bowen and Ma, Chih-Yao and Chuang, Ching-Yao and others},
  journal={arXiv preprint arXiv:2410.13720},
  year={2024}
}
@article{yuan2024identity,
  title={Identity-Preserving Text-to-Video Generation by Frequency Decomposition},
  author={Yuan, Shenghai and Huang, Jinfa and He, Xianyi and Ge, Yunyuan and Shi, Yujun and Chen, Liuhan and Luo, Jiebo and Yuan, Li},
  journal={arXiv preprint arXiv:2411.17440},
  year={2024}
}
@incollection{wang2024animatelcm,
  title={AnimateLCM: Computation-Efficient Personalized Style Video Generation without Personalized Video Data},
  author={Wang, Fu-Yun and Huang, Zhaoyang and Bian, Weikang and Shi, Xiaoyu and Sun, Keqiang and Song, Guanglu and Liu, Yu and Li, Hongsheng},
  booktitle={SIGGRAPH Asia 2024 Technical Communications},
  pages={1--5},
  year={2024}
}
@article{sitzmann2021light,
  title={Light field networks: Neural scene representations with single-evaluation rendering},
  author={Sitzmann, Vincent and Rezchikov, Semon and Freeman, Bill and Tenenbaum, Josh and Durand, Fredo},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={19313--19325},
  year={2021}
}

% object
@article{wang2024boximator,
  title={Boximator: Generating rich and controllable motions for video synthesis},
  author={Wang, Jiawei and Zhang, Yuchen and Zou, Jiaxin and Zeng, Yan and Wei, Guoqiang and Yuan, Liping and Li, Hang},
  journal={arXiv preprint arXiv:2402.01566},
  year={2024}
}
@article{huang2023fine,
  title={Fine-grained controllable video generation via object appearance and context},
  author={Huang, Hsin-Ping and Su, Yu-Chuan and Sun, Deqing and Jiang, Lu and Jia, Xuhui and Zhu, Yukun and Yang, Ming-Hsuan},
  journal={arXiv preprint arXiv:2312.02919},
  year={2023}
}
@inproceedings{guo2024sparsectrl,
  title={Sparsectrl: Adding sparse controls to text-to-video diffusion models},
  author={Guo, Yuwei and Yang, Ceyuan and Rao, Anyi and Agrawala, Maneesh and Lin, Dahua and Dai, Bo},
  booktitle={ECCV},
  pages={330--348},
  year={2024}
}
@article{namekata2024sg,
  title={Sg-i2v: Self-guided trajectory control in image-to-video generation},
  author={Namekata, Koichi and Bahmani, Sherwin and Wu, Ziyi and Kant, Yash and Gilitschenski, Igor and Lindell, David B},
  journal={arXiv preprint arXiv:2411.04989},
  year={2024}
}
@inproceedings{ma2024trailblazer,
  title={Trailblazer: Trajectory control for diffusion-based video generation},
  author={Ma, Wan-Duo Kurt and Lewis, John P and Kleijn, W Bastiaan},
  booktitle={SIGGRAPH Asia},
  year={2024}
}
@article{ma2024follow,
  title={Follow-your-click: Open-domain regional image animation via short prompts},
  author={Ma, Yue and He, Yingqing and Wang, Hongfa and Wang, Andong and Qi, Chenyang and Cai, Chengfei and Li, Xiu and Li, Zhifeng and Shum, Heung-Yeung and Liu, Wei and others},
  journal={arXiv preprint arXiv:2403.08268},
  year={2024}
}
@inproceedings{yu2024zero,
  title={Zero-shot controllable image-to-video animation via motion decomposition},
  author={Yu, Shoubin and Fang, Jacob Zhiyuan and Zheng, Jian and Sigurdsson, Gunnar and Ordonez, Vicente and Piramuthu, Robinson and Bansal, Mohit},
  booktitle={ACM MM},
  year={2024}
}
@article{mou2024revideo,
  title={ReVideo: Remake a Video with Motion and Content Control},
  author={Mou, Chong and Cao, Mingdeng and Wang, Xintao and Zhang, Zhaoyang and Shan, Ying and Zhang, Jian},
  journal={arXiv preprint arXiv:2405.13865},
  year={2024}
}
@article{pandey2024motion,
  title={Motion Modes: What Could Happen Next?},
  author={Pandey, Karran and Gadelha, Matheus and Hold-Geoffroy, Yannick and Singh, Karan and Mitra, Niloy J and Guerrero, Paul},
  journal={arXiv preprint arXiv:2412.00148},
  year={2024}
}

% implicit motion learning
@inproceedings{ouyang2024i2vedit,
  title={I2VEdit: First-Frame-Guided Video Editing via Image-to-Video Diffusion Models},
  author={Ouyang, Wenqi and Dong, Yi and Yang, Lei and Si, Jianlou and Pan, Xingang},
  booktitle={SIGGRAPH Asia},
  year={2024}
}

% motion transfer (editing)
@inproceedings{esser2023structure,
  title={Structure and content-guided video synthesis with diffusion models},
  author={Esser, Patrick and Chiu, Johnathan and Atighehchian, Parmida and Granskog, Jonathan and Germanidis, Anastasis},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={7346--7356},
  year={2023}
}
@article{geyer2023tokenflow,
  title={Tokenflow: Consistent diffusion features for consistent video editing},
  author={Geyer, Michal and Bar-Tal, Omer and Bagon, Shai and Dekel, Tali},
  journal={arXiv preprint arXiv:2307.10373},
  year={2023}
}
@article{pondaven2024video,
  title={Video Motion Transfer with Diffusion Transformers},
  author={Pondaven, Alexander and Siarohin, Aliaksandr and Tulyakov, Sergey and Torr, Philip and Pizzati, Fabio},
  journal={arXiv preprint arXiv:2412.07776},
  year={2024}
}
@article{wang2024videocomposer,
  title={Videocomposer: Compositional video synthesis with motion controllability},
  author={Wang, Xiang and Yuan, Hangjie and Zhang, Shiwei and Chen, Dayou and Wang, Jiuniu and Zhang, Yingya and Shen, Yujun and Zhao, Deli and Zhou, Jingren},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}
@article{pondaven2024video,
  title={Video Motion Transfer with Diffusion Transformers},
  author={Pondaven, Alexander and Siarohin, Aliaksandr and Tulyakov, Sergey and Torr, Philip and Pizzati, Fabio},
  journal={arXiv preprint arXiv:2412.07776},
  year={2024}
}
@inproceedings{yatim2024space,
  title={Space-time diffusion features for zero-shot text-driven motion transfer},
  author={Yatim, Danah and Fridman, Rafail and Bar-Tal, Omer and Kasten, Yoni and Dekel, Tali},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={8466--8476},
  year={2024}
}
@article{park2024spectral,
  title={Spectral motion alignment for video motion transfer using diffusion models},
  author={Park, Geon Yeong and Jeong, Hyeonho and Lee, Sang Wan and Ye, Jong Chul},
  journal={arXiv preprint arXiv:2403.15249},
  year={2024}
}
@article{meral2024motionflow,
  title={MotionFlow: Attention-Driven Motion Transfer in Video Diffusion Models},
  author={Meral, Tuna Han Salih and Yesiltepe, Hidir and Dunlop, Connor and Yanardag, Pinar},
  journal={arXiv preprint arXiv:2412.05275},
  year={2024}
}
% physics-aware
@article{tan2024physmotion,
  title={PhysMotion: Physics-Grounded Dynamics From a Single Image},
  author={Tan, Xiyang and Jiang, Ying and Li, Xuan and Zong, Zeshun and Xie, Tianyi and Yang, Yin and Jiang, Chenfanfu},
  journal={arXiv preprint arXiv:2411.17189},
  year={2024}
}
@inproceedings{xie2024physgaussian,
  title={Physgaussian: Physics-integrated 3d gaussians for generative dynamics},
  author={Xie, Tianyi and Zong, Zeshun and Qiu, Yuxing and Li, Xuan and Feng, Yutao and Yang, Yin and Jiang, Chenfanfu},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={4389--4398},
  year={2024}
}
@inproceedings{jiang2024vr,
  title={Vr-gs: A physical dynamics-aware interactive gaussian splatting system in virtual reality},
  author={Jiang, Ying and Yu, Chang and Xie, Tianyi and Li, Xuan and Feng, Yutao and Wang, Huamin and Li, Minchen and Lau, Henry and Gao, Feng and Yang, Yin and others},
  booktitle={ACM SIGGRAPH 2024 Conference Papers},
  pages={1--1},
  year={2024}
}
@inproceedings{liu2025physgen,
  title={Physgen: Rigid-body physics-grounded image-to-video generation},
  author={Liu, Shaowei and Ren, Zhongzheng and Gupta, Saurabh and Wang, Shenlong},
  booktitle={European Conference on Computer Vision},
  pages={360--378},
  year={2024},
  organization={Springer}
}
@incollection{jiang2016material,
  title={The material point method for simulating continuum materials},
  author={Jiang, Chenfanfu and Schroeder, Craig and Teran, Joseph and Stomakhin, Alexey and Selle, Andrew},
  booktitle={Acm siggraph 2016 courses},
  pages={1--52},
  year={2016}
}
@inproceedings{macklin2016xpbd,
  title={XPBD: position-based simulation of compliant constrained dynamics},
  author={Macklin, Miles and M{\"u}ller, Matthias and Chentanez, Nuttapong},
  booktitle={Proceedings of the 9th International Conference on Motion in Games},
  pages={49--54},
  year={2016}
}
@inproceedings{zhang2025physdreamer,
  title={Physdreamer: Physics-based interaction with 3d objects via video generation},
  author={Zhang, Tianyuan and Yu, Hong-Xing and Wu, Rundi and Feng, Brandon Y and Zheng, Changxi and Snavely, Noah and Wu, Jiajun and Freeman, William T},
  booktitle={European Conference on Computer Vision},
  pages={388--406},
  year={2024},
  organization={Springer}
}
@article{poole2022dreamfusion,
  title={Dreamfusion: Text-to-3d using 2d diffusion},
  author={Poole, Ben and Jain, Ajay and Barron, Jonathan T and Mildenhall, Ben},
  journal={arXiv preprint arXiv:2209.14988},
  year={2022}
}
%object manipulation
@article{chen2023motion,
  title={Motion-conditioned diffusion model for controllable video synthesis},
  author={Chen, Tsai-Shien and Lin, Chieh Hubert and Tseng, Hung-Yu and Lin, Tsung-Yi and Yang, Ming-Hsuan},
  journal={arXiv preprint arXiv:2304.14404},
  year={2023}
}
@article{li2024image,
  title={Image conductor: Precision control for interactive video synthesis},
  author={Li, Yaowei and Wang, Xintao and Zhang, Zhaoyang and Wang, Zhouxia and Yuan, Ziyang and Xie, Liangbin and Zou, Yuexian and Shan, Ying},
  journal={arXiv preprint arXiv:2406.15339},
  year={2024}
}
@article{mou2024revideo,
  title={ReVideo: Remake a Video with Motion and Content Control},
  author={Mou, Chong and Cao, Mingdeng and Wang, Xintao and Zhang, Zhaoyang and Shan, Ying and Zhang, Jian},
  journal={arXiv preprint arXiv:2405.13865},
  year={2024}
}
@article{teng2023drag,
  title={Drag-a-video: Non-rigid video editing with point-based interaction},
  author={Teng, Yao and Xie, Enze and Wu, Yue and Han, Haoyu and Li, Zhenguo and Liu, Xihui},
  journal={arXiv preprint arXiv:2312.02936},
  year={2023}
}
@inproceedings{wu2025draganything,
  title={Draganything: Motion control for anything using entity representation},
  author={Wu, Weijia and Li, Zhuang and Gu, Yuchao and Zhao, Rui and He, Yefei and Zhang, David Junhao and Shou, Mike Zheng and Li, Yan and Gao, Tingting and Zhang, Di},
  booktitle={European Conference on Computer Vision},
  pages={331--348},
  year={2024},
  organization={Springer}
}
@article{yin2023dragnuwa,
  title={Dragnuwa: Fine-grained control in video generation by integrating text, image, and trajectory},
  author={Yin, Shengming and Wu, Chenfei and Liang, Jian and Shi, Jie and Li, Houqiang and Ming, Gong and Duan, Nan},
  journal={arXiv preprint arXiv:2308.08089},
  year={2023}
}
@article{wang2024objctrl,
  title={ObjCtrl-2.5 D: Training-free Object Control with Camera Poses},
  author={Wang, Zhouxia and Lan, Yushi and Zhou, Shangchen and Loy, Chen Change},
  journal={arXiv preprint arXiv:2412.07721},
  year={2024}
}
@inproceedings{jain2024peekaboo,
  title={Peekaboo: Interactive video generation via masked-diffusion},
  author={Jain, Yash and Nasery, Anshul and Vineet, Vibhav and Behl, Harkirat},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={8079--8088},
  year={2024}
}
@inproceedings{ma2024trailblazer,
  title={Trailblazer: Trajectory control for diffusion-based video generation},
  author={Ma, Wan-Duo Kurt and Lewis, John P and Kleijn, W Bastiaan},
  booktitle={SIGGRAPH Asia 2024 Conference Papers},
  pages={1--11},
  year={2024}
}
@article{qiu2024freetraj,
  title={Freetraj: Tuning-free trajectory control in video diffusion models},
  author={Qiu, Haonan and Chen, Zhaoxi and Wang, Zhouxia and He, Yingqing and Xia, Menghan and Liu, Ziwei},
  journal={arXiv preprint arXiv:2406.16863},
  year={2024}
}
@article{wang2024boximator,
  title={Boximator: Generating rich and controllable motions for video synthesis},
  author={Wang, Jiawei and Zhang, Yuchen and Zou, Jiaxin and Zeng, Yan and Wei, Guoqiang and Yuan, Liping and Li, Hang},
  journal={arXiv preprint arXiv:2402.01566},
  year={2024}
}
@inproceedings{yang2024direct,
  title={Direct-a-video: Customized video generation with user-directed camera movement and object motion},
  author={Yang, Shiyuan and Hou, Liang and Huang, Haibin and Ma, Chongyang and Wan, Pengfei and Zhang, Di and Chen, Xiaodong and Liao, Jing},
  booktitle={ACM SIGGRAPH 2024 Conference Papers},
  pages={1--12},
  year={2024}
}
%mesh 
@inproceedings{cao2023texfusion,
  title={Texfusion: Synthesizing 3d textures with text-guided image diffusion models},
  author={Cao, Tianshi and Kreis, Karsten and Fidler, Sanja and Sharp, Nicholas and Yin, Kangxue},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={4169--4181},
  year={2023}
}
@inproceedings{richardson2023texture,
  title={Texture: Text-guided texturing of 3d shapes},
  author={Richardson, Elad and Metzer, Gal and Alaluf, Yuval and Giryes, Raja and Cohen-Or, Daniel},
  booktitle={ACM SIGGRAPH 2023 conference proceedings},
  pages={1--11},
  year={2023}
}
@article{wang2023breathing,
  title={Breathing new life into 3d assets with generative repainting},
  author={Wang, Tianfu and Kanakis, Menelaos and Schindler, Konrad and Van Gool, Luc and Obukhov, Anton},
  journal={arXiv preprint arXiv:2309.08523},
  year={2023}
}
@inproceedings{cai2024generative,
  title={Generative rendering: Controllable 4d-guided video generation with 2d diffusion models},
  author={Cai, Shengqu and Ceylan, Duygu and Gadelha, Matheus and Huang, Chun-Hao Paul and Wang, Tuanfeng Yang and Wetzstein, Gordon},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={7611--7620},
  year={2024}
}
% similar works - motion related
@inproceedings{shi2024motion,
  title={Motion-i2v: Consistent and controllable image-to-video generation with explicit motion modeling},
  author={Shi, Xiaoyu and Huang, Zhaoyang and Wang, Fu-Yun and Bian, Weikang and Li, Dasong and Zhang, Yi and Zhang, Manyuan and Cheung, Ka Chun and See, Simon and Qin, Hongwei and others},
  booktitle={SIGGRAPH},
  year={2024}
} % 2D flow guidance
@article{koroglu2024onlyflow,
  title={OnlyFlow: Optical Flow based Motion Conditioning for Video Diffusion Models},
  author={Koroglu, Mathis and Caselles-Dupr{\'e}, Hugo and Sanmiguel, Guillaume Jeanneret and Cord, Matthieu},
  journal={arXiv preprint arXiv:2411.10501},
  year={2024}
} % 2D flow guidance
@inproceedings{niu2025mofa,
  title={Mofa-video: Controllable image animation via generative motion field adaptions in frozen image-to-video diffusion model},
  author={Niu, Muyao and Cun, Xiaodong and Wang, Xintao and Zhang, Yong and Shan, Ying and Zheng, Yinqiang},
  booktitle={ECCV},
  year={2024}
} % warping feature
@article{lei2024animateanything,
  title={AnimateAnything: Consistent and Controllable Animation for Video Generation},
  author={Lei, Guojun and Wang, Chi and Li, Hong and Zhang, Rong and Wang, Yikai and Xu, Weiwei},
  journal={arXiv preprint arXiv:2411.10836},
  year={2024}
} % predict 2D flow

@article{geng2024motion,
  title={Motion Prompting: Controlling Video Generation with Motion Trajectories},
  author={Geng, Daniel and Herrmann, Charles and Hur, Junhwa and Cole, Forrester and Zhang, Serena and Pfaff, Tobias and Lopez-Guevara, Tatiana and Doersch, Carl and Aytar, Yusuf and Rubinstein, Michael and others},
  journal={arXiv preprint arXiv:2412.02700},
  year={2024}
}% motion prompting
@article{xiao2024trajectory,
  title={Trajectory Attention for Fine-grained Video Motion Control},
  author={Xiao, Zeqi and Ouyang, Wenqi and Zhou, Yifan and Yang, Shuai and Yang, Lei and Si, Jianlou and Pan, Xingang},
  journal={arXiv preprint arXiv:2411.19324},
  year={2024}
} % implicit motion learning with attention
@article{feng2024i2vcontrol,
  title={I2VControl: Disentangled and Unified Video Motion Synthesis Control},
  author={Feng, Wanquan and Qi, Tianhao and Liu, Jiawei and Sun, Mingzhen and Tu, Pengqi and Ma, Tianxiang and Dai, Fei and Zhao, Songtao and Zhou, Siyu and He, Qian},
  journal={arXiv preprint arXiv:2411.17765},
  year={2024}
}% manipulate 2D patches
@article{jeong2024track4gen,
  title={Track4Gen: Teaching Video Diffusion Models to Track Points Improves Video Generation},
  author={Jeong, Hyeonho and Huang, Chun-Hao Paul and Ye, Jong Chul and Mitra, Niloy and Ceylan, Duygu},
  journal={arXiv preprint arXiv:2412.06016},
  year={2024}
}%train with tracking








@article{bochkovskii2024depth,
  title={Depth pro: Sharp monocular metric depth in less than a second},
  author={Bochkovskii, Aleksei and Delaunoy, Ama{\"e}l and Germain, Hugo and Santos, Marcel and Zhou, Yichao and Richter, Stephan R and Koltun, Vladlen},
  journal={arXiv preprint arXiv:2410.02073},
  year={2024}
}
@article{ranftl2020towards,
  title={Towards robust monocular depth estimation: Mixing datasets for zero-shot cross-dataset transfer},
  author={Ranftl, Ren{\'e} and Lasinger, Katrin and Hafner, David and Schindler, Konrad and Koltun, Vladlen},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={44},
  number={3},
  pages={1623--1637},
  year={2020},
  publisher={IEEE}
}
@article{lu2024align3r,
  title={Align3R: Aligned Monocular Depth Estimation for Dynamic Videos},
  author={Lu, Jiahao and Huang, Tianyu and Li, Peng and Dou, Zhiyang and Lin, Cheng and Cui, Zhiming and Dong, Zhen and Yeung, Sai-Kit and Wang, Wenping and Liu, Yuan},
  journal={arXiv preprint arXiv:2412.03079},
  year={2024}
}
@inproceedings{xiao2024spatialtracker,
  title={SpatialTracker: Tracking Any 2D Pixels in 3D Space},
  author={Xiao, Yuxi and Wang, Qianqian and Zhang, Shangzhan and Xue, Nan and Peng, Sida and Shen, Yujun and Zhou, Xiaowei},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={20406--20417},
  year={2024}
}

@misc{flux,
  title={FLUX},
  author={Black Forest Labs},
  url={https://github.com/black-forest-labs/flux},
  year={2024}
}

@inproceedings{zhang2023adding,
  title={Adding conditional control to text-to-image diffusion models},
  author={Zhang, Lvmin and Rao, Anyi and Agrawala, Maneesh},
  booktitle={ICCV},
  pages={3836--3847},
  year={2023}
}

@misc{ju2024miradatalargescalevideodataset,
      title={MiraData: A Large-Scale Video Dataset with Long Durations and Structured Captions}, 
      author={Xuan Ju and Yiming Gao and Zhaoyang Zhang and Ziyang Yuan and Xintao Wang and Ailing Zeng and Yu Xiong and Qiang Xu and Ying Shan},
      year={2024},
      eprint={2407.06358},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2407.06358}, 
}

@article{Pont-Tuset_arXiv_2017,
  author = {Jordi Pont-Tuset and Federico Perazzi and Sergi Caelles and Pablo Arbel\'aez and Alexander Sorkine-Hornung and Luc {Van Gool}},
  title = {The 2017 DAVIS Challenge on Video Object Segmentation},
  journal = {arXiv:1704.00675},
  year = {2017}
}

@ARTICLE{1284395,
  author={Zhou Wang and Bovik, A.C. and Sheikh, H.R. and Simoncelli, E.P.},
  journal={IEEE Transactions on Image Processing}, 
  title={Image quality assessment: from error visibility to structural similarity}, 
  year={2004},
  volume={13},
  number={4},
  pages={600-612},
  keywords={Image quality;Humans;Transform coding;Visual system;Visual perception;Data mining;Layout;Quality assessment;Degradation;Indexes},
  doi={10.1109/TIP.2003.819861}}

@misc{zhang2018unreasonableeffectivenessdeepfeatures,
      title={The Unreasonable Effectiveness of Deep Features as a Perceptual Metric}, 
      author={Richard Zhang and Phillip Isola and Alexei A. Efros and Eli Shechtman and Oliver Wang},
      year={2018},
      eprint={1801.03924},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1801.03924}, 
}

@misc{unterthiner2019accurategenerativemodelsvideo,
      title={Towards Accurate Generative Models of Video: A New Metric \& Challenges}, 
      author={Thomas Unterthiner and Sjoerd van Steenkiste and Karol Kurach and Raphael Marinier and Marcin Michalski and Sylvain Gelly},
      year={2019},
      eprint={1812.01717},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1812.01717}, 
}

@misc{ccedit,
      title={CCEdit: Creative and Controllable Video Editing via Diffusion Models}, 
      author={Ruoyu Feng and Wenming Weng and Yanhui Wang and Yuhui Yuan and Jianmin Bao and Chong Luo and Zhibo Chen and Baining Guo},
      year={2024},
      eprint={2309.16496},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2309.16496}, 
}

@misc{tokenflow,
      title={TokenFlow: Consistent Diffusion Features for Consistent Video Editing}, 
      author={Michal Geyer and Omer Bar-Tal and Shai Bagon and Tali Dekel},
      year={2023},
      eprint={2307.10373},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2307.10373}, 
}

@misc{hessel2022clipscorereferencefreeevaluationmetric,
      title={CLIPScore: A Reference-free Evaluation Metric for Image Captioning}, 
      author={Jack Hessel and Ari Holtzman and Maxwell Forbes and Ronan Le Bras and Yejin Choi},
      year={2022},
      eprint={2104.08718},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2104.08718}, 
}

@misc{radford2021learningtransferablevisualmodels,
      title={Learning Transferable Visual Models From Natural Language Supervision}, 
      author={Alec Radford and Jong Wook Kim and Chris Hallacy and Aditya Ramesh and Gabriel Goh and Sandhini Agarwal and Girish Sastry and Amanda Askell and Pamela Mishkin and Jack Clark and Gretchen Krueger and Ilya Sutskever},
      year={2021},
      eprint={2103.00020},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2103.00020}, 
}

@misc{zhu2024champ,
      title={Champ: Controllable and Consistent Human Image Animation with 3D Parametric Guidance}, 
      author={Shenhao Zhu and Junming Leo Chen and Zuozhuo Dai and Yinghui Xu and Xun Cao and Yao Yao and Hao Zhu and Siyu Zhu},
      year={2024},
      eprint={2403.14781},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{kirillov2023segment,
  title={Segment anything},
  author={Kirillov, Alexander and Mintun, Eric and Ravi, Nikhila and Mao, Hanzi and Rolland, Chloe and Gustafson, Laura and Xiao, Tete and Whitehead, Spencer and Berg, Alexander C and Lo, Wan-Yen and others},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={4015--4026},
  year={2023}
}

@misc{peebles2023scalablediffusionmodelstransformers,
      title={Scalable Diffusion Models with Transformers}, 
      author={William Peebles and Saining Xie},
      year={2023},
      eprint={2212.09748},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2212.09748}, 
}


@article{song2020denoising,
  title={Denoising diffusion implicit models},
  author={Song, Jiaming and Meng, Chenlin and Ermon, Stefano},
  journal={arXiv preprint arXiv:2010.02502},
  year={2020}
}
@article{chen2023videocrafter1,
  title={Videocrafter1: Open diffusion models for high-quality video generation},
  author={Chen, Haoxin and Xia, Menghan and He, Yingqing and Zhang, Yong and Cun, Xiaodong and Yang, Shaoshu and Xing, Jinbo and Liu, Yaofang and Chen, Qifeng and Wang, Xintao and others},
  journal={arXiv preprint arXiv:2310.19512},
  year={2023}
}
@article{xing2024tooncrafter,
  title={Tooncrafter: Generative cartoon interpolation},
  author={Xing, Jinbo and Liu, Hanyuan and Xia, Menghan and Zhang, Yong and Wang, Xintao and Shan, Ying and Wong, Tien-Tsin},
  journal={ACM Transactions on Graphics (TOG)},
  volume={43},
  number={6},
  pages={1--11},
  year={2024},
  publisher={ACM New York, NY, USA}
}
@inproceedings{xing2025dynamicrafter,
  title={Dynamicrafter: Animating open-domain images with video diffusion priors},
  author={Xing, Jinbo and Xia, Menghan and Zhang, Yong and Chen, Haoxin and Yu, Wangbo and Liu, Hanyuan and Liu, Gongye and Wang, Xintao and Shan, Ying and Wong, Tien-Tsin},
  booktitle={European Conference on Computer Vision},
  pages={399--417},
  year={2024},
  organization={Springer}
}
@inproceedings{chen2024videocrafter2,
  title={Videocrafter2: Overcoming data limitations for high-quality video diffusion models},
  author={Chen, Haoxin and Zhang, Yong and Cun, Xiaodong and Xia, Menghan and Wang, Xintao and Weng, Chao and Shan, Ying},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={7310--7320},
  year={2024}
}
@inproceedings{ma2024follow,
  title={Follow your pose: Pose-guided text-to-video generation using pose-free videos},
  author={Ma, Yue and He, Yingqing and Cun, Xiaodong and Wang, Xintao and Chen, Siran and Li, Xiu and Chen, Qifeng},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={5},
  pages={4117--4125},
  year={2024}
}
@article{he2022latent,
  title={Latent video diffusion models for high-fidelity long video generation},
  author={He, Yingqing and Yang, Tianyu and Zhang, Yong and Shan, Ying and Chen, Qifeng},
  journal={arXiv preprint arXiv:2211.13221},
  year={2022}
}
@article{qiu2024freetraj,
  title={Freetraj: Tuning-free trajectory control in video diffusion models},
  author={Qiu, Haonan and Chen, Zhaoxi and Wang, Zhouxia and He, Yingqing and Xia, Menghan and Liu, Ziwei},
  journal={arXiv preprint arXiv:2406.16863},
  year={2024}
}
@article{guo2023animatediff,
  title={Animatediff: Animate your personalized text-to-image diffusion models without specific tuning},
  author={Guo, Yuwei and Yang, Ceyuan and Rao, Anyi and Liang, Zhengyang and Wang, Yaohui and Qiao, Yu and Agrawala, Maneesh and Lin, Dahua and Dai, Bo},
  journal={arXiv preprint arXiv:2307.04725},
  year={2023}
}
@incollection{loper2023smpl,
  title={SMPL: A skinned multi-person linear model},
  author={Loper, Matthew and Mahmood, Naureen and Romero, Javier and Pons-Moll, Gerard and Black, Michael J},
  booktitle={Seminal Graphics Papers: Pushing the Boundaries, Volume 2},
  pages={851--866},
  year={2023}
}

@misc{wang2024mogeunlockingaccuratemonocular,
      title={MoGe: Unlocking Accurate Monocular Geometry Estimation for Open-Domain Images with Optimal Training Supervision}, 
      author={Ruicheng Wang and Sicheng Xu and Cassie Dai and Jianfeng Xiang and Yu Deng and Xin Tong and Jiaolong Yang},
      year={2024},
      eprint={2410.19115},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2410.19115}, 
}
@article{zhang2024protracker,
    title={ProTracker: Probabilistic Integration for Robust and Accurate Point Tracking},
    author={Tingyang Zhang and Chen Wang and Zhiyang Dou and Qingzhe Gao, Jiahui Lei and Baoquan Chen and Lingjie Liu},
    journal={arXiv preprint arxiv:2501.03220},
    year={2025}
}
@inproceedings{chen2025pixart,
  title={PIXART-Sigma: Weak-to-Strong Training of Diffusion Transformer for 4K Text-to-Image Generation},
  author={Chen, Junsong and Ge, Chongjian and Xie, Enze and Wu, Yue and Yao, Lewei and Ren, Xiaozhe and Wang, Zhongdao and Luo, Ping and Lu, Huchuan and Li, Zhenguo},
  booktitle={European Conference on Computer Vision},
  pages={74--91},
  year={2024},
  organization={Springer}
}
@article{zhang2024world,
  title={World-consistent Video Diffusion with Explicit 3D Modeling},
  author={Zhang, Qihang and Zhai, Shuangfei and Bautista, Miguel Angel and Miao, Kevin and Toshev, Alexander and Susskind, Joshua and Gu, Jiatao},
  journal={arXiv preprint arXiv:2412.01821},
  year={2024}
}