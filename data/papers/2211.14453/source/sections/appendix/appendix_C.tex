\section{Properties of Frequency Domain Models}
%
\subsection{Preliminary Results}
%
\begin{lemma}[Finite cosine series convergence] \label{lem:finite-cosine-series-simple}
    Let $k\in \mathbb{N}^+$, $N\in \mathbb{N}^+$ with $N \geq 2$. The following holds
    \begin{equation}
    \sum_{n=0}^{N-1} \cos(\frac{2 \pi k n}{N}) = 0.
    \end{equation}
\end{lemma}
\proof

Let us substitute $z = \frac{2 \pi k}{N}$ for simplicity. We can rewrite the finite series as follows

\begin{equation}
    y = \sum_{n=0}^{N-1} \cos(z n) = \cos(z \cdot 0) + \cos(z \cdot 1) + \dots + \cos(z (N-1)).
\end{equation}

By multiplying both sides of the equation by $2 \sin(z)$ we obtain

\begin{equation}
    \label{eq:cosine-series-expanded}
    2 \sin(z) y = 2 \cos(z \cdot 0) \sin(z) + 2 \cos(z \cdot  1) \sin(z) + \dots + 2 \cos(z (N-1)) \sin(z).
\end{equation}

By applying the following trigonometric identity

\begin{equation}
    2 \cos(\alpha) \sin(\beta) = \sin(\alpha + \beta) - \sin(\alpha - \beta),
\end{equation}

Equation \eqref{eq:cosine-series-expanded} becomes
\begin{equation}
    \begin{aligned}
    2 \sin(z) y =& ~2 \sin(z)\\
    &+ \sin(z + z) - \sin(z - z) \\
    &+ \sin(2z + z) - \sin(2z - z) \\
    &+ \sin(3z + z) - \sin(3z - z) \\
    &+ \dots \\
    &+ \sin((N-1)z + z) - \sin((N-1)z - z) \\
    \end{aligned}
\end{equation}

where terms on the right-hand side cancel out pairwise\footnote{Alternatively, we could think about the finite cosine series itself as the summation of $N$ cosine terms on a circle with terms from $0$ up to $N-1$ -- scaled by $k$, which does not affect the result. The cosine terms then cancel out in a pair--wise fashion (or in triplets, depending on even or odd $N$).}. After cleanup, we are left with the following 

\begin{equation}
    \begin{aligned}
        2 \sin(z) y =&  \sin(z) + \sin((N-1)z) + \sin(N z).
    \end{aligned}
\end{equation}

By substituting back $z = \frac{2 \pi k}{N}$ we obtain

\begin{equation}
    \begin{aligned}
        2 \sin(\frac{2 \pi k}{N}) \cdot y =&  \sin(\frac{2 \pi k}{N}) + \sin((N-1)\frac{2 \pi k}{N}) + \sin(N \frac{2 \pi k}{N})\\
        =&  \cancel{\sin(\frac{2 \pi k}{N})} - \cancel{\sin(\frac{2 \pi k}{N})} + \cancelto{0}{\sin(2 \pi k)},
    \end{aligned}
\end{equation}

where we used the trigonometric identity $\sin(-\alpha) = - \sin(\alpha)$. After dividing by the factor $ 2 \sin(\frac{2 \pi k}{N})$, we readily obtain the result $y = 0$.

\endproof
%
\begin{lemma}[Finite squared cosine series convergence] \label{lem:finite-cosine-series-squared}
    Let $k\in \mathbb{N}^+$, $N\in \mathbb{N}^+$ with $N \geq 2$. The following holds
    \begin{equation}
    \sum_{n=0}^{N-1} \cos^2 \left( \frac{2 \pi k n}{N} \right) = \frac{N}{2}.
    \end{equation}
\end{lemma}
\proof
We recall the following trigonometric identity

\begin{equation}
    \cos^2(\alpha) = \frac{1 + \cos(2\alpha)}{2}.
\end{equation}

Let us substitute $z = \frac{2 \pi k}{N}$ for simplicity. We can thus rewrite the finite series as follows

\begin{equation}
    \begin{aligned}
    \sum_{n=0}^{N-1}  \cos^2(z n )  &= \sum_{n=0}^{N-1} \frac{1 + \cos( 2 z n )}{2} \\
    &= \frac{1 + \cos(2 z \cdot 0)}{2} + \frac{1 + \cos(2 z \cdot 1)}{2} + \dots + \frac{1 + \cos(2 z (N-1))}{2} \\
    &= \frac{N}{2} + \frac{1}{2}  \left[ \cos(2 z \cdot 0) + \cos(2 z \cdot 1) + \dots + \cos(2 z (N-1)) \right] \\
    &= \frac{N}{2} + \cancelto{0}{\frac{1}{2} \sum_{n=0}^{N-1} \cos(2 z t)} \quad \text{(from Lemma \ref{lem:finite-cosine-series-simple})}\\
    &= \frac{N}{2}.
    \end{aligned}
\end{equation}
\endproof

%

\subsection{Statistics Under Fourier Transform}
%
There are various ways to show how probability measures and moments propagated under frequency domain transforms. We showcase two additional proof methods based on change of variables or explicit computation for simple input distributions.

\begin{lemma}[Central moment preservation under unitary linear operators]\label{pres}
    Let $x\sim p_x(x)$, $x\in\bC$ and let $\cT$ be a unitary linear operator. With $X = \cT(x)$, it holds
    %
    \[
        p_X(X) = p_x(\cT^{-1}(X))
    \]
    %
\end{lemma}
\proof
    The result follows immediately from the change of variables formula
    %
    \[
        \begin{aligned}
            p_X(X) &= p_x(\cT^{-1}(X))\det \left[\frac{\dd}{\dd X}\cT^{-1}(X)\right]\\
            & = p_x(x),
        \end{aligned}
    \]
    %
    being $\partial_X\cT(X)$ the Jacobian of $\cT$, since 
    $$\det\frac{\dd}{\dd X}\cT^{-1}(X) = \det\frac{\dd}{\dd X}\cT(X) = 1.$$
\endproof
%

%boh
%\begin{tcolorbox}[enhanced, colback=green!5, breakable, drop fuzzy shadow, frame hidden]
%
\begin{lemma}[Variance preservation under unitary linear operators]\label{explicit_vp}
Let $x\in\R^N$ be a random vector with 
%
\[
    \bE[x] = \0, \quad~ \mathbb{V}[x] = \sigma^2 \Id.
\]
with $\cT$ a normalized DFT. If $X = \cT(x)$, it holds
    %
    \[
        \forall k,n: \quad \bE[X_k] = \bE[x_n] = 0 \quad \text{and} \quad \bV[X_k] = \bV[x_n] = \sigma^2
    \]
\end{lemma}
\proof

Let $x$ be real-valued input and distributed according to
\[
p_{\Re(x)} = \mathcal{N}(0, \sigma^2 \Id) \quad p_{\Im(x)} = \delta(\0).
\]

Consider a single element of $X$ 
\[
    X_k = \sum_{n=0}^{N-1} v_n
\]
with 
%
\[
    v_n = \frac{1}{\sqrt{N}}e^{\frac{2\pi jnk}{N}}x_n = \frac{1}{\sqrt{N}}\cos \frac{2\pi nk}{N}x_n + j\frac{1}{\sqrt{N}}\sin\frac{2\pi nk}{N}x_n.
\]
%
For clarity, we will treat the real part $\Re(X_k)$ first. 
%
\[
    \Re(v_n) = \frac{1}{\sqrt{N}}\cos \frac{2\pi nk}{N} \Re(x_n) 
\]
%
and 
%
\[
    \begin{aligned}
        \bE[v_n] &= \frac{1}{N} \cos^2{\frac{2\pi nk}{N}}\mathbb{E}[x_n] = 0\\
        \mathbb{V}[v_n] &= \frac{1}{N} \cos^2{\frac{2\pi nk}{N}}\mathbb{V}[x_n] = \frac{\sigma^2}{N} \cos^2{\frac{2\pi nk}{N}}  
    \end{aligned}
\]
%
where we have used the fact that 
%
\[
    \frac{1}{\sqrt{N}}\sin\frac{2\pi nk}{N}\Im(x_n) = 0.
\]
%
Thus,
%
\[
    \begin{aligned}
        \bE[\Re(X_k)] &= 0\\
        \mathbb{V}[\Re(X_k)] &= \sum_{n=0}^{N-1}\frac{\sigma^2}{N} \cos^2{\frac{2\pi nk}{N}}
    \end{aligned}
\]
%
We observe that (a) the first central moment is preserved and (b) the variance term can be simplified as 
%
\[
    \begin{aligned}
    \mathbb{V}[\Re(X_k)] &= \sum_{n=0}^{N-1}\frac{\sigma^2}{N} \cos^2{\frac{2\pi nk}{N}} \\
    &=\frac{\sigma^2}{N}\sum_{n=0}^{N-1} \cos^2{\frac{2\pi nk}{N}} \\
    &= \frac{\sigma^2}{N}\frac{N}{2}\quad \text{(from Lemma \ref{lem:finite-cosine-series-squared})} \\
    &= \frac{\sigma^2}{2}
    \end{aligned}
\]
%
We follow a similar procedure for $\Im(X_k)$, arriving at
%
\[
    \begin{aligned}
        \bE[\Im(X_k)] &= 0\\
        \mathbb{V}[\Im(X_k)] &= \sum_{n=0}^{N-1}\frac{\sigma^2}{N} \sin^2{\frac{2\pi nk}{N}}
    \end{aligned}
\]
%
where the variance again simplifies to
%
\[
    \sum_{n=0}^{N-1}\frac{\sigma^2}{N} \sin^2{\frac{2\pi nk}{N}} = \frac{\sigma^2}{2}
\]

Since $X_k = \Re(X_k) + j\Im(X_k)$,  
%
\[
    \begin{aligned}
        \bE[X_k] &= \bE[\Re(X_k)] + j\bE[\Im(X_k)] = 0 + j0 = 0\\
        \mathbb{V}[X_k] &= \bV[\Re(X_k)] + \bV[\Im(X_k)] = \sigma^2
    \end{aligned}
\]
%
% $$
% p_{X_k} = \mathcal{N}(0, \sigma^2) \implies p_{Z} = \mathcal{N}(0, \sigma^2 I_{n_x})
% $$
\endproof

A similar argument can be developed using basic properties of circular-symmetry of complex Normals.

% $$
% p_{\Im(X_k)} = \mathcal{N}(0, \sum_{t=0}^{T-1}\frac{\sigma^2 \sin^2{(\frac{2\pi k t}{T})}}{T})
% $$


It is critical that the normalization factor $\frac{1}{\sqrt{N}}$ be included in $W$ in order to preserve the variance of $\mathbb{V}[X]$.

Indeed, normalization factors used in different conventions lead to different results
$$
\begin{aligned}
&\textsf{forward factor}~~\frac{1}{N} \implies \mathbb{V}[X_k] = \frac{\sigma^2}{N} \\
&\textsf{backward factor}~~1 \implies \mathbb{V}[X_k] = N \sigma^2
    \end{aligned}
$$
As $N$ can easily be in the order of hundreds or thousands for generic signals, explosion of variance can be an issue if the orthogonalization factor $\frac{1}{\sqrt{N}}$ is not applied to $W$.
%
