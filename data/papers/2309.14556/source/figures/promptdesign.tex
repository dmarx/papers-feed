\section{Converting expert questions to quantifiable Natural language instructions} \label{sec:prompting}

\begin{table*}[!h]
\centering
\small
\def\arraystretch{1.15}
\begin{tabular}{|l|l|}
\hline
\begin{tabular}[c]{@{}l@{}}Expert \\ Measure\end{tabular}               & Does the writer make the fictional world believable at the sensory level?                                                                                                                                     \\ \hline
\begin{tabular}[c]{@{}l@{}}Expanded\\ Expert\\ Measure (M)\end{tabular} & \begin{tabular}[c]{@{}l@{}}Sensory details pertain to the five senses - sight, sound, touch, taste, and smell. An effective \\ writer can use these elements to paint a detailed picture of the story's environment, making\\ it feel tangible and real to the reader.\\ \\ For example, describing the specific colors and shapes in a scene, the sounds that fill a space,the \\ textures and temperatures that a character comes into contact with, the flavors of the food they \\ eat, or the scents that fill the air, can all contribute to creating a sensory-rich and believable world.\\ \\ By stimulating the reader's senses, the writer can make the reader feel as though they're \\ experiencing the events of the story firsthand.This level of detail contributes to the believability of\\ the world, even if it's a completely fictional or fantastical setting. It helps the reader to suspend\\ disbelief and become more deeply invested in the narrative.\end{tabular} \\ \hline
\begin{tabular}[c]{@{}l@{}}Human\\ Instruction\end{tabular}             & \begin{tabular}[c]{@{}l@{}}\{\{M\}\}\\ \\ Based on the story that you just read, answer the following question.\\ \textit{\color{blue}Does the writer make the fictional world believable at the sensory level?}\end{tabular}                                                                       \\ \hline
\begin{tabular}[c]{@{}l@{}}LLM\\ Instruction\end{tabular}               & \begin{tabular}[c]{@{}l@{}}\{\{M\}\}\\ \\ Given the story above, list out the elements in the story that call to each of the\\ five senses. Then overall, give your reasoning about the question below and give\\ an answer to it between 'Yes' or 'No' only\\ \\ \textit{\color{blue} Q) Does the writer make the fictional world believable at the sensory level?}\end{tabular}                                                                                                                                                                                                                                 \\ \hline
\end{tabular}
\vspace{2ex}
\caption{\label{prompting}Expert suggested question for World Building and setting (Row1) ; Elucidated prompt designed for other expert humans (Row2); Elucidated quantifiable prompt designed for Large Language Models that elicit Chain of Thought Reasoning(Row3) }
\vspace{-5ex}
\end{table*}

An expert suggested questions for empirically evaluating creative writing might frequently elicit ambiguity in Large Language Models or even other creative writing experts. In order for LLMs or other experts to comprehend the suggested questions in Table \ref{CreativityTest} we attempt at expanding them by adding more details. Recent pre-trained LLMs (e.g., GPT-4 \cite{OpenAI2023GPT4TR} GPT3.5 \cite{ChatGPT}) can engage in fluent, multi-turn conversations out of the box, substantially lowering the data and programming-skill barriers to creating passable conversational user experiences. People can improve LLM outputs by prepending prompts—textual instructions and examples of their desired interactions—to LLM inputs. The prompts steer the model towards generating the desired outputs, raising the ceiling of what conversational UX is achievable for non-AI experts.To elucidate these questions we prompt GPT4 with the following instruction \textit{What do creative experts mean when they say the following: \{\{expert question\}\}}. Once GPT4 gives a response 3 domain experts carefully verify the response and edit it where required in order to convert it into a detailed natural language instruction. Table \ref{prompting} (Row2) shows the human-verified GPT4 elucidated instruction in response to the input prompt.

Prior work \cite{wei2022chain} has shown how generating a \textit{chain of thought} -- a series of intermediate reasoning steps -- significantly improves the ability of large language models to perform complex reasoning. Taking advantage of this we design the prompts for large language models in a slightly different fashion as that of expert humans as can be seen in Table \ref{prompting}. To help the model make an informed decision we first ask it to list out elements specific to any given test such as ``elements in the story that call to each of the five senses" for the World Building and setting test followed by asking it decide overall and then provide its reasoning before choosing an answer between `Yes' or `No'.More examples of Human and LLM instructions for the remaining 13 tests are provided in Appendix \ref{appendix}