\section{Limitations and Future Work}

\paragraph{Response Diversity and Temperature.} In our experimental design, we employed the default generation parameters for the models, specifically a temperature setting, ($T=1.0$), aiming to evaluate the model's capabilities in a non-optimized setting. Notably, variations in parameters such as temperature have been documented to potentially enhance the originality of generated content \cite{roemmele2018automated}. Consequently, there exists a possibility that utilizing alternative generation parameters might lead to outputs that surpass a greater fraction of the TTCW. As the associated costs of conducting TTCW evaluations decrease, subsequent research endeavors could provide a more comprehensive insight into the influence of generation parameters on creativity within the context of the TTCW framework.

\paragraph{Coverage of the TTCW}
When selecting which expert measures would yield a TTCW test, we attempted to maximize coverage while minimizing overlap between the tests. Yet it is very likely that the passing of a test is correlated with another test, as the tests touch on common story elements (e.g., characters, prose). We did not investigate the degree of overlap between pairs of tests. We encourage future work to further refine the TTCW tests and propose additional tests.

\paragraph{Prompt Engineering and Optimization.}
We open-source the prompts used to instruct the LLMs to generate the stories as well as prompts to administer the TTCW tests, which we iterated on and reviewed carefully. While there is no upper bound on engineering the `best' prompt for a particular task, the output of an LLM is still dependent on the input prompt \cite{zhou2022large}. The LLMs that we evaluate in the study are closed-source models and the quality of their generation has been observed to change over time \cite{chen2023chatgpt}. We hope future work can explore further refining of the prompts and parameters used in our work, and exploring their impact on the results.

\paragraph{Generalization beyond short fictional stories.}
Our tests were explicitly designed for short fiction and we do not study the generalization of TTCW to other forms of creative writing. Empirical evaluation would need to be conducted to verify whether the TTCW is adequate and comprehensive to evaluate other forms of creative writing, including scripts, novels, or marketing material such as slogans. We posit there are specific metrics for each specific type of creative writing, which our current tests do not cover. For example, evaluating or critiquing poetry might require different fine-grained evaluation metrics compared to short stories. 

\paragraph{Objectivity in the Evaluation of Creativity.}
Creativity emerges over time in a complex interplay of factors. Human judgments of creativity are often biased by personal tastes, expectations, and hindsight. The definition of an `expert' or `amateur' creative writer is not clear-cut in a field that has unclear professional delineations \cite{gero2023social}. Many successful writers retain full-time jobs as teachers, editors, or in unrelated professions, as few are able to make a living from their writing alone. Although we emphasize the validity of our results by computing agreement levels among recruited experts, we note that work in creativity should not solely aim to maximize agreement, since subjective differences are an inherent property of divergent thinking, which is central to creativity. Future work looking to expand our line of work should seek to select experts with diverse backgrounds, offering a more comprehensive view of the creative process.