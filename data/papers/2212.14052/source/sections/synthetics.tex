\section{Synthetic Language Modeling Tasks}
\input{tables/synthetic_tasks.tex}
We describe two synthetic tasks we use to understand the gap between SSMs and attention in language modeling, summarized in Table~\ref{table:synthetic_tasks}. The \textbf{Induction Head} task, inspired by the analysis of~\citet{olsson2022context}, tests how well a model can recall content after a special token.
At the end of the sequence, the model recall the token that appeared immediately after a special token earlier in the sequence. \textbf{Associative Recall}~\citep{ba2016using} tests how well a model can associate specific values to keys. The model is shown a series of key-value pairs, and must recall an associated value at the end.

\input{tables/synthetics.tex}
Table~\ref{table:synthetics} shows the performance of two-layer GPT-style models with attention or continuous SSMs on these synthetic tasks.
These failures suggest two missing capabilities: to remember tokens that appear after a particular event (e.g., the special token in the induction head task), and to compare tokens across the sequence (e.g., comparing keys to decide which value to recall).
In Section~\ref{sec:method}, we design our new layer \hthree to capture these capabilities.