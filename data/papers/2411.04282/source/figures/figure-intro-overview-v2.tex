\begin{figure}[htbp]
    \begin{tikzpicture}[scale=1]
        \node[anchor=north west] (query) at (0,0) {
            \begin{tcolorbox}[colback=white, colframe=gray, width=2.5cm, arc=1mm, auto outer arc, fontupper=\color{black}\scriptsize, boxsep=0.5mm, left=0.5mm, right=0.5mm, top=0.5mm, bottom=0.5mm]
                \centering
                \textbf{Question} $\px$
            \end{tcolorbox}
        };
        \node[anchor=west] (model) at ([shift={(0.3, 0)}]query.east){
            \begin{tcolorbox}[colback=blue!5!white, colframe=main, width=1.5cm, height=1cm, arc=1mm, valign=center, auto outer arc, fontupper=\color{black}\scriptsize, boxsep=0.5mm, left=0.5mm, right=0.5mm, top=0.5mm, bottom=0.5mm]
                \centering
                Language Model $\llm$
            \end{tcolorbox}
        };
        \draw[->] (query.east)--(model.west);
        \node[anchor=west] (rationales) at ([shift={(0.3, 0)}]model.east) {
            \begin{tcolorbox}[colback=white, colframe=gray, width=2.5cm, arc=1mm, valign=top, auto outer arc, fontupper=\color{black}\scriptsize, boxsep=0.5mm, left=0.5mm, right=0.5mm, top=0.5mm, bottom=0.5mm]
                \centering
                \textbf{Sampled Rationale}
                
                $\pz_1, \pz_2, \ldots, \pz_K$
                
            \end{tcolorbox}
        };
        \draw[->] (model.east) --(rationales.west);
        \node[right=0.3cm of rationales.east, anchor=west] (rewards) {
            \begin{tcolorbox}[colback=white, colframe=gray, width=3cm, arc=1mm, valign=top, auto outer arc, fontupper=\color{black}\scriptsize, boxsep=0.5mm, left=0.5mm, right=0.5mm, top=0.5mm, bottom=0.5mm]
            \centering
            \textbf{Self-reward}: Compute the likelihood of $\llm$ generating $\py$ after observing $\px$ and $\pz$.
            \end{tcolorbox}
        };
        \node[below=0.3cm of rewards.south, anchor=north] (groundtruth){
            \begin{tcolorbox}[colback=white, colframe=gray, width=2.5cm, arc=1mm, valign=top, auto outer arc, fontupper=\color{black}\scriptsize, boxsep=0.5mm, left=0.5mm, right=0.5mm, top=0.5mm, bottom=0.5mm]
            \centering
            \textbf{Groundtruth $\py$}
            \end{tcolorbox}
        };

        \draw[->] (rationales.east) --  (rewards.west);
        \draw[->] (groundtruth.north) -- (rewards.south);
        \draw[->] (model.north) -- ([yshift=0.3cm]model.north) -- ([yshift=0.25cm]rewards.north) -- (rewards.north);
        \node[anchor=west] (model_2) at ([shift={(0.5, 0)}]rewards.east){
            \begin{tcolorbox}[colback=blue!5!white, colframe=main, width=1.5cm, height=1cm, arc=1mm, valign=center, auto outer arc, fontupper=\color{black}\scriptsize, boxsep=0.5mm, left=0.5mm, right=0.5mm, top=0.5mm, bottom=0.5mm]
                \centering
                Language Model $\llm$
            \end{tcolorbox}
        };
        \draw[->] (rewards.east) -- node[below]{\tiny update}(model_2.west);
        \node[anchor=north west] (example) at (0, -2.5) {
            \begin{tcolorbox}[colback=white, colframe=gray, width=\textwidth, arc=1mm, valign=top, auto outer arc, fontupper=\color{black}\footnotesize, boxsep=0.5mm, left=0.5mm, right=0.5mm, top=0.5mm, bottom=0.5mm]
                \textbf{Question}: A robe takes 2 bolts of blue fiber and half that much white fiber. How many bolts does it take?

                \textbf{Groundtruth}: The answer is 3.

                
                \textbf{Sampled Rationale 1 (correct ✅, higher likelihood)}: It takes 2/2 = 1 bolt of white fiber. 2 + 1 = 3. So, it takes a total of 3 bolts of fiber.

                \textbf{Sampled Rationale 2 (incorrect ❌, lower likelihood)}: We need 2 bolts of blue and 2 bolts of white fiber. In total, it is 2 + 2 = 4.

            \end{tcolorbox}
        };
    \end{tikzpicture}
    \caption{\small Overview of LaTRO with an example question from GSM8K \citep{cobbe2021training}. LaTRO treats reasoning trajectories as latent variables and optimizes the underlying distribution through self-rewarding. Given a question, the language model generates multiple reasoning rationales, evaluates their likelihood of producing the correct answer, and updates its parameters to favor high-quality rationales. This iterative process allows the model to improve both its ability to generate good reasoning paths and to evaluate the quality of those paths.}
    \label{fig:overview}
    \vspace{-0.2cm}
\end{figure}