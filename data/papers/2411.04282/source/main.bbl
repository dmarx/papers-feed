\begin{thebibliography}{56}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abdin et~al.(2024)Abdin, Jacobs, Awan, Aneja, Awadallah, Awadalla, Bach, Bahree, Bakhtiari, Behl, Benhaim, Bilenko, Bjorck, Bubeck, Cai, Mendes, Chen, Chaudhary, Chopra, Giorno, de~Rosa, Dixon, Eldan, Iter, Garg, Goswami, Gunasekar, Haider, Hao, Hewett, Huynh, Javaheripi, Jin, Kauffmann, Karampatziakis, Kim, Khademi, Kurilenko, Lee, Lee, Li, Liang, Liu, Lin, Lin, Madan, Mitra, Modi, Nguyen, Norick, Patra, Perez{-}Becker, Portet, Pryzant, Qin, Radmilac, Rosset, Roy, Ruwase, Saarikivi, Saied, Salim, Santacroce, Shah, Shang, Sharma, Song, Tanaka, Wang, Ward, Wang, Witte, Wyatt, Xu, Xu, Yadav, Yang, Yang, Yu, Zhang, Zhang, Zhang, Zhang, Zhang, Zhang, Zhang, and Zhou]{DBLP:journals/corr/abs-2404-14219}
Marah~I Abdin, Sam~Ade Jacobs, Ammar~Ahmad Awan, Jyoti Aneja, Ahmed Awadallah, Hany Awadalla, Nguyen Bach, Amit Bahree, Arash Bakhtiari, Harkirat~S. Behl, Alon Benhaim, Misha Bilenko, Johan Bjorck, S{\'{e}}bastien Bubeck, Martin Cai, Caio C{\'{e}}sar~Teodoro Mendes, Weizhu Chen, Vishrav Chaudhary, Parul Chopra, Allie~Del Giorno, Gustavo de~Rosa, Matthew Dixon, Ronen Eldan, Dan Iter, Amit Garg, Abhishek Goswami, Suriya Gunasekar, Emman Haider, Junheng Hao, Russell~J. Hewett, Jamie Huynh, Mojan Javaheripi, Xin Jin, Piero Kauffmann, Nikos Karampatziakis, Dongwoo Kim, Mahoud Khademi, Lev Kurilenko, James~R. Lee, Yin~Tat Lee, Yuanzhi Li, Chen Liang, Weishung Liu, Eric Lin, Zeqi Lin, Piyush Madan, Arindam Mitra, Hardik Modi, Anh Nguyen, Brandon Norick, Barun Patra, Daniel Perez{-}Becker, Thomas Portet, Reid Pryzant, Heyang Qin, Marko Radmilac, Corby Rosset, Sambudha Roy, Olatunji Ruwase, Olli Saarikivi, Amin Saied, Adil Salim, Michael Santacroce, Shital Shah, Ning Shang, Hiteshi Sharma, Xia Song, Masahiro Tanaka,
  Xin Wang, Rachel Ward, Guanhua Wang, Philipp Witte, Michael Wyatt, Can Xu, Jiahang Xu, Sonali Yadav, Fan Yang, Ziyi Yang, Donghan Yu, Chengruidong Zhang, Cyril Zhang, Jianwen Zhang, Li~Lyna Zhang, Yi~Zhang, Yue Zhang, Yunan Zhang, and Xiren Zhou.
\newblock Phi-3 technical report: {A} highly capable language model locally on your phone.
\newblock \emph{CoRR}, abs/2404.14219, 2024.
\newblock \doi{10.48550/ARXIV.2404.14219}.
\newblock URL \url{https://doi.org/10.48550/arXiv.2404.14219}.

\bibitem[Abdolmaleki et~al.(2018)Abdolmaleki, Springenberg, Tassa, Munos, Heess, and Riedmiller]{abdolmaleki2018maximum}
Abbas Abdolmaleki, Jost~Tobias Springenberg, Yuval Tassa, Remi Munos, Nicolas Heess, and Martin Riedmiller.
\newblock Maximum a posteriori policy optimisation.
\newblock \emph{arXiv preprint arXiv:1806.06920}, 2018.

\bibitem[Ahmadian et~al.(2024)Ahmadian, Cremer, Gall{\'e}, Fadaee, Kreutzer, {\"U}st{\"u}n, and Hooker]{ahmadian2024back}
Arash Ahmadian, Chris Cremer, Matthias Gall{\'e}, Marzieh Fadaee, Julia Kreutzer, Ahmet {\"U}st{\"u}n, and Sara Hooker.
\newblock Back to basics: Revisiting reinforce style optimization for learning from human feedback in llms.
\newblock \emph{arXiv preprint arXiv:2402.14740}, 2024.

\bibitem[Ansel et~al.(2024)Ansel, Yang, He, Gimelshein, Jain, Voznesensky, Bao, Bell, Berard, Burovski, Chauhan, Chourdia, Constable, Desmaison, DeVito, Ellison, Feng, Gong, Gschwind, Hirsh, Huang, Kalambarkar, Kirsch, Lazos, Lezcano, Liang, Liang, Lu, Luk, Maher, Pan, Puhrsch, Reso, Saroufim, Siraichi, Suk, Zhang, Suo, Tillet, Zhao, Wang, Zhou, Zou, Wang, Mathews, Wen, Chanan, Wu, and Chintala]{Ansel2024PyTorch2F}
Jason Ansel, Edward Yang, Horace He, Natalia Gimelshein, Animesh Jain, Michael Voznesensky, Bin Bao, Peter Bell, David Berard, Evgeni Burovski, Geeta Chauhan, Anjali Chourdia, Will Constable, Alban Desmaison, Zachary DeVito, Elias Ellison, Will Feng, Jiong Gong, Michael Gschwind, Brian Hirsh, Sherlock Huang, Kshiteej Kalambarkar, Laurent Kirsch, Michael Lazos, Mario Lezcano, Yanbo Liang, Jason Liang, Yinghai Lu, C.~K. Luk, Bert Maher, Yunjie Pan, Christian Puhrsch, Matthias Reso, Mark-Albert Saroufim, Marcos~Yukio Siraichi, Helen Suk, Shunting Zhang, Michael Suo, Phil Tillet, Xu~Zhao, Eikan Wang, Keren Zhou, Richard Zou, Xiaodong Wang, Ajit Mathews, William Wen, Gregory Chanan, Peng Wu, and Soumith Chintala.
\newblock Pytorch 2: Faster machine learning through dynamic python bytecode transformation and graph compilation.
\newblock \emph{Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2}, 2024.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:268794728}.

\bibitem[Besta et~al.(2024)Besta, Blach, Kubicek, Gerstenberger, Podstawski, Gianinazzi, Gajda, Lehmann, Niewiadomski, Nyczyk, and Hoefler]{DBLP:conf/aaai/BestaBKGPGGLNNH24}
Maciej Besta, Nils Blach, Ales Kubicek, Robert Gerstenberger, Michal Podstawski, Lukas Gianinazzi, Joanna Gajda, Tomasz Lehmann, Hubert Niewiadomski, Piotr Nyczyk, and Torsten Hoefler.
\newblock Graph of thoughts: Solving elaborate problems with large language models.
\newblock In Michael~J. Wooldridge, Jennifer~G. Dy, and Sriraam Natarajan (eds.), \emph{Thirty-Eighth {AAAI} Conference on Artificial Intelligence, {AAAI} 2024, Thirty-Sixth Conference on Innovative Applications of Artificial Intelligence, {IAAI} 2024, Fourteenth Symposium on Educational Advances in Artificial Intelligence, {EAAI} 2014, February 20-27, 2024, Vancouver, Canada}, pp.\  17682--17690. {AAAI} Press, 2024.
\newblock \doi{10.1609/AAAI.V38I16.29720}.
\newblock URL \url{https://doi.org/10.1609/aaai.v38i16.29720}.

\bibitem[Brown et~al.(2024)Brown, Juravsky, Ehrlich, Clark, Le, R{\'e}, and Mirhoseini]{brown2024large}
Bradley Brown, Jordan Juravsky, Ryan Ehrlich, Ronald Clark, Quoc~V Le, Christopher R{\'e}, and Azalia Mirhoseini.
\newblock Large language monkeys: Scaling inference compute with repeated sampling.
\newblock \emph{arXiv preprint arXiv:2407.21787}, 2024.

\bibitem[Chen et~al.(2023)Chen, Ma, Wang, and Cohen]{DBLP:journals/tmlr/ChenM0C23}
Wenhu Chen, Xueguang Ma, Xinyi Wang, and William~W. Cohen.
\newblock Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks.
\newblock \emph{Trans. Mach. Learn. Res.}, 2023, 2023.
\newblock URL \url{https://openreview.net/forum?id=YfZ4ZPt8zd}.

\bibitem[Cobbe et~al.(2021{\natexlab{a}})Cobbe, Kosaraju, Bavarian, Chen, Jun, Kaiser, Plappert, Tworek, Hilton, Nakano, Hesse, and Schulman]{DBLP:journals/corr/abs-2110-14168}
Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, and John Schulman.
\newblock Training verifiers to solve math word problems.
\newblock \emph{CoRR}, abs/2110.14168, 2021{\natexlab{a}}.
\newblock URL \url{https://arxiv.org/abs/2110.14168}.

\bibitem[Cobbe et~al.(2021{\natexlab{b}})Cobbe, Kosaraju, Bavarian, Chen, Jun, Kaiser, Plappert, Tworek, Hilton, Nakano, et~al.]{cobbe2021training}
Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, et~al.
\newblock Training verifiers to solve math word problems.
\newblock \emph{arXiv preprint arXiv:2110.14168}, 2021{\natexlab{b}}.

\bibitem[Dao et~al.(2022)Dao, Fu, Ermon, Rudra, and R{\'{e}}]{DBLP:conf/nips/DaoFERR22}
Tri Dao, Daniel~Y. Fu, Stefano Ermon, Atri Rudra, and Christopher R{\'{e}}.
\newblock Flashattention: Fast and memory-efficient exact attention with io-awareness.
\newblock In Sanmi Koyejo, S.~Mohamed, A.~Agarwal, Danielle Belgrave, K.~Cho, and A.~Oh (eds.), \emph{Advances in Neural Information Processing Systems 35: Annual Conference on Neural Information Processing Systems 2022, NeurIPS 2022, New Orleans, LA, USA, November 28 - December 9, 2022}, 2022.
\newblock URL \url{http://papers.nips.cc/paper\_files/paper/2022/hash/67d57c32e20fd0a7a302cb81d36e40d5-Abstract-Conference.html}.

\bibitem[Dubey et~al.(2024)Dubey, Jauhri, Pandey, Kadian, Al{-}Dahle, Letman, Mathur, Schelten, Yang, Fan, Goyal, Hartshorn, Yang, Mitra, Sravankumar, Korenev, Hinsvark, Rao, Zhang, Rodriguez, Gregerson, Spataru, Rozi{\`{e}}re, Biron, Tang, Chern, Caucheteux, Nayak, Bi, Marra, McConnell, Keller, Touret, Wu, Wong, Ferrer, Nikolaidis, Allonsius, Song, Pintz, Livshits, Esiobu, Choudhary, Mahajan, Garcia{-}Olano, Perino, Hupkes, Lakomkin, AlBadawy, Lobanova, Dinan, Smith, Radenovic, Zhang, Synnaeve, Lee, Anderson, Nail, Mialon, Pang, Cucurell, Nguyen, Korevaar, Xu, Touvron, Zarov, Ibarra, Kloumann, Misra, Evtimov, Copet, Lee, Geffert, Vranes, Park, Mahadeokar, Shah, van~der Linde, Billock, Hong, Lee, Fu, Chi, Huang, Liu, Wang, Yu, Bitton, Spisak, Park, Rocca, Johnstun, Saxe, Jia, Alwala, Upasani, Plawiak, Li, Heafield, Stone, and et~al.]{DBLP:journals/corr/abs-2407-21783}
Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al{-}Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Amy Yang, Angela Fan, Anirudh Goyal, Anthony Hartshorn, Aobo Yang, Archi Mitra, Archie Sravankumar, Artem Korenev, Arthur Hinsvark, Arun Rao, Aston Zhang, Aur{\'{e}}lien Rodriguez, Austen Gregerson, Ava Spataru, Baptiste Rozi{\`{e}}re, Bethany Biron, Binh Tang, Bobbie Chern, Charlotte Caucheteux, Chaya Nayak, Chloe Bi, Chris Marra, Chris McConnell, Christian Keller, Christophe Touret, Chunyang Wu, Corinne Wong, Cristian~Canton Ferrer, Cyrus Nikolaidis, Damien Allonsius, Daniel Song, Danielle Pintz, Danny Livshits, David Esiobu, Dhruv Choudhary, Dhruv Mahajan, Diego Garcia{-}Olano, Diego Perino, Dieuwke Hupkes, Egor Lakomkin, Ehab AlBadawy, Elina Lobanova, Emily Dinan, Eric~Michael Smith, Filip Radenovic, Frank Zhang, Gabriel Synnaeve, Gabrielle Lee, Georgia~Lewis Anderson, Graeme Nail, Gr{\'{e}}goire Mialon, Guan Pang, Guillem Cucurell, Hailey Nguyen, Hannah Korevaar, Hu~Xu, Hugo
  Touvron, Iliyan Zarov, Imanol~Arrieta Ibarra, Isabel~M. Kloumann, Ishan Misra, Ivan Evtimov, Jade Copet, Jaewon Lee, Jan Geffert, Jana Vranes, Jason Park, Jay Mahadeokar, Jeet Shah, Jelmer van~der Linde, Jennifer Billock, Jenny Hong, Jenya Lee, Jeremy Fu, Jianfeng Chi, Jianyu Huang, Jiawen Liu, Jie Wang, Jiecao Yu, Joanna Bitton, Joe Spisak, Jongsoo Park, Joseph Rocca, Joshua Johnstun, Joshua Saxe, Junteng Jia, Kalyan~Vasuden Alwala, Kartikeya Upasani, Kate Plawiak, Ke~Li, Kenneth Heafield, Kevin Stone, and et~al.
\newblock The llama 3 herd of models.
\newblock \emph{CoRR}, abs/2407.21783, 2024.
\newblock \doi{10.48550/ARXIV.2407.21783}.
\newblock URL \url{https://doi.org/10.48550/arXiv.2407.21783}.

\bibitem[Guo et~al.(2024)Guo, Zhu, Yang, Xie, Dong, Zhang, Chen, Bi, Wu, Li, et~al.]{guo2024deepseek}
Daya Guo, Qihao Zhu, Dejian Yang, Zhenda Xie, Kai Dong, Wentao Zhang, Guanting Chen, Xiao Bi, Yu~Wu, YK~Li, et~al.
\newblock Deepseek-coder: When the large language model meets programming--the rise of code intelligence.
\newblock \emph{arXiv preprint arXiv:2401.14196}, 2024.

\bibitem[Havrilla et~al.(2024)Havrilla, Du, Raparthy, Nalmpantis, Dwivedi-Yu, Zhuravinskyi, Hambro, Sukhbaatar, and Raileanu]{havrilla2024teaching}
Alex Havrilla, Yuqing Du, Sharath~Chandra Raparthy, Christoforos Nalmpantis, Jane Dwivedi-Yu, Maksym Zhuravinskyi, Eric Hambro, Sainbayar Sukhbaatar, and Roberta Raileanu.
\newblock Teaching large language models to reason with reinforcement learning.
\newblock \emph{arXiv preprint arXiv:2403.04642}, 2024.

\bibitem[Hendrycks et~al.(2021)Hendrycks, Burns, Kadavath, Arora, Basart, Tang, Song, and Steinhardt]{hendrycks2021measuring}
Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song, and Jacob Steinhardt.
\newblock Measuring mathematical problem solving with the math dataset.
\newblock \emph{arXiv preprint arXiv:2103.03874}, 2021.

\bibitem[Higgins et~al.(2017)Higgins, Matthey, Pal, Burgess, Glorot, Botvinick, Mohamed, and Lerchner]{higgins2017beta}
Irina Higgins, Loic Matthey, Arka Pal, Christopher~P Burgess, Xavier Glorot, Matthew~M Botvinick, Shakir Mohamed, and Alexander Lerchner.
\newblock beta-vae: Learning basic visual concepts with a constrained variational framework.
\newblock \emph{ICLR (Poster)}, 3, 2017.

\bibitem[Hoffman et~al.(2024)Hoffman, Phan, Dohan, Douglas, Le, Parisi, Sountsov, Sutton, Vikram, and A~Saurous]{hoffman2024training}
Matthew~Douglas Hoffman, Du~Phan, David Dohan, Sholto Douglas, Tuan~Anh Le, Aaron Parisi, Pavel Sountsov, Charles Sutton, Sharad Vikram, and Rif A~Saurous.
\newblock Training chain-of-thought via latent-variable inference.
\newblock \emph{Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem[Hu et~al.(2023)Hu, Jain, Elmoznino, Kaddar, Lajoie, Bengio, and Malkin]{hu2023amortizing}
Edward~J Hu, Moksh Jain, Eric Elmoznino, Younesse Kaddar, Guillaume Lajoie, Yoshua Bengio, and Nikolay Malkin.
\newblock Amortizing intractable inference in large language models.
\newblock \emph{arXiv preprint arXiv:2310.04363}, 2023.

\bibitem[Huang et~al.(2023)Huang, Chen, Mishra, Zheng, Yu, Song, and Zhou]{huang2023large}
Jie Huang, Xinyun Chen, Swaroop Mishra, Huaixiu~Steven Zheng, Adams~Wei Yu, Xinying Song, and Denny Zhou.
\newblock Large language models cannot self-correct reasoning yet.
\newblock \emph{arXiv preprint arXiv:2310.01798}, 2023.

\bibitem[Jiang et~al.(2023)Jiang, Sablayrolles, Mensch, Bamford, Chaplot, de~Las~Casas, Bressand, Lengyel, Lample, Saulnier, Lavaud, Lachaux, Stock, Scao, Lavril, Wang, Lacroix, and Sayed]{DBLP:journals/corr/abs-2310-06825}
Albert~Q. Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra~Singh Chaplot, Diego de~Las~Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, L{\'{e}}lio~Renard Lavaud, Marie{-}Anne Lachaux, Pierre Stock, Teven~Le Scao, Thibaut Lavril, Thomas Wang, Timoth{\'{e}}e Lacroix, and William~El Sayed.
\newblock Mistral 7b.
\newblock \emph{CoRR}, abs/2310.06825, 2023.
\newblock \doi{10.48550/ARXIV.2310.06825}.
\newblock URL \url{https://doi.org/10.48550/arXiv.2310.06825}.

\bibitem[Jimenez et~al.(2023)Jimenez, Yang, Wettig, Yao, Pei, Press, and Narasimhan]{jimenez2023swe}
Carlos~E Jimenez, John Yang, Alexander Wettig, Shunyu Yao, Kexin Pei, Ofir Press, and Karthik Narasimhan.
\newblock Swe-bench: Can language models resolve real-world github issues?
\newblock \emph{arXiv preprint arXiv:2310.06770}, 2023.

\bibitem[Kingma(2013)]{kingma2013auto}
Diederik~P Kingma.
\newblock Auto-encoding variational bayes.
\newblock \emph{arXiv preprint arXiv:1312.6114}, 2013.

\bibitem[Kool et~al.(2019)Kool, van Hoof, and Welling]{DBLP:conf/iclr/KoolHW19a}
Wouter Kool, Herke van Hoof, and Max Welling.
\newblock Buy 4 {REINFORCE} samples, get a baseline for free!
\newblock In \emph{Deep Reinforcement Learning Meets Structured Prediction, {ICLR} 2019 Workshop, New Orleans, Louisiana, United States, May 6, 2019}. OpenReview.net, 2019.
\newblock URL \url{https://openreview.net/forum?id=r1lgTGL5DE}.

\bibitem[Kumar et~al.(2024)Kumar, Zhuang, Agarwal, Su, Co-Reyes, Singh, Baumli, Iqbal, Bishop, Roelofs, et~al.]{kumar2024training}
Aviral Kumar, Vincent Zhuang, Rishabh Agarwal, Yi~Su, John~D Co-Reyes, Avi Singh, Kate Baumli, Shariq Iqbal, Colton Bishop, Rebecca Roelofs, et~al.
\newblock Training language models to self-correct via reinforcement learning.
\newblock \emph{arXiv preprint arXiv:2409.12917}, 2024.

\bibitem[Levine et~al.(2020)Levine, Kumar, Tucker, and Fu]{levine2020offline}
Sergey Levine, Aviral Kumar, George Tucker, and Justin Fu.
\newblock Offline reinforcement learning: Tutorial, review, and perspectives on open problems.
\newblock \emph{arXiv preprint arXiv:2005.01643}, 2020.

\bibitem[Lightman et~al.(2023)Lightman, Kosaraju, Burda, Edwards, Baker, Lee, Leike, Schulman, Sutskever, and Cobbe]{lightman2023let}
Hunter Lightman, Vineet Kosaraju, Yura Burda, Harri Edwards, Bowen Baker, Teddy Lee, Jan Leike, John Schulman, Ilya Sutskever, and Karl Cobbe.
\newblock Let's verify step by step.
\newblock \emph{arXiv preprint arXiv:2305.20050}, 2023.

\bibitem[Liu et~al.(2024)Liu, Liu, Zhou, and Ma]{DBLP:conf/iclr/0001LZ024}
Zhiyuan Liu, Hong Liu, Denny Zhou, and Tengyu Ma.
\newblock Chain of thought empowers transformers to solve inherently serial problems.
\newblock In \emph{The Twelfth International Conference on Learning Representations, {ICLR} 2024, Vienna, Austria, May 7-11, 2024}. OpenReview.net, 2024.
\newblock URL \url{https://openreview.net/forum?id=3EWTEy9MTM}.

\bibitem[Liu et~al.(2022)Liu, Cen, Isenbaev, Liu, Wu, Li, and Zhao]{liu2022constrained}
Zuxin Liu, Zhepeng Cen, Vladislav Isenbaev, Wei Liu, Steven Wu, Bo~Li, and Ding Zhao.
\newblock Constrained variational policy optimization for safe reinforcement learning.
\newblock In \emph{International Conference on Machine Learning}, pp.\  13644--13668. PMLR, 2022.

\bibitem[Luo et~al.(2024)Luo, Liu, Liu, Phatale, Lara, Li, Shu, Zhu, Meng, Sun, et~al.]{luo2024improve}
Liangchen Luo, Yinxiao Liu, Rosanne Liu, Samrat Phatale, Harsh Lara, Yunxuan Li, Lei Shu, Yun Zhu, Lei Meng, Jiao Sun, et~al.
\newblock Improve mathematical reasoning in language models by automated process supervision.
\newblock \emph{arXiv preprint arXiv:2406.06592}, 2024.

\bibitem[Madaan et~al.(2023)Madaan, Tandon, Gupta, Hallinan, Gao, Wiegreffe, Alon, Dziri, Prabhumoye, Yang, Gupta, Majumder, Hermann, Welleck, Yazdanbakhsh, and Clark]{NEURIPS2023_91edff07}
Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, Shashank Gupta, Bodhisattwa~Prasad Majumder, Katherine Hermann, Sean Welleck, Amir Yazdanbakhsh, and Peter Clark.
\newblock Self-refine: Iterative refinement with self-feedback.
\newblock In A.~Oh, T.~Naumann, A.~Globerson, K.~Saenko, M.~Hardt, and S.~Levine (eds.), \emph{Advances in Neural Information Processing Systems}, volume~36, pp.\  46534--46594. Curran Associates, Inc., 2023.
\newblock URL \url{https://proceedings.neurips.cc/paper_files/paper/2023/file/91edff07232fb1b55a505a9e9f6c0ff3-Paper-Conference.pdf}.

\bibitem[{OpenAI}(2024)]{openai_learning_2024}
{OpenAI}.
\newblock Learning to reason with {LLMs}.
\newblock \url{https://openai.com/index/learning-to-reason-with-llms/}, 2024.
\newblock [Online].

\bibitem[Ouyang et~al.(2022)Ouyang, Wu, Jiang, Almeida, Wainwright, Mishkin, Zhang, Agarwal, Slama, Ray, et~al.]{ouyang2022training}
Long Ouyang, Jeffrey Wu, Xu~Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et~al.
\newblock Training language models to follow instructions with human feedback.
\newblock \emph{Advances in neural information processing systems}, 35:\penalty0 27730--27744, 2022.

\bibitem[Polu \& Sutskever(2020)Polu and Sutskever]{polu2020generative}
Stanislas Polu and Ilya Sutskever.
\newblock Generative language modeling for automated theorem proving.
\newblock \emph{arXiv preprint arXiv:2009.03393}, 2020.

\bibitem[Rafailov et~al.(2024)Rafailov, Sharma, Mitchell, Manning, Ermon, and Finn]{rafailov2024direct}
Rafael Rafailov, Archit Sharma, Eric Mitchell, Christopher~D Manning, Stefano Ermon, and Chelsea Finn.
\newblock Direct preference optimization: Your language model is secretly a reward model.
\newblock \emph{Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem[Rasley et~al.(2020)Rasley, Rajbhandari, Ruwase, and He]{DBLP:conf/kdd/RasleyRRH20}
Jeff Rasley, Samyam Rajbhandari, Olatunji Ruwase, and Yuxiong He.
\newblock Deepspeed: System optimizations enable training deep learning models with over 100 billion parameters.
\newblock In Rajesh Gupta, Yan Liu, Jiliang Tang, and B.~Aditya Prakash (eds.), \emph{{KDD} '20: The 26th {ACM} {SIGKDD} Conference on Knowledge Discovery and Data Mining, Virtual Event, CA, USA, August 23-27, 2020}, pp.\  3505--3506. {ACM}, 2020.
\newblock \doi{10.1145/3394486.3406703}.
\newblock URL \url{https://doi.org/10.1145/3394486.3406703}.

\bibitem[Rein et~al.(2023)Rein, Hou, Stickland, Petty, Pang, Dirani, Michael, and Bowman]{rein2023gpqa}
David Rein, Betty~Li Hou, Asa~Cooper Stickland, Jackson Petty, Richard~Yuanzhe Pang, Julien Dirani, Julian Michael, and Samuel~R Bowman.
\newblock Gpqa: A graduate-level google-proof q\&a benchmark.
\newblock \emph{arXiv preprint arXiv:2311.12022}, 2023.

\bibitem[Saunders et~al.(2022)Saunders, Yeh, Wu, Bills, Ouyang, Ward, and Leike]{saunders2022self}
William Saunders, Catherine Yeh, Jeff Wu, Steven Bills, Long Ouyang, Jonathan Ward, and Jan Leike.
\newblock Self-critiquing models for assisting human evaluators.
\newblock \emph{arXiv preprint arXiv:2206.05802}, 2022.

\bibitem[Shinn et~al.(2023)Shinn, Cassano, Gopinath, Narasimhan, and Yao]{DBLP:conf/nips/ShinnCGNY23}
Noah Shinn, Federico Cassano, Ashwin Gopinath, Karthik Narasimhan, and Shunyu Yao.
\newblock Reflexion: language agents with verbal reinforcement learning.
\newblock In Alice Oh, Tristan Naumann, Amir Globerson, Kate Saenko, Moritz Hardt, and Sergey Levine (eds.), \emph{Advances in Neural Information Processing Systems 36: Annual Conference on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA, December 10 - 16, 2023}, 2023.
\newblock URL \url{http://papers.nips.cc/paper\_files/paper/2023/hash/1b44b878bb782e6954cd888628510e90-Abstract-Conference.html}.

\bibitem[Sprague et~al.(2024)Sprague, Yin, Rodriguez, Jiang, Wadhwa, Singhal, Zhao, Ye, Mahowald, and Durrett]{sprague2024cot}
Zayne Sprague, Fangcong Yin, Juan~Diego Rodriguez, Dongwei Jiang, Manya Wadhwa, Prasann Singhal, Xinyu Zhao, Xi~Ye, Kyle Mahowald, and Greg Durrett.
\newblock To cot or not to cot? chain-of-thought helps mainly on math and symbolic reasoning.
\newblock \emph{CoRR}, abs/2409.12183, 2024.
\newblock URL \url{http://arxiv.org/abs/2409.12183}.

\bibitem[Talmor et~al.(2019)Talmor, Herzig, Lourie, and Berant]{DBLP:conf/naacl/TalmorHLB19}
Alon Talmor, Jonathan Herzig, Nicholas Lourie, and Jonathan Berant.
\newblock Commonsenseqa: {A} question answering challenge targeting commonsense knowledge.
\newblock In Jill Burstein, Christy Doran, and Thamar Solorio (eds.), \emph{Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, {NAACL-HLT} 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long and Short Papers)}, pp.\  4149--4158. Association for Computational Linguistics, 2019.
\newblock \doi{10.18653/V1/N19-1421}.
\newblock URL \url{https://doi.org/10.18653/v1/n19-1421}.

\bibitem[Trinh et~al.(2024)Trinh, Wu, Le, He, and Luong]{trinh2024solving}
Trieu~H Trinh, Yuhuai Wu, Quoc~V Le, He~He, and Thang Luong.
\newblock Solving olympiad geometry without human demonstrations.
\newblock \emph{Nature}, 625\penalty0 (7995):\penalty0 476--482, 2024.

\bibitem[Trung et~al.(2024)Trung, Zhang, Jie, Sun, Jin, and Li]{trung2024reft}
Luong Trung, Xinbo Zhang, Zhanming Jie, Peng Sun, Xiaoran Jin, and Hang Li.
\newblock Reft: Reasoning with reinforced fine-tuning.
\newblock In \emph{Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)}, pp.\  7601--7614, 2024.

\bibitem[von Werra et~al.(2020)von Werra, Belkada, Tunstall, Beeching, Thrush, Lambert, and Huang]{vonwerra2022trl}
Leandro von Werra, Younes Belkada, Lewis Tunstall, Edward Beeching, Tristan Thrush, Nathan Lambert, and Shengyi Huang.
\newblock Trl: Transformer reinforcement learning.
\newblock \url{https://github.com/huggingface/trl}, 2020.

\bibitem[Wang \& Zhou(2024)Wang and Zhou]{wang2024chain}
Xuezhi Wang and Denny Zhou.
\newblock Chain-of-thought reasoning without prompting.
\newblock \emph{arXiv preprint arXiv:2402.10200}, 2024.

\bibitem[Wang et~al.(2022)Wang, Wei, Schuurmans, Le, Chi, Narang, Chowdhery, and Zhou]{wang2022self}
Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed~Chi, Sharan Narang, Aakanksha Chowdhery, and Denny Zhou.
\newblock Self-consistency improves chain of thought reasoning in language models.
\newblock \emph{arXiv preprint arXiv:2203.11171}, 2022.

\bibitem[Wang et~al.(2023)Wang, Wei, Schuurmans, Le, Chi, Narang, Chowdhery, and Zhou]{DBLP:conf/iclr/0002WSLCNCZ23}
Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc~V. Le, Ed~H. Chi, Sharan Narang, Aakanksha Chowdhery, and Denny Zhou.
\newblock Self-consistency improves chain of thought reasoning in language models.
\newblock In \emph{The Eleventh International Conference on Learning Representations, {ICLR} 2023, Kigali, Rwanda, May 1-5, 2023}. OpenReview.net, 2023.
\newblock URL \url{https://openreview.net/forum?id=1PL1NIMMrw}.

\bibitem[Wei et~al.(2022)Wei, Wang, Schuurmans, Bosma, Ichter, Xia, Chi, Le, and Zhou]{DBLP:conf/nips/Wei0SBIXCLZ22}
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed~H. Chi, Quoc~V. Le, and Denny Zhou.
\newblock Chain-of-thought prompting elicits reasoning in large language models.
\newblock In Sanmi Koyejo, S.~Mohamed, A.~Agarwal, Danielle Belgrave, K.~Cho, and A.~Oh (eds.), \emph{Advances in Neural Information Processing Systems 35: Annual Conference on Neural Information Processing Systems 2022, NeurIPS 2022, New Orleans, LA, USA, November 28 - December 9, 2022}, 2022.
\newblock URL \url{http://papers.nips.cc/paper\_files/paper/2022/hash/9d5609613524ecf4f15af0f7b31abca4-Abstract-Conference.html}.

\bibitem[Williams(1992)]{williams1992simple}
Ronald~J Williams.
\newblock Simple statistical gradient-following algorithms for connectionist reinforcement learning.
\newblock \emph{Machine learning}, 8:\penalty0 229--256, 1992.

\bibitem[Wolf et~al.(2020)Wolf, Debut, Sanh, Chaumond, Delangue, Moi, Cistac, Rault, Louf, Funtowicz, Davison, Shleifer, von Platen, Ma, Jernite, Plu, Xu, Scao, Gugger, Drame, Lhoest, and Rush]{wolf-etal-2020-transformers}
Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven~Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest, and Alexander~M. Rush.
\newblock Transformers: State-of-the-art natural language processing.
\newblock In \emph{Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations}, pp.\  38--45, Online, October 2020. Association for Computational Linguistics.
\newblock URL \url{https://www.aclweb.org/anthology/2020.emnlp-demos.6}.

\bibitem[Wu et~al.(2024)Wu, Sun, Li, Welleck, and Yang]{wu2024empirical}
Yangzhen Wu, Zhiqing Sun, Shanda Li, Sean Welleck, and Yiming Yang.
\newblock An empirical analysis of compute-optimal inference for problem-solving with language models.
\newblock \emph{arXiv preprint arXiv:2408.00724}, 2024.

\bibitem[Yao et~al.(2023{\natexlab{a}})Yao, Zhao, Yu, Du, Shafran, Narasimhan, and Cao]{DBLP:conf/iclr/YaoZYDSN023}
Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik~R. Narasimhan, and Yuan Cao.
\newblock React: Synergizing reasoning and acting in language models.
\newblock In \emph{The Eleventh International Conference on Learning Representations, {ICLR} 2023, Kigali, Rwanda, May 1-5, 2023}. OpenReview.net, 2023{\natexlab{a}}.
\newblock URL \url{https://openreview.net/forum?id=WE\_vluYUL-X}.

\bibitem[Yao et~al.(2024)Yao, Yu, Zhao, Shafran, Griffiths, Cao, and Narasimhan]{yao2024tree}
Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Tom Griffiths, Yuan Cao, and Karthik Narasimhan.
\newblock Tree of thoughts: Deliberate problem solving with large language models.
\newblock \emph{Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem[Yao et~al.(2023{\natexlab{b}})Yao, Heinecke, Niebles, Liu, Feng, Xue, Murthy, Chen, Zhang, Arpit, et~al.]{yao2023retroformer}
Weiran Yao, Shelby Heinecke, Juan~Carlos Niebles, Zhiwei Liu, Yihao Feng, Le~Xue, Rithesh Murthy, Zeyuan Chen, Jianguo Zhang, Devansh Arpit, et~al.
\newblock Retroformer: Retrospective large language agents with policy gradient optimization.
\newblock \emph{arXiv preprint arXiv:2308.02151}, 2023{\natexlab{b}}.

\bibitem[Zelikman et~al.(2022)Zelikman, Wu, Mu, and Goodman]{zelikman2022star}
Eric Zelikman, Yuhuai Wu, Jesse Mu, and Noah Goodman.
\newblock Star: Bootstrapping reasoning with reasoning.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 15476--15488, 2022.

\bibitem[Zelikman et~al.(2024)Zelikman, Harik, Shao, Jayasiri, Haber, and Goodman]{zelikman2024quiet}
Eric Zelikman, Georges Harik, Yijia Shao, Varuna Jayasiri, Nick Haber, and Noah~D Goodman.
\newblock Quiet-star: Language models can teach themselves to think before speaking.
\newblock \emph{arXiv preprint arXiv:2403.09629}, 2024.

\bibitem[Zhang et~al.(2024)Zhang, Yao, Liu, Feng, Liu, Murthy, Lan, Li, Lou, Xu, et~al.]{zhang2024diversity}
Kexun Zhang, Weiran Yao, Zuxin Liu, Yihao Feng, Zhiwei Liu, Rithesh Murthy, Tian Lan, Lei Li, Renze Lou, Jiacheng Xu, et~al.
\newblock Diversity empowers intelligence: Integrating expertise of software engineering agents.
\newblock \emph{arXiv preprint arXiv:2408.07060}, 2024.

\bibitem[Zheng et~al.(2024)Zheng, Zhou, Meng, Zhou, and Huang]{zheng2024large}
Chujie Zheng, Hao Zhou, Fandong Meng, Jie Zhou, and Minlie Huang.
\newblock Large language models are not robust multiple choice selectors.
\newblock In \emph{The Twelfth International Conference on Learning Representations}, 2024.
\newblock URL \url{https://openreview.net/forum?id=shr9PXz7T0}.

\end{thebibliography}
