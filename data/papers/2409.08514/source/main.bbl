% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{lattner2021stochastic}
S.~Lattner and J.~Nistal, ``Stochastic restoration of heavily compressed musical audio using generative adversarial networks,'' \emph{Electronics}, vol.~10, no.~11, p. 1349, 2021.

\bibitem{liu2021voicefixer}
H.~Liu, Q.~Kong, Q.~Tian, Y.~Zhao, D.~Wang, C.~Huang, and Y.~Wang, ``Voicefixer: Toward general speech restoration with neural vocoder,'' \emph{arXiv preprint arXiv:2109.13731}, 2021.

\bibitem{deng2020exploiting}
J.~Deng, B.~Schuller, F.~Eyben, D.~Schuller, Z.~Zhang, H.~Francois, and E.~Oh, ``Exploiting time-frequency patterns with lstm-rnns for low-bitrate audio restoration,'' \emph{Neural Computing and Applications}, vol.~32, no.~4, pp. 1095--1107, 2020.

\bibitem{dietz2002spectral}
M.~Dietz, L.~Liljeryd, K.~Kjorling, and O.~Kunz, ``Spectral band replication, a novel approach in audio coding,'' in \emph{Audio Engineering Society Convention 112}.\hskip 1em plus 0.5em minus 0.4em\relax Audio Engineering Society, 2002.

\bibitem{backstrom2017speech}
T.~B{\"a}ckstr{\"o}m, \emph{Speech coding: with code-excited linear prediction}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 2017.

\bibitem{li2024audio}
K.~Li, F.~Xie, H.~Chen, K.~Yuan, and X.~Hu, ``An audio-visual speech separation model inspired by cortico-thalamo-cortical circuits,'' \emph{IEEE Transactions on Pattern Analysis and Machine Intelligence}, 2024.

\bibitem{lemercier2024diffusion}
J.-M. Lemercier, J.~Richter, S.~Welker, E.~Moliner, V.~V{\"a}lim{\"a}ki, and T.~Gerkmann, ``Diffusion models for audio restoration,'' \emph{arXiv preprint arXiv:2402.09821}, 2024.

\bibitem{moliner2023solving}
E.~Moliner, J.~Lehtinen, and V.~V{\"a}lim{\"a}ki, ``Solving audio inverse problems with a diffusion model,'' in \emph{ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2023, pp. 1--5.

\bibitem{ji2020comprehensive}
S.~Ji, J.~Luo, and X.~Yang, ``A comprehensive survey on deep music generation: Multi-level representations, algorithms, evaluations, and future directions,'' \emph{arXiv preprint arXiv:2011.06801}, 2020.

\bibitem{uhlich2024sound}
S.~Uhlich, G.~Fabbro, M.~Hirano, S.~Takahashi, G.~Wichern \emph{et~al.}, ``The sound demixing challenge 2023-cinematic demixing track.''

\bibitem{larsen2005audio}
E.~Larsen and R.~M. Aarts, \emph{Audio bandwidth extension: application of psychoacoustics, signal processing and loudspeaker design}.\hskip 1em plus 0.5em minus 0.4em\relax John Wiley \& Sons, 2005.

\bibitem{goodfellow2020generative}
I.~Goodfellow, J.~Pouget-Abadie, M.~Mirza, B.~Xu, D.~Warde-Farley, S.~Ozair, A.~Courville, and Y.~Bengio, ``Generative adversarial networks,'' \emph{Communications of the ACM}, vol.~63, no.~11, pp. 139--144, 2020.

\bibitem{pascual2017segan}
S.~Pascual, A.~Bonafonte, and J.~Serra, ``Segan: Speech enhancement generative adversarial network,'' \emph{arXiv preprint arXiv:1703.09452}, 2017.

\bibitem{wu2023audiodec}
Y.-C. Wu, I.~D. Gebru, D.~Markovi{\'c}, and A.~Richard, ``Audiodec: An open-source streaming high-fidelity neural audio codec,'' in \emph{ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2023, pp. 1--5.

\bibitem{kumar2024high}
R.~Kumar, P.~Seetharaman, A.~Luebs, I.~Kumar, and K.~Kumar, ``High-fidelity audio compression with improved rvqgan,'' in \emph{Advances in Neural Information Processing Systems}, 2024.

\bibitem{luo2024gull}
Y.~Luo, J.~Yu, H.~Chen, R.~Gu, and C.~Weng, ``Gull: A generative multifunctional audio codec,'' \emph{arXiv preprint arXiv:2404.04947}, 2024.

\bibitem{brandenburg1999mp3}
K.~Brandenburg, ``Mp3 and aac explained,'' in \emph{Audio Engineering Society Conference: 17th International Conference: High-Quality Audio Coding}.\hskip 1em plus 0.5em minus 0.4em\relax Audio Engineering Society, 1999.

\bibitem{su2024roformer}
J.~Su, M.~Ahmed, Y.~Lu, S.~Pan, W.~Bo, and Y.~Liu, ``Roformer: Enhanced transformer with rotary position embedding,'' \emph{Neurocomputing}, vol. 568, p. 127063, 2024.

\bibitem{rafii2019musdb18}
Z.~Rafii, A.~Liutkus, F.-R. St{\"o}ter, S.~I. Mimilakis, and R.~Bittner, ``Musdb18-hq-an uncompressed version of musdb18,'' \emph{doi. org/10.5281/zenodo}, vol. 3338373, 2019.

\bibitem{pereira2023moisesdb}
I.~Pereira, F.~Ara{\'u}jo, F.~Korzeniowski, and R.~Vogl, ``Moisesdb: A dataset for source separation beyond 4-stems,'' \emph{arXiv preprint arXiv:2307.15913}, 2023.

\bibitem{bai2018empirical}
S.~Bai, J.~Z. Kolter, and V.~Koltun, ``An empirical evaluation of generic convolutional and recurrent networks for sequence modeling,'' \emph{arXiv preprint arXiv:1803.01271}, 2018.

\bibitem{li2022efficient}
K.~Li, R.~Yang, and X.~Hu, ``An efficient encoder-decoder architecture with top-down attention for speech separation,'' \emph{arXiv preprint arXiv:2209.15200}, 2022.

\bibitem{zhang2019root}
B.~Zhang and R.~Sennrich, ``Root mean square layer normalization,'' \emph{Advances in Neural Information Processing Systems}, vol.~32, 2019.

\bibitem{luo2023music}
Y.~Luo and J.~Yu, ``Music source separation with band-split rnn,'' \emph{IEEE/ACM Transactions on Audio, Speech, and Language Processing}, vol.~31, pp. 1893--1901, 2023.

\bibitem{mao2017least}
X.~Mao, Q.~Li, H.~Xie, R.~Y. Lau, Z.~Wang, and S.~Paul~Smolley, ``Least squares generative adversarial networks,'' in \emph{Proceedings of the IEEE international conference on computer vision}, 2017, pp. 2794--2802.

\bibitem{li2024subnetwork}
K.~Li and Y.~Luo, ``Subnetwork-to-go: Elastic neural network with dynamic training and customizable inference,'' in \emph{ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2024, pp. 6775--6779.

\bibitem{loshchilov2017decoupled}
I.~Loshchilov, ``Decoupled weight decay regularization,'' \emph{arXiv preprint arXiv:1711.05101}, 2017.

\bibitem{le2019sdr}
J.~Le~Roux, S.~Wisdom, H.~Erdogan, and J.~R. Hershey, ``Sdr--half-baked or well done?'' in \emph{ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2019, pp. 626--630.

\bibitem{vincent2006performance}
E.~Vincent, R.~Gribonval, and C.~F{\'e}votte, ``Performance measurement in blind audio source separation,'' \emph{IEEE transactions on audio, speech, and language processing}, vol.~14, no.~4, pp. 1462--1469, 2006.

\bibitem{hines2015visqol}
A.~Hines, J.~Skoglund, A.~C. Kokaram, and N.~Harte, ``Visqol: an objective speech quality model,'' \emph{EURASIP Journal on Audio, Speech, and Music Processing}, vol. 2015, pp. 1--18, 2015.

\end{thebibliography}
