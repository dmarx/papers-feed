\begin{table*}[t]
\centering
\small
\scalebox{0.85}{
\begin{threeparttable}
\begin{tabular}{lllllll}
% p{5cm}p{2cm}p{5cm}p{3cm}
\toprule
{\bf Multi-modality Instruction} & \multirow{2}{*}{\bf \# Params} & \multirow{2}{*}{\bf Modality} & \multicolumn{2}{c}{\bf Base Model} & \multicolumn{2}{c}{\bf Fine-tuning Trainset}\\
{\bf Fine-tuned LLMs} & & & {\bf Model Name} & {\bf \# Params} & {\bf Self-build} & {\bf Size} \\\midrule
{{InstructPix2Pix}~\citep{Brooks2022InstructPix2PixLT}\tnotex{id:1}} & 983M & I/T & Stable Diffusion & 983M & Yes & 450K \\
\midrule
\multirow{2}{*}{{LLaVA}~\citep{Liu2023VisualIT}\tnotex{id:2}} & \multirow{2}{*}{13B} & \multirow{2}{*}{I/T} & CLIP~\citep{Radford2021LearningTV} & 400M & \multirow{2}{*}{Yes} & 158K \\
& & & LLaMA~\citep{Touvron2023LLaMAOA} & 7B & & \\
& & & LLaMA~\citep{Touvron2023LLaMAOA} & 7B & & \\
\midrule
\multirow{3}{*}{Video-LLaMA~\citep{damonlpsg2023videollama}\tnotex{id:3}} & \multirow{3}{*}{-} & \multirow{3}{*}{I/T/V/A} & BLIP-2~\citep{li2023blip2} & - & \multirow{3}{*}{No} & \multirow{3}{*}{-} \\
& & & ImageBind~\citep{girdhar2023imagebind} & - & & \\
& & & Vicuna~\citep{chiang2023vicuna} & 7B/13B & & \\
\midrule
{InstructBLIP (1.2B)}~\citep{Dai2023InstructBLIPTG}\tnotex{id:4} & - & I/T/V & BLIP-2~\citep{li2023blip2} & - & No & - \\
\midrule
{Otter}~\citep{Li2023OtterAM}\tnotex{id:5} & - & I/T/V & OpenFlamingo~\citep{anas_awadalla_2023_7733589} & 9B & Yes & 2.8M \\
\midrule
{MultiModal-GPT}~\citep{Gong2023MultiModalGPTAV}\tnotex{id:6} & - & I/T/V & OpenFlamingo~\citep{anas_awadalla_2023_7733589} & 9B & No & - \\
\bottomrule
\end{tabular}
\end{threeparttable}
}
\begin{multicols}{2}
\begin{tablenotes}
\item[1] \label{id:1} {$^1$ https://github.com/timothybrooks/instruct-pix2pix} 
\item[2] \label{id:2} {$^2$ https://github.com/haotian-liu/LLaVA}
\item[3] \label{id:3} {$^3$ https://github.com/DAMO-NLP-SG/Video-LLaMA}
\item[4] \label{id:4} {$^4$ https://github.com/salesforce/LAVIS/tree/main/projects/instructblip}
\item[5] \label{id:5} {$^5$ https://github.com/Luodian/Otter}
\item[6] \label{id:6} {$^6$ https://github.com/open-mmlab/Multimodal-GPT}
\end{tablenotes}
\end{multicols}
\caption{An overview of multi-modality instruction fine-tuned LLMs. I/T/V/A stand for Image/Text/Video/Audio}
\label{tab:mmllms_model_table}
\end{table*}