@article{lin2023unlocking,
  title={The unlocking spell on base llms: Rethinking alignment via in-context learning},
  author={Lin, Bill Yuchen and Ravichander, Abhilasha and Lu, Ximing and Dziri, Nouha and Sclar, Melanie and Chandu, Khyathi and Bhagavatula, Chandra and Choi, Yejin},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2023}
}

@article{lin2024wildbench,
  title={WILDBENCH: Benchmarking LLMs with Challenging Tasks from Real Users in the Wild},
  author={Lin, Bill Yuchen and Deng, Yuntian and Chandu, Khyathi and Brahman, Faeze and Ravichander, Abhilasha and Pyatkin, Valentina and Dziri, Nouha and Bras, Ronan Le and Choi, Yejin},
  journal={arXiv preprint arXiv:2406.04770},
  year={2024}
}

@article{zheng2023judging,
  title={Judging llm-as-a-judge with mt-bench and chatbot arena},
  author={Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={46595--46623},
  year={2023}
}

@article{dubois2024length,
  title={Length-Controlled AlpacaEval: A Simple Way to Debias Automatic Evaluators},
  author={Dubois, Yann and Galambosi, Bal{\'a}zs and Liang, Percy and Hashimoto, Tatsunori B},
  journal={arXiv preprint arXiv:2404.04475},
  year={2024}
}

@article{alpaca_eval,
  author = {Xuechen Li and Tianyi Zhang and Yann Dubois and Rohan Taori and Ishaan Gulrajani and Carlos Guestrin and Percy Liang and Tatsunori B. Hashimoto },
  title = {AlpacaEval: An Automatic Evaluator of Instruction-following Models},
  year = {2023},
  month = {5},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/tatsu-lab/alpaca_eval}}
}

@article{zhou2023instruction,
  title={Instruction-following evaluation for large language models},
  author={Zhou, Jeffrey and Lu, Tianjian and Mishra, Swaroop and Brahma, Siddhartha and Basu, Sujoy and Luan, Yi and Zhou, Denny and Hou, Le},
  journal={arXiv preprint arXiv:2311.07911},
  year={2023}
}

@article{chen2021evaluating,
  title={Evaluating large language models trained on code},
  author={Chen, Mark and Tworek, Jerry and Jun, Heewoo and Yuan, Qiming and Pinto, Henrique Ponde De Oliveira and Kaplan, Jared and Edwards, Harri and Burda, Yuri and Joseph, Nicholas and Brockman, Greg and others},
  journal={arXiv preprint arXiv:2107.03374},
  year={2021}
}

@article{suzgun2022challenging,
  title={Challenging big-bench tasks and whether chain-of-thought can solve them},
  author={Suzgun, Mirac and Scales, Nathan and Sch{\"a}rli, Nathanael and Gehrmann, Sebastian and Tay, Yi and Chung, Hyung Won and Chowdhery, Aakanksha and Le, Quoc V and Chi, Ed H and Zhou, Denny and others},
  journal={arXiv preprint arXiv:2210.09261},
  year={2022}
}

@article{srivastava2022beyond,
  title={Beyond the imitation game: Quantifying and extrapolating the capabilities of language models},
  author={Srivastava, Aarohi and Rastogi, Abhinav and Rao, Abhishek and Shoeb, Abu Awal Md and Abid, Abubakar and Fisch, Adam and Brown, Adam R and Santoro, Adam and Gupta, Aditya and Garriga-Alonso, Adri{\`a} and others},
  journal={arXiv preprint arXiv:2206.04615},
  year={2022}
}

@article{hendrycks2021measuring,
  title={Measuring mathematical problem solving with the math dataset},
  author={Hendrycks, Dan and Burns, Collin and Kadavath, Saurav and Arora, Akul and Basart, Steven and Tang, Eric and Song, Dawn and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2103.03874},
  year={2021}
}

@article{hendrycks2020measuring,
  title={Measuring massive multitask language understanding},
  author={Hendrycks, Dan and Burns, Collin and Basart, Steven and Zou, Andy and Mazeika, Mantas and Song, Dawn and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2009.03300},
  year={2020}
}

@article{bai2023qwen,
  title={Qwen-vl: A versatile vision-language model for understanding, localization, text reading, and beyond},
  author={Bai, Jinze and Bai, Shuai and Yang, Shusheng and Wang, Shijie and Tan, Sinan and Wang, Peng and Lin, Junyang and Zhou, Chang and Zhou, Jingren},
  year={2023}
}

@article{chen2023sharegpt4v,
  title={Sharegpt4v: Improving large multi-modal models with better captions},
  author={Chen, Lin and Li, Jisong and Dong, Xiaoyi and Zhang, Pan and He, Conghui and Wang, Jiaqi and Zhao, Feng and Lin, Dahua},
  journal={arXiv preprint arXiv:2311.12793},
  year={2023}
}

@article{yang2023dawn,
  title={The dawn of lmms: Preliminary explorations with gpt-4v (ision)},
  author={Yang, Zhengyuan and Li, Linjie and Lin, Kevin and Wang, Jianfeng and Lin, Chung-Ching and Liu, Zicheng and Wang, Lijuan},
  journal={arXiv preprint arXiv:2309.17421},
  volume={9},
  number={1},
  pages={1},
  year={2023}
}

@article{chen2024allava,
  title={ALLaVA: Harnessing GPT4V-synthesized Data for A Lite Vision-Language Model},
  author={Chen, Guiming Hardy and Chen, Shunian and Zhang, Ruifei and Chen, Junying and Wu, Xiangbo and Zhang, Zhiyi and Chen, Zhihong and Li, Jianquan and Wan, Xiang and Wang, Benyou},
  journal={arXiv preprint arXiv:2402.11684},
  year={2024}
}

@article{xu2024vision,
  title={Vision-Flan: Scaling Human-Labeled Tasks in Visual Instruction Tuning},
  author={Xu, Zhiyang and Feng, Chao and Shao, Rulin and Ashby, Trevor and Shen, Ying and Jin, Di and Cheng, Yu and Wang, Qifan and Huang, Lifu},
  journal={arXiv preprint arXiv:2402.11690},
  year={2024}
}

@article{overwijk2022clueweb22,
  title={Clueweb22: 10 billion web documents with visual and semantic information},
  author={Overwijk, Arnold and Xiong, Chenyan and Liu, Xiao and VandenBerg, Cameron and Callan, Jamie},
  journal={arXiv preprint arXiv:2211.15848},
  year={2022}
}

@article{li2023self,
  title={Self-alignment with instruction backtranslation},
  author={Li, Xian and Yu, Ping and Zhou, Chunting and Schick, Timo and Zettlemoyer, Luke and Levy, Omer and Weston, Jason and Lewis, Mike},
  journal={arXiv preprint arXiv:2308.06259},
  year={2023}
}

@article{chen2024self,
  title={Self-play fine-tuning converts weak language models to strong language models},
  author={Chen, Zixiang and Deng, Yihe and Yuan, Huizhuo and Ji, Kaixuan and Gu, Quanquan},
  journal={arXiv preprint arXiv:2401.01335},
  year={2024}
}

@article{zhao2024wildchat,
  title={wildchat: 570k chatGPT interaction logs in the wild},
  author={Zhao, Wenting and Ren, Xiang and Hessel, Jack and Cardie, Claire and Choi, Yejin and Deng, Yuntian},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2024}
}


@article{zheng2024judging,
  title={Judging llm-as-a-judge with mt-bench and chatbot arena},
  author={Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{zhu2023starling,
  title={Starling-7b: Improving llm helpfulness \& harmlessness with rlaif},
  author={Zhu, Banghua and Frick, Evan and Wu, Tianhao and Zhu, Hanlin and Jiao, Jiantao},
  year={2023},
  publisher={November}
}

@article{li2023textbooks,
  title={Textbooks are all you need ii: phi-1.5 technical report},
  author={Li, Yuanzhi and Bubeck, S{\'e}bastien and Eldan, Ronen and Del Giorno, Allie and Gunasekar, Suriya and Lee, Yin Tat},
  journal={arXiv preprint arXiv:2309.05463},
  year={2023}
}

@article{gunasekar2023textbooks,
  title={Textbooks Are All You Need},
  author={Gunasekar, Suriya and Zhang, Yi and Aneja, Jyoti and Mendes, Caio C{\'e}sar Teodoro and Del Giorno, Allie and Gopi, Sivakanth and Javaheripi, Mojan and Kauffmann, Piero and de Rosa, Gustavo and Saarikivi, Olli and others},
  journal={arXiv preprint arXiv:2306.11644},
  year={2023}
}

@article{yu2023wavecoder,
  title={Wavecoder: Widespread and versatile enhanced instruction tuning with refined data generation},
  author={Yu, Zhaojian and Zhang, Xin and Shang, Ning and Huang, Yangyu and Xu, Can and Zhao, Yishujie and Hu, Wenxiang and Yin, Qiufeng},
  journal={arXiv preprint arXiv:2312.14187},
  year={2023}
}

@article{wei2023magicoder,
  title={Magicoder: Source code is all you need},
  author={Wei, Yuxiang and Wang, Zhe and Liu, Jiawei and Ding, Yifeng and Zhang, Lingming},
  journal={arXiv preprint arXiv:2312.02120},
  year={2023}
}

@article{mukherjee2023orca,
  title={Orca: Progressive learning from complex explanation traces of gpt-4},
  author={Mukherjee, Subhabrata and Mitra, Arindam and Jawahar, Ganesh and Agarwal, Sahaj and Palangi, Hamid and Awadallah, Ahmed},
  journal={arXiv preprint arXiv:2306.02707},
  year={2023}
}

@article{mitra2023orca,
  title={Orca 2: Teaching small language models how to reason},
  author={Mitra, Arindam and Del Corro, Luciano and Mahajan, Shweti and Codas, Andres and Simoes, Clarisse and Agarwal, Sahaj and Chen, Xuxi and Razdaibiedina, Anastasia and Jones, Erik and Aggarwal, Kriti and others},
  journal={arXiv preprint arXiv:2311.11045},
  year={2023}
}

@article{wang2022self,
  title={Self-instruct: Aligning language model with self generated instructions},
  author={Wang, Yizhong and Kordi, Yeganeh and Mishra, Swaroop and Liu, Alisa and Smith, Noah A and Khashabi, Daniel and Hajishirzi, Hannaneh},
  journal={arXiv preprint arXiv:2212.10560},
  year={2022}
}


@article{nous-hermes, 
    author    = {NousResearch},
    year      = {2023},
journal= {software: huggingface.co/NousResearch/Nous-Hermes-13b}
}
@article{minotaur, 
    author    = {OpenAccess AI Collective},
    year      = {2023},
journal= {software: huggingface.co/openaccess-ai-collective/minotaur-15b}
}
@article{airoboros, 
    author    = {Durbin, Jon},
    title     = {Airoboros},
    year      = {2023},
journal= {software: github.com/jondurbin/airoboros}
}
@article{moss, 
    author    = {Tianxiang, Sun and Xipeng, Qiu},
    title     = {MOSS},
    year      = {2023},
    urldate   = {Feb 20, 2023},
journal= {Blog post txsun1997.github.io/blogs/moss.html}
}
@article{chatgpt, 
    author    = {OpenAI},
    title     = {Introducing ChatGPT},
    year      = {2022},
    urldate   = {November 30, 2022},
journal= {Blog post openai.com/blog/chatgpt}
}
@article{sanh2021multitask,
  title={Multitask prompted training enables zero-shot task generalization},
  author={Sanh, Victor and Webson, Albert and Raffel, Colin and Bach, Stephen H and Sutawika, Lintang and Alyafeai, Zaid and Chaffin, Antoine and Stiegler, Arnaud and Scao, Teven Le and Raja, Arun and others},
  journal={arXiv preprint arXiv:2110.08207},
  year={2021}
}
@article{khashabi2020unifiedqa,
  title={Unifiedqa: Crossing format boundaries with a single qa system},
  author={Khashabi, Daniel and Min, Sewon and Khot, Tushar and Sabharwal, Ashish and Tafjord, Oyvind and Clark, Peter and Hajishirzi, Hannaneh},
  journal={arXiv preprint arXiv:2005.00700},
  year={2020}
}
@article{DatabricksBlog2023DollyV2,
    author    = {Mike Conover and Matt Hayes and Ankit Mathur and Jianwei Xie and Jun Wan and Sam Shah and Ali Ghodsi and Patrick Wendell and Matei Zaharia and Reynold Xin},
    title     = {Free Dolly: Introducing the World's First Truly Open Instruction-Tuned LLM},
    year      = {2023},
}
@article{kopf2023openassistant,
  title={OpenAssistant Conversations--Democratizing Large Language Model Alignment},
  author={K{\"o}pf, Andreas and Kilcher, Yannic and von R{\"u}tte, Dimitri and Anagnostidis, Sotiris and Tam, Zhi-Rui and Stevens, Keith and Barhoum, Abdullah and Duc, Nguyen Minh and Stanley, Oliver and Nagyfi, Rich{\'a}rd and others},
  journal={arXiv preprint arXiv:2304.07327},
  year={2023}
}
@article{wang2022super,
  title={Super-naturalinstructions: Generalization via declarative instructions on 1600+ nlp tasks},
  author={Wang, Yizhong and Mishra, Swaroop and Alipoormolabashi, Pegah and Kordi, Yeganeh and Mirzaei, Amirreza and Arunkumar, Anjana and Ashok, Arjun and Dhanasekaran, Arut Selvan and Naik, Atharva and Stap, David and others},
  journal={arXiv preprint arXiv:2204.07705},
  year={2022}
}
@article{mishra2021cross,
  title={Cross-task generalization via natural language crowdsourcing instructions},
  author={Mishra, Swaroop and Khashabi, Daniel and Baral, Chitta and Hajishirzi, Hannaneh},
  journal={arXiv preprint arXiv:2104.08773},
  year={2021}
}
@article{Ning2023AlbumSW,
  title={Album Storytelling with Iterative Story-aware Captioning and Large Language Models},
  author={Munan Ning and Yujia Xie and Dongdong Chen and Zeyin Song and Lu Yuan and Yonghong Tian and Qixiang Ye and Liuliang Yuan},
  journal={ArXiv},
  year={2023},
  volume={abs/2305.12943}
}
@inproceedings{Xu2020ControllableSG,
  title={Controllable Story Generation with External Knowledge Using Large-Scale Language Models},
  author={Peng Xu and Mostofa Patwary and Mohammad Shoeybi and Raul Puri and Pascale Fung and Anima Anandkumar and Bryan Catanzaro},
  booktitle={Conference on Empirical Methods in Natural Language Processing},
  year={2020}
}
@article{gudibande2023false,
  title={The false promise of imitating proprietary llms},
  author={Gudibande, Arnav and Wallace, Eric and Snell, Charlie and Geng, Xinyang and Liu, Hao and Abbeel, Pieter and Levine, Sergey and Song, Dawn},
  journal={arXiv preprint arXiv:2305.15717},
  year={2023}
}
@inproceedings{Zhao2021CalibrateBU,
  title={Calibrate Before Use: Improving Few-Shot Performance of Language Models},
  author={Tony Zhao and Eric Wallace and Shi Feng and Dan Klein and Sameer Singh},
  booktitle={International Conference on Machine Learning},
  year={2021}
}
@inproceedings{Chen2023DistinguishBA,
  title={Distinguish Before Answer: Generating Contrastive Explanation as Knowledge for Commonsense Question Answering},
  author={Qianglong Chen and Guohai Xu and Mingshi Yan and Ji Zhang and Fei Huang and Luo Si and Yin Zhang},
  booktitle={Annual Meeting of the Association for Computational Linguistics},
  year={2023}
}
@article{shuster2022language,
  title={Language models that seek for knowledge: Modular search \& generation for dialogue and prompt completion},
  author={Shuster, Kurt and Komeili, Mojtaba and Adolphs, Leonard and Roller, Stephen and Szlam, Arthur and Weston, Jason},
  journal={arXiv preprint arXiv:2203.13224},
  year={2022}
}
@article{madotto2021few,
  title={Few-shot bot: Prompt-based learning for dialogue systems},
  author={Madotto, Andrea and Lin, Zhaojiang and Winata, Genta Indra and Fung, Pascale},
  journal={arXiv preprint arXiv:2110.08118},
  year={2021}
}
@article{liu2022multi,
  title={Multi-stage prompting for knowledgeable dialogue generation},
  author={Liu, Zihan and Patwary, Mostofa and Prenger, Ryan and Prabhumoye, Shrimai and Ping, Wei and Shoeybi, Mohammad and Catanzaro, Bryan},
  journal={arXiv preprint arXiv:2203.08745},
  year={2022}
}
@article{Chen2023ControllableMD,
  title={Controllable Mixed-Initiative Dialogue Generation through Prompting},
  author={Maximillian Chen and Xiao Yu and Weiyan Shi and Urvi Awasthi and Zhou Yu},
  journal={ArXiv},
  year={2023},
  volume={abs/2305.04147}
}
@article{Gao2023ExploringTF,
  title={Exploring the Feasibility of ChatGPT for Event Extraction},
  author={Jun Gao and Huan Zhao and Changlong Yu and Ruifeng Xu},
  journal={ArXiv},
  year={2023},
  volume={abs/2303.03836}
}
@article{Li2023EvaluatingCI,
  title={Evaluating ChatGPT's Information Extraction Capabilities: An Assessment of Performance, Explainability, Calibration, and Faithfulness},
  author={Bo Li and Gexiang Fang and Yang Yang and Quansen Wang and Wei Ye and Wen Zhao and Shikun Zhang},
  journal={ArXiv},
  year={2023},
  volume={abs/2304.11633}
}
@article{Yang2022TailorAP,
  title={Tailor: A Prompt-Based Approach to Attribute-Based Controlled Text Generation},
  author={Kexin Yang and Dayiheng Liu and Wenqiang Lei and Baosong Yang and Mingfeng Xue and Boxing Chen and Jun Xie},
  journal={ArXiv},
  year={2022},
  volume={abs/2204.13362}
}
@article{Liu2023AttributeCD,
  title={Attribute Controlled Dialogue Prompting},
  author={Runcheng Liu and Ahmad Rashid and Ivan Kobyzev and Mehdi Rezagholizadeh and Pascal Poupart},
  journal={ArXiv},
  year={2023},
  volume={abs/2307.05228}
}
@article{Adlakha2023EvaluatingCA,
  title={Evaluating Correctness and Faithfulness of Instruction-Following Models for Question Answering},
  author={Vaibhav Adlakha and Parishad BehnamGhader and Xing Han Lu and Nicholas Meade and Siva Reddy},
  journal={ArXiv},
  year={2023},
  volume={abs/2307.16877}
}
@article{Lee2022CoAuthorDA,
  title={CoAuthor: Designing a Human-AI Collaborative Writing Dataset for Exploring Language Model Capabilities},
  author={Mina Lee and Percy Liang and Qian Yang},
  journal={Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
  year={2022}
}
@article{Wang2022SelfConsistencyIC,
  title={Self-Consistency Improves Chain of Thought Reasoning in Language Models},
  author={Xuezhi Wang and Jason Wei and Dale Schuurmans and Quoc Le and Ed Huai-hsin Chi and Denny Zhou},
  journal={ArXiv},
  year={2022},
  volume={abs/2203.11171}
}

@article{Yao2023TreeOT,
  title={Tree of Thoughts: Deliberate Problem Solving with Large Language Models},
  author={Shunyu Yao and Dian Yu and Jeffrey Zhao and Izhak Shafran and Thomas L. Griffiths and Yuan Cao and Karthik Narasimhan},
  journal={ArXiv},
  year={2023},
  volume={abs/2305.10601}
}
@article{Sun2023AnsweringAQ,
  title={Answering Ambiguous Questions via Iterative Prompting},
  author={Weiwei Sun and Hengyi Cai and Hongshen Chen and Pengjie Ren and Zhumin Chen and Maarten de Rijke and Zhaochun Ren},
  journal={ArXiv},
  year={2023},
  volume={abs/2307.03897}
}
@article{Sheng2023ADS,
  title={A Dialogue System for Assessing Activities of Daily Living: Improving Consistency with Grounded Knowledge},
  author={Zhecheng Sheng and Raymond L. Finzel and Michael Lucke and Sheena Dufresne and Maria L. Gini and Serguei V. S. Pakhomov},
  journal={ArXiv},
  year={2023},
  volume={abs/2307.07544}
}
@article{wei2023zero,
  title={Zero-shot information extraction via chatting with chatgpt},
  author={Wei, Xiang and Cui, Xingyu and Cheng, Ning and Wang, Xiaobin and Zhang, Xin and Huang, Shen and Xie, Pengjun and Xu, Jinan and Chen, Yufeng and Zhang, Meishan and others},
  journal={arXiv preprint arXiv:2302.10205},
  year={2023}
}
@article{wang2021mrc,
  title={An mrc framework for semantic role labeling},
  author={Wang, Nan and Li, Jiwei and Meng, Yuxian and Sun, Xiaofei and Qiu, Han and Wang, Ziyao and Wang, Guoyin and He, Jun},
  journal={arXiv preprint arXiv:2109.06660},
  year={2021}
}
@article{wang2022k,
  title={$ k $ NN-NER: Named Entity Recognition with Nearest Neighbor Search},
  author={Wang, Shuhe and Li, Xiaoya and Meng, Yuxian and Zhang, Tianwei and Ouyang, Rongbin and Li, Jiwei and Wang, Guoyin},
  journal={arXiv preprint arXiv:2203.17103},
  year={2022}
}
@article{sun2021paraphrase,
  title={Paraphrase generation as unsupervised machine translation},
  author={Sun, Xiaofei and Tian, Yufei and Meng, Yuxian and Peng, Nanyun and Wu, Fei and Li, Jiwei and Fan, Chun},
  journal={arXiv preprint arXiv:2109.02950},
  year={2021}
}
@article{li2017adversarial,
  title={Adversarial learning for neural dialogue generation},
  author={Li, Jiwei and Monroe, Will and Shi, Tianlin and Jean, S{\'e}bastien and Ritter, Alan and Jurafsky, Dan},
  journal={arXiv preprint arXiv:1701.06547},
  year={2017}
}
@article{duan2018temporality,
  title={Temporality-enhanced knowledgememory network for factoid question answering},
  author={Duan, Xin-yu and Tang, Si-liang and Zhang, Sheng-yu and Zhang, Yin and Zhao, Zhou and Xue, Jian-ru and Zhuang, Yue-ting and Wu, Fei},
  journal={Frontiers of Information Technology \& Electronic Engineering},
  volume={19},
  number={1},
  pages={104--115},
  year={2018},
  publisher={Springer}
}
@article{li2016deep,
  title={Deep reinforcement learning for dialogue generation},
  author={Li, Jiwei and Monroe, Will and Ritter, Alan and Galley, Michel and Gao, Jianfeng and Jurafsky, Dan},
  journal={arXiv preprint arXiv:1606.01541},
  year={2016}
}
@article{li2016persona,
  title={A persona-based neural conversation model},
  author={Li, Jiwei and Galley, Michel and Brockett, Chris and Spithourakis, Georgios P and Gao, Jianfeng and Dolan, Bill},
  journal={arXiv preprint arXiv:1603.06155},
  year={2016}
}
@article{li2015diversity,
  title={A diversity-promoting objective function for neural conversation models},
  author={Li, Jiwei and Galley, Michel and Brockett, Chris and Gao, Jianfeng and Dolan, Bill},
  journal={arXiv preprint arXiv:1510.03055},
  year={2015}
}
@article{gan2021dependency,
  title={Dependency parsing as mrc-based span-span prediction},
  author={Gan, Leilei and Meng, Yuxian and Kuang, Kun and Sun, Xiaofei and Fan, Chun and Wu, Fei and Li, Jiwei},
  journal={arXiv preprint arXiv:2105.07654},
  year={2021}
}
@article{li2019entity,
  title={Entity-relation extraction as multi-turn question answering},
  author={Li, Xiaoya and Yin, Fan and Sun, Zijun and Li, Xiayu and Yuan, Arianna and Chai, Duo and Zhou, Mingxin and Li, Jiwei},
  journal={arXiv preprint arXiv:1905.05529},
  year={2019}
}
@article{sun2021paraphrase,
  title={Paraphrase generation as unsupervised machine translation},
  author={Sun, Xiaofei and Tian, Yufei and Meng, Yuxian and Peng, Nanyun and Wu, Fei and Li, Jiwei and Fan, Chun},
  journal={arXiv preprint arXiv:2109.02950},
  year={2021}
}
@article{sun2020summarize,
  title={Summarize, outline, and elaborate: Long-text generation via hierarchical supervision from extractive summaries},
  author={Sun, Xiaofei and Sun, Zijun and Meng, Yuxian and Li, Jiwei and Fan, Chun},
  journal={arXiv preprint arXiv:2010.07074},
  year={2020}
}
@article{li2019unified,
  title={A unified MRC framework for named entity recognition},
  author={Li, Xiaoya and Feng, Jingrong and Meng, Yuxian and Han, Qinghong and Wu, Fei and Li, Jiwei},
  journal={arXiv preprint arXiv:1910.11476},
  year={2019}
}
@article{lin2021bertgcn,
  title={Bertgcn: Transductive text classification by combining gcn and bert},
  author={Lin, Yuxiao and Meng, Yuxian and Sun, Xiaofei and Han, Qinghong and Kuang, Kun and Li, Jiwei and Wu, Fei},
  journal={arXiv preprint arXiv:2105.05727},
  year={2021}
}
@article{meng2021conrpg,
  title={ConRPG: paraphrase generation using contexts as regularizer},
  author={Meng, Yuxian and Ao, Xiang and He, Qing and Sun, Xiaofei and Han, Qinghong and Wu, Fei and Li, Jiwei and others},
  journal={arXiv preprint arXiv:2109.00363},
  year={2021}
}
@article{chen2022controllable,
  title={Controllable Text Generation with Language Constraints},
  author={Chen, Howard and Li, Huihan and Chen, Danqi and Narasimhan, Karthik},
  journal={arXiv preprint arXiv:2212.10466},
  year={2022}
}
@article{gao2023enabling,
  title={Enabling Large Language Models to Generate Text with Citations},
  author={Gao, Tianyu and Yen, Howard and Yu, Jiatong and Chen, Danqi},
  journal={arXiv preprint arXiv:2305.14627},
  year={2023}
}
@article{qian2022controllable,
  title={Controllable natural language generation with contrastive prefixes},
  author={Qian, Jing and Dong, Li and Shen, Yelong and Wei, Furu and Chen, Weizhu},
  journal={arXiv preprint arXiv:2202.13257},
  year={2022}
}
@article{liu2021makes,
  title={What Makes Good In-Context Examples for GPT-$3 $?},
  author={Liu, Jiachang and Shen, Dinghan and Zhang, Yizhe and Dolan, Bill and Carin, Lawrence and Chen, Weizhu},
  journal={arXiv preprint arXiv:2101.06804},
  year={2021}
}
@article{wiegreffe2021reframing,
  title={Reframing human-AI collaboration for generating free-text explanations},
  author={Wiegreffe, Sarah and Hessel, Jack and Swayamdipta, Swabha and Riedl, Mark and Choi, Yejin},
  journal={arXiv preprint arXiv:2112.08674},
  year={2021}
}

@article{yang2022re3,
  title={Re3: Generating longer stories with recursive reprompting and revision},
  author={Yang, Kevin and Peng, Nanyun and Tian, Yuandong and Klein, Dan},
  journal={arXiv preprint arXiv:2210.06774},
  year={2022}
}
@article{sun2023text,
  title={Text Classification via Large Language Models},
  author={Sun, Xiaofei and Li, Xiaoya and Li, Jiwei and Wu, Fei and Guo, Shangwei and Zhang, Tianwei and Wang, Guoyin},
  journal={arXiv preprint arXiv:2305.08377},
  year={2023}
}
@article{wan2023gpt,
  title={Gpt-re: In-context learning for relation extraction using large language models},
  author={Wan, Zhen and Cheng, Fei and Mao, Zhuoyuan and Liu, Qianying and Song, Haiyue and Li, Jiwei and Kurohashi, Sadao},
  journal={arXiv preprint arXiv:2305.02105},
  year={2023}
}
@article{wang2023gpt,
  title={Gpt-ner: Named entity recognition via large language models},
  author={Wang, Shuhe and Sun, Xiaofei and Li, Xiaoya and Ouyang, Rongbin and Wu, Fei and Zhang, Tianwei and Li, Jiwei and Wang, Guoyin},
  journal={arXiv preprint arXiv:2304.10428},
  year={2023}
}
@article{thoppilan2022lamda,
  title={Lamda: Language models for dialog applications},
  author={Thoppilan, Romal and De Freitas, Daniel and Hall, Jamie and Shazeer, Noam and Kulshreshtha, Apoorv and Cheng, Heng-Tze and Jin, Alicia and Bos, Taylor and Baker, Leslie and Du, Yu and others},
  journal={arXiv preprint arXiv:2201.08239},
  year={2022}
}
@article{rae2021scaling,
  title={Scaling language models: Methods, analysis \& insights from training gopher},
  author={Rae, Jack W and Borgeaud, Sebastian and Cai, Trevor and Millican, Katie and Hoffmann, Jordan and Song, Francis and Aslanides, John and Henderson, Sarah and Ring, Roman and Young, Susannah and others},
  journal={arXiv preprint arXiv:2112.11446},
  year={2021}
}
@article{Fedus2021SwitchTS,
  title={Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity},
  author={William Fedus and Barret Zoph and Noam M. Shazeer},
  journal={J. Mach. Learn. Res.},
  year={2021},
  volume={23},
  pages={120:1-120:39}
}
@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}
@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}
@inproceedings{DBLP:conf/iclr/WeiBZGYLDDL22,
  author       = {Jason Wei and
                  Maarten Bosma and
                  Vincent Y. Zhao and
                  Kelvin Guu and
                  Adams Wei Yu and
                  Brian Lester and
                  Nan Du and
                  Andrew M. Dai and
                  Quoc V. Le},
  title        = {Finetuned Language Models are Zero-Shot Learners},
  booktitle    = {The Tenth International Conference on Learning Representations, {ICLR}},
  year         = {2022}
}
@article{sun2023pushing,
  title={Pushing the Limits of ChatGPT on NLP Tasks},
  author={Sun, Xiaofei and Dong, Linfeng and Li, Xiaoya and Wan, Zhen and Wang, Shuhe and Zhang, Tianwei and Li, Jiwei and Cheng, Fei and Lyu, Lingjuan and Wu, Fei and others},
  journal={arXiv preprint arXiv:2306.09719},
  year={2023}
}

@article{yang2023harnessing,
  title={Harnessing the power of llms in practice: A survey on chatgpt and beyond},
  author={Yang, Jingfeng and Jin, Hongye and Tang, Ruixiang and Han, Xiaotian and Feng, Qizhang and Jiang, Haoming and Yin, Bing and Hu, Xia},
  journal={arXiv preprint arXiv:2304.13712},
  year={2023}
}
@article{wang2023aligning,
  title={Aligning Large Language Models with Human: A Survey},
  author={Wang, Yufei and Zhong, Wanjun and Li, Liangyou and Mi, Fei and Zeng, Xingshan and Huang, Wenyong and Shang, Lifeng and Jiang, Xin and Liu, Qun},
  journal={arXiv preprint arXiv:2307.12966},
  year={2023}
}
@article{huang2022towards,
  title={Towards reasoning in large language models: A survey},
  author={Huang, Jie and Chang, Kevin Chen-Chuan},
  journal={arXiv preprint arXiv:2212.10403},
  year={2022}
}
@article{zhao2023survey,
  title={A survey of large language models},
  author={Zhao, Wayne Xin and Zhou, Kun and Li, Junyi and Tang, Tianyi and Wang, Xiaolei and Hou, Yupeng and Min, Yingqian and Zhang, Beichen and Zhang, Junjie and Dong, Zican and others},
  journal={arXiv preprint arXiv:2303.18223},
  year={2023}
}
@inproceedings{DBLP:conf/acl/ZakenGR22,
  author       = {Elad Ben Zaken and
                  Yoav Goldberg and
                  Shauli Ravfogel},
  title        = {BitFit: Simple Parameter-efficient Fine-tuning for Transformer-based
                  Masked Language-models},
  booktitle    = {Proceedings of the 60th Annual Meeting of the Association for Computational
                  Linguistics (Volume 2: Short Papers), {ACL} 2022, Dublin, Ireland,
                  May 22-27, 2022},
  pages        = {1--9},
  publisher    = {Association for Computational Linguistics},
  year         = {2022}
}
@inproceedings{DBLP:conf/eacl/SchickS21,
  author       = {Timo Schick and
                  Hinrich Sch{\"{u}}tze},
  title        = {Exploiting Cloze-Questions for Few-Shot Text Classification and Natural
                  Language Inference},
  booktitle    = {Proceedings of the 16th Conference of the European Chapter of the
                  Association for Computational Linguistics: Main Volume},
  pages        = {255--269},
  year         = {2021}
}
@inproceedings{DBLP:conf/icml/HoulsbyGJMLGAG19,
  author       = {Neil Houlsby and
                  Andrei Giurgiu and
                  Stanislaw Jastrzebski and
                  Bruna Morrone and
                  Quentin de Laroussilhe and
                  Andrea Gesmundo and
                  Mona Attariyan and
                  Sylvain Gelly},
  title        = {Parameter-Efficient Transfer Learning for {NLP}},
  booktitle    = {Proceedings of the 36th International Conference on Machine Learning},
  volume       = {97},
  pages        = {2790--2799},
  publisher    = {{PMLR}},
  year         = {2019}
}
@article{cobbe2021training,
  title={Training Verifiers to Solve Math Word Problems},
  author={Karl Cobbe and Vineet Kosaraju and Mohammad Bavarian and Mark Chen and Heewoo Jun and Lukasz Kaiser and Matthias Plappert and Jerry Tworek and Jacob Hilton and Reiichiro Nakano and Christopher Hesse and John Schulman},
  journal={ArXiv},
  year={2021},
  volume={abs/2110.14168}
}
@article{Srivastava2022BeyondTI,
  title={Beyond the imitation game: Quantifying and extrapolating the capabilities of language models},
  author={Srivastava, Aarohi and Rastogi, Abhinav and Rao, Abhishek and Shoeb, Abu Awal Md and Abid, Abubakar and Fisch, Adam and Brown, Adam R and Santoro, Adam and Gupta, Aditya and Garriga-Alonso, Adri{\`a} and others},
  journal={arXiv preprint arXiv:2206.04615},
  year={2022}
}
@article{Wei2022ChainOT,
  title={Chain of Thought Prompting Elicits Reasoning in Large Language Models},
  author={Jason Wei and Xuezhi Wang and Dale Schuurmans and Maarten Bosma and Ed Huai-hsin Chi and F. Xia and Quoc Le and Denny Zhou},
  journal={ArXiv},
  year={2022},
  volume={abs/2201.11903}
}
@article{Clark2018ThinkYH,
  title={Think you have Solved Question Answering? Try ARC, the AI2 Reasoning Challenge},
  author={Peter Clark and Isaac Cowhey and Oren Etzioni and Tushar Khot and Ashish Sabharwal and Carissa Schoenick and Oyvind Tafjord},
  journal={ArXiv},
  year={2018},
  volume={abs/1803.05457}
}
@article{Clark2019BoolQET,
  title={BoolQ: Exploring the Surprising Difficulty of Natural Yes/No Questions},
  author={Christopher Clark and Kenton Lee and Ming-Wei Chang and Tom Kwiatkowski and Michael Collins and Kristina Toutanova},
  journal={ArXiv},
  year={2019},
  volume={abs/1905.10044}
}
@misc{li2023camel,
    title={CAMEL: Communicative Agents for "Mind" Exploration of Large Scale Language Model Society},
    author={Guohao Li and Hasan Abed Al Kader Hammoud and Hani Itani and Dmitrii Khizbullin and Bernard Ghanem},
    year={2023},
    archivePrefix={arXiv},
    primaryClass={cs.AI}
}
@misc{chaudhary2023code,
  title={Code alpaca: An instruction-following llama model for code generation},
  author={Chaudhary, Sahil},
  year={2023}
}
@article{li2023starcoder,
  title={StarCoder: may the source be with you!},
  author={Li, Raymond and Allal, Loubna Ben and Zi, Yangtian and Muennighoff, Niklas and Kocetkov, Denis and Mou, Chenghao and Marone, Marc and Akiki, Christopher and Li, Jia and Chim, Jenny and others},
  journal={arXiv preprint arXiv:2305.06161},
  year={2023}
}
@misc{almazrouei2023falcon,
  title={Falcon-40B: an open large language model with state-of-the-art performance},
  author={Almazrouei, Ebtesam and Alobeidli, Hamza and Alshamsi, Abdulaziz and Cappelli, Alessandro and Cojocaru, Ruxandra and Debbah, Merouane and Goffinet, Etienne and Heslow, Daniel and Launay, Julien and Malartic, Quentin and others},
  year={2023}
}
@article{beeching2023open,
  title={Open LLM Leaderboard},
  author={Beeching, Edward and Han, Sheon and Lambert, Nathan and Rajani, Nazneen and Sanseviero, Omar and Tunstall, Lewis and Wolf, Thomas},
  journal={Hugging Face},
  year={2023}
}
@inproceedings{dao2022flashattention,
  title={Flash{A}ttention: Fast and Memory-Efficient Exact Attention with {IO}-Awareness},
  author={Dao, Tri and Fu, Daniel Y. and Ermon, Stefano and Rudra, Atri and R{\'e}, Christopher},
  booktitle={Advances in Neural Information Processing Systems},
  year={2022}
}
@article{penedo2023refinedweb,
  title={The RefinedWeb dataset for Falcon LLM: outperforming curated corpora with web data, and web data only},
  author={Penedo, Guilherme and Malartic, Quentin and Hesslow, Daniel and Cojocaru, Ruxandra and Cappelli, Alessandro and Alobeidli, Hamza and Pannier, Baptiste and Almazrouei, Ebtesam and Launay, Julien},
  journal={arXiv preprint arXiv:2306.01116},
  year={2023}
}
@article{Xu2023BaizeAO,
  title={Baize: An Open-Source Chat Model with Parameter-Efficient Tuning on Self-Chat Data},
  author={Canwen Xu and Daya Guo and Nan Duan and Julian McAuley},
  journal={ArXiv},
  year={2023},
  volume={abs/2304.01196}
}
@article{Black2022GPTNeoX20BAO,
  title={GPT-NeoX-20B: An Open-Source Autoregressive Language Model},
  author={Sid Black and Stella Rose Biderman and Eric Hallahan and Quentin G. Anthony and Leo Gao and Laurence Golding and Horace He and Connor Leahy and Kyle McDonell and Jason Phang and Michael Martin Pieler and USVSN Sai Prashanth and Shivanshu Purohit and Laria Reynolds and Jonathan Tow and Benqi Wang and Samuel Weinbach},
  journal={ArXiv},
  year={2022},
  volume={abs/2204.06745}
}
@article{gao2021framework,
  title={A framework for few-shot language model evaluation},
  author={Gao, Leo and Tow, Jonathan and Biderman, Stella and Black, Sid and DiPofi, Anthony and Foster, Charles and Golding, Laurence and Hsu, Jeffrey and McDonell, Kyle and Muennighoff, Niklas and others},
  journal={Version v0. 0.1. Sept},
  year={2021}
}
@article{Bach2022PromptSourceAI,
  title={PromptSource: An Integrated Development Environment and Repository for Natural Language Prompts},
  author={Stephen H. Bach and Victor Sanh and Zheng Xin Yong and Albert Webson and Colin Raffel and Nihal V. Nayak and Abheesht Sharma and Taewoon Kim and M Saiful Bari and Thibault F{\'e}vry and Zaid Alyafeai and Manan Dey and Andrea Santilli and Zhiqing Sun and Srulik Ben-David and Canwen Xu and Gunjan Chhablani and Han Wang and Jason Alan Fries and Maged S. Al-shaibani and Shanya Sharma and Urmish Thakker and Khalid Almubarak and Xiangru Tang and Mike Tian-Jian Jiang and Alexander M. Rush},
  journal={ArXiv},
  year={2022},
  volume={abs/2202.01279}
}
@article{Zhang2022OPTOP,
  title={OPT: Open Pre-trained Transformer Language Models},
  author={Susan Zhang and Stephen Roller and Naman Goyal and Mikel Artetxe and Moya Chen and Shuohui Chen and Christopher Dewan and Mona T. Diab and Xian Li and Xi Victoria Lin and Todor Mihaylov and Myle Ott and Sam Shleifer and Kurt Shuster and Daniel Simig and Punit Singh Koura and Anjali Sridhar and Tianlu Wang and Luke Zettlemoyer},
  journal={ArXiv},
  year={2022},
  volume={abs/2205.01068}
}
@inproceedings{Xie2022UnifiedSKGUA,
  title={UnifiedSKG: Unifying and Multi-Tasking Structured Knowledge Grounding with Text-to-Text Language Models},
  author={Tianbao Xie and Chen Henry Wu and Peng Shi and Ruiqi Zhong and Torsten Scholak and Michihiro Yasunaga and Chien-Sheng Wu and Ming Zhong and Pengcheng Yin and Sida I. Wang and Victor Zhong and Bailin Wang and Chengzu Li and Connor Boyle and Ansong Ni and Ziyu Yao and Dragomir R. Radev and Caiming Xiong and Lingpeng Kong and Rui Zhang and Noah A. Smith and Luke Zettlemoyer and Tao Yu},
  booktitle={Conference on Empirical Methods in Natural Language Processing},
  year={2022}
}
@inproceedings{Wang2022SuperNaturalInstructionsGV,
  title={Super-NaturalInstructions: Generalization via Declarative Instructions on 1600+ NLP Tasks},
  author={Yizhong Wang and Swaroop Mishra and Pegah Alipoormolabashi and Yeganeh Kordi and Amirreza Mirzaei and Anjana Arunkumar and Arjun Ashok and Arut Selvan Dhanasekaran and Atharva Naik and David Stap and Eshaan Pathak and Giannis Karamanolakis and Haizhi Gary Lai and Ishan Purohit and Ishani Mondal and Jacob Anderson and Kirby Kuznia and Krima Doshi and Maitreya Patel and Kuntal Kumar Pal and M. Moradshahi and Mihir Parmar and Mirali Purohit and Neeraj Varshney and Phani Rohitha Kaza and Pulkit Verma and Ravsehaj Singh Puri and Rushang Karia and Shailaja Keyur Sampat and Savan Doshi and Siddharth Deepak Mishra and Sujan Reddy and Sumanta Patro and Tanay Dixit and Xudong Shen and Chitta Baral and Yejin Choi and Noah A. Smith and Hanna Hajishirzi and Daniel Khashabi},
  booktitle={Conference on Empirical Methods in Natural Language Processing},
  year={2022}
}
@inproceedings{Baumgartner2020ThePR,
  title={The Pushshift Reddit Dataset},
  author={Jason Baumgartner and Savvas Zannettou and Brian Keegan and Megan Squire and Jeremy Blackburn},
  booktitle={International Conference on Web and Social Media},
  year={2020}
}
@article{bai2022constitutional,
  title={Constitutional AI: Harmlessness from AI Feedback},
  author={Bai, Yuntao and Kadavath, Saurav and Kundu, Sandipan and Askell, Amanda and Kernion, Jackson and Jones, Andy and Chen, Anna and Goldie, Anna and Mirhoseini, Azalia and McKinnon, Cameron and others},
  journal={arXiv preprint arXiv:2212.08073},
  year={2022}
}
@article{Ding2023ParameterefficientFO,
  title={Parameter-efficient fine-tuning of large-scale pre-trained language models},
  author={Ning Ding and Yujia Qin and Guang Yang and Fu Wei and Zonghan Yang and Yusheng Su and Shengding Hu and Yulin Chen and Chi-Min Chan and Weize Chen and Jing Yi and Weilin Zhao and Xiaozhi Wang and Zhiyuan Liu and Haitao Zheng and Jianfei Chen and Y. Liu and Jie Tang and Juanzi Li and Maosong Sun},
  journal={Nature Machine Intelligence},
  year={2023},
  volume={5},
  pages={220-235}
}
@article{Sun2023PrincipleDrivenSO,
  title={Principle-Driven Self-Alignment of Language Models from Scratch with Minimal Human Supervision},
  author={Zhiqing Sun and Yikang Shen and Qinhong Zhou and Hongxin Zhang and Zhenfang Chen and David D. Cox and Yiming Yang and Chuang Gan},
  journal={ArXiv},
  year={2023},
  volume={abs/2305.03047}
}
@article{huang2023ceval,
title={C-Eval: A Multi-Level Multi-Discipline Chinese Evaluation Suite for Foundation Models}, 
author={Huang, Yuzhen and Bai, Yuzhuo and Zhu, Zhihao and Zhang, Junlei and Zhang, Jinghan and Su, Tangjun and Liu, Junteng and Lv, Chuancheng and Zhang, Yikai and Lei, Jiayi and  Fu, Yao and Sun, Maosong and He, Junxian},
journal={arXiv preprint arXiv:2305.08322},
year={2023}
}
@article{Liang2022HolisticEO,
  title={Holistic Evaluation of Language Models},
  author={Percy Liang and Rishi Bommasani and Tony Lee and Dimitris Tsipras and Dilara Soylu and Michihiro Yasunaga and Yian Zhang and Deepak Narayanan and Yuhuai Wu and Ananya Kumar and Benjamin Newman and Binhang Yuan and Bobby Yan and Ce Zhang and Christian Cosgrove and Christopher D. Manning and Christopher R'e and Diana Acosta-Navas and Drew A. Hudson and E. Zelikman and Esin Durmus and Faisal Ladhak and Frieda Rong and Hongyu Ren and Huaxiu Yao and Jue Wang and Keshav Santhanam and Laurel J. Orr and Lucia Zheng and Mert Yuksekgonul and Mirac Suzgun and Nathan S. Kim and Neel Guha and Niladri S. Chatterji and Omar Khattab and Peter Henderson and Qian Huang and Ryan Chi and Sang Michael Xie and Shibani Santurkar and Surya Ganguli and Tatsunori Hashimoto and Thomas F. Icard and Tianyi Zhang and Vishrav Chaudhary and William Wang and Xuechen Li and Yifan Mai and Yuhui Zhang and Yuta Koreeda},
  journal={Annals of the New York Academy of Sciences},
  year={2022}
}
@article{Schulman2017ProximalPO,
  title={Proximal Policy Optimization Algorithms},
  author={John Schulman and Filip Wolski and Prafulla Dhariwal and Alec Radford and Oleg Klimov},
  journal={ArXiv},
  year={2017},
  volume={abs/1707.06347}
}
@article{Iyer2022OPTIMLSL,
  title={OPT-IML: Scaling Language Model Instruction Meta Learning through the Lens of Generalization},
  author={Srinivas Iyer and Xiaojuan Lin and Ramakanth Pasunuru and Todor Mihaylov and Daniel Simig and Ping Yu and Kurt Shuster and Tianlu Wang and Qing Liu and Punit Singh Koura and Xian Li and Brian O'Horo and Gabriel Pereyra and Jeff Wang and Christopher Dewan and Asli Celikyilmaz and Luke Zettlemoyer and Veselin Stoyanov},
  journal={ArXiv},
  year={2022},
  volume={abs/2212.12017}
}

@article{OpenAI2023GPT4TR,
  title={GPT-4 Technical Report},
  author={OpenAI},
  journal={ArXiv},
  year={2023},
  volume={abs/2303.08774}
}
@article{Touvron2023LLaMAOA,
  title={LLaMA: Open and Efficient Foundation Language Models},
  author={Hugo Touvron and Thibaut Lavril and Gautier Izacard and Xavier Martinet and Marie-Anne Lachaux and Timoth{\'e}e Lacroix and Baptiste Rozi{\`e}re and Naman Goyal and Eric Hambro and Faisal Azhar and Aur'elien Rodriguez and Armand Joulin and Edouard Grave and Guillaume Lample},
  journal={ArXiv},
  year={2023},
  volume={abs/2302.13971}
}
@article{Scao2022BLOOMA1,
  title={BLOOM: A 176B-Parameter Open-Access Multilingual Language Model},
  author={Teven Le Scao and Angela Fan and Christopher Akiki and Elizabeth-Jane Pavlick and Suzana Ili'c and Daniel Hesslow and Roman Castagn'e and Alexandra Sasha Luccioni and Franccois Yvon and Matthias Gall{\'e} and Jonathan Tow and Alexander M. Rush and Stella Rose Biderman and Albert Webson and Pawan Sasanka Ammanamanchi and Thomas Wang and Beno{\^i}t Sagot and Niklas Muennighoff and Albert Villanova del Moral and Olatunji Ruwase and Rachel Bawden and Stas Bekman and Angelina McMillan-Major and Iz Beltagy and Huu Nguyen and Lucile Saulnier and Samson Tan and Pedro Ortiz Suarez and Victor Sanh and Hugo Laurenccon and Yacine Jernite and Julien Launay and Margaret Mitchell and Colin Raffel and Aaron Gokaslan and Adi Simhi and Aitor Soroa Etxabe and Alham Fikri Aji and Amit Alfassy and Anna Rogers and Ariel Kreisberg Nitzav and Canwen Xu and Chenghao Mou and Chris C. Emezue and Christopher Klamm and Colin Leong and Daniel Alexander van Strien and David Ifeoluwa Adelani and Dragomir R. Radev and Eduardo Gonz'alez Ponferrada and Efrat Levkovizh and Ethan Kim and Eyal Bar Natan and Francesco De Toni and G{\'e}rard Dupont and Germ{\'a}n Kruszewski and Giada Pistilli and Hady ElSahar and Hamza Benyamina and Hieu Trung Tran and Ian Yu and Idris Abdulmumin and Isaac Johnson and Itziar Gonzalez-Dios and Javier de la Rosa and Jenny Chim and Jesse Dodge and Jian Zhu and Jonathan Chang and Jorg Frohberg and Josephine L. Tobing and Joydeep Bhattacharjee and Khalid Almubarak and Kimbo Chen and Kyle Lo and Leandro von Werra and Leon Weber and Long Phan and Loubna Ben Allal and Ludovic Tanguy and Manan Dey and Manuel Romero Mu{\~n}oz and Maraim Masoud and Mar'ia Grandury and Mario vSavsko and Max Huang and Maximin Coavoux and Mayank Singh and Mike Tian-Jian Jiang and Minh Chien Vu and Mohammad Ali Jauhar and Mustafa Ghaleb and Nishant Subramani and Nora Kassner and Nurulaqilla Khamis and Olivier Nguyen and Omar Espejel and Ona de Gibert and Paulo Villegas and Peter Henderson and Pierre Colombo and Priscilla A. Amuok and Quentin Lhoest and Rheza Harliman and Rishi Bommasani and Roberto L'opez and Rui Ribeiro and Salomey Osei and Sampo Pyysalo and Sebastian Nagel and Shamik Bose and Shamsuddeen Hassan Muhammad and Shanya Sharma and S. Longpre and Somaieh Nikpoor and Stanislav Silberberg and Suhas Pai and Sydney Zink and Tiago Timponi Torrent and Timo Schick and Tristan Thrush and Valentin Danchev and Vassilina Nikoulina and Veronika Laippala and Violette Lepercq and Vrinda Prabhu and Zaid Alyafeai and Zeerak Talat and Arun Raja and Benjamin Heinzerling and Chenglei Si and Elizabeth Salesky and Sabrina J. Mielke and Wilson Y. Lee and Abheesht Sharma and Andrea Santilli and Antoine Chaffin and Arnaud Stiegler and Debajyoti Datta and Eliza Szczechla and Gunjan Chhablani and Han Wang and Harshit Pandey and Hendrik Strobelt and Jason Alan Fries and Jos Rozen and Leo Gao and Lintang Sutawika and M Saiful Bari and Maged S. Al-shaibani and Matteo Manica and Nihal V. Nayak and Ryan Teehan and Samuel Albanie and Sheng Shen and Srulik Ben-David and Stephen H. Bach and Taewoon Kim and Tali Bers and Thibault F{\'e}vry and Trishala Neeraj and Urmish Thakker and Vikas Raunak and Xiang Tang and Zheng Xin Yong and Zhiqing Sun and Shaked Brody and Y Uri and Hadar Tojarieh and Adam Roberts and Hyung Won Chung and Jaesung Tae and Jason Phang and Ofir Press and Conglong Li and Deepak Narayanan and Hatim Bourfoune and Jared Casper and Jeff Rasley and Max Ryabinin and Mayank Mishra and Minjia Zhang and Mohammad Shoeybi and Myriam Peyrounette and Nicolas Patry and Nouamane Tazi and Omar Sanseviero and Patrick von Platen and Pierre Cornette and Pierre Franccois Lavall'ee and R{\'e}mi Lacroix and Samyam Rajbhandari and Sanchit Gandhi and Shaden Smith and St{\'e}phane Requena and Suraj Patil and Tim Dettmers and Ahmed Baruwa and Amanpreet Singh and Anastasia Cheveleva and Anne-Laure Ligozat and Arjun Subramonian and Aur'elie N'ev'eol and Charles Lovering and Daniel H Garrette and Deepak R. Tunuguntla and Ehud Reiter and Ekaterina Taktasheva and Ekaterina Voloshina and Eli Bogdanov and Genta Indra Winata and Hailey Schoelkopf and Jan-Christoph Kalo and Jekaterina Novikova and Jessica Zosa Forde and Xiangru Tang and Jungo Kasai and Ken Kawamura and Liam Hazan and Marine Carpuat and Miruna Clinciu and Najoung Kim and Newton Cheng and Oleg Serikov and Omer Antverg and Oskar van der Wal and Rui Zhang and Ruochen Zhang and Sebastian Gehrmann and Shachar Mirkin and S. Osher Pais and Tatiana Shavrina and Thomas Scialom and Tian Yun and Tomasz Limisiewicz and Verena Rieser and Vitaly Protasov and Vladislav Mikhailov and Yada Pruksachatkun and Yonatan Belinkov and Zachary Bamberger and Zdenvek Kasner and Alice Rueda and Amanda Pestana and Amir Feizpour and Ammar Khan and Amy Faranak and Ananda Santa Rosa Santos and Anthony Hevia and Antigona Unldreaj and Arash Aghagol and Arezoo Abdollahi and Aycha Tammour and Azadeh HajiHosseini and Bahareh Behroozi and Benjamin Olusola Ajibade and Bharat Kumar Saxena and Carlos Mu{\~n}oz Ferrandis and Danish Contractor and David M. Lansky and Davis David and Douwe Kiela and Duong Anh Nguyen and Edward Tan and Emily Baylor and Ezinwanne Ozoani and Fatim T Mirza and Frankline Ononiwu and Habib Rezanejad and H.A. Jones and Indrani Bhattacharya and Irene Solaiman and Irina Sedenko and Isar Nejadgholi and Jan Passmore and Joshua Seltzer and Julio Bonis Sanz and Karen Fort and L{\'i}via Macedo Dutra and Mairon Samagaio and Maraim Elbadri and Margot Mieskes and Marissa Gerchick and Martha Akinlolu and Michael McKenna and Mike Qiu and M. K. K. Ghauri and Mykola Burynok and Nafis Abrar and Nazneen Rajani and Nour Elkott and Nourhan Fahmy and Olanrewaju Samuel and Ran An and R. P. Kromann and Ryan Hao and Samira Alizadeh and Sarmad Shubber and Silas L. Wang and Sourav Roy and Sylvain Viguier and Thanh-Cong Le and Tobi Oyebade and Trieu Nguyen Hai Le and Yoyo Yang and Zachary Kyle Nguyen and Abhinav Ramesh Kashyap and A. Palasciano and Alison Callahan and Anima Shukla and Antonio Miranda-Escalada and Ayush Kumar Singh and Benjamin Beilharz and Bo Wang and Caio Matheus Fonseca de Brito and Chenxi Zhou and Chirag Jain and Chuxin Xu and Cl{\'e}mentine Fourrier and Daniel Le'on Perin'an and Daniel Molano and Dian Yu and Enrique Manjavacas and Fabio Barth and Florian Fuhrimann and Gabriel Altay and Giyaseddin Bayrak and Gully Burns and Helena U. Vrabec and Iman I.B. Bello and Isha Dash and Ji Soo Kang and John Giorgi and Jonas Golde and Jose David Posada and Karthi Sivaraman and Lokesh Bulchandani and Lu Liu and Luisa Shinzato and Madeleine Hahn de Bykhovetz and Maiko Takeuchi and Marc P{\`a}mies and Mar{\'i}a Andrea Castillo and Marianna Nezhurina and Mario Sanger and Matthias Samwald and Michael Cullan and Michael Weinberg and M Wolf and Mina Mihaljcic and Minna Liu and Moritz Freidank and Myungsun Kang and Natasha Seelam and Nathan Dahlberg and Nicholas Michio Broad and Nikolaus Muellner and Pascale Fung and Patricia Haller and R. Chandrasekhar and R. Eisenberg and Robert Martin and Rodrigo L. Canalli and Rosaline Su and Ruisi Su and Samuel Cahyawijaya and Samuele Garda and Shlok S Deshmukh and Shubhanshu Mishra and Sid Kiblawi and Simon Ott and Sinee Sang-aroonsiri and Srishti Kumar and Stefan Schweter and Sushil Pratap Bharati and T. A. Laud and Th'eo Gigant and Tomoya Kainuma and Wojciech Kusa and Yanis Labrak and Yashasvi Bajaj and Y. Venkatraman and Yifan Xu and Ying Xu and Yun-chao Xu and Zhee Xao Tan and Zhongli Xie and Zifan Ye and Mathilde Bras and Younes Belkada and Thomas Wolf},
  journal={ArXiv},
  year={2022},
  volume={abs/2211.05100}
}
@article{Chen2021EvaluatingLL,
  title={Evaluating Large Language Models Trained on Code},
  author={Mark Chen and Jerry Tworek and Heewoo Jun and Qiming Yuan and Henrique Ponde and Jared Kaplan and Harrison Edwards and Yura Burda and Nicholas Joseph and Greg Brockman and Alex Ray and Raul Puri and Gretchen Krueger and Michael Petrov and Heidy Khlaaf and Girish Sastry and Pamela Mishkin and Brooke Chan and Scott Gray and Nick Ryder and Mikhail Pavlov and Alethea Power and Lukasz Kaiser and Mohammad Bavarian and Clemens Winter and Philippe Tillet and Felipe Petroski Such and David W. Cummings and Matthias Plappert and Fotios Chantzis and Elizabeth Barnes and Ariel Herbert-Voss and William H. Guss and Alex Nichol and Igor Babuschkin and S. Arun Balaji and Shantanu Jain and Andrew Carr and Jan Leike and Joshua Achiam and Vedant Misra and Evan Morikawa and Alec Radford and Matthew M. Knight and Miles Brundage and Mira Murati and Katie Mayer and Peter Welinder and Bob McGrew and Dario Amodei and Sam McCandlish and Ilya Sutskever and Wojciech Zaremba},
  journal={ArXiv},
  year={2021},
  volume={abs/2107.03374}
}
@article{Shi2022LanguageMA,
  title={Language Models are Multilingual Chain-of-Thought Reasoners},
  author={Freda Shi and Mirac Suzgun and Markus Freitag and Xuezhi Wang and Suraj Srivats and Soroush Vosoughi and Hyung Won Chung and Yi Tay and Sebastian Ruder and Denny Zhou and Dipanjan Das and Jason Wei},
  journal={ArXiv},
  year={2022},
  volume={abs/2210.03057}
}
@article{Clark2020TyDiQA,
  title={TyDi QA: A Benchmark for Information-Seeking Question Answering in Typologically Diverse Languages},
  author={J. Clark and Eunsol Choi and Michael Collins and Dan Garrette and Tom Kwiatkowski and Vitaly Nikolaev and Jennimaria Palomaki},
  journal={Transactions of the Association for Computational Linguistics},
  year={2020},
  volume={8},
  pages={454-470}
}
@article{Suzgun2022ChallengingBT,
  title={Challenging BIG-Bench Tasks and Whether Chain-of-Thought Can Solve Them},
  author={Mirac Suzgun and Nathan Scales and Nathanael Scharli and Sebastian Gehrmann and Yi Tay and Hyung Won Chung and Aakanksha Chowdhery and Quoc V. Le and Ed Huai-hsin Chi and Denny Zhou and Jason Wei},
  journal={ArXiv},
  year={2022},
  volume={abs/2210.09261}
}
@article{Hendrycks2020MeasuringMM,
  title={Measuring Massive Multitask Language Understanding},
  author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Xiaodong Song and Jacob Steinhardt},
  journal={ArXiv},
  year={2020},
  volume={abs/2009.03300}
}
@article{Chowdhery2022PaLMSL,
  title={PaLM: Scaling Language Modeling with Pathways},
  author={Aakanksha Chowdhery and Sharan Narang and Jacob Devlin and Maarten Bosma and Gaurav Mishra and Adam Roberts and Paul Barham and Hyung Won Chung and Charles Sutton and Sebastian Gehrmann and Parker Schuh and Kensen Shi and Sasha Tsvyashchenko and Joshua Maynez and Abhishek Rao and Parker Barnes and Yi Tay and Noam M. Shazeer and Vinodkumar Prabhakaran and Emily Reif and Nan Du and Benton C. Hutchinson and Reiner Pope and James Bradbury and Jacob Austin and Michael Isard and Guy Gur-Ari and Pengcheng Yin and Toju Duke and Anselm Levskaya and Sanjay Ghemawat and Sunipa Dev and Henryk Michalewski and Xavier Garc{\'i}a and Vedant Misra and Kevin Robinson and Liam Fedus and Denny Zhou and Daphne Ippolito and David Luan and Hyeontaek Lim and Barret Zoph and Alexander Spiridonov and Ryan Sepassi and David Dohan and Shivani Agrawal and Mark Omernick and Andrew M. Dai and Thanumalayan Sankaranarayana Pillai and Marie Pellat and Aitor Lewkowycz and Erica Moreira and Rewon Child and Oleksandr Polozov and Katherine Lee and Zongwei Zhou and Xuezhi Wang and Brennan Saeta and Mark D{\'i}az and Orhan Firat and Michele Catasta and Jason Wei and Kathleen S. Meier-Hellstern and Douglas Eck and Jeff Dean and Slav Petrov and Noah Fiedel},
  journal={ArXiv},
  year={2022},
  volume={abs/2204.02311}
}
@article{Gehman2020RealToxicityPromptsEN,
  title={RealToxicityPrompts: Evaluating Neural Toxic Degeneration in Language Models},
  author={Samuel Gehman and Suchin Gururangan and Maarten Sap and Yejin Choi and Noah A. Smith},
  journal={ArXiv},
  year={2020},
  volume={abs/2009.11462}
}
@article{Raffel2019ExploringTL,
  title={Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
  author={Colin Raffel and Noam M. Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},
  journal={ArXiv},
  year={2019},
  volume={abs/1910.10683}
}
@article{Brown2020LanguageMA,
  title={Language Models are Few-Shot Learners},
  author={Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and T. J. Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeff Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
  journal={ArXiv},
  year={2020},
  volume={abs/2005.14165}
}
@inproceedings{Lin2021TruthfulQAMH,
  title={TruthfulQA: Measuring How Models Mimic Human Falsehoods},
  author={Stephanie C. Lin and Jacob Hilton and Owain Evans},
  booktitle={Annual Meeting of the Association for Computational Linguistics},
  year={2021}
}
@inproceedings{supernaturalinstructions,
  title={Super-NaturalInstructions:Generalization via Declarative Instructions on 1600+ Tasks},
  author={Wang, Yizhong and Mishra, Swaroop and Alipoormolabashi, Pegah and Kordi, Yeganeh and Mirzaei, Amirreza and Arunkumar, Anjana and Ashok, Arjun and Dhanasekaran, Arut Selvan and Naik, Atharva and Stap, David and others},
  booktitle={EMNLP},
  year={2022}
}
@article{dubois2023alpacafarm,
  title={Alpacafarm: A simulation framework for methods that learn from human feedback},
  author={Dubois, Yann and Li, Xuechen and Taori, Rohan and Zhang, Tianyi and Gulrajani, Ishaan and Ba, Jimmy and Guestrin, Carlos and Liang, Percy and Hashimoto, Tatsunori B},
  journal={arXiv preprint arXiv:2305.14387},
  year={2023}
}
@misc{YuLan-Chat,
  author = {YuLan-Chat-Team},
  title = {YuLan-Chat: An Open-Source Bilingual Chatbot},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {https://github.com/RUC-GSAI/YuLan-Chat},
}
@inproceedings{du2022glm,
  title={GLM: General Language Model Pretraining with Autoregressive Blank Infilling},
  author={Du, Zhengxiao and Qian, Yujie and Liu, Xiao and Ding, Ming and Qiu, Jiezhong and Yang, Zhilin and Tang, Jie},
  booktitle={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={320--335},
  year={2022}
}
@misc{ChatGLM-Med,
  author={Haochun Wang and Chi Liu and Sendong Zhao and Bing Qin and Ting Liu},
  title = {ChatGLM-Med.},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {https://github.com/SCIR-HI/Med-ChatGLM},
}
@article{Yin2023DynosaurAD,
  title={Dynosaur: A Dynamic Growth Paradigm for Instruction-Tuning Data Curation},
  author={Da Yin and Xiao Liu and Fan Yin and Ming Zhong and Hritik Bansal and Jiawei Han and Kai-Wei Chang},
  journal={ArXiv},
  year={2023},
  volume={abs/2305.14327}
}
@article{Wang2023HowFC,
  title={How Far Can Camels Go? Exploring the State of Instruction Tuning on Open Resources},
  author={Yizhong Wang and Hamish Ivison and Pradeep Dasigi and Jack Hessel and Tushar Khot and Khyathi Raghavi Chandu and David Wadden and Kelsey MacMillan and Noah A. Smith and Iz Beltagy and Hanna Hajishirzi},
  journal={ArXiv},
  year={2023},
  volume={abs/2306.04751}
}
@misc{luo2023wizardcoder,
      title={WizardCoder: Empowering Code Large Language Models with Evol-Instruct}, 
      author={Ziyang Luo and Can Xu and Pu Zhao and Qingfeng Sun and Xiubo Geng and Wenxiang Hu and Chongyang Tao and Jing Ma and Qingwei Lin and Daxin Jiang},
      year={2023},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{xu2023wizardlm,
      title={WizardLM: Empowering Large Language Models to Follow Complex Instructions}, 
      author={Can Xu and Qingfeng Sun and Kai Zheng and Xiubo Geng and Pu Zhao and Jiazhan Feng and Chongyang Tao and Daxin Jiang},
      year={2023},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@article{falcon40b,
  title={{Falcon-40B}: an open large language model with state-of-the-art performance},
  author={Almazrouei, Ebtesam and Alobeidli, Hamza and Alshamsi, Abdulaziz and Cappelli, Alessandro and Cojocaru, Ruxandra and Debbah, Merouane and Goffinet, Etienne and Heslow, Daniel and Launay, Julien and Malartic, Quentin and Noune, Badreddine and Pannier, Baptiste and Penedo, Guilherme},
  year={2023}
}
@article{Ivison2022HINTHI,
  title={HINT: Hypernetwork Instruction Tuning for Efficient Zero-Shot Generalisation},
  author={Hamish Ivison and Akshita Bhagia and Yizhong Wang and Hannaneh Hajishirzi and Matthew E. Peters},
  journal={ArXiv},
  year={2022},
  volume={abs/2212.10315}
}
@article{Biderman2023PythiaAS,
  title={Pythia: A Suite for Analyzing Large Language Models Across Training and Scaling},
  author={Stella Rose Biderman and Hailey Schoelkopf and Quentin G. Anthony and Herbie Bradley and Kyle O'Brien and Eric Hallahan and Mohammad Aflah Khan and Shivanshu Purohit and USVSN Sai Prashanth and Edward Raff and Aviya Skowron and Lintang Sutawika and Oskar van der Wal},
  journal={ArXiv},
  year={2023},
  volume={abs/2304.01373}
}
@inproceedings{Lv2023FullPF,
  title={Full Parameter Fine-tuning for Large Language Models with Limited Resources},
  author={Kai Lv and Yuqing Yang and Tengxiao Liu and Qi-jie Gao and Qipeng Guo and Xipeng Qiu},
  year={2023}
}

@article{liu2023goat,
  title={Goat: Fine-tuned LLaMA Outperforms GPT-4 on Arithmetic Tasks},
  author={Liu, Tiedong and Low, Bryan Kian Hsiang},
  journal={arXiv preprint arXiv:2305.14201},
  year={2023}
}
@article{chen2023maybe,
  title={Maybe Only 0.5\% Data is Needed: A Preliminary Exploration of Low Training Data Instruction Tuning},
  author={Chen, Hao and Zhang, Yiming and Zhang, Qi and Yang, Hantao and Hu, Xiaomeng and Ma, Xuetao and Yanggong, Yifan and Zhao, Junbo},
  journal={arXiv preprint arXiv:2305.09246},
  year={2023}
}
@article{ding2023enhancing,
  title={Enhancing Chat Language Models by Scaling High-quality Instructional Conversations},
  author={Ding, Ning and Chen, Yulin and Xu, Bokai and Qin, Yujia and Zheng, Zhi and Hu, Shengding and Liu, Zhiyuan and Sun, Maosong and Zhou, Bowen},
  journal={arXiv preprint arXiv:2305.14233},
  year={2023}
}
@misc{Guanaco,
  title={Guanaco: Generative Universal Assistant for Natural-language Adaptive Context-aware Omnilingual outputs},
  author={JosephusCheung},
  year={2021},
  volume={guanaco-model.github.io}
}
@misc{instructionwild,
  author = {Fuzhao Xue and Kabir Jain and Mahir Hitesh Shah and Zangwei Zheng and Yang You },
  title = {Instruction in the Wild: A User-based Instruction Dataset},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {https://github.com/XueFuzhao/InstructionWild},
}
@misc{2023oig,
  title={Oig: the Open Instruction Generalist dataset},
  author={LAION.ai},
  year={2023},
  volume={laion.ai/blog/oig-dataset}
}
@article{dettmers2023qlora,
  title={Qlora: Efficient finetuning of quantized llms},
  author={Dettmers, Tim and Pagnoni, Artidoro and Holtzman, Ari and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:2305.14314},
  year={2023}
}
@article{Yin2023LAMMLM,
  title={LAMM: Language-Assisted Multi-Modal Instruction-Tuning Dataset, Framework, and Benchmark},
  author={Zhenfei Yin and Jiong Wang and Jianjian Cao and Zhelun Shi and Dingning Liu and Mukai Li and Lu Sheng and Lei Bai and Xiaoshui Huang and Zhiyong Wang and Wanli Ouyang and Jing Shao},
  journal={ArXiv},
  year={2023},
  volume={abs/2306.06687}
}
@article{Li2023ChatDoctorAM,
  title={ChatDoctor: A Medical Chat Model Fine-tuned on LLaMA Model using Medical Domain Knowledge},
  author={Yunxiang Li and Zihan Li and Kai Zhang and Ruilong Dan and You Zhang},
  journal={ArXiv},
  year={2023},
  volume={abs/2303.14070}
}
@inproceedings{Liu2023RadiologyGPTAL,
  title={Radiology-GPT: A Large Language Model for Radiology},
  author={Zheng Liu and Aoxiao Zhong and Yiwei Li and Longtao Yang and Chao Ju and Zihao Wu and Chong Ma and Peng Shu and Cheng Chen and Sekeun Kim and Haixing Dai and Lin Zhao and Dajiang Zhu and Jun Liu and Wei Liu and Dinggang Shen and Xiang Li and Quanzheng Li and Tianming Liu},
  year={2023}
}
@article{conover2023free,
  title={Free dolly: Introducing the worlds first truly open instruction-tuned llm},
  author={Conover, Mike and Hayes, Matt and Mathur, Ankit and Meng, Xiangrui and Xie, Jianwei and Wan, Jun and Shah, Sam and Ghodsi, Ali and Wendell, Patrick and Zaharia, Matei and others},
  year={2023}
}
@article{Chakrabarty2022HelpMW,
  title={Help me write a Poem - Instruction Tuning as a Vehicle for Collaborative Poetry Writing},
  author={Tuhin Chakrabarty and Vishakh Padmakumar and Hengxing He},
  journal={ArXiv},
  year={2022},
  volume={abs/2210.13669}
}

@article{Gong2023MultiModalGPTAV,
  title={MultiModal-GPT: A Vision and Language Model for Dialogue with Humans},
  author={Tao Gong and Chengqi Lyu and Shilong Zhang and Yudong Wang and Miao Zheng and Qianmengke Zhao and Kuikun Liu and Wenwei Zhang and Ping Luo and Kai Chen},
  journal={ArXiv},
  year={2023},
  volume={abs/2305.04790}
}
@article{hu2021lora,
  title={Lora: Low-rank adaptation of large language models},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  journal={arXiv preprint arXiv:2106.09685},
  year={2021}
}
@article{Zhang2023TowardsBT,
  title={Towards Building the Federated GPT: Federated Instruction Tuning},
  author={Jianyi Zhang and Saeed Vahidian and Martin Kuo and Chunyuan Li and Ruiyi Zhang and Guoyin Wang and Yiran Chen},
  journal={ArXiv},
  year={2023},
  volume={abs/2305.05644}
}
@article{Raheja2023CoEdITTE,
  title={CoEdIT: Text Editing by Task-Specific Instruction Tuning},
  author={Vipul Raheja and Dhruv Kumar and Ryan Koo and Dongyeop Kang},
  journal={ArXiv},
  year={2023},
  volume={abs/2305.09857}
}

@article{Zhang2023PMCVQAVI,
  title={PMC-VQA: Visual Instruction Tuning for Medical Visual Question Answering},
  author={Xiaoman Zhang and Chaoyi Wu and Ziheng Zhao and Weixiong Lin and Ya Zhang and Yanfeng Wang and Weidi Xie},
  journal={ArXiv},
  year={2023},
  volume={abs/2305.10415}
}

@article{Liu2023LogiCoTLC,
  title={LogiCoT: Logical Chain-of-Thought Instruction-Tuning Data Collection with GPT-4},
  author={Hanmeng Liu and Zhiyang Teng and Leyang Cui and Chaoli Zhang and Qiji Zhou and Yue Zhang},
  journal={ArXiv},
  year={2023},
  volume={abs/2305.12147}
}
@article{Zhang2023MultiTaskIT,
  title={Multi-Task Instruction Tuning of LLaMa for Specific Scenarios: A Preliminary Study on Writing Assistance},
  author={Yue Zhang and Leyang Cui and Deng Cai and Xinting Huang and Tao Fang and Wei Bi},
  journal={ArXiv},
  year={2023},
  volume={abs/2305.13225}
}
@article{Li2023OtterAM,
  title={Otter: A Multi-Modal Model with In-Context Instruction Tuning},
  author={Bo Li and Yuanhan Zhang and Liangyu Chen and Jinghao Wang and Jingkang Yang and Ziwei Liu},
  journal={ArXiv},
  year={2023},
  volume={abs/2305.03726}
}
@article{Zhou2023LIMALI,
  title={LIMA: Less Is More for Alignment},
  author={Chunting Zhou and Pengfei Liu and Puxin Xu and Srini Iyer and Jiao Sun and Yuning Mao and Xuezhe Ma and Avia Efrat and Ping Yu and L. Yu and Susan Zhang and Gargi Ghosh and Mike Lewis and Luke Zettlemoyer and Omer Levy},
  journal={ArXiv},
  year={2023},
  volume={abs/2305.11206}
}
@inproceedings{Rosenbaum2022LINGUISTLM,
  title={LINGUIST: Language Model Instruction Tuning to Generate Annotated Utterances for Intent Classification and Slot Tagging},
  author={Andrew Rosenbaum and Saleh Soltan and Wael Hamza and Yannick Versley and Markus Boese},
  booktitle={International Conference on Computational Linguistics},
  year={2022}
}
@article{gupta2023instruction,
  title={Instruction Tuned Models are Quick Learners},
  author={Gupta, Himanshu and Sawant, Saurabh Arjun and Mishra, Swaroop and Nakamura, Mutsumi and Mitra, Arindam and Mashetty, Santosh and Baral, Chitta},
  journal={arXiv preprint arXiv:2306.05539},
  year={2023}
}
@article{Kung2023DoMR,
  title={Do Models Really Learn to Follow Instructions? An Empirical Study of Instruction Tuning},
  author={Po-Nien Kung and Nanyun Peng},
  journal={ArXiv},
  year={2023},
  volume={abs/2305.11383}
}
@article{Varia2022InstructionTF,
  title={Instruction Tuning for Few-Shot Aspect-Based Sentiment Analysis},
  author={Siddharth Varia and Shuai Wang and Kishaloy Halder and Robert Vacareanu and Miguel Ballesteros and Yassine Benajiba and Neha Ann John and Rishita Anubhai and Smaranda Muresan and Dan Roth},
  journal={ArXiv},
  year={2022},
  volume={abs/2210.06629}
}
@article{Xu2022MultiInstructIM,
  title={MultiInstruct: Improving Multi-Modal Zero-Shot Learning via Instruction Tuning},
  author={Zhiyang Xu and Ying Shen and Lifu Huang},
  journal={ArXiv},
  year={2022},
  volume={abs/2212.10773}
}
@article{Wang2023InstructUIEMI,
  title={InstructUIE: Multi-task Instruction Tuning for Unified Information Extraction},
  author={Xiao Wang and Wei Zhou and Can Zu and Han Xia and Tianze Chen and Yuan Zhang and Rui Zheng and Junjie Ye and Qi Zhang and Tao Gui and Jihua Kang and J. Yang and Siyuan Li and Chunsai Du},
  journal={ArXiv},
  year={2023},
  volume={abs/2304.08085}
}
@inproceedings{Gupta2022InstructDialIZ,
  title={InstructDial: Improving Zero and Few-shot Generalization in Dialogue through Instruction Tuning},
  author={Prakhar Gupta and Cathy Jiao and Yi-Ting Yeh and Shikib Mehri and Maxine Esk{\'e}nazi and Jeffrey P. Bigham},
  booktitle={Conference on Empirical Methods in Natural Language Processing},
  year={2022}
}
@article{Brooks2022InstructPix2PixLT,
  title={InstructPix2Pix: Learning to Follow Image Editing Instructions},
  author={Tim Brooks and Aleksander Holynski and Alexei A. Efros},
  journal={ArXiv},
  year={2022},
  volume={abs/2211.09800}
}
@article{muennighoff2022crosslingual,
  title={Crosslingual generalization through multitask finetuning},
  author={Muennighoff, Niklas and Wang, Thomas and Sutawika, Lintang and Roberts, Adam and Biderman, Stella and Scao, Teven Le and Bari, M Saiful and Shen, Sheng and Yong, Zheng-Xin and Schoelkopf, Hailey and others},
  journal={arXiv preprint arXiv:2211.01786},
  year={2022}
}

@article{honovich2022unnatural,
  title={Unnatural Instructions: Tuning Language Models with (Almost) No Human Labor},
  author={Honovich, Or and Scialom, Thomas and Levy, Omer and Schick, Timo},
  journal={arXiv preprint arXiv:2212.09689},
  year={2022}
}
@article{Zhang2023ChineseOI,
  title={Chinese Open Instruction Generalist: A Preliminary Release},
  author={Ge Zhang and Yemin Shi and Ruibo Liu and Ruibin Yuan and Yizhi Li and Siwei Dong and Yu Shu and Zhaoqun Li and Zekun Wang and Chenghua Lin and Wen-Fen Huang and Jie Fu},
  journal={ArXiv},
  year={2023},
  volume={abs/2304.07987}
}
@article{Chung2022ScalingIL,
  title={Scaling Instruction-Finetuned Language Models},
  author={Hyung Won Chung and Le Hou and S. Longpre and Barret Zoph and Yi Tay and William Fedus and Eric Li and Xuezhi Wang and Mostafa Dehghani and Siddhartha Brahma and Albert Webson and Shixiang Shane Gu and Zhuyun Dai and Mirac Suzgun and Xinyun Chen and Aakanksha Chowdhery and Dasha Valter and Sharan Narang and Gaurav Mishra and Adams Wei Yu and Vincent Zhao and Yanping Huang and Andrew M. Dai and Hongkun Yu and Slav Petrov and Ed Huai-hsin Chi and Jeff Dean and Jacob Devlin and Adam Roberts and Denny Zhou and Quoc V. Le and Jason Wei},
  journal={ArXiv},
  year={2022},
  volume={abs/2210.11416}
}
@article{Dai2023InstructBLIPTG,
  title={InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning},
  author={Wenliang Dai and Junnan Li and Dongxu Li and Anthony Meng Huat Tiong and Junqi Zhao and Weisheng Wang and Boyang Li and Pascale Fung and Steven Hoi},
  journal={ArXiv},
  year={2023},
  volume={abs/2305.06500}
}
@article{muennighoff2022crosslingua,
  title={Crosslingual generalization through multitask finetuning},
  author={Muennighoff, Niklas and Wang, Thomas and Sutawika, Lintang and Roberts, Adam and Biderman, Stella and Scao, Teven Le and Bari, M Saiful and Shen, Sheng and Yong, Zheng-Xin and Schoelkopf, Hailey and others},
  journal={arXiv preprint arXiv:2211.01786},
  year={2022}
}
@article{peng2023instruction,
  title={Instruction tuning with gpt-4},
  author={Peng, Baolin and Li, Chunyuan and He, Pengcheng and Galley, Michel and Gao, Jianfeng},
  journal={arXiv preprint arXiv:2304.03277},
  year={2023}
}
@inproceedings{rasley2020deepspeed,
  title={Deepspeed: System optimizations enable training deep learning models with over 100 billion parameters},
  author={Rasley, Jeff and Rajbhandari, Samyam and Ruwase, Olatunji and He, Yuxiong},
  booktitle={Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
  pages={3505--3506},
  year={2020}
}
@article{anand2023gpt4all,
  title={Gpt4all: Training an assistant-style chatbot with large scale data distillation from gpt-3.5-turbo},
  author={Anand, Yuvanesh and Nussbaum, Zach and Duderstadt, Brandon and Schmidt, Benjamin and Mulyar, Andriy},
  journal={GitHub},
  year={2023}
}
@article{chiang2023vicuna,
  title={Vicuna: An open-source chatbot impressing gpt-4 with 90\%* chatgpt quality},
  author={Chiang, Wei-Lin and Li, Zhuohan and Lin, Zi and Sheng, Ying and Wu, Zhanghao and Zhang, Hao and Zheng, Lianmin and Zhuang, Siyuan and Zhuang, Yonghao and Gonzalez, Joseph E and others},
  journal={See https://vicuna. lmsys. org (accessed 14 April 2023)},
  year={2023}
}

@article{longpre2023flan,
  title={The flan collection: Designing data and methods for effective instruction tuning},
  author={Longpre, Shayne and Hou, Le and Vu, Tu and Webson, Albert and Chung, Hyung Won and Tay, Yi and Zhou, Denny and Le, Quoc V and Zoph, Barret and Wei, Jason and others},
  journal={arXiv preprint arXiv:2301.13688},
  year={2023}
}
@article{taori2023alpaca,
  title={Alpaca: A strong, replicable instruction-following model},
  author={Taori, Rohan and Gulrajani, Ishaan and Zhang, Tianyi and Dubois, Yann and Li, Xuechen and Guestrin, Carlos and Liang, Percy and Hashimoto, Tatsunori B},
  journal={Stanford Center for Research on Foundation Models. https://crfm. stanford. edu/2023/03/13/alpaca. html},
  volume={3},
  number={6},
  pages={7},
  year={2023}
}
@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}
@article{Liu2023VisualIT,
  title={Visual Instruction Tuning},
  author={Haotian Liu and Chunyuan Li and Qingyang Wu and Yong Jae Lee},
  journal={ArXiv},
  year={2023},
  volume={abs/2304.08485}
}
@inproceedings{DBLP:conf/icml/WangYMLBLMZZY22,
  title={Ofa: Unifying architectures, tasks, and modalities through a simple sequence-to-sequence learning framework},
  author={Wang, Peng and Yang, An and Men, Rui and Lin, Junyang and Bai, Shuai and Li, Zhikang and Ma, Jianxin and Zhou, Chang and Zhou, Jingren and Yang, Hongxia},
  booktitle={International Conference on Machine Learning},
  pages={23318--23340},
  year={2022},
  organization={PMLR}
}
@inproceedings{mishra-etal-2022-cross,
    title = "Cross-Task Generalization via Natural Language Crowdsourcing Instructions",
    author = "Mishra, Swaroop  and
      Khashabi, Daniel  and
      Baral, Chitta  and
      Hajishirzi, Hannaneh",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.244",
    doi = "10.18653/v1/2022.acl-long.244",
    pages = "3470--3487"
}
@InProceedings{Rombach_2022_CVPR,
    author    = {Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj\"orn},
    title     = {High-Resolution Image Synthesis With Latent Diffusion Models},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2022},
    pages     = {10684-10695}
}
@inproceedings{bar2022text2live,
  title={Text2live: Text-driven layered image and video editing},
  author={Bar-Tal, Omer and Ofri-Amar, Dolev and Fridman, Rafail and Kasten, Yoni and Dekel, Tali},
  booktitle={European Conference on Computer Vision},
  pages={707--723},
  year={2022},
  organization={Springer}
}
@inproceedings{
      meng2022sdedit,
      title={{SDE}dit: Guided Image Synthesis and Editing with Stochastic Differential Equations},
      author={Chenlin Meng and Yutong He and Yang Song and Jiaming Song and Jiajun Wu and Jun-Yan Zhu and Stefano Ermon},
      booktitle={International Conference on Learning Representations},
      year={2022},
}
@inproceedings{li2023blip2,
      title={{BLIP-2:} Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models}, 
      author={Junnan Li and Dongxu Li and Silvio Savarese and Steven Hoi},
      year={2023},
      booktitle={ICML},
}
@inproceedings{girdhar2023imagebind,
  title={ImageBind: One Embedding Space To Bind Them All},
  author={Girdhar, Rohit and El-Nouby, Alaaeldin and Liu, Zhuang
and Singh, Mannat and Alwala, Kalyan Vasudev and Joulin, Armand and Misra, Ishan},
  booktitle={CVPR},
  year={2023}
}
@article{damonlpsg2023videollama,
  title={Video-llama: An instruction-tuned audio-visual language model for video understanding},
  author={Zhang, Hang and Li, Xin and Bing, Lidong},
  journal={arXiv preprint arXiv:2306.02858},
  year={2023}
}
@article{zhu2023minigpt,
  title={MiniGPT-4: Enhancing Vision-Language Understanding with Advanced Large Language Models},
  author={Zhu, Deyao and Chen, Jun and Shen, Xiaoqian and Li, Xiang and Elhoseiny, Mohamed},
  journal={arXiv preprint arXiv:2304.10592},
  year={2023}
}
@article{2023videochat,
  title={VideoChat: Chat-Centric Video Understanding},
  author={Li, Kunchang and He, Yinan and Wang, Yi and Li, Yizhuo and Wang, Wenhai and Luo, Ping and Wang, Yali and Wang, Limin and Qiao, Yu},
  journal={arXiv preprint arXiv:2305.06355},
  year={2023}
}
@InProceedings{bain2021frozen,
  author       = "Max Bain and Arsha Nagrani and G{\"u}l Varol and Andrew Zisserman",
  title        = "Frozen in Time: A Joint Video and Image Encoder for End-to-End Retrieval",
  booktitle    = "IEEE International Conference on Computer Vision",
  year         = "2021",
}
@inproceedings{Radford2021LearningTV,
  title={Learning Transferable Visual Models From Natural Language Supervision},
  author={Alec Radford and Jong Wook Kim and Chris Hallacy and Aditya Ramesh and Gabriel Goh and Sandhini Agarwal and Girish Sastry and Amanda Askell and Pamela Mishkin and Jack Clark and Gretchen Krueger and Ilya Sutskever},
  booktitle={International Conference on Machine Learning},
  year={2021}
}

@inproceedings{DBLP:conf/nips/AlayracDLMBHLMM22,
  author       = {Jean{-}Baptiste Alayrac and
                  Jeff Donahue and
                  Pauline Luc and
                  Antoine Miech and
                  Iain Barr and
                  Yana Hasson and
                  Karel Lenc and
                  Arthur Mensch and
                  Katherine Millican and
                  Malcolm Reynolds and
                  Roman Ring and
                  Eliza Rutherford and
                  Serkan Cabi and
                  Tengda Han and
                  Zhitao Gong and
                  Sina Samangooei and
                  Marianne Monteiro and
                  Jacob L. Menick and
                  Sebastian Borgeaud and
                  Andy Brock and
                  Aida Nematzadeh and
                  Sahand Sharifzadeh and
                  Mikolaj Binkowski and
                  Ricardo Barreira and
                  Oriol Vinyals and
                  Andrew Zisserman and
                  Kar{\'{e}}n Simonyan},
  title        = {Flamingo: a Visual Language Model for Few-Shot Learning},
  booktitle    = {NeurIPS},
  year         = {2022}
}
@article{lin2023pmc,
  title={PMC-CLIP: Contrastive Language-Image Pre-training using Biomedical Documents},
  author={Lin, Weixiong and Zhao, Ziheng and Zhang, Xiaoman and Wu, Chaoyi and Zhang, Ya and Wang, Yanfeng and Xie, Weidi},
  journal={arXiv preprint arXiv:2303.07240},
  year={2023}
}
@article{lau2018dataset,
  title={A dataset of clinically generated visual questions and answers about radiology images},
  author={Lau, Jason J and Gayen, Soumya and Ben Abacha, Asma and Demner-Fushman, Dina},
  journal={Scientific data},
  volume={5},
  number={1},
  pages={1--10},
  year={2018},
  publisher={Nature Publishing Group}
}
@inproceedings{liu2021slake,
  title={Slake: A semantically-labeled knowledge-enhanced dataset for medical visual question answering},
  author={Liu, Bo and Zhan, Li-Ming and Xu, Li and Ma, Lin and Yang, Yan and Wu, Xiao-Ming},
  booktitle={2021 IEEE 18th International Symposium on Biomedical Imaging (ISBI)},
  pages={1650--1654},
  year={2021},
  organization={IEEE}
}
@article{tay2022ul2,
  title={Ul2: Unifying language learning paradigms},
  author={Tay, Yi and Dehghani, Mostafa and Tran, Vinh Q and Garcia, Xavier and Wei, Jason and Wang, Xuezhi and Chung, Hyung Won and Bahri, Dara and Schuster, Tal and Zheng, Steven and others},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2022}
}

@article{bai2022training,
  title={Training a helpful and harmless assistant with reinforcement learning from human feedback},
  author={Bai, Yuntao and Jones, Andy and Ndousse, Kamal and Askell, Amanda and Chen, Anna and DasSarma, Nova and Drain, Dawn and Fort, Stanislav and Ganguli, Deep and Henighan, Tom and others},
  journal={arXiv preprint arXiv:2204.05862},
  year={2022}
}

@article{touvron2023llama,
  title={Llama: Open and efficient foundation language models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}
@article{zhang2022bamboo,
  title={Bamboo: Building mega-scale vision dataset continually with human-machine synergy},
  author={Zhang, Yuanhan and Sun, Qinghong and Zhou, Yichun and He, Zexin and Yin, Zhenfei and Wang, Kun and Sheng, Lu and Qiao, Yu and Shao, Jing and Liu, Ziwei},
  journal={arXiv preprint arXiv:2203.07845},
  year={2022}
}
@misc{anas_awadalla_2023_7733589,
  title={Openflamingo},
  author={Awadalla, Anas and Gao, Irena and Gardner, Joshua and Hessel, Jack and Hanafy, Yusuf and Zhu, Wanrong and Marathe, Kalyani and Bitton, Yonatan and Gadre, Samir and Jitsev, Jenia and others},
  year={2023},
  publisher={March}
}
@article{xu2023baize,
  title={Baize: An Open-Source Chat Model with Parameter-Efficient Tuning on Self-Chat Data},
  author={Xu, Canwen and Guo, Daya and Duan, Nan and McAuley, Julian},
  journal={arXiv preprint arXiv:2304.01196},
  year={2023}
}
@inproceedings{lester-etal-2021-power,
  title={The Power of Scale for Parameter-Efficient Prompt Tuning},
  author={Brian Lester and Rami Al-Rfou and Noah Constant},
  booktitle={Conference on Empirical Methods in Natural Language Processing},
  year={2021}
}

@article{lin2022unsupervised,
  title={Unsupervised Cross-Task Generalization via Retrieval Augmentation},
  author={Bill Yuchen Lin and Kangmin Tan and Chris Miller and Beiwen Tian and Xiang Ren},
  journal={ArXiv},
  year={2022},
  volume={abs/2204.07937}
}
@inproceedings{lewis-etal-2020-bart,
  title={BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension},
  author={Mike Lewis and Yinhan Liu and Naman Goyal and Marjan Ghazvininejad and Abdel-rahman Mohamed and Omer Levy and Veselin Stoyanov and Luke Zettlemoyer},
  booktitle={Annual Meeting of the Association for Computational Linguistics},
  year={2019}
}
@article{soltan2022alexatm,
  title={Alexatm 20b: Few-shot learning using a large-scale multilingual seq2seq model},
  author={Soltan, Saleh and Ananthakrishnan, Shankar and FitzGerald, Jack and Gupta, Rahul and Hamza, Wael and Khan, Haidar and Peris, Charith and Rawls, Stephen and Rosenbaum, Andy and Rumshisky, Anna and others},
  journal={arXiv preprint arXiv:2208.01448},
  year={2022}
}
@article{DBLP:journals/corr/abs-1805-10190,
  title={Snips voice platform: an embedded spoken language understanding system for private-by-design voice interfaces},
  author={Coucke, Alice and Saade, Alaa and Ball, Adrien and Bluche, Th{\'e}odore and Caulier, Alexandre and Leroy, David and Doumouro, Cl{\'e}ment and Gisselbrecht, Thibault and Caltagirone, Francesco and Lavril, Thibaut and others},
  journal={arXiv preprint arXiv:1805.10190},
  year={2018}
}
@article{xu2020endtoend,
  title={End-to-end slot alignment and recognition for cross-lingual NLU},
  author={Xu, Weijia and Haider, Batool and Mansour, Saab},
  journal={arXiv preprint arXiv:2004.14353},
  year={2020}
}
@article{devlin-etal-2019-bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}
@misc{dwivediyu2022editeval,
      title={EditEval: An Instruction-Based Benchmark for Text Improvements}, 
      author={Jane Dwivedi-Yu and Timo Schick and Zhengbao Jiang and Maria Lomeli and Patrick Lewis and Gautier Izacard and Edouard Grave and Sebastian Riedel and Fabio Petroni},
      year={2022},
      eprint={2209.13331},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{alpaca,
  author = {Rohan Taori and Ishaan Gulrajani and Tianyi Zhang and Yann Dubois and Xuechen Li and Carlos Guestrin and Percy Liang and Tatsunori B. Hashimoto },
  title = {Stanford Alpaca: An Instruction-following LLaMA model},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/tatsu-lab/stanford_alpaca}},
}
@misc{stabilityStabilityLaunches,
	author = {Anel Islamovic},
	title = {{S}tability {A}{I} {L}aunches the {F}irst of its {S}table{L}{M} {S}uite of {L}anguage {M}odels  {S}tability {A}{I} --- stability.ai},
	howpublished = {\url{https://stability.ai/blog/stability-ai-launches-the-first-of-its-stablelm-suite-of-language-models}},
	year = {},
	note = {[Accessed 09-Jun-2023]},
}
@misc{databricksFreeDolly,
	author = {},
	title = {{F}ree {D}olly: {I}ntroducing the {W}orld's {F}irst {T}ruly {O}pen {I}nstruction-{T}uned {L}{L}{M} --- databricks.com},
	howpublished = {\url{https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm}},
	year = {},
	note = {[Accessed 09-Jun-2023]},
}
@misc{chowdhery2022palm,
      title={PaLM: Scaling Language Modeling with Pathways}, 
      author={Aakanksha Chowdhery and Sharan Narang and Jacob Devlin and Maarten Bosma and Gaurav Mishra and Adam Roberts and Paul Barham and Hyung Won Chung and Charles Sutton and Sebastian Gehrmann and Parker Schuh and Kensen Shi and Sasha Tsvyashchenko and Joshua Maynez and Abhishek Rao and Parker Barnes and Yi Tay and Noam Shazeer and Vinodkumar Prabhakaran and Emily Reif and Nan Du and Ben Hutchinson and Reiner Pope and James Bradbury and Jacob Austin and Michael Isard and Guy Gur-Ari and Pengcheng Yin and Toju Duke and Anselm Levskaya and Sanjay Ghemawat and Sunipa Dev and Henryk Michalewski and Xavier Garcia and Vedant Misra and Kevin Robinson and Liam Fedus and Denny Zhou and Daphne Ippolito and David Luan and Hyeontaek Lim and Barret Zoph and Alexander Spiridonov and Ryan Sepassi and David Dohan and Shivani Agrawal and Mark Omernick and Andrew M. Dai and Thanumalayan Sankaranarayana Pillai and Marie Pellat and Aitor Lewkowycz and Erica Moreira and Rewon Child and Oleksandr Polozov and Katherine Lee and Zongwei Zhou and Xuezhi Wang and Brennan Saeta and Mark Diaz and Orhan Firat and Michele Catasta and Jason Wei and Kathy Meier-Hellstern and Douglas Eck and Jeff Dean and Slav Petrov and Noah Fiedel},
      year={2022},
      eprint={2204.02311},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{srivastava2023imitation,
      title={Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models}, 
      author={Aarohi Srivastava and Abhinav Rastogi and Abhishek Rao and Abu Awal Md Shoeb and Abubakar Abid and Adam Fisch and Adam R. Brown and Adam Santoro and Aditya Gupta and Adri Garriga-Alonso and Agnieszka Kluska and Aitor Lewkowycz and Akshat Agarwal and Alethea Power and Alex Ray and Alex Warstadt and Alexander W. Kocurek and Ali Safaya and Ali Tazarv and Alice Xiang and Alicia Parrish and Allen Nie and Aman Hussain and Amanda Askell and Amanda Dsouza and Ambrose Slone and Ameet Rahane and Anantharaman S. Iyer and Anders Andreassen and Andrea Madotto and Andrea Santilli and Andreas Stuhlmller and Andrew Dai and Andrew La and Andrew Lampinen and Andy Zou and Angela Jiang and Angelica Chen and Anh Vuong and Animesh Gupta and Anna Gottardi and Antonio Norelli and Anu Venkatesh and Arash Gholamidavoodi and Arfa Tabassum and Arul Menezes and Arun Kirubarajan and Asher Mullokandov and Ashish Sabharwal and Austin Herrick and Avia Efrat and Aykut Erdem and Ayla Karaka and B. Ryan Roberts and Bao Sheng Loe and Barret Zoph and Bartomiej Bojanowski and Batuhan zyurt and Behnam Hedayatnia and Behnam Neyshabur and Benjamin Inden and Benno Stein and Berk Ekmekci and Bill Yuchen Lin and Blake Howald and Bryan Orinion and Cameron Diao and Cameron Dour and Catherine Stinson and Cedrick Argueta and Csar Ferri Ramrez and Chandan Singh and Charles Rathkopf and Chenlin Meng and Chitta Baral and Chiyu Wu and Chris Callison-Burch and Chris Waites and Christian Voigt and Christopher D. Manning and Christopher Potts and Cindy Ramirez and Clara E. Rivera and Clemencia Siro and Colin Raffel and Courtney Ashcraft and Cristina Garbacea and Damien Sileo and Dan Garrette and Dan Hendrycks and Dan Kilman and Dan Roth and Daniel Freeman and Daniel Khashabi and Daniel Levy and Daniel Mosegu Gonzlez and Danielle Perszyk and Danny Hernandez and Danqi Chen and Daphne Ippolito and Dar Gilboa and David Dohan and David Drakard and David Jurgens and Debajyoti Datta and Deep Ganguli and Denis Emelin and Denis Kleyko and Deniz Yuret and Derek Chen and Derek Tam and Dieuwke Hupkes and Diganta Misra and Dilyar Buzan and Dimitri Coelho Mollo and Diyi Yang and Dong-Ho Lee and Dylan Schrader and Ekaterina Shutova and Ekin Dogus Cubuk and Elad Segal and Eleanor Hagerman and Elizabeth Barnes and Elizabeth Donoway and Ellie Pavlick and Emanuele Rodola and Emma Lam and Eric Chu and Eric Tang and Erkut Erdem and Ernie Chang and Ethan A. Chi and Ethan Dyer and Ethan Jerzak and Ethan Kim and Eunice Engefu Manyasi and Evgenii Zheltonozhskii and Fanyue Xia and Fatemeh Siar and Fernando Martnez-Plumed and Francesca Happ and Francois Chollet and Frieda Rong and Gaurav Mishra and Genta Indra Winata and Gerard de Melo and Germn Kruszewski and Giambattista Parascandolo and Giorgio Mariani and Gloria Wang and Gonzalo Jaimovitch-Lpez and Gregor Betz and Guy Gur-Ari and Hana Galijasevic and Hannah Kim and Hannah Rashkin and Hannaneh Hajishirzi and Harsh Mehta and Hayden Bogar and Henry Shevlin and Hinrich Schtze and Hiromu Yakura and Hongming Zhang and Hugh Mee Wong and Ian Ng and Isaac Noble and Jaap Jumelet and Jack Geissinger and Jackson Kernion and Jacob Hilton and Jaehoon Lee and Jaime Fernndez Fisac and James B. Simon and James Koppel and James Zheng and James Zou and Jan Koco and Jana Thompson and Janelle Wingfield and Jared Kaplan and Jarema Radom and Jascha Sohl-Dickstein and Jason Phang and Jason Wei and Jason Yosinski and Jekaterina Novikova and Jelle Bosscher and Jennifer Marsh and Jeremy Kim and Jeroen Taal and Jesse Engel and Jesujoba Alabi and Jiacheng Xu and Jiaming Song and Jillian Tang and Joan Waweru and John Burden and John Miller and John U. Balis and Jonathan Batchelder and Jonathan Berant and Jrg Frohberg and Jos Rozen and Jose Hernandez-Orallo and Joseph Boudeman and Joseph Guerr and Joseph Jones and Joshua B. Tenenbaum and Joshua S. Rule and Joyce Chua and Kamil Kanclerz and Karen Livescu and Karl Krauth and Karthik Gopalakrishnan and Katerina Ignatyeva and Katja Markert and Kaustubh D. Dhole and Kevin Gimpel and Kevin Omondi and Kory Mathewson and Kristen Chiafullo and Ksenia Shkaruta and Kumar Shridhar and Kyle McDonell and Kyle Richardson and Laria Reynolds and Leo Gao and Li Zhang and Liam Dugan and Lianhui Qin and Lidia Contreras-Ochando and Louis-Philippe Morency and Luca Moschella and Lucas Lam and Lucy Noble and Ludwig Schmidt and Luheng He and Luis Oliveros Coln and Luke Metz and Ltfi Kerem enel and Maarten Bosma and Maarten Sap and Maartje ter Hoeve and Maheen Farooqi and Manaal Faruqui and Mantas Mazeika and Marco Baturan and Marco Marelli and Marco Maru and Maria Jose Ramrez Quintana and Marie Tolkiehn and Mario Giulianelli and Martha Lewis and Martin Potthast and Matthew L. Leavitt and Matthias Hagen and Mtys Schubert and Medina Orduna Baitemirova and Melody Arnaud and Melvin McElrath and Michael A. Yee and Michael Cohen and Michael Gu and Michael Ivanitskiy and Michael Starritt and Michael Strube and Micha Swdrowski and Michele Bevilacqua and Michihiro Yasunaga and Mihir Kale and Mike Cain and Mimee Xu and Mirac Suzgun and Mitch Walker and Mo Tiwari and Mohit Bansal and Moin Aminnaseri and Mor Geva and Mozhdeh Gheini and Mukund Varma T and Nanyun Peng and Nathan A. Chi and Nayeon Lee and Neta Gur-Ari Krakover and Nicholas Cameron and Nicholas Roberts and Nick Doiron and Nicole Martinez and Nikita Nangia and Niklas Deckers and Niklas Muennighoff and Nitish Shirish Keskar and Niveditha S. Iyer and Noah Constant and Noah Fiedel and Nuan Wen and Oliver Zhang and Omar Agha and Omar Elbaghdadi and Omer Levy and Owain Evans and Pablo Antonio Moreno Casares and Parth Doshi and Pascale Fung and Paul Pu Liang and Paul Vicol and Pegah Alipoormolabashi and Peiyuan Liao and Percy Liang and Peter Chang and Peter Eckersley and Phu Mon Htut and Pinyu Hwang and Piotr Mikowski and Piyush Patil and Pouya Pezeshkpour and Priti Oli and Qiaozhu Mei and Qing Lyu and Qinlang Chen and Rabin Banjade and Rachel Etta Rudolph and Raefer Gabriel and Rahel Habacker and Ramon Risco and Raphal Millire and Rhythm Garg and Richard Barnes and Rif A. Saurous and Riku Arakawa and Robbe Raymaekers and Robert Frank and Rohan Sikand and Roman Novak and Roman Sitelew and Ronan LeBras and Rosanne Liu and Rowan Jacobs and Rui Zhang and Ruslan Salakhutdinov and Ryan Chi and Ryan Lee and Ryan Stovall and Ryan Teehan and Rylan Yang and Sahib Singh and Saif M. Mohammad and Sajant Anand and Sam Dillavou and Sam Shleifer and Sam Wiseman and Samuel Gruetter and Samuel R. Bowman and Samuel S. Schoenholz and Sanghyun Han and Sanjeev Kwatra and Sarah A. Rous and Sarik Ghazarian and Sayan Ghosh and Sean Casey and Sebastian Bischoff and Sebastian Gehrmann and Sebastian Schuster and Sepideh Sadeghi and Shadi Hamdan and Sharon Zhou and Shashank Srivastava and Sherry Shi and Shikhar Singh and Shima Asaadi and Shixiang Shane Gu and Shubh Pachchigar and Shubham Toshniwal and Shyam Upadhyay and Shyamolima and Debnath and Siamak Shakeri and Simon Thormeyer and Simone Melzi and Siva Reddy and Sneha Priscilla Makini and Soo-Hwan Lee and Spencer Torene and Sriharsha Hatwar and Stanislas Dehaene and Stefan Divic and Stefano Ermon and Stella Biderman and Stephanie Lin and Stephen Prasad and Steven T. Piantadosi and Stuart M. Shieber and Summer Misherghi and Svetlana Kiritchenko and Swaroop Mishra and Tal Linzen and Tal Schuster and Tao Li and Tao Yu and Tariq Ali and Tatsu Hashimoto and Te-Lin Wu and Tho Desbordes and Theodore Rothschild and Thomas Phan and Tianle Wang and Tiberius Nkinyili and Timo Schick and Timofei Kornev and Titus Tunduny and Tobias Gerstenberg and Trenton Chang and Trishala Neeraj and Tushar Khot and Tyler Shultz and Uri Shaham and Vedant Misra and Vera Demberg and Victoria Nyamai and Vikas Raunak and Vinay Ramasesh and Vinay Uday Prabhu and Vishakh Padmakumar and Vivek Srikumar and William Fedus and William Saunders and William Zhang and Wout Vossen and Xiang Ren and Xiaoyu Tong and Xinran Zhao and Xinyi Wu and Xudong Shen and Yadollah Yaghoobzadeh and Yair Lakretz and Yangqiu Song and Yasaman Bahri and Yejin Choi and Yichi Yang and Yiding Hao and Yifu Chen and Yonatan Belinkov and Yu Hou and Yufang Hou and Yuntao Bai and Zachary Seid and Zhuoye Zhao and Zijian Wang and Zijie J. Wang and Zirui Wang and Ziyi Wu},
      year={2023},
      eprint={2206.04615},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
