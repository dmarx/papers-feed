\section{Related works}
\paragraph{Diffusion Models.}
Recent advances in DMs make great progress in the field of image synthesis and show state-of-the-art performance \cite{sohl2015deep, ho2020denoising, song2020denoising}. 
An important subject in the diffusion model is the introduction of gradient guidance, including classifier-free guidance, to control the generative process \cite{dhariwal2021diffusion,sehwag2022generating,avrahami2022blended,liu2021more,nichol2021glide,rombach2022high}. 
The work by \citet{song2020score} has facilitated the unification of DMs with score-based models using SDEs, enhancing our understanding of DMs as a reverse diffusion process.
However, the latent space is still largely unexplored, and our understanding is limited.

\paragraph{The study of latent space in GANs.} The study of latent spaces has gained significant attention in recent years. In the field of Generative Adversarial Networks (GANs), researchers have proposed various methods to manipulate the latent space to achieve the desired effect in the generated images \cite{ramesh2018spectral,patashnik2021styleclip,abdal2021styleflow, harkonen2020ganspace,shen2021closed,yuksel2021latentclr, pan2023drag}.
% \modify{For example, local latent space manipulation techniques \cite{ramesh2018spectral,patashnik2021styleclip,abdal2021styleflow} have been developed, as well as global manipulation techniques  \cite{harkonen2020ganspace,shen2021closed,yuksel2021latentclr}. 이젠 굳이 local global 나누지 말죠} 
More recently, several studies \cite{zhu2021low, choi2021not} have examined the geometrical properties of latent space in GANs and utilized these findings for image manipulations. These studies bring the advantage of better understanding the characteristics of the latent space and facilitating the analysis and utilization of GANs. In contrast, the latent space of DMs remains poorly understood, making it difficult to fully utilize their capabilities.

\paragraph{Image manipulation in DMs.}
Early works include \citet{choi2021ilvr} and \citet{meng2021sdedit} have attempted to manipulate the resulting images of DMs by replacing latent variables, allowing the generation of desired random images. 
However, due to the lack of semantics in the latent variables of DMs, current approaches have critical problems with semantic image editing.
Alternative approaches have explored the potential of using the feature space within the U-Net for semantic image manipulation. For example, \citet{kwon2022diffusion} have shown that the bottleneck of the U-Net, \ehspace{}, can be used as a semantic latent space. \modify{Specifically, they used CLIP \cite{radford2021learning} to identify directions within $\mathcal{H}$ that facilitate genuine image editing.} \citet{baranchuk2021label} and \citet{tumanyan2022plug} use the feature map of the U-Net for semantic segmentation and maintaining the structure of generated images. 
% Unlike previous works, our editing method directly traverses the latent variable along the latent basis.
Unlike previous works, our editing method \modify{finds the editing direction without supervision}, and directly traverses the latent variable along the latent basis.

% \yh{
% It is worth noting that, as a concurrent work, \citet{haas2023discovering} aims to find the semantic direction which could manipulate the generative process. However, they are only dealing with operations in a proxy semantic latent space, \ehspace{}. 
% % Moreover, they manipulate on synthetic latent variables and thus, it is  not a real image editing. 
% On the other hand, we manipulate the latent variable directly, but also find a semantic local subspace in \exspace{}, which gives us a useful insight for DM's mechanism.
% }

%%% ICML ver
% An important subject is the introduction of gradient guidance, including classifier-free guidance, to control the generative process \cite{dhariwal2021diffusion,sehwag2022generating,avrahami2022blended,liu2021more,nichol2021glide,rombach2022high}. \citet{choi2021ilvr} and \citet{meng2021sdedit} have attempted to manipulate the resulting images of DMs by replacing latent variables, allowing the generation of desired random images. However, due to the lack of semantics in the latent variables of DMs, current approaches have critical problems with semantic image editing.

%%% ICML ver
% Alternative approaches have explored the potential of using the feature space within the U-Net for semantic image manipulation. For example, \citet{baranchuk2021label} and \citet{tumanyan2022plug} use the feature map of the U-Net for semantic segmentation and maintaining the structure of generated images. \citet{kwon2022diffusion} have shown that the bottleneck of the U-Net, \ehspace{}, can be used as a semantic latent space.
% But the experimental observation lacks a theoretical understanding of the feature map of DMs.
% \yh{
% It is worth noting that, as a concurrent work, \citet{haas2023discovering} aims to find the semantic direction which could manipulate the generative process. However, they are only dealing with operations in a proxy semantic latent space, \ehspace{}. 
% % Moreover, they manipulate on synthetic latent variables and thus, it is  not a real image editing. 
% On the other hand, we manipulate the latent variable directly, but also find a semantic local subspace in \exspace{}, which gives us a useful insight for DM's mechanism.
% }


\paragraph{Riemannain Geometry.} Some studies have applied Riemannian geometry to analyze the latent spaces of deep generative models, such as Variational Autoencoders (VAEs) and GANs \cite{arvanitidis2017latent, shao2018riemannian, chen2018metrics, arvanitidis2020geometrically, lee2023explicit, pmlr-v162-lee22d, yonghyeon2021regularized}. \citet{shao2018riemannian} proposed a pullback metric on the latent space from image space Euclidean metric to analyze the latent space's geometry. This method has been widely used in VAEs and GANs because it only requires a differentiable map from latent space to image space.
% \modify{However, it has limitations such as a lack of evidence for applying the Euclidean metric in image space. 이부분 저희 이번 논문에서 해결을 안해준것 같은데..ㅎ}
However, no studies have investigated the geometry of latent space of DMs utilizing the pullback metric.