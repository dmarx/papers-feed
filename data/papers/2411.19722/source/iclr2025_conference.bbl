\begin{thebibliography}{76}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Aghajanyan et~al.(2022)Aghajanyan, Huang, Ross, Karpukhin, Xu, Goyal,
  Okhonko, Joshi, Ghosh, Lewis, and Zettlemoyer]{aghajanyan2022cm3}
Armen Aghajanyan, Po-Yao Huang, Candace Ross, Vladimir Karpukhin, Hu~Xu, Naman
  Goyal, Dmytro Okhonko, Mandar Joshi, Gargi Ghosh, Mike Lewis, and Luke
  Zettlemoyer.
\newblock {CM3}: A causal masked multimodal model of the internet.
\newblock \emph{arXiv:2201.07520}, 2022.

\bibitem[Aghajanyan et~al.(2023)Aghajanyan, Yu, Conneau, Hsu, Hambardzumyan,
  Zhang, Roller, Goyal, Levy, and Zettlemoyer]{aghajanyan2023scaling}
Armen Aghajanyan, Lili Yu, Alexis Conneau, Wei-Ning Hsu, Karen Hambardzumyan,
  Susan Zhang, Stephen Roller, Naman Goyal, Omer Levy, and Luke Zettlemoyer.
\newblock Scaling laws for generative mixed-modal language models.
\newblock In \emph{ICML}, 2023.

\bibitem[Alayrac et~al.(2022)Alayrac, Donahue, Luc, Miech, Barr, Hasson, Lenc,
  Mensch, Millican, Reynolds, Ring, Rutherford, Cabi, Han, Gong, Samangooei,
  Monteiro, Menick, Borgeaud, Brock, Nematzadeh, Sharifzadeh, Binkowski,
  Barreira, Vinyals, Zisserman, and Simonyan]{flamingo_paper_22}
Jean{-}Baptiste Alayrac, Jeff Donahue, Pauline Luc, Antoine Miech, Iain Barr,
  Yana Hasson, Karel Lenc, Arthur Mensch, Katie Millican, Malcolm Reynolds,
  Roman Ring, Eliza Rutherford, Serkan Cabi, Tengda Han, Zhitao Gong, Sina
  Samangooei, Marianne Monteiro, Jacob Menick, Sebastian Borgeaud, Andrew
  Brock, Aida Nematzadeh, Sahand Sharifzadeh, Mikolaj Binkowski, Ricardo
  Barreira, Oriol Vinyals, Andrew Zisserman, and Karen Simonyan.
\newblock Flamingo: A visual language model for few-shot learning.
\newblock In \emph{{NeurIPS}}, 2022.

\bibitem[{Anonymous}(2024)]{jet2024}
{Anonymous}.
\newblock Jet: A modern transformer-based normalizing flow.
\newblock \emph{In preparation}, 2024.

\bibitem[Beyer et~al.(2024)Beyer, Steiner, Pinto, Kolesnikov, Wang, Salz,
  Neumann, Alabdulmohsin, Tschannen, Bugliarello, et~al.]{beyer2024paligemma}
Lucas Beyer, Andreas Steiner, Andr{\'e}~Susano Pinto, Alexander Kolesnikov,
  Xiao Wang, Daniel Salz, Maxim Neumann, Ibrahim Alabdulmohsin, Michael
  Tschannen, Emanuele Bugliarello, et~al.
\newblock Pali{G}emma: A versatile 3{B} {VLM} for transfer.
\newblock \emph{arXiv:2407.07726}, 2024.

\bibitem[Brock et~al.(2018)Brock, Donahue, and Simonyan]{brock2018large}
Andrew Brock, Jeff Donahue, and Karen Simonyan.
\newblock Large scale {GAN} training for high fidelity natural image synthesis.
\newblock In \emph{ICLR}, 2018.

\bibitem[Chen et~al.(2020)Chen, Radford, Child, Wu, Jun, Luan, and
  Sutskever]{chen2020generative}
Mark Chen, Alec Radford, Rewon Child, Jeffrey Wu, Heewoo Jun, David Luan, and
  Ilya Sutskever.
\newblock Generative pretraining from pixels.
\newblock In \emph{ICML}, 2020.

\bibitem[Chen et~al.(2023{\natexlab{a}})Chen, Djolonga, Padlewski, Mustafa,
  Changpinyo, Wu, Ruiz, Goodman, Wang, Tay, Shakeri, Dehghani, Salz, Lucic,
  Tschannen, Nagrani, Hu, Joshi, Pang, Montgomery, Pietrzyk, Ritter,
  Piergiovanni, Minderer, Pavetic, Waters, Li, Alabdulmohsin, Beyer, Amelot,
  Lee, Steiner, Li, Keysers, Arnab, Xu, Rong, Kolesnikov, Seyedhosseini,
  Angelova, Zhai, Houlsby, and Soricut]{palix}
Xi~Chen, Josip Djolonga, Piotr Padlewski, Basil Mustafa, Soravit Changpinyo,
  Jialin Wu, Carlos~Riquelme Ruiz, Sebastian Goodman, Xiao Wang, Yi~Tay, Siamak
  Shakeri, Mostafa Dehghani, Daniel Salz, Mario Lucic, Michael Tschannen, Arsha
  Nagrani, Hexiang Hu, Mandar Joshi, Bo~Pang, Ceslee Montgomery, Paulina
  Pietrzyk, Marvin Ritter, AJ~Piergiovanni, Matthias Minderer, Filip Pavetic,
  Austin Waters, Gang Li, Ibrahim Alabdulmohsin, Lucas Beyer, Julien Amelot,
  Kenton Lee, Andreas~Peter Steiner, Yang Li, Daniel Keysers, Anurag Arnab,
  Yuanzhong Xu, Keran Rong, Alexander Kolesnikov, Mojtaba Seyedhosseini, Anelia
  Angelova, Xiaohua Zhai, Neil Houlsby, and Radu Soricut.
\newblock {PaLI-X}: On scaling up a multilingual vision and language model.
\newblock \emph{arXiv:2305.18565}, 2023{\natexlab{a}}.

\bibitem[Chen et~al.(2023{\natexlab{b}})Chen, Wang, Changpinyo, Piergiovanni,
  Padlewski, Salz, Goodman, Grycner, Mustafa, Beyer, et~al.]{chen2022pali}
Xi~Chen, Xiao Wang, Soravit Changpinyo, AJ~Piergiovanni, Piotr Padlewski,
  Daniel Salz, Sebastian Goodman, Adam Grycner, Basil Mustafa, Lucas Beyer,
  et~al.
\newblock {PaLI}: A jointly-scaled multilingual language-image model.
\newblock \emph{ICLR}, 2023{\natexlab{b}}.

\bibitem[Dhariwal \& Nichol(2021)Dhariwal and Nichol]{dhariwal2021diffusion}
Prafulla Dhariwal and Alexander Nichol.
\newblock Diffusion models beat {GANs} on image synthesis.
\newblock \emph{NeurIPS}, 2021.

\bibitem[Dieleman(2024)]{dieleman2024diffusion}
Sander Dieleman.
\newblock Diffusion is spectral autoregression.
\newblock \emph{Blog post}, 2024.
\newblock URL \url{https://sander.ai/2024/09/02/spectral-autoregression.html}.

\bibitem[Ding et~al.(2021)Ding, Yang, Hong, Zheng, Zhou, Yin, Lin, Zou, Shao,
  Yang, et~al.]{ding2021cogview}
Ming Ding, Zhuoyi Yang, Wenyi Hong, Wendi Zheng, Chang Zhou, Da~Yin, Junyang
  Lin, Xu~Zou, Zhou Shao, Hongxia Yang, et~al.
\newblock Cogview: Mastering text-to-image generation via transformers.
\newblock \emph{NeurIPS}, 2021.

\bibitem[Ding et~al.(2022)Ding, Zheng, Hong, and Tang]{ding2022cogview2}
Ming Ding, Wendi Zheng, Wenyi Hong, and Jie Tang.
\newblock Cogview2: Faster and better text-to-image generation via hierarchical
  transformers.
\newblock \emph{NeurIPS}, 2022.

\bibitem[Dinh et~al.(2014)Dinh, Krueger, and Bengio]{dinh2014nice}
Laurent Dinh, David Krueger, and Yoshua Bengio.
\newblock {NICE}: Non-linear independent components estimation.
\newblock \emph{arXiv:1410.8516}, 2014.

\bibitem[Dinh et~al.(2016)Dinh, Sohl-Dickstein, and Bengio]{dinh2016density}
Laurent Dinh, Jascha Sohl-Dickstein, and Samy Bengio.
\newblock Density estimation using real {NVP}.
\newblock \emph{arXiv:1605.08803}, 2016.

\bibitem[Dong et~al.(2023)Dong, Han, Peng, Qi, Ge, Yang, Zhao, Sun, Zhou, Wei,
  Kong, Zhang, Ma, and Yi]{dongdreamllm}
Runpei Dong, Chunrui Han, Yuang Peng, Zekun Qi, Zheng Ge, Jinrong Yang, Liang
  Zhao, Jianjian Sun, Hongyu Zhou, Haoran Wei, Xiangwen Kong, Xiangyu Zhang,
  Kaisheng Ma, and Li~Yi.
\newblock Dreamllm: Synergistic multimodal comprehension and creation.
\newblock In \emph{ICLR}, 2023.

\bibitem[Dosovitskiy et~al.(2021)Dosovitskiy, Beyer, Kolesnikov, Weissenborn,
  Zhai, Unterthiner, Dehghani, Minderer, Heigold, Gelly, Uszkoreit, and
  Houlsby]{dosovitskiy2020image}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn,
  Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg
  Heigold, Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock \emph{ICLR}, 2021.

\bibitem[Esser et~al.(2020)Esser, Rombach, and Ommer]{esser2020taming}
Patrick Esser, Robin Rombach, and Bj{\"o}rn Ommer.
\newblock Taming transformers for high-resolution image synthesis.
\newblock In \emph{CVPR}, 2020.

\bibitem[Gafni et~al.(2022)Gafni, Polyak, Ashual, Sheynin, Parikh, and
  Taigman]{gafni2022make}
Oran Gafni, Adam Polyak, Oron Ashual, Shelly Sheynin, Devi Parikh, and Yaniv
  Taigman.
\newblock Make-a-scene: Scene-based text-to-image generation with human priors.
\newblock In \emph{ECCV}, 2022.

\bibitem[Ge et~al.(2024)Ge, Zhao, Zhu, Ge, Yi, Song, Li, Ding, and
  Shan]{ge2024seed}
Yuying Ge, Sijie Zhao, Jinguo Zhu, Yixiao Ge, Kun Yi, Lin Song, Chen Li,
  Xiaohan Ding, and Ying Shan.
\newblock Seed-x: Multimodal models with unified multi-granularity
  comprehension and generation.
\newblock \emph{arXiv:2404.14396}, 2024.

\bibitem[{Gemma Team} et~al.(2024){Gemma Team}, Mesnard, Hardin, Dadashi,
  Bhupatiraju, Pathak, Sifre, Rivi{\`e}re, Kale, Love, et~al.]{team2024gemma}
{Gemma Team}, Thomas Mesnard, Cassidy Hardin, Robert Dadashi, Surya
  Bhupatiraju, Shreya Pathak, Laurent Sifre, Morgane Rivi{\`e}re, Mihir~Sanjay
  Kale, Juliette Love, et~al.
\newblock Gemma: Open models based on gemini research and technology.
\newblock \emph{arXiv:2403.08295}, 2024.

\bibitem[Ho \& Salimans(2022)Ho and Salimans]{ho2022classifier}
Jonathan Ho and Tim Salimans.
\newblock Classifier-free diffusion guidance.
\newblock \emph{arXiv:2207.12598}, 2022.

\bibitem[Ho et~al.(2019)Ho, Chen, Srinivas, Duan, and Abbeel]{ho2019flow++}
Jonathan Ho, Xi~Chen, Aravind Srinivas, Yan Duan, and Pieter Abbeel.
\newblock Flow++: Improving flow-based generative models with variational
  dequantization and architecture design.
\newblock In \emph{ICML}, 2019.

\bibitem[Huang et~al.(2023)Huang, Dong, Wang, Hao, Singhal, Ma, Lv, Cui,
  Mohammed, Liu, Aggarwal, Chi, Bjorck, Chaudhary, Som, Song, and Wei]{kosmos}
Shaohan Huang, Li~Dong, Wenhui Wang, Yaru Hao, Saksham Singhal, Shuming Ma,
  Tengchao Lv, Lei Cui, Owais~Khan Mohammed, Qiang Liu, Kriti Aggarwal, Zewen
  Chi, Johan Bjorck, Vishrav Chaudhary, Subhojit Som, Xia Song, and Furu Wei.
\newblock Language is not all you need: Aligning perception with language
  models.
\newblock \emph{arXiv:2302.14045}, 2023.

\bibitem[Jia et~al.(2021)Jia, Yang, Xia, Chen, Parekh, Pham, Le, Sung, Li, and
  Duerig]{align}
Chao Jia, Yinfei Yang, Ye~Xia, Yi-Ting Chen, Zarana Parekh, Hieu Pham, Quoc Le,
  Yun-Hsuan Sung, Zhen Li, and Tom Duerig.
\newblock Scaling up visual and vision-language representation learning with
  noisy text supervision.
\newblock In \emph{ICML}, 2021.

\bibitem[Kim et~al.(2023)Kim, Jo, Lee, and Kim]{kim2023magvlt}
Sungwoong Kim, Daejin Jo, Donghoon Lee, and Jongmin Kim.
\newblock {MAGVLT}: Masked generative vision-and-language transformer.
\newblock In \emph{CVPR}, 2023.

\bibitem[Kingma \& Gao(2023)Kingma and Gao]{kingma2024understanding}
Diederik Kingma and Ruiqi Gao.
\newblock Understanding diffusion objectives as the {ELBO} with simple data
  augmentation.
\newblock \emph{NeurIPS}, 2023.

\bibitem[Kingma \& Dhariwal(2018)Kingma and Dhariwal]{kingma2018glow}
Durk~P Kingma and Prafulla Dhariwal.
\newblock Glow: Generative flow with invertible 1x1 convolutions.
\newblock \emph{NeurIPS}, 2018.

\bibitem[Kolesnikov \& Lampert(2017)Kolesnikov and
  Lampert]{kolesnikov2017pixelcnn}
Alexander Kolesnikov and Christoph~H Lampert.
\newblock Pixel{CNN} models with auxiliary variables for natural image
  modeling.
\newblock In \emph{ICML}, 2017.

\bibitem[Kolesnikov et~al.(2022)Kolesnikov, Susano~Pinto, Beyer, Zhai, Harmsen,
  and Houlsby]{kolesnikov2022uvim}
Alexander Kolesnikov, Andr{\'e} Susano~Pinto, Lucas Beyer, Xiaohua Zhai,
  Jeremiah Harmsen, and Neil Houlsby.
\newblock {UViM}: A unified modeling approach for vision with learned guiding
  codes.
\newblock \emph{NeurIPS}, 2022.

\bibitem[Li et~al.(2023)Li, Li, Savarese, and Hoi]{blip2}
Junnan Li, Dongxu Li, Silvio Savarese, and Steven Hoi.
\newblock {BLIP-2}: Bootstrapping language-image pre-training with frozen image
  encoders and large language models.
\newblock \emph{arXiv:2301.12597}, 2023.

\bibitem[Li et~al.(2022)Li, Mao, Girshick, and He]{li2022exploring}
Yanghao Li, Hanzi Mao, Ross Girshick, and Kaiming He.
\newblock Exploring plain vision transformer backbones for object detection.
\newblock In \emph{ECCV}, 2022.

\bibitem[Lin et~al.(2014)Lin, Maire, Belongie, Hays, Perona, Ramanan,
  Doll{\'a}r, and Zitnick]{coco2014}
Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva
  Ramanan, Piotr Doll{\'a}r, and C~Lawrence Zitnick.
\newblock Microsoft {COCO}: Common objects in context.
\newblock In \emph{ECCV}, 2014.

\bibitem[Liu et~al.(2024)Liu, Li, Wu, and Lee]{liu2024visual}
Haotian Liu, Chunyuan Li, Qingyang Wu, and Yong~Jae Lee.
\newblock Visual instruction tuning.
\newblock \emph{NeurIPS}, 2024.

\bibitem[Lu et~al.(2022)Lu, Clark, Zellers, Mottaghi, and
  Kembhavi]{lu2022unified}
Jiasen Lu, Christopher Clark, Rowan Zellers, Roozbeh Mottaghi, and Aniruddha
  Kembhavi.
\newblock Unified-{IO}: A unified model for vision, language, and multi-modal
  tasks.
\newblock In \emph{ICLR}, 2022.

\bibitem[Meng et~al.(2024)Meng, Zhou, Liu, Chen, Han, Hu, Liu, Li, Zhao, Wu,
  et~al.]{meng2024autoregressive}
Lingwei Meng, Long Zhou, Shujie Liu, Sanyuan Chen, Bing Han, Shujie Hu, Yanqing
  Liu, Jinyu Li, Sheng Zhao, Xixin Wu, et~al.
\newblock Autoregressive speech synthesis without vector quantization.
\newblock \emph{arXiv:2407.08551}, 2024.

\bibitem[Menick \& Kalchbrenner(2019)Menick and
  Kalchbrenner]{menick2018generating}
Jacob Menick and Nal Kalchbrenner.
\newblock Generating high fidelity images with subscale pixel networks and
  multidimensional upscaling.
\newblock \emph{ICLR}, 2019.

\bibitem[Mentzer et~al.(2024)Mentzer, Minnen, Agustsson, and
  Tschannen]{mentzer2023finite}
Fabian Mentzer, David Minnen, Eirikur Agustsson, and Michael Tschannen.
\newblock Finite scalar quantization: {VQ-VAE} made simple.
\newblock \emph{ICLR}, 2024.

\bibitem[Mizrahi et~al.(2024)Mizrahi, Bachmann, Kar, Yeo, Gao, Dehghan, and
  Zamir]{mizrahi20244m}
David Mizrahi, Roman Bachmann, Oguzhan Kar, Teresa Yeo, Mingfei Gao, Afshin
  Dehghan, and Amir Zamir.
\newblock {4M}: Massively multimodal masked modeling.
\newblock \emph{NeurIPS}, 2024.

\bibitem[Nachmani et~al.(2023)Nachmani, Levkovitch, Hirsch, Salazar,
  Asawaroengchai, Mariooryad, Rivlin, Skerry-Ryan, and
  Ramanovich]{nachmani2023lms}
Eliya Nachmani, Alon Levkovitch, Roy Hirsch, Julian Salazar, Chulayuth
  Asawaroengchai, Soroosh Mariooryad, Ehud Rivlin, RJ~Skerry-Ryan, and
  Michelle~Tadmor Ramanovich.
\newblock Spoken question answering and speech continuation using
  spectrogram-powered llm.
\newblock \emph{arXiv preprint arXiv:2305.15255}, 2023.

\bibitem[Nash et~al.(2021)Nash, Menick, Dieleman, and
  Battaglia]{nash2021generating}
Charlie Nash, Jacob Menick, Sander Dieleman, and Peter Battaglia.
\newblock Generating images with sparse representations.
\newblock In \emph{ICML}, 2021.

\bibitem[Nichol et~al.(2022)Nichol, Dhariwal, Ramesh, Shyam, Mishkin, Mcgrew,
  Sutskever, and Chen]{nichol2022glide}
Alexander~Quinn Nichol, Prafulla Dhariwal, Aditya Ramesh, Pranav Shyam, Pamela
  Mishkin, Bob Mcgrew, Ilya Sutskever, and Mark Chen.
\newblock {GLIDE}: Towards photorealistic image generation and editing with
  text-guided diffusion models.
\newblock In \emph{ICML}, 2022.

\bibitem[Pan et~al.(2024)Pan, Tang, Li, Fan, Chow, Yan, Chua, Zhuang, and
  Zhang]{pan2024auto}
Kaihang Pan, Siliang Tang, Juncheng Li, Zhaoyu Fan, Wei Chow, Shuicheng Yan,
  Tat-Seng Chua, Yueting Zhuang, and Hanwang Zhang.
\newblock Auto-encoding morph-tokens for multimodal llm.
\newblock \emph{arXiv:2405.01926}, 2024.

\bibitem[Parmar et~al.(2018)Parmar, Vaswani, Uszkoreit, Kaiser, Shazeer, Ku,
  and Tran]{parmar2018image}
Niki Parmar, Ashish Vaswani, Jakob Uszkoreit, Lukasz Kaiser, Noam Shazeer,
  Alexander Ku, and Dustin Tran.
\newblock Image transformer.
\newblock In \emph{ICML}, 2018.

\bibitem[Po et~al.(2024)Po, Yifan, Golyanik, Aberman, Barron, Bermano, Chan,
  Dekel, Holynski, Kanazawa, et~al.]{po2024state}
Ryan Po, Wang Yifan, Vladislav Golyanik, Kfir Aberman, Jonathan~T Barron, Amit
  Bermano, Eric Chan, Tali Dekel, Aleksander Holynski, Angjoo Kanazawa, et~al.
\newblock State of the art on diffusion models for visual computing.
\newblock In \emph{Computer Graphics Forum}, 2024.

\bibitem[Radford et~al.(2018)Radford, Narasimhan, Salimans, and
  Sutskever]{radford2018improving}
Alec Radford, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever.
\newblock Improving language understanding by generative pre-training.
\newblock 2018.

\bibitem[Radford et~al.(2021)Radford, Kim, Hallacy, Ramesh, Goh, Agarwal,
  Sastry, Askell, Mishkin, Clark, et~al.]{clip}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh,
  Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark,
  et~al.
\newblock Learning transferable visual models from natural language
  supervision.
\newblock In \emph{ICML}, 2021.

\bibitem[Raffel et~al.(2020)Raffel, Shazeer, Roberts, Lee, Narang, Matena,
  Zhou, Li, and Liu]{t5}
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael
  Matena, Yanqi Zhou, Wei Li, and Peter~J Liu.
\newblock Exploring the limits of transfer learning with a unified text-to-text
  transformer.
\newblock \emph{JMLR}, 2020.

\bibitem[Ramesh et~al.(2021)Ramesh, Pavlov, Goh, Gray, Voss, Radford, Chen, and
  Sutskever]{ramesh2021zero}
Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray, Chelsea Voss, Alec
  Radford, Mark Chen, and Ilya Sutskever.
\newblock Zero-shot text-to-image generation.
\newblock In \emph{ICML}, 2021.

\bibitem[Ramesh et~al.(2022)Ramesh, Dhariwal, Nichol, Chu, and
  Chen]{ramesh2022hierarchical}
Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen.
\newblock Hierarchical text-conditional image generation with clip latents.
\newblock \emph{arXiv:2204.06125}, 2022.

\bibitem[Razavi et~al.(2019)Razavi, Van~den Oord, and
  Vinyals]{razavi2019generating}
Ali Razavi, Aaron Van~den Oord, and Oriol Vinyals.
\newblock Generating diverse high-fidelity images with {VQ-VAE-2}.
\newblock \emph{NeurIPS}, 2019.

\bibitem[Rombach et~al.(2022)Rombach, Blattmann, Lorenz, Esser, and
  Ommer]{rombach2021high}
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj{\"o}rn
  Ommer.
\newblock High-resolution image synthesis with latent diffusion models.
\newblock In \emph{CVPR}, 2022.

\bibitem[Russakovsky et~al.(2015)Russakovsky, Deng, Su, Krause, Satheesh, Ma,
  Huang, Karpathy, Khosla, Bernstein, et~al.]{russakovsky2015imagenet}
Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma,
  Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, et~al.
\newblock Imagenet large scale visual recognition challenge.
\newblock \emph{IJCV}, 2015.

\bibitem[Saharia et~al.(2022)Saharia, Chan, Saxena, Li, Whang, Denton,
  Ghasemipour, Gontijo~Lopes, Karagol~Ayan, Salimans,
  et~al.]{saharia2022photorealistic}
Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily~L
  Denton, Kamyar Ghasemipour, Raphael Gontijo~Lopes, Burcu Karagol~Ayan, Tim
  Salimans, et~al.
\newblock Photorealistic text-to-image diffusion models with deep language
  understanding.
\newblock \emph{NeurIPS}, 2022.

\bibitem[Sajjadi et~al.(2018)Sajjadi, Bachem, Lucic, Bousquet, and
  Gelly]{sajjadi2018assessing}
Mehdi~SM Sajjadi, Olivier Bachem, Mario Lucic, Olivier Bousquet, and Sylvain
  Gelly.
\newblock Assessing generative models via precision and recall.
\newblock \emph{NeurIPS}, 2018.

\bibitem[Salimans et~al.(2016)Salimans, Karpathy, Chen, and
  Kingma]{salimans2016pixelcnn}
Tim Salimans, Andrej Karpathy, Xi~Chen, and Diederik~P Kingma.
\newblock {PixelCNN++}: Improving the {PixelCNN} with discretized logistic
  mixture likelihood and other modifications.
\newblock In \emph{ICLR}, 2016.

\bibitem[Singh et~al.(2019)Singh, Natarjan, Shah, Jiang, Chen, Parikh, and
  Rohrbach]{singh2019towards-textvqa}
Amanpreet Singh, Vivek Natarjan, Meet Shah, Yu~Jiang, Xinlei Chen, Devi Parikh,
  and Marcus Rohrbach.
\newblock Towards {VQA} models that can read.
\newblock In \emph{CVPR}, 2019.

\bibitem[Sohl-Dickstein et~al.(2015)Sohl-Dickstein, Weiss, Maheswaranathan, and
  Ganguli]{sohl2015deep}
Jascha Sohl-Dickstein, Eric Weiss, Niru Maheswaranathan, and Surya Ganguli.
\newblock Deep unsupervised learning using nonequilibrium thermodynamics.
\newblock In \emph{ICML}, 2015.

\bibitem[Strudel et~al.(2021)Strudel, Garcia, Laptev, and
  Schmid]{strudel2021segmenter}
Robin Strudel, Ricardo Garcia, Ivan Laptev, and Cordelia Schmid.
\newblock Segmenter: {Transformer} for semantic segmentation.
\newblock In \emph{CVPR}, 2021.

\bibitem[Sutton(2019)]{sutton2019bitter}
Richard Sutton.
\newblock The bitter lesson.
\newblock \emph{Incomplete Ideas (blog)}, 2019.

\bibitem[Theis et~al.(2015)Theis, Oord, and Bethge]{theis2015note}
Lucas Theis, A{\"a}ron van~den Oord, and Matthias Bethge.
\newblock A note on the evaluation of generative models.
\newblock \emph{arXiv:1511.01844}, 2015.

\bibitem[Tipping \& Bishop(1999)Tipping and Bishop]{tipping1999probabilistic}
Michael~E Tipping and Christopher~M Bishop.
\newblock Probabilistic principal component analysis.
\newblock \emph{Journal of the Royal Statistical Society Series B: Statistical
  Methodology}, 1999.

\bibitem[Tschannen et~al.(2023)Tschannen, Kumar, Steiner, Zhai, Houlsby, and
  Beyer]{tschannen2023image}
Michael Tschannen, Manoj Kumar, Andreas Steiner, Xiaohua Zhai, Neil Houlsby,
  and Lucas Beyer.
\newblock Image captioners are scalable vision learners too.
\newblock In \emph{NeurIPS}, 2023.

\bibitem[Tschannen et~al.(2024)Tschannen, Eastwood, and
  Mentzer]{tschannen2023givt}
Michael Tschannen, Cian Eastwood, and Fabian Mentzer.
\newblock {GIVT}: Generative infinite-vocabulary transformers.
\newblock In \emph{ECCV}, 2024.

\bibitem[Van~den Oord et~al.(2016{\natexlab{a}})Van~den Oord, Kalchbrenner,
  Espeholt, Vinyals, Graves, et~al.]{van2016conditional}
Aaron Van~den Oord, Nal Kalchbrenner, Lasse Espeholt, Oriol Vinyals, Alex
  Graves, et~al.
\newblock Conditional image generation with pixelcnn decoders.
\newblock \emph{NeurIPS}, 2016{\natexlab{a}}.

\bibitem[Van~den Oord et~al.(2016{\natexlab{b}})Van~den Oord, Kalchbrenner, and
  Kavukcuoglu]{van2016pixel}
A{\"a}ron Van~den Oord, Nal Kalchbrenner, and Koray Kavukcuoglu.
\newblock Pixel recurrent neural networks.
\newblock In \emph{ICML}, 2016{\natexlab{b}}.

\bibitem[van~den Oord et~al.(2017)van~den Oord, Vinyals, and
  Kavukcuoglu]{van2017neural}
A{\"a}ron van~den Oord, Oriol Vinyals, and Koray Kavukcuoglu.
\newblock Neural discrete representation learning.
\newblock \emph{NeurIPS}, 2017.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{vaswani2017attention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N Gomez, {\L}ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock \emph{NeurIPS}, 2017.

\bibitem[Wang et~al.(2022{\natexlab{a}})Wang, Yang, Hu, Li, Lin, Gan, Liu, Liu,
  and Wang]{git2_22}
Jianfeng Wang, Zhengyuan Yang, Xiaowei Hu, Linjie Li, Kevin Lin, Zhe Gan,
  Zicheng Liu, Ce~Liu, and Lijuan Wang.
\newblock {GIT:} {A} generative image-to-text transformer for vision and
  language.
\newblock \emph{TMLR}, 2022{\natexlab{a}}.

\bibitem[Wang et~al.(2022{\natexlab{b}})Wang, Yu, Yu, Dai, Tsvetkov, and
  Cao]{simvlm_22}
Zirui Wang, Jiahui Yu, Adams~Wei Yu, Zihang Dai, Yulia Tsvetkov, and Yuan Cao.
\newblock {SimVLM}: Simple visual language model pretraining with weak
  supervision.
\newblock \emph{ICLR}, 2022{\natexlab{b}}.

\bibitem[Xu et~al.(2024)Xu, Yang, Song, and Xu]{xu2024libra}
Yifan Xu, Xiaoshan Yang, Yaguang Song, and Changsheng Xu.
\newblock Libra: Building decoupled vision system on large language models.
\newblock \emph{arXiv:2405.10140}, 2024.

\bibitem[You et~al.(2023)You, Guo, Wang, Chang, Baldridge, and
  Yu]{you2023cobit}
Haoxuan You, Mandy Guo, Zhecan Wang, Kai-Wei Chang, Jason Baldridge, and Jiahui
  Yu.
\newblock Co{BIT}: A contrastive bi-directional image-text generation model.
\newblock \emph{arXiv:2303.13455}, 2023.

\bibitem[Yu et~al.(2022{\natexlab{a}})Yu, Li, Koh, Zhang, Pang, Qin, Ku, Xu,
  Baldridge, and Wu]{yu2021vector}
Jiahui Yu, Xin Li, Jing~Yu Koh, Han Zhang, Ruoming Pang, James Qin, Alexander
  Ku, Yuanzhong Xu, Jason Baldridge, and Yonghui Wu.
\newblock Vector-quantized image modeling with improved {VQGAN}.
\newblock \emph{ICLR}, 2022{\natexlab{a}}.

\bibitem[Yu et~al.(2022{\natexlab{b}})Yu, Wang, Vasudevan, Yeung,
  Seyedhosseini, and Wu]{yu2022coca}
Jiahui Yu, Zirui Wang, Vijay Vasudevan, Legg Yeung, Mojtaba Seyedhosseini, and
  Yonghui Wu.
\newblock Coca: Contrastive captioners are image-text foundation models.
\newblock \emph{TMLR}, 2022{\natexlab{b}}.

\bibitem[Yu et~al.(2022{\natexlab{c}})Yu, Xu, Koh, Luong, Baid, Wang,
  Vasudevan, Ku, Yang, Ayan, Hutchinson, Han, Parekh, Li, Zhang, Baldridge, and
  Wu]{yu2022scaling}
Jiahui Yu, Yuanzhong Xu, Jing~Yu Koh, Thang Luong, Gunjan Baid, Zirui Wang,
  Vijay Vasudevan, Alexander Ku, Yinfei Yang, Burcu~Karagol Ayan, Benton~C.
  Hutchinson, Wei Han, Zarana Parekh, Xin Li, Han Zhang, Jason Baldridge, and
  Yonghui Wu.
\newblock Scaling autoregressive models for content-rich text-to-image
  generation.
\newblock \emph{TMLR}, 2022{\natexlab{c}}.

\bibitem[Zhou et~al.(2024)Zhou, Yu, Babu, Tirumala, Yasunaga, Shamis, Kahn, Ma,
  Zettlemoyer, and Levy]{zhou2024transfusion}
Chunting Zhou, Lili Yu, Arun Babu, Kushal Tirumala, Michihiro Yasunaga, Leonid
  Shamis, Jacob Kahn, Xuezhe Ma, Luke Zettlemoyer, and Omer Levy.
\newblock Transfusion: Predict the next token and diffuse images with one
  multi-modal model.
\newblock \emph{arXiv:2408.11039}, 2024.

\end{thebibliography}
