\begin{thebibliography}{96}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Beltagy et~al.(2020)Beltagy, Peters, and Cohan]{beltagy2020longformer}
Iz~Beltagy, Matthew~E. Peters, and Arman Cohan.
\newblock Longformer: The long-document transformer.
\newblock \emph{arXiv:2004.05150}, 2020.

\bibitem[Bhat et~al.(2020)Bhat, Lawin, Danelljan, Robinson, Felsberg, Van~Gool, and Timofte]{bhat2020learning}
Goutam Bhat, Felix~J{\"a}remo Lawin, Martin Danelljan, Andreas Robinson, Michael Felsberg, Luc Van~Gool, and Radu Timofte.
\newblock Learning what to learn for video object segmentation.
\newblock In \emph{Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part II 16}, pages 777--794. Springer, 2020.

\bibitem[Brox and Malik(2010)]{brox2010object}
Thomas Brox and Jitendra Malik.
\newblock Object segmentation by long term analysis of point trajectories.
\newblock In \emph{European conference on computer vision}, pages 282--295. Springer, 2010.

\bibitem[Caelles et~al.(2018)Caelles, Montes, Maninis, Chen, Van~Gool, Perazzi, and Pont-Tuset]{caelles20182018}
Sergi Caelles, Alberto Montes, Kevis-Kokitsi Maninis, Yuhua Chen, Luc Van~Gool, Federico Perazzi, and Jordi Pont-Tuset.
\newblock The 2018 davis challenge on video object segmentation.
\newblock \emph{arXiv preprint arXiv:1803.00557}, 2018.

\bibitem[Cai et~al.(2023)Cai, Li, Hu, Gan, and Han]{cai2023efficientvit}
Han Cai, Junyan Li, Muyan Hu, Chuang Gan, and Song Han.
\newblock Efficientvit: Lightweight multi-scale attention for high-resolution dense prediction.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 17302--17313, 2023.

\bibitem[Cen et~al.(2023)Cen, Wu, Wang, Li, Yang, Pei, Kong, Liu, and Chen]{cen2023sad}
Jun Cen, Yizheng Wu, Kewei Wang, Xingyi Li, Jingkang Yang, Yixuan Pei, Lingdong Kong, Ziwei Liu, and Qifeng Chen.
\newblock Sad: Segment any rgbd.
\newblock \emph{arXiv preprint arXiv:2305.14207}, 2023.

\bibitem[Chen et~al.(2023{\natexlab{a}})Chen, Yang, and Zhang]{chen2023semantic}
Jiaqi Chen, Zeyu Yang, and Li~Zhang.
\newblock Semantic segment anything.
\newblock \url{https://github.com/fudan-zvg/Semantic-Segment-Anything}, 2023{\natexlab{a}}.

\bibitem[Chen et~al.(2023{\natexlab{b}})Chen, Zhu, Deng, Cao, Wang, Zhang, Li, Sun, Zang, and Mao]{chen2023sam}
Tianrun Chen, Lanyun Zhu, Chaotao Deng, Runlong Cao, Yan Wang, Shangzhan Zhang, Zejian Li, Lingyun Sun, Ying Zang, and Papa Mao.
\newblock Sam-adapter: Adapting segment anything in underperformed scenes.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 3367--3375, 2023{\natexlab{b}}.

\bibitem[Cheng et~al.(2022)Cheng, Misra, Schwing, Kirillov, and Girdhar]{cheng2022masked}
Bowen Cheng, Ishan Misra, Alexander~G Schwing, Alexander Kirillov, and Rohit Girdhar.
\newblock Masked-attention mask transformer for universal image segmentation.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 1290--1299, 2022.

\bibitem[Cheng and Schwing(2022)]{cheng2022xmem}
Ho~Kei Cheng and Alexander~G Schwing.
\newblock Xmem: Long-term video object segmentation with an atkinson-shiffrin memory model.
\newblock In \emph{European Conference on Computer Vision}, pages 640--658. Springer, 2022.

\bibitem[Cheng et~al.(2021{\natexlab{a}})Cheng, Tai, and Tang]{cheng2021modular}
Ho~Kei Cheng, Yu-Wing Tai, and Chi-Keung Tang.
\newblock Modular interactive video object segmentation: Interaction-to-mask, propagation and difference-aware fusion.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 5559--5568, 2021{\natexlab{a}}.

\bibitem[Cheng et~al.(2021{\natexlab{b}})Cheng, Tai, and Tang]{cheng2021rethinking}
Ho~Kei Cheng, Yu-Wing Tai, and Chi-Keung Tang.
\newblock Rethinking space-time networks with improved memory coverage for efficient video object segmentation.
\newblock \emph{Advances in Neural Information Processing Systems}, 34:\penalty0 11781--11794, 2021{\natexlab{b}}.

\bibitem[Cheng et~al.(2023{\natexlab{a}})Cheng, Oh, Price, Schwing, and Lee]{cheng2023tracking}
Ho~Kei Cheng, Seoung~Wug Oh, Brian Price, Alexander Schwing, and Joon-Young Lee.
\newblock Tracking anything with decoupled video segmentation.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 1316--1326, 2023{\natexlab{a}}.

\bibitem[Cheng et~al.(2024)Cheng, Oh, Price, Lee, and Schwing]{cheng2024putting}
Ho~Kei Cheng, Seoung~Wug Oh, Brian Price, Joon-Young Lee, and Alexander Schwing.
\newblock Putting the object back into video object segmentation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 3151--3161, 2024.

\bibitem[Cheng et~al.(2023{\natexlab{b}})Cheng, Li, Xu, Li, Yang, Wang, and Yang]{cheng2023segment}
Yangming Cheng, Liulei Li, Yuanyou Xu, Xiaodi Li, Zongxin Yang, Wenguan Wang, and Yi~Yang.
\newblock Segment and track anything.
\newblock \emph{arXiv preprint arXiv:2305.06558}, 2023{\natexlab{b}}.

\bibitem[Choromanski et~al.(2020)Choromanski, Likhosherstov, Dohan, Song, Gane, Sarlos, Hawkins, Davis, Mohiuddin, Kaiser, et~al.]{choromanski2020rethinking}
Krzysztof Choromanski, Valerii Likhosherstov, David Dohan, Xingyou Song, Andreea Gane, Tamas Sarlos, Peter Hawkins, Jared Davis, Afroz Mohiuddin, Lukasz Kaiser, et~al.
\newblock Rethinking attention with performers.
\newblock \emph{arXiv preprint arXiv:2009.14794}, 2020.

\bibitem[Clark et~al.(2020)Clark, Luong, Le, and Manning]{clark2020electra}
Kevin Clark, Minh-Thang Luong, Quoc~V. Le, and Christopher~D. Manning.
\newblock {ELECTRA}: Pre-training text encoders as discriminators rather than generators.
\newblock In \emph{ICLR}, 2020.
\newblock \url{https://openreview.net/pdf?id=r1xMH1BtvB}.

\bibitem[Delatolas et~al.(2024)Delatolas, Kalogeiton, and Papadopoulos]{delatolas2024learning}
Thanos Delatolas, Vicky Kalogeiton, and Dim~P Papadopoulos.
\newblock Learning the what and how of annotation in video object segmentation.
\newblock In \emph{Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision}, pages 6951--6961, 2024.

\bibitem[Deng et~al.(2023)Deng, Cui, Liu, Yao, Remedios, Bao, Landman, Wheless, Coburn, Wilson, et~al.]{deng2023segment}
Ruining Deng, Can Cui, Quan Liu, Tianyuan Yao, Lucas~W Remedios, Shunxing Bao, Bennett~A Landman, Lee~E Wheless, Lori~A Coburn, Keith~T Wilson, et~al.
\newblock Segment anything model (sam) for digital pathology: Assess zero-shot segmentation on whole slide imaging.
\newblock \emph{arXiv preprint arXiv:2304.04155}, 2023.

\bibitem[Ding et~al.(2023)Ding, Liu, He, Jiang, Torr, and Bai]{ding2023mose}
Henghui Ding, Chang Liu, Shuting He, Xudong Jiang, Philip~HS Torr, and Song Bai.
\newblock Mose: A new dataset for video object segmentation in complex scenes.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 20224--20234, 2023.

\bibitem[Ding et~al.(2024)Ding, Qian, Dong, Zhang, Zang, Cao, Guo, Lin, and Wang]{ding2024sam2long}
Shuangrui Ding, Rui Qian, Xiaoyi Dong, Pan Zhang, Yuhang Zang, Yuhang Cao, Yuwei Guo, Dahua Lin, and Jiaqi Wang.
\newblock Sam2long: Enhancing sam 2 for long video segmentation with a training-free memory tree.
\newblock \emph{arXiv preprint arXiv:2410.16268}, 2024.

\bibitem[Dosovitskiy et~al.(2020)Dosovitskiy, Beyer, Kolesnikov, Weissenborn, Zhai, Unterthiner, Dehghani, Minderer, Heigold, Gelly, et~al.]{dosovitskiy2020image}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, et~al.
\newblock An image is worth 16x16 words: Transformers for image recognition at scale.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Duke et~al.(2021)Duke, Ahmed, Wolf, Aarabi, and Taylor]{duke2021sstvos}
Brendan Duke, Abdalla Ahmed, Christian Wolf, Parham Aarabi, and Graham~W Taylor.
\newblock Sstvos: Sparse spatiotemporal transformers for video object segmentation.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 5912--5921, 2021.

\bibitem[Faktor and Irani(2014)]{faktor2014video}
Alon Faktor and Michal Irani.
\newblock Video segmentation by non-local consensus voting.
\newblock In \emph{BMVC}, volume~2, page~8, 2014.

\bibitem[Fan et~al.(2021)Fan, Xiong, Mangalam, Li, Yan, Malik, and Feichtenhofer]{fan2021multiscale}
Haoqi Fan, Bo~Xiong, Karttikeya Mangalam, Yanghao Li, Zhicheng Yan, Jitendra Malik, and Christoph Feichtenhofer.
\newblock Multiscale vision transformers.
\newblock In \emph{Proceedings of the IEEE/CVF international conference on computer vision}, pages 6824--6835, 2021.

\bibitem[Fragkiadaki et~al.(2012)Fragkiadaki, Zhang, and Shi]{fragkiadaki2012video}
Katerina Fragkiadaki, Geng Zhang, and Jianbo Shi.
\newblock Video segmentation by tracing discontinuities in a trajectory embedding.
\newblock In \emph{2012 IEEE Conference on Computer Vision and Pattern Recognition}, pages 1846--1853. IEEE, 2012.

\bibitem[Gao et~al.(2023)Gao, Lin, Xie, Zhou, Cheng, and Yan]{gao2023editanything}
Shanghua Gao, Zhijie Lin, Xingyu Xie, Pan Zhou, Ming-Ming Cheng, and Shuicheng Yan.
\newblock Editanything: Empowering unparalleled flexibility in image editing and generation.
\newblock In \emph{Proceedings of the 31st ACM International Conference on Multimedia}, pages 9414--9416, 2023.

\bibitem[Graham et~al.(2021)Graham, El-Nouby, Touvron, Stock, Joulin, J{\'e}gou, and Douze]{graham2021levit}
Benjamin Graham, Alaaeldin El-Nouby, Hugo Touvron, Pierre Stock, Armand Joulin, Herv{\'e} J{\'e}gou, and Matthijs Douze.
\newblock Levit: a vision transformer in convnet's clothing for faster inference.
\newblock In \emph{Proceedings of the IEEE/CVF international conference on computer vision}, pages 12259--12269, 2021.

\bibitem[Grundmann et~al.(2010)Grundmann, Kwatra, Han, and Essa]{grundmann2010efficient}
Matthias Grundmann, Vivek Kwatra, Mei Han, and Irfan Essa.
\newblock Efficient hierarchical graph-based video segmentation.
\newblock In \emph{2010 ieee computer society conference on computer vision and pattern recognition}, pages 2141--2148. IEEE, 2010.

\bibitem[Han et~al.(2023)Han, Zhang, Qiao, Qamar, Jung, Lee, Bae, and Hong]{han2023segment}
Dongsheng Han, Chaoning Zhang, Yu~Qiao, Maryam Qamar, Yuna Jung, SeungKyu Lee, Sung-Ho Bae, and Choong~Seon Hong.
\newblock Segment anything model (sam) meets glass: Mirror and transparent objects cannot be easily detected.
\newblock \emph{arXiv preprint arXiv:2305.00278}, 2023.

\bibitem[Heo et~al.(2020)Heo, Jun~Koh, and Kim]{heo2020interactive}
Yuk Heo, Yeong Jun~Koh, and Chang-Su Kim.
\newblock Interactive video object segmentation using global and local transfer modules.
\newblock In \emph{Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part XVII 16}, pages 297--313. Springer, 2020.

\bibitem[Homayounfar et~al.(2021)Homayounfar, Liang, Ma, and Urtasun]{homayounfar2021videoclick}
Namdar Homayounfar, Justin Liang, Wei-Chiu Ma, and Raquel Urtasun.
\newblock Videoclick: Video object segmentation with a single click.
\newblock \emph{arXiv preprint arXiv:2101.06545}, 2021.

\bibitem[Hong et~al.(2024)Hong, Liu, Chen, Tan, Feng, Zhou, Guo, Li, Chen, Gao, et~al.]{hong2024lvos}
Lingyi Hong, Zhongying Liu, Wenchao Chen, Chenzhi Tan, Yuang Feng, Xinyu Zhou, Pinxue Guo, Jinglun Li, Zhaoyu Chen, Shuyong Gao, et~al.
\newblock Lvos: A benchmark for large-scale long-term video object segmentation.
\newblock \emph{arXiv preprint arXiv:2404.19326}, 2024.

\bibitem[Jiang and Holz(2023)]{jiang2023restore}
Jiaxi Jiang and Christian Holz.
\newblock Restore anything pipeline: Segment anything meets image restoration.
\newblock \emph{arXiv preprint arXiv:2305.13093}, 2023.

\bibitem[Katharopoulos et~al.(2020)Katharopoulos, Vyas, Pappas, and Fleuret]{katharopoulos-et-al-2020}
A.~Katharopoulos, A.~Vyas, N.~Pappas, and F.~Fleuret.
\newblock Transformers are rnns: Fast autoregressive transformers with linear attention.
\newblock In \emph{Proceedings of the International Conference on Machine Learning (ICML)}, 2020.

\bibitem[Kirillov et~al.(2023)Kirillov, Mintun, Ravi, Mao, Rolland, Gustafson, Xiao, Whitehead, Berg, Lo, et~al.]{kirillov2023segment}
Alexander Kirillov, Eric Mintun, Nikhila Ravi, Hanzi Mao, Chloe Rolland, Laura Gustafson, Tete Xiao, Spencer Whitehead, Alexander~C Berg, Wan-Yen Lo, et~al.
\newblock Segment anything.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 4015--4026, 2023.

\bibitem[LeCun et~al.(1989)LeCun, Boser, Denker, Henderson, Howard, Hubbard, and Jackel]{lecun1989backpropagation}
Yann LeCun, Bernhard Boser, John~S Denker, Donnie Henderson, Richard~E Howard, Wayne Hubbard, and Lawrence~D Jackel.
\newblock Backpropagation applied to handwritten zip code recognition.
\newblock \emph{Neural computation}, 1\penalty0 (4):\penalty0 541--551, 1989.

\bibitem[Lee et~al.(2011)Lee, Kim, and Grauman]{lee2011key}
Yong~Jae Lee, Jaechul Kim, and Kristen Grauman.
\newblock Key-segments for video object segmentation.
\newblock In \emph{2011 International conference on computer vision}, pages 1995--2002. IEEE, 2011.

\bibitem[Li et~al.(2013)Li, Kim, Humayun, Tsai, and Rehg]{li2013video}
Fuxin Li, Taeyoung Kim, Ahmad Humayun, David Tsai, and James~M Rehg.
\newblock Video segmentation by tracking many figure-ground segments.
\newblock In \emph{Proceedings of the IEEE international conference on computer vision}, pages 2192--2199, 2013.

\bibitem[Li et~al.(2022{\natexlab{a}})Li, Xia, Li, Li, Wang, Xiao, Wang, Zheng, and Pan]{li2022next}
Jiashi Li, Xin Xia, Wei Li, Huixia Li, Xing Wang, Xuefeng Xiao, Rui Wang, Min Zheng, and Xin Pan.
\newblock Next-vit: Next generation vision transformer for efficient deployment in realistic industrial scenarios.
\newblock \emph{arXiv preprint arXiv:2207.05501}, 2022{\natexlab{a}}.

\bibitem[Li et~al.(2022{\natexlab{b}})Li, Hu, Xiong, Zhang, Pan, and Liu]{li2022recurrent}
Mingxing Li, Li~Hu, Zhiwei Xiong, Bang Zhang, Pan Pan, and Dong Liu.
\newblock Recurrent dynamic embedding for video object segmentation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 1332--1341, 2022{\natexlab{b}}.

\bibitem[Li et~al.(2022{\natexlab{c}})Li, Mao, Girshick, and He]{li2022exploring}
Yanghao Li, Hanzi Mao, Ross Girshick, and Kaiming He.
\newblock Exploring plain vision transformer backbones for object detection.
\newblock In \emph{European conference on computer vision}, pages 280--296. Springer, 2022{\natexlab{c}}.

\bibitem[Li et~al.(2022{\natexlab{d}})Li, Wu, Fan, Mangalam, Xiong, Malik, and Feichtenhofer]{li2022mvitv2}
Yanghao Li, Chao-Yuan Wu, Haoqi Fan, Karttikeya Mangalam, Bo~Xiong, Jitendra Malik, and Christoph Feichtenhofer.
\newblock Mvitv2: Improved multiscale vision transformers for classification and detection.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 4804--4814, 2022{\natexlab{d}}.

\bibitem[Li et~al.(2022{\natexlab{e}})Li, Yuan, Wen, Hu, Evangelidis, Tulyakov, Wang, and Ren]{li2022efficientformer}
Yanyu Li, Geng Yuan, Yang Wen, Ju~Hu, Georgios Evangelidis, Sergey Tulyakov, Yanzhi Wang, and Jian Ren.
\newblock Efficientformer: Vision transformers at mobilenet speed.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 12934--12949, 2022{\natexlab{e}}.

\bibitem[Liu et~al.(2023{\natexlab{a}})Liu, Zeng, Ren, Li, Zhang, Yang, Jiang, Li, Yang, Su, et~al.]{liu2023grounding}
Shilong Liu, Zhaoyang Zeng, Tianhe Ren, Feng Li, Hao Zhang, Jie Yang, Qing Jiang, Chunyuan Li, Jianwei Yang, Hang Su, et~al.
\newblock Grounding dino: Marrying dino with grounded pre-training for open-set object detection.
\newblock \emph{arXiv preprint arXiv:2303.05499}, 2023{\natexlab{a}}.

\bibitem[Liu et~al.(2023{\natexlab{b}})Liu, Peng, Zheng, Yang, Hu, and Yuan]{liu2023efficientvit}
Xinyu Liu, Houwen Peng, Ningxin Zheng, Yuqing Yang, Han Hu, and Yixuan Yuan.
\newblock Efficientvit: Memory efficient vision transformer with cascaded group attention.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 14420--14430, 2023{\natexlab{b}}.

\bibitem[Liu et~al.(2021)Liu, Lin, Cao, Hu, Wei, Zhang, Lin, and Guo]{liu2021swin}
Ze~Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, and Baining Guo.
\newblock Swin transformer: Hierarchical vision transformer using shifted windows.
\newblock In \emph{Proceedings of the IEEE/CVF international conference on computer vision}, pages 10012--10022, 2021.

\bibitem[Loshchilov and Hutter(2019)]{loshchilov2017decoupled}
Ilya Loshchilov and Frank Hutter.
\newblock Decoupled weight decay regularization.
\newblock 2019.

\bibitem[Ma and Wang(2023)]{ma2023segment}
Jun Ma and Bo~Wang.
\newblock Segment anything in medical images.
\newblock \emph{arXiv preprint arXiv:2304.12306}, 2023.

\bibitem[Mehta and Rastegari(2021)]{mehta2021mobilevit}
Sachin Mehta and Mohammad Rastegari.
\newblock Mobilevit: Light-weight, general-purpose, and mobile-friendly vision transformer.
\newblock In \emph{International Conference on Learning Representations}, 2021.

\bibitem[Oh et~al.(2019)Oh, Lee, Xu, and Kim]{oh2019video}
Seoung~Wug Oh, Joon-Young Lee, Ning Xu, and Seon~Joo Kim.
\newblock Video object segmentation using space-time memory networks.
\newblock In \emph{Proceedings of the IEEE/CVF international conference on computer vision}, pages 9226--9235, 2019.

\bibitem[Papazoglou and Ferrari(2013)]{papazoglou2013fast}
Anestis Papazoglou and Vittorio Ferrari.
\newblock Fast object segmentation in unconstrained video.
\newblock In \emph{Proceedings of the IEEE international conference on computer vision}, pages 1777--1784, 2013.

\bibitem[Perazzi et~al.(2012)Perazzi, Kr{\"a}henb{\"u}hl, Pritch, and Hornung]{perazzi2012saliency}
Federico Perazzi, Philipp Kr{\"a}henb{\"u}hl, Yael Pritch, and Alexander Hornung.
\newblock Saliency filters: Contrast based filtering for salient region detection.
\newblock In \emph{2012 IEEE conference on computer vision and pattern recognition}, pages 733--740. IEEE, 2012.

\bibitem[Perazzi et~al.(2016)Perazzi, Pont-Tuset, McWilliams, Van~Gool, Gross, and Sorkine-Hornung]{perazzi2016benchmark}
Federico Perazzi, Jordi Pont-Tuset, Brian McWilliams, Luc Van~Gool, Markus Gross, and Alexander Sorkine-Hornung.
\newblock A benchmark dataset and evaluation methodology for video object segmentation.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and pattern recognition}, pages 724--732, 2016.

\bibitem[Pont-Tuset et~al.(2017)Pont-Tuset, Perazzi, Caelles, Arbel{\'a}ez, Sorkine-Hornung, and Van~Gool]{pont20172017}
Jordi Pont-Tuset, Federico Perazzi, Sergi Caelles, Pablo Arbel{\'a}ez, Alex Sorkine-Hornung, and Luc Van~Gool.
\newblock The 2017 davis challenge on video object segmentation.
\newblock \emph{arXiv preprint arXiv:1704.00675}, 2017.

\bibitem[Qin et~al.(2024)Qin, Leichner, Delakis, Fornoni, Luo, Yang, Wang, Banbury, Ye, Akin, et~al.]{qin2024mobilenetv4}
Danfeng Qin, Chas Leichner, Manolis Delakis, Marco Fornoni, Shixin Luo, Fan Yang, Weijun Wang, Colby Banbury, Chengxi Ye, Berkin Akin, et~al.
\newblock Mobilenetv4-universal models for the mobile ecosystem.
\newblock \emph{arXiv preprint arXiv:2404.10518}, 2024.

\bibitem[Qiu et~al.(2024)Qiu, Liu, Li, Zhang, and Li]{qiu2024ded}
Junlong Qiu, Wei Liu, Erzhu Li, Lianpeng Zhang, and Xing Li.
\newblock Ded-sam: Adapting segment anything model 2 for dual encoder-decoder change detection.
\newblock \emph{IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing}, 2024.

\bibitem[Raji{\v{c}} et~al.(2023)Raji{\v{c}}, Ke, Tai, Tang, Danelljan, and Yu]{rajivc2023segment}
Frano Raji{\v{c}}, Lei Ke, Yu-Wing Tai, Chi-Keung Tang, Martin Danelljan, and Fisher Yu.
\newblock Segment anything meets point tracking.
\newblock \emph{arXiv preprint arXiv:2307.01197}, 2023.

\bibitem[Ravi et~al.(2024)Ravi, Gabeur, Hu, Hu, Ryali, Ma, Khedr, R{\"a}dle, Rolland, Gustafson, et~al.]{ravi2024sam}
Nikhila Ravi, Valentin Gabeur, Yuan-Ting Hu, Ronghang Hu, Chaitanya Ryali, Tengyu Ma, Haitham Khedr, Roman R{\"a}dle, Chloe Rolland, Laura Gustafson, et~al.
\newblock Sam 2: Segment anything in images and videos.
\newblock \emph{arXiv preprint arXiv:2408.00714}, 2024.

\bibitem[Robinson et~al.(2020)Robinson, Lawin, Danelljan, Khan, and Felsberg]{robinson2020learning}
Andreas Robinson, Felix~Jaremo Lawin, Martin Danelljan, Fahad~Shahbaz Khan, and Michael Felsberg.
\newblock Learning fast and robust target models for video object segmentation.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 7406--7415, 2020.

\bibitem[Ryali et~al.(2023)Ryali, Hu, Bolya, Wei, Fan, Huang, Aggarwal, Chowdhury, Poursaeed, Hoffman, et~al.]{ryali2023hiera}
Chaitanya Ryali, Yuan-Ting Hu, Daniel Bolya, Chen Wei, Haoqi Fan, Po-Yao Huang, Vaibhav Aggarwal, Arkabandhu Chowdhury, Omid Poursaeed, Judy Hoffman, et~al.
\newblock Hiera: A hierarchical vision transformer without the bells-and-whistles.
\newblock In \emph{International Conference on Machine Learning}, pages 29441--29454. PMLR, 2023.

\bibitem[Shen et~al.(2024)Shen, Ding, Shao, and Unberath]{shen2024performance}
Yiqing Shen, Hao Ding, Xinyuan Shao, and Mathias Unberath.
\newblock Performance and non-adversarial robustness of the segment anything model 2 in surgical video segmentation.
\newblock \emph{arXiv preprint arXiv:2408.04098}, 2024.

\bibitem[Shen et~al.(2018)Shen, Zhang, Zhao, Yi, and Li]{shen2018efficient}
Zhuoran Shen, Mingyuan Zhang, Haiyu Zhao, Shuai Yi, and Hongsheng Li.
\newblock Efficient attention: Attention with linear complexities.
\newblock \emph{arXiv preprint arXiv:1812.01243}, 2018.

\bibitem[Sun et~al.(2023)Sun, Ma, Yuan, and Wang]{sun2023explain}
Ao~Sun, Pingchuan Ma, Yuanyuan Yuan, and Shuai Wang.
\newblock Explain any concept: Segment anything meets concept-based explanation.
\newblock \emph{arXiv preprint arXiv:2305.10289}, 2023.

\bibitem[Tang et~al.(2024)Tang, Zhao, Ford, Benhaim, and Zhang]{tang2024segment}
George Tang, William Zhao, Logan Ford, David Benhaim, and Paul Zhang.
\newblock Segment any mesh: Zero-shot mesh part segmentation via lifting segment anything 2 to 3d.
\newblock \emph{arXiv preprint arXiv:2408.13679}, 2024.

\bibitem[Tang et~al.(2023)Tang, Xiao, and Li]{tang2023can}
Lv~Tang, Haoke Xiao, and Bo~Li.
\newblock Can sam segment anything? when sam meets camouflaged object detection.
\newblock \emph{arXiv preprint arXiv:2304.04709}, 2023.

\bibitem[Tariq et~al.(2023)Tariq, Arfeto, Zhang, and Shin]{tariq2023segment}
Shehbaz Tariq, Brian~Estadimas Arfeto, Chaoning Zhang, and Hyundong Shin.
\newblock Segment anything meets semantic communication.
\newblock \emph{arXiv preprint arXiv:2306.02094}, 2023.

\bibitem[Taylor et~al.(2015)Taylor, Karasev, and Soatto]{taylor2015causal}
Brian Taylor, Vasiliy Karasev, and Stefano Soatto.
\newblock Causal video object segmentation from persistence of occlusions.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and pattern recognition}, pages 4268--4276, 2015.

\bibitem[Touvron et~al.(2021)Touvron, Cord, Douze, Massa, Sablayrolles, and J{\'e}gou]{touvron2021training}
Hugo Touvron, Matthieu Cord, Matthijs Douze, Francisco Massa, Alexandre Sablayrolles, and Herv{\'e} J{\'e}gou.
\newblock Training data-efficient image transformers \& distillation through attention.
\newblock In \emph{International conference on machine learning}, pages 10347--10357. PMLR, 2021.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez, Kaiser, and Polosukhin]{attention_is_all_you_need}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan~N. Gomez, \L{}ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock In \emph{Proceedings of the 31st International Conference on Neural Information Processing Systems}, NIPS'17, page 6000–6010, Red Hook, NY, USA, 2017. Curran Associates Inc.
\newblock ISBN 9781510860964.

\bibitem[Wang et~al.(2023)Wang, Chen, Wu, Luo, Tang, Dai, Zhao, Xie, Yuan, and Jiang]{wang2023look}
Junke Wang, Dongdong Chen, Zuxuan Wu, Chong Luo, Chuanxin Tang, Xiyang Dai, Yucheng Zhao, Yujia Xie, Lu~Yuan, and Yu-Gang Jiang.
\newblock Look before you match: Instance understanding matters in video object segmentation.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 2268--2278, 2023.

\bibitem[Wang et~al.(2020)Wang, Li, Khabsa, Fang, and Ma]{wang2020linformer}
Sinong Wang, Belinda Li, Madian Khabsa, Han Fang, and Hao Ma.
\newblock Linformer: Self-attention with linear complexity.
\newblock \emph{arXiv preprint arXiv:2006.04768}, 2020.

\bibitem[Wang et~al.(2015)Wang, Shen, and Porikli]{wang2015saliency}
Wenguan Wang, Jianbing Shen, and Fatih Porikli.
\newblock Saliency-aware geodesic video object segmentation.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and pattern recognition}, pages 3395--3402, 2015.

\bibitem[Wang et~al.(2021)Wang, Xie, Li, Fan, Song, Liang, Lu, Luo, and Shao]{wang2021pyramid}
Wenhai Wang, Enze Xie, Xiang Li, Deng-Ping Fan, Kaitao Song, Ding Liang, Tong Lu, Ping Luo, and Ling Shao.
\newblock Pyramid vision transformer: A versatile backbone for dense prediction without convolutions.
\newblock In \emph{Proceedings of the IEEE/CVF international conference on computer vision}, pages 568--578, 2021.

\bibitem[Wu et~al.(2022)Wu, Zhang, Peng, Liu, Xiao, Fu, and Yuan]{wu2022tinyvit}
Kan Wu, Jinnian Zhang, Houwen Peng, Mengchen Liu, Bin Xiao, Jianlong Fu, and Lu~Yuan.
\newblock Tinyvit: Fast pretraining distillation for small vision transformers.
\newblock In \emph{European Conference on Computer Vision}, pages 68--85. Springer, 2022.

\bibitem[Wu et~al.(2023)Wu, Yang, Wu, and Chan]{wu2023scalable}
Qiangqiang Wu, Tianyu Yang, Wei Wu, and Antoni~B Chan.
\newblock Scalable video object segmentation with simplified framework.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 13879--13889, 2023.

\bibitem[Xiong et~al.(2024{\natexlab{a}})Xiong, Wu, Tan, Li, Tang, Chen, Li, Ma, and Li]{xiong2024sam2}
Xinyu Xiong, Zihuang Wu, Shuangyi Tan, Wenxue Li, Feilong Tang, Ying Chen, Siying Li, Jie Ma, and Guanbin Li.
\newblock Sam2-unet: Segment anything 2 makes strong encoder for natural and medical image segmentation.
\newblock \emph{arXiv preprint arXiv:2408.08870}, 2024{\natexlab{a}}.

\bibitem[Xiong et~al.(2021)Xiong, Zeng, Chakraborty, Tan, Fung, Li, and Singh]{xiong2021nystromformer}
Yunyang Xiong, Zhanpeng Zeng, Rudrasis Chakraborty, Mingxing Tan, Glenn Fung, Yin Li, and Vikas Singh.
\newblock Nystr{\"o}mformer: A nystr{\"o}m-based algorithm for approximating self-attention.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial Intelligence}, volume~35, pages 14138--14148, 2021.

\bibitem[Xiong et~al.(2024{\natexlab{b}})Xiong, Varadarajan, Wu, Xiang, Xiao, Zhu, Dai, Wang, Sun, Iandola, et~al.]{xiong2024efficientsam}
Yunyang Xiong, Bala Varadarajan, Lemeng Wu, Xiaoyu Xiang, Fanyi Xiao, Chenchen Zhu, Xiaoliang Dai, Dilin Wang, Fei Sun, Forrest Iandola, et~al.
\newblock Efficientsam: Leveraged masked image pretraining for efficient segment anything.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 16111--16121, 2024{\natexlab{b}}.

\bibitem[Xu and Corso(2012)]{xu2012evaluation}
Chenliang Xu and Jason~J Corso.
\newblock Evaluation of super-voxel methods for early video processing.
\newblock In \emph{2012 IEEE conference on computer vision and pattern recognition}, pages 1202--1209. IEEE, 2012.

\bibitem[Xu et~al.(2018)Xu, Yang, Fan, Yang, Yue, Liang, Price, Cohen, and Huang]{xu2018youtube}
Ning Xu, Linjie Yang, Yuchen Fan, Jianchao Yang, Dingcheng Yue, Yuchen Liang, Brian Price, Scott Cohen, and Thomas Huang.
\newblock Youtube-vos: Sequence-to-sequence video object segmentation.
\newblock In \emph{Proceedings of the European conference on computer vision (ECCV)}, pages 585--601, 2018.

\bibitem[Yang et~al.(2023)Yang, Gao, Li, Gao, Wang, and Zheng]{yang2023track}
Jinyu Yang, Mingqi Gao, Zhe Li, Shang Gao, Fangjing Wang, and Feng Zheng.
\newblock Track anything: Segment anything meets videos.
\newblock \emph{arXiv preprint arXiv:2304.11968}, 2023.

\bibitem[Yang and Yang(2022)]{yang2022decoupling}
Zongxin Yang and Yi~Yang.
\newblock Decoupling features in hierarchical propagation for video object segmentation.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 36324--36336, 2022.

\bibitem[Yang et~al.(2024)Yang, Miao, Wei, Wang, Wang, and Yang]{yang2024scalable}
Zongxin Yang, Jiaxu Miao, Yunchao Wei, Wenguan Wang, Xiaohan Wang, and Yi~Yang.
\newblock Scalable video object segmentation with identification mechanism.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine Intelligence}, 2024.

\bibitem[You et~al.(2023)You, Xiong, Dai, Wu, Zhang, Fan, Vajda, and Lin]{you2023castling}
Haoran You, Yunyang Xiong, Xiaoliang Dai, Bichen Wu, Peizhao Zhang, Haoqi Fan, Peter Vajda, and Yingyan~Celine Lin.
\newblock Castling-vit: Compressing self-attention via switching towards linear-angular attention at vision transformer inference.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 14431--14442, 2023.

\bibitem[Yu et~al.(2023)Yu, Feng, Feng, Liu, Jin, Zeng, and Chen]{yu2023inpaint}
Tao Yu, Runseng Feng, Ruoyu Feng, Jinming Liu, Xin Jin, Wenjun Zeng, and Zhibo Chen.
\newblock Inpaint anything: Segment anything meets image inpainting.
\newblock \emph{arXiv preprint arXiv:2304.06790}, 2023.

\bibitem[Zaheer et~al.(2020)Zaheer, Guruganesh, Dubey, Ainslie, Alberti, Ontanon, Pham, Ravula, Wang, Yang, et~al.]{zaheer2020bigbird}
Manzil Zaheer, Guru Guruganesh, Avinava Dubey, Joshua Ainslie, Chris Alberti, Santiago Ontanon, Philip Pham, Anirudh Ravula, Qifan Wang, Li~Yang, et~al.
\newblock Big bird: Transformers for longer sequences.
\newblock \emph{arXiv preprint arXiv:2007.14062}, 2020.

\bibitem[Zhai et~al.(2022)Zhai, Kolesnikov, Houlsby, and Beyer]{zhai2022scaling}
Xiaohua Zhai, Alexander Kolesnikov, Neil Houlsby, and Lucas Beyer.
\newblock Scaling vision transformers.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 12104--12113, 2022.

\bibitem[Zhang et~al.(2023{\natexlab{a}})Zhang, Han, Qiao, Kim, Bae, Lee, and Hong]{zhang2023faster}
Chaoning Zhang, Dongshen Han, Yu~Qiao, Jung~Uk Kim, Sung-Ho Bae, Seungkyu Lee, and Choong~Seon Hong.
\newblock Faster segment anything: Towards lightweight sam for mobile applications.
\newblock \emph{arXiv preprint arXiv:2306.14289}, 2023{\natexlab{a}}.

\bibitem[Zhang et~al.(2013)Zhang, Javed, and Shah]{zhang2013video}
Dong Zhang, Omar Javed, and Mubarak Shah.
\newblock Video object segmentation through spatially accurate and temporally dense extraction of primary object regions.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and pattern recognition}, pages 628--635, 2013.

\bibitem[Zhang et~al.(2023{\natexlab{b}})Zhang, Cui, Wu, and Wang]{zhang2023joint}
Jiaming Zhang, Yutao Cui, Gangshan Wu, and Limin Wang.
\newblock Joint modeling of feature, correspondence, and a compressed memory for video object segmentation.
\newblock \emph{arXiv preprint arXiv:2308.13505}, 2023{\natexlab{b}}.

\bibitem[Zhang et~al.(2024{\natexlab{a}})Zhang, Wang, Gu, Li, Wang, Ling, and Tao]{zhang2024sam2}
Mingya Zhang, Liang Wang, Limei Gu, Zhao Li, Yaohui Wang, Tingshen Ling, and Xianping Tao.
\newblock Sam2-path: A better segment anything model for semantic segmentation in digital pathology.
\newblock \emph{arXiv preprint arXiv:2408.03651}, 2024{\natexlab{a}}.

\bibitem[Zhang et~al.(2023{\natexlab{c}})Zhang, Song, and Yao]{zhang2023deshadow}
Xiao~Feng Zhang, Tian~Yi Song, and Jia~Wei Yao.
\newblock Deshadow-anything: When segment anything model meets zero-shot shadow removal.
\newblock \emph{arXiv preprint arXiv:2309.11715}, 2023{\natexlab{c}}.

\bibitem[Zhang et~al.(2024{\natexlab{b}})Zhang, Cheng, Hu, Liu, Liu, Ran, Chen, Liu, and Wang]{zhang2024evf}
Yuxuan Zhang, Tianheng Cheng, Rui Hu, Lei Liu, Heng Liu, Longjin Ran, Xiaoxin Chen, Wenyu Liu, and Xinggang Wang.
\newblock Evf-sam: Early vision-language fusion for text-prompted segment anything model.
\newblock \emph{arXiv preprint arXiv:2406.20076}, 2024{\natexlab{b}}.

\bibitem[Zhao et~al.(2023)Zhao, Ding, An, Du, Yu, Li, Tang, and Wang]{zhao2023fast}
Xu~Zhao, Wenchao Ding, Yongqi An, Yinglong Du, Tao Yu, Min Li, Ming Tang, and Jinqiao Wang.
\newblock Fast segment anything.
\newblock \emph{arXiv preprint arXiv:2306.12156}, 2023.

\bibitem[Zhou et~al.(2024)Zhou, Sun, Li, Benini, and Konukoglu]{zhou2024sam2}
Yuli Zhou, Guolei Sun, Yawei Li, Luca Benini, and Ender Konukoglu.
\newblock When sam2 meets video camouflaged object segmentation: A comprehensive evaluation and adaptation.
\newblock \emph{arXiv preprint arXiv:2409.18653}, 2024.

\end{thebibliography}
