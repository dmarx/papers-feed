\documentclass[nonacm, sigconf]{acmart}
% \documentclass[sigconf,screen,balance]{acmart}
\settopmatter{printacmref=false} % Removes citation information below abstract
\renewcommand\footnotetextcopyrightpermission[1]{} % removes footnote with conference information in first column
\pagestyle{plain} % removes running headers

\usepackage{hyperref}
\usepackage[hyphenbreaks]{breakurl}
\usepackage{balance}
\usepackage{url}
\usepackage{color}
\usepackage{caption}
\usepackage{diagbox}
\usepackage{subfigure}
\usepackage{multirow}
\usepackage{booktabs}
\usepackage{epsfig,endnotes}
\usepackage{enumitem}
\newcommand{\RNum}[1]{\uppercase\expandafter{\romannumeral #1\relax}}

\newcommand{\model}{{\mathcal{F}_{\theta}}}
\newcommand{\orgmodel}{{\mathcal{F}_{o}}}
\DeclareMathOperator{\sign}{sign}


\DeclareMathOperator*{\argmin}{argmin}

\newcommand{\para}[1]{{\vspace{2pt} \noindent \textbf{#1}
    \hspace{6pt}}}

% \newcommand{\subpara}[1]{{\vspace{1.0pt} \noindent \emph{#1}
%     \hspace{6pt}}}

\newcommand{\subpara}[1]{{\vspace{1.0pt} \textbf{#1}
    \hspace{4pt}}}

\newcommand{\fixme}[1]{{\color{red} #1}}
\newcommand{\rewrite}[1]{{\color{black} #1}}
\newcommand{\todo}[1]{{\color{red}TODO:  #1}}
\newcommand{\wip}[1]{{\color{gray} #1}}

\newcommand{\askben}[1]{{\color{red} Q:  #1}}
\definecolor{applegreen}{rgb}{0.55, 0.71, 0.0}

\newcommand{\shawn}[1]{{\color{brown}Shawn: #1}}
\newcommand{\shawnc}[1]{{\color{red}Shawn: #1}}
\newcommand{\stanleyc}[1]{{\color{orange}Stanley: #1}}
\newcommand{\josephine}[1]{{\color{blue}Josephine: #1}}
\newcommand{\rev}[1]{{\color{black} #1}}


\newcommand{\htedit}[1]{{\color{black} #1}}

\newcommand{\bencheck}[1]{{\color{black} #1}}

\newcommand{\ssedit}[1]{{\color{black} #1}}
\newcommand{\outline}[1]{{\color{blue} #1}}
\newcommand{\ol}[1]{{\color{blue} #1}}

\newcommand{\etal}{{\em et al.\ }}
\newcommand{\eg}{{\em e.g.,\ }}
\newcommand{\ie}{{\em i.e.,\ }}

\newcommand{\secspace}{\vspace{-0.05in}}
\newcommand{\secspacesm}{\vspace{0.0in}}

\newcommand{\ad}[1]{{$\mathcal{A}$}}
\newcommand{\service}[1]{{$\mathcal{S}$}}
\newcommand{\mcD}{\mathcal{D}}

\newcommand{\ytface}{{\tt YTFace}}
\newcommand{\cifarS}{{\tt CIFAR10}}
\newcommand{\cifar}{{\tt CIFAR10}}
\newcommand{\skin}{{\tt SkinCancer}}

\newcommand{\cifarL}{{\tt CIFAR100}}

\newcommand{\imagenet}{{\tt ImageNet}}

\newcommand{\system}{{\em Gimbal\/}} 

\newenvironment{packed_itemize}{
\begin{list}{\labelitemi}{\leftmargin=0.5em}
  \setlength{\itemsep}{1pt}
  \setlength{\parskip}{0pt}
  \setlength{\parsep}{0pt}
  \setlength{\headsep}{0pt}
  \setlength{\topskip}{0pt}
  \setlength{\topmargin}{0pt}
  \setlength{\topsep}{0pt}
  \setlength{\partopsep}{0pt}
}{\end{list}}

\newenvironment{packed_enumerate}{
\begin{enumerate}
 \setlength{\itemsep}{1pt}
 \setlength{\parskip}{0pt}
 \setlength{\parsep}{0pt}
 \setlength{\headsep}{0pt}
 \setlength{\topskip}{0pt}
 \setlength{\topmargin}{0pt}
 \setlength{\topsep}{0pt}
 \setlength{\partopsep}{0pt}
}{\end{enumerate}}


\begin{document}

\title{Disrupting Style Mimicry Attacks on Video Imagery}
\author{Josephine Passananti$^\dag$, Stanley Wu$^\dag$, Shawn Shan, Haitao Zheng, Ben Y. Zhao\\
$^\dag$ denotes authors with equal contribution\\
  {\em Department of Computer Science, University of Chicago}\\
  {\em \{josephinep, stanleywu, shawnshan, htzheng, ravenben\}@cs.uchicago.edu}}

\begin{abstract}
  Generative AI models are often used to perform mimicry attacks, where a
  pretrained model is fine-tuned on a small sample of images to learn to
  mimic a specific artist of interest. While researchers have introduced
  multiple anti-mimicry protection tools (Mist, Glaze, Anti-Dreambooth),
  recent evidence points to a growing trend of mimicry models using videos as
  sources of training data. 

  This paper presents our experiences exploring techniques to disrupt style
  mimicry on video imagery. We first validate that mimicry attacks can
  succeed by training on individual frames extracted from videos. We show
  that while anti-mimicry tools can offer protection when applied to individual
  frames, this approach is vulnerable to an adaptive countermeasure that removes protection
  by exploiting randomness in optimization results of consecutive
  (nearly-identical) frames. We develop a new, tool-agnostic
  framework that segments videos into short scenes based on frame-level
  similarity, and use a per-scene optimization baseline to remove inter-frame
  randomization while reducing computational cost. We show via both image
  level metrics and an end-to-end user study that the resulting
  protection restores protection against mimicry (including the
  countermeasure). Finally, we develop another adaptive countermeasure and
  find that it falls short against our framework.
\end{abstract}

\maketitle
\pagestyle{plain}

\input{intro}
\input{back}
\input{threat1}
\input{eval-limitations}

\input{method1}
\input{eval}
\input{countermeasures}
\input{discussion}

\bibliographystyle{ACM-Reference-Format}
\bibliography{vg}
\balance

\appendix
\input{appendix}

\end{document}
