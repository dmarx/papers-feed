\begin{thebibliography}{51}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[ano(Coming soon, 2024)]{anonymousrevisions}
Training revision models with synthetic data.
\newblock Coming soon, 2024.

\bibitem[Andrieu et~al.(2003)Andrieu, De~Freitas, Doucet, and Jordan]{andrieu2003introduction}
C.~Andrieu, N.~De~Freitas, A.~Doucet, and M.~I. Jordan.
\newblock An introduction to mcmc for machine learning.
\newblock 2003.

\bibitem[Anil et~al.(2023)Anil, Dai, Firat, Johnson, Lepikhin, Passos, Shakeri, Taropa, Bailey, Chen, Chu, Clark, Shafey, Huang, Meier-Hellstern, Mishra, Moreira, Omernick, Robinson, Ruder, Tay, Xiao, Xu, Zhang, Abrego, Ahn, Austin, Barham, Botha, Bradbury, Brahma, Brooks, Catasta, Cheng, Cherry, Choquette-Choo, Chowdhery, Crepy, Dave, Dehghani, Dev, Devlin, Díaz, Du, Dyer, Feinberg, Feng, Fienber, Freitag, Garcia, Gehrmann, Gonzalez, Gur-Ari, Hand, Hashemi, Hou, Howland, Hu, Hui, Hurwitz, Isard, Ittycheriah, Jagielski, Jia, Kenealy, Krikun, Kudugunta, Lan, Lee, Lee, Li, Li, Li, Li, Li, Lim, Lin, Liu, Liu, Maggioni, Mahendru, Maynez, Misra, Moussalem, Nado, Nham, Ni, Nystrom, Parrish, Pellat, Polacek, Polozov, Pope, Qiao, Reif, Richter, Riley, Ros, Roy, Saeta, Samuel, Shelby, Slone, Smilkov, So, Sohn, Tokumine, Valter, Vasudevan, Vodrahalli, Wang, Wang, Wang, Wang, Wieting, Wu, Xu, Xu, Xue, Yin, Yu, Zhang, Zheng, Zheng, Zhou, Zhou, Petrov, and Wu]{anil2023palm}
R.~Anil, A.~M. Dai, O.~Firat, M.~Johnson, D.~Lepikhin, A.~Passos, S.~Shakeri, E.~Taropa, P.~Bailey, Z.~Chen, E.~Chu, J.~H. Clark, L.~E. Shafey, Y.~Huang, K.~Meier-Hellstern, G.~Mishra, E.~Moreira, M.~Omernick, K.~Robinson, S.~Ruder, Y.~Tay, K.~Xiao, Y.~Xu, Y.~Zhang, G.~H. Abrego, J.~Ahn, J.~Austin, P.~Barham, J.~Botha, J.~Bradbury, S.~Brahma, K.~Brooks, M.~Catasta, Y.~Cheng, C.~Cherry, C.~A. Choquette-Choo, A.~Chowdhery, C.~Crepy, S.~Dave, M.~Dehghani, S.~Dev, J.~Devlin, M.~Díaz, N.~Du, E.~Dyer, V.~Feinberg, F.~Feng, V.~Fienber, M.~Freitag, X.~Garcia, S.~Gehrmann, L.~Gonzalez, G.~Gur-Ari, S.~Hand, H.~Hashemi, L.~Hou, J.~Howland, A.~Hu, J.~Hui, J.~Hurwitz, M.~Isard, A.~Ittycheriah, M.~Jagielski, W.~Jia, K.~Kenealy, M.~Krikun, S.~Kudugunta, C.~Lan, K.~Lee, B.~Lee, E.~Li, M.~Li, W.~Li, Y.~Li, J.~Li, H.~Lim, H.~Lin, Z.~Liu, F.~Liu, M.~Maggioni, A.~Mahendru, J.~Maynez, V.~Misra, M.~Moussalem, Z.~Nado, J.~Nham, E.~Ni, A.~Nystrom, A.~Parrish, M.~Pellat, M.~Polacek, A.~Polozov, R.~Pope, S.~Qiao, E.~Reif, B.~Richter,
  P.~Riley, A.~C. Ros, A.~Roy, B.~Saeta, R.~Samuel, R.~Shelby, A.~Slone, D.~Smilkov, D.~R. So, D.~Sohn, S.~Tokumine, D.~Valter, V.~Vasudevan, K.~Vodrahalli, X.~Wang, P.~Wang, Z.~Wang, T.~Wang, J.~Wieting, Y.~Wu, K.~Xu, Y.~Xu, L.~Xue, P.~Yin, J.~Yu, Q.~Zhang, S.~Zheng, C.~Zheng, W.~Zhou, D.~Zhou, S.~Petrov, and Y.~Wu.
\newblock Palm 2 technical report, 2023.

\bibitem[Bai et~al.(2022)Bai, Kadavath, Kundu, Askell, Kernion, Jones, Chen, Goldie, Mirhoseini, McKinnon, Chen, Olsson, Olah, Hernandez, Drain, Ganguli, Li, Tran-Johnson, Perez, Kerr, Mueller, Ladish, Landau, Ndousse, Lukosuite, Lovitt, Sellitto, Elhage, Schiefer, Mercado, DasSarma, Lasenby, Larson, Ringer, Johnston, Kravec, Showk, Fort, Lanham, Telleen-Lawton, Conerly, Henighan, Hume, Bowman, Hatfield-Dodds, Mann, Amodei, Joseph, McCandlish, Brown, and Kaplan]{bai2022constitutional}
Y.~Bai, S.~Kadavath, S.~Kundu, A.~Askell, J.~Kernion, A.~Jones, A.~Chen, A.~Goldie, A.~Mirhoseini, C.~McKinnon, C.~Chen, C.~Olsson, C.~Olah, D.~Hernandez, D.~Drain, D.~Ganguli, D.~Li, E.~Tran-Johnson, E.~Perez, J.~Kerr, J.~Mueller, J.~Ladish, J.~Landau, K.~Ndousse, K.~Lukosuite, L.~Lovitt, M.~Sellitto, N.~Elhage, N.~Schiefer, N.~Mercado, N.~DasSarma, R.~Lasenby, R.~Larson, S.~Ringer, S.~Johnston, S.~Kravec, S.~E. Showk, S.~Fort, T.~Lanham, T.~Telleen-Lawton, T.~Conerly, T.~Henighan, T.~Hume, S.~R. Bowman, Z.~Hatfield-Dodds, B.~Mann, D.~Amodei, N.~Joseph, S.~McCandlish, T.~Brown, and J.~Kaplan.
\newblock Constitutional ai: Harmlessness from ai feedback, 2022.

\bibitem[Blakeney et~al.(2024)Blakeney, Paul, Larsen, Owen, and Frankle]{blakeney2024doesdatasparkjoy}
C.~Blakeney, M.~Paul, B.~W. Larsen, S.~Owen, and J.~Frankle.
\newblock Does your data spark joy? performance gains from domain upsampling at the end of training, 2024.
\newblock URL \url{https://arxiv.org/abs/2406.03476}.

\bibitem[Chen et~al.(2024)Chen, Liao, Li, and Fan]{chen2024alphamath}
G.~Chen, M.~Liao, C.~Li, and K.~Fan.
\newblock Alphamath almost zero: process supervision without process, 2024.

\bibitem[Cobbe et~al.(2021)Cobbe, Kosaraju, Bavarian, Chen, Jun, Kaiser, Plappert, Tworek, Hilton, Nakano, Hesse, and Schulman]{cobbe2021training}
K.~Cobbe, V.~Kosaraju, M.~Bavarian, M.~Chen, H.~Jun, L.~Kaiser, M.~Plappert, J.~Tworek, J.~Hilton, R.~Nakano, C.~Hesse, and J.~Schulman.
\newblock Training verifiers to solve math word problems, 2021.

\bibitem[Du et~al.(2023)Du, Li, Torralba, Tenenbaum, and Mordatch]{du2023improving}
Y.~Du, S.~Li, A.~Torralba, J.~B. Tenenbaum, and I.~Mordatch.
\newblock Improving factuality and reasoning in language models through multiagent debate, 2023.

\bibitem[Evans(1984)]{evans1984heuristic}
J.~S. B.~T. Evans.
\newblock Heuristic and analytic processes in reasoning.
\newblock \emph{British Journal of Psychology}, 75(4):\penalty0 451--468, 1984.

\bibitem[Feng et~al.(2024)Feng, Wan, Wen, McAleer, Wen, Zhang, and Wang]{feng2024alphazerolike}
X.~Feng, Z.~Wan, M.~Wen, S.~M. McAleer, Y.~Wen, W.~Zhang, and J.~Wang.
\newblock Alphazero-like tree-search can guide large language model decoding and training, 2024.

\bibitem[Gao et~al.(2023)Gao, Madaan, Zhou, Alon, Liu, Yang, Callan, and Neubig]{gao2023palprogramaidedlanguagemodels}
L.~Gao, A.~Madaan, S.~Zhou, U.~Alon, P.~Liu, Y.~Yang, J.~Callan, and G.~Neubig.
\newblock Pal: Program-aided language models, 2023.
\newblock URL \url{https://arxiv.org/abs/2211.10435}.

\bibitem[Goyal et~al.(2024)Goyal, Ji, Rawat, Menon, Kumar, and Nagarajan]{goyal2024thinkspeaktraininglanguage}
S.~Goyal, Z.~Ji, A.~S. Rawat, A.~K. Menon, S.~Kumar, and V.~Nagarajan.
\newblock Think before you speak: Training language models with pause tokens, 2024.
\newblock URL \url{https://arxiv.org/abs/2310.02226}.

\bibitem[Hendrycks et~al.(2021)Hendrycks, Burns, Kadavath, Arora, Basart, Tang, Song, and Steinhardt]{hendrycks2021measuring}
D.~Hendrycks, C.~Burns, S.~Kadavath, A.~Arora, S.~Basart, E.~Tang, D.~Song, and J.~Steinhardt.
\newblock Measuring mathematical problem solving with the math dataset, 2021.

\bibitem[Hoffmann et~al.(2022)Hoffmann, Borgeaud, Mensch, Buchatskaya, Cai, Rutherford, de~Las~Casas, Hendricks, Welbl, Clark, Hennigan, Noland, Millican, van~den Driessche, Damoc, Guy, Osindero, Simonyan, Elsen, Rae, Vinyals, and Sifre]{hoffmann2022training}
J.~Hoffmann, S.~Borgeaud, A.~Mensch, E.~Buchatskaya, T.~Cai, E.~Rutherford, D.~de~Las~Casas, L.~A. Hendricks, J.~Welbl, A.~Clark, T.~Hennigan, E.~Noland, K.~Millican, G.~van~den Driessche, B.~Damoc, A.~Guy, S.~Osindero, K.~Simonyan, E.~Elsen, J.~W. Rae, O.~Vinyals, and L.~Sifre.
\newblock Training compute-optimal large language models, 2022.

\bibitem[Huang et~al.(2023)Huang, Chen, Mishra, Zheng, Yu, Song, and Zhou]{huang2023large}
J.~Huang, X.~Chen, S.~Mishra, H.~S. Zheng, A.~W. Yu, X.~Song, and D.~Zhou.
\newblock Large language models cannot self-correct reasoning yet, 2023.

\bibitem[Jones(2021)]{jones2021scalingscalinglawsboard}
A.~L. Jones.
\newblock Scaling scaling laws with board games, 2021.
\newblock URL \url{https://arxiv.org/abs/2104.03113}.

\bibitem[Kahneman(2003)]{kahneman2003maps}
D.~Kahneman.
\newblock Maps of bounded rationality: Psychology for behavioral economics.
\newblock \emph{The American Economic Review}, 93(5):\penalty0 1449--1475, 2003.

\bibitem[Kahneman(2013)]{kahneman2013thinking}
D.~Kahneman.
\newblock \emph{Thinking, fast and slow}.
\newblock Farrar, Straus and Giroux, New York, first paperback edition edition, 2013.

\bibitem[Kocsis and Szepesv{'a}ri(2006)]{kocsis2006bandit}
L.~Kocsis and C.~Szepesv{'a}ri.
\newblock Bandit based monte-carlo planning.
\newblock In \emph{European conference on machine learning}, pages 282--293. Springer, 2006.

\bibitem[Lewkowycz et~al.(2022)Lewkowycz, Andreassen, Dohan, Dyer, Michalewski, Ramasesh, Slone, Anil, Schlag, Gutman-Solo, Wu, Neyshabur, Gur-Ari, and Misra]{lewkowycz2022solving}
A.~Lewkowycz, A.~Andreassen, D.~Dohan, E.~Dyer, H.~Michalewski, V.~Ramasesh, A.~Slone, C.~Anil, I.~Schlag, T.~Gutman-Solo, Y.~Wu, B.~Neyshabur, G.~Gur-Ari, and V.~Misra.
\newblock Solving quantitative reasoning problems with language models, 2022.

\bibitem[Li et~al.(2023)Li, Lin, Zhang, Fu, Chen, Lou, and Chen]{li2023making}
Y.~Li, Z.~Lin, S.~Zhang, Q.~Fu, B.~Chen, J.-G. Lou, and W.~Chen.
\newblock Making large language models better reasoners with step-aware verifier, 2023.

\bibitem[Lightman et~al.(2023)Lightman, Kosaraju, Burda, Edwards, Baker, Lee, Leike, Schulman, Sutskever, and Cobbe]{lightman2023lets}
H.~Lightman, V.~Kosaraju, Y.~Burda, H.~Edwards, B.~Baker, T.~Lee, J.~Leike, J.~Schulman, I.~Sutskever, and K.~Cobbe.
\newblock Let's verify step by step, 2023.

\bibitem[Madaan et~al.(2023)Madaan, Tandon, Gupta, Hallinan, Gao, Wiegreffe, Alon, Dziri, Prabhumoye, Yang, Gupta, Majumder, Hermann, Welleck, Yazdanbakhsh, and Clark]{madaan2023selfrefine}
A.~Madaan, N.~Tandon, P.~Gupta, S.~Hallinan, L.~Gao, S.~Wiegreffe, U.~Alon, N.~Dziri, S.~Prabhumoye, Y.~Yang, S.~Gupta, B.~P. Majumder, K.~Hermann, S.~Welleck, A.~Yazdanbakhsh, and P.~Clark.
\newblock Self-refine: Iterative refinement with self-feedback, 2023.

\bibitem[McAleese et~al.(2024)McAleese, Pokorny, Cerón~Uribe, Nitishinskaya, Trębacz, and Leike]{llmcriticscatchbugs}
N.~McAleese, R.~Pokorny, J.~F. Cerón~Uribe, E.~Nitishinskaya, M.~Trębacz, and J.~Leike.
\newblock Llm critics help catch llm bugs.
\newblock \emph{OpenAI}, 2024.

\bibitem[OpenAI(2024)]{openai2024gpt4}
OpenAI.
\newblock Gpt-4 technical report, 2024.

\bibitem[Qin et~al.(2023)Qin, Liang, Ye, Zhu, Yan, Lu, Lin, Cong, Tang, Qian, Zhao, Hong, Tian, Xie, Zhou, Gerstein, Li, Liu, and Sun]{qin2023toolllmfacilitatinglargelanguage}
Y.~Qin, S.~Liang, Y.~Ye, K.~Zhu, L.~Yan, Y.~Lu, Y.~Lin, X.~Cong, X.~Tang, B.~Qian, S.~Zhao, L.~Hong, R.~Tian, R.~Xie, J.~Zhou, M.~Gerstein, D.~Li, Z.~Liu, and M.~Sun.
\newblock Toolllm: Facilitating large language models to master 16000+ real-world apis, 2023.
\newblock URL \url{https://arxiv.org/abs/2307.16789}.

\bibitem[Qu et~al.(2024{\natexlab{a}})Qu, Dai, Wei, Cai, Wang, Yin, Xu, and Wen]{qu2024toollearninglargelanguage}
C.~Qu, S.~Dai, X.~Wei, H.~Cai, S.~Wang, D.~Yin, J.~Xu, and J.-R. Wen.
\newblock Tool learning with large language models: A survey, 2024{\natexlab{a}}.
\newblock URL \url{https://arxiv.org/abs/2405.17935}.

\bibitem[Qu et~al.(2024{\natexlab{b}})Qu, Zhang, Garg, and Kumar]{qu2024recursive}
Y.~Qu, T.~Zhang, N.~Garg, and A.~Kumar.
\newblock Recursive introspection: Teaching foundation models how to self-improve.
\newblock 2024{\natexlab{b}}.

\bibitem[Sardana and Frankle(2023)]{sardana2023chinchillaoptimal}
N.~Sardana and J.~Frankle.
\newblock Beyond chinchilla-optimal: Accounting for inference in language model scaling laws, 2023.

\bibitem[Saunders et~al.(2022)Saunders, Yeh, Wu, Bills, Ouyang, Ward, and Leike]{saunders2022selfcritiquing}
W.~Saunders, C.~Yeh, J.~Wu, S.~Bills, L.~Ouyang, J.~Ward, and J.~Leike.
\newblock Self-critiquing models for assisting human evaluators, 2022.

\bibitem[Setlur et~al.(2024)Setlur, Garg, Geng, Garg, Smith, and Kumar]{setlur2024rl}
A.~Setlur, S.~Garg, X.~Geng, N.~Garg, V.~Smith, and A.~Kumar.
\newblock Rl on incorrect synthetic data scales the efficiency of llm math reasoning by eight-fold.
\newblock \emph{arXiv preprint arXiv:2406.14532}, 2024.

\bibitem[Shao et~al.(2024)Shao, Wang, Zhu, Xu, Song, Bi, Zhang, Zhang, Li, Wu, and Guo]{shao2024deepseekmath}
Z.~Shao, P.~Wang, Q.~Zhu, R.~Xu, J.~Song, X.~Bi, H.~Zhang, M.~Zhang, Y.~K. Li, Y.~Wu, and D.~Guo.
\newblock Deepseekmath: Pushing the limits of mathematical reasoning in open language models, 2024.

\bibitem[Sharma et~al.(2024)Sharma, Keh, Mitchell, Finn, Arora, and Kollar]{sharma2024criticalevaluationaifeedback}
A.~Sharma, S.~Keh, E.~Mitchell, C.~Finn, K.~Arora, and T.~Kollar.
\newblock A critical evaluation of ai feedback for aligning large language models, 2024.
\newblock URL \url{https://arxiv.org/abs/2402.12366}.

\bibitem[Shinn et~al.(2023)Shinn, Cassano, Berman, Gopinath, Narasimhan, and Yao]{shinn2023reflexion}
N.~Shinn, F.~Cassano, E.~Berman, A.~Gopinath, K.~Narasimhan, and S.~Yao.
\newblock Reflexion: Language agents with verbal reinforcement learning, 2023.

\bibitem[Singh et~al.(2024)Singh, Co-Reyes, Agarwal, Anand, Patil, Garcia, Liu, Harrison, Lee, Xu, Parisi, Kumar, Alemi, Rizkowsky, Nova, Adlam, Bohnet, Elsayed, Sedghi, Mordatch, Simpson, Gur, Snoek, Pennington, Hron, Kenealy, Swersky, Mahajan, Culp, Xiao, Bileschi, Constant, Novak, Liu, Warkentin, Qian, Bansal, Dyer, Neyshabur, Sohl-Dickstein, and Fiedel]{singh2024human}
A.~Singh, J.~D. Co-Reyes, R.~Agarwal, A.~Anand, P.~Patil, X.~Garcia, P.~J. Liu, J.~Harrison, J.~Lee, K.~Xu, A.~Parisi, A.~Kumar, A.~Alemi, A.~Rizkowsky, A.~Nova, B.~Adlam, B.~Bohnet, G.~Elsayed, H.~Sedghi, I.~Mordatch, I.~Simpson, I.~Gur, J.~Snoek, J.~Pennington, J.~Hron, K.~Kenealy, K.~Swersky, K.~Mahajan, L.~Culp, L.~Xiao, M.~L. Bileschi, N.~Constant, R.~Novak, R.~Liu, T.~Warkentin, Y.~Qian, Y.~Bansal, E.~Dyer, B.~Neyshabur, J.~Sohl-Dickstein, and N.~Fiedel.
\newblock Beyond human data: Scaling self-training for problem-solving with language models, 2024.

\bibitem[Snell et~al.(2024)Snell, Wallace, Klein, and Levine]{predictemergence}
C.~Snell, E.~Wallace, D.~Klein, and S.~Levine.
\newblock Predicting emergent capabilities by finetuning.
\newblock \emph{Conference on Language Modeling 2024}, 2024.

\bibitem[Stechly et~al.(2023)Stechly, Marquez, and Kambhampati]{stechly2023gpt4}
K.~Stechly, M.~Marquez, and S.~Kambhampati.
\newblock Gpt-4 doesn't know it's wrong: An analysis of iterative prompting for reasoning problems, 2023.

\bibitem[Sutton and Barto(2018)]{suttonrlbook}
R.~S. Sutton and A.~G. Barto.
\newblock \emph{Reinforcement learning: An introduction}.
\newblock Second edition, 2018.

\bibitem[Team(2024)]{geminiteam2024gemini}
G.~Team.
\newblock Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context, 2024.

\bibitem[Tian et~al.(2024)Tian, Peng, Song, Jin, Yu, Mi, and Yu]{tian2024selfimprovement}
Y.~Tian, B.~Peng, L.~Song, L.~Jin, D.~Yu, H.~Mi, and D.~Yu.
\newblock Toward self-improvement of llms via imagination, searching, and criticizing, 2024.

\bibitem[Touvron et~al.(2023)Touvron, Martin, Stone, Albert, Almahairi, Babaei, Bashlykov, Batra, Bhargava, Bhosale, Bikel, Blecher, Ferrer, Chen, Cucurull, Esiobu, Fernandes, Fu, Fu, Fuller, Gao, Goswami, Goyal, Hartshorn, Hosseini, Hou, Inan, Kardas, Kerkez, Khabsa, Kloumann, Korenev, Koura, Lachaux, Lavril, Lee, Liskovich, Lu, Mao, Martinet, Mihaylov, Mishra, Molybog, Nie, Poulton, Reizenstein, Rungta, Saladi, Schelten, Silva, Smith, Subramanian, Tan, Tang, Taylor, Williams, Kuan, Xu, Yan, Zarov, Zhang, Fan, Kambadur, Narang, Rodriguez, Stojnic, Edunov, and Scialom]{touvron2023llama2openfoundation}
H.~Touvron, L.~Martin, K.~Stone, P.~Albert, A.~Almahairi, Y.~Babaei, N.~Bashlykov, S.~Batra, P.~Bhargava, S.~Bhosale, D.~Bikel, L.~Blecher, C.~C. Ferrer, M.~Chen, G.~Cucurull, D.~Esiobu, J.~Fernandes, J.~Fu, W.~Fu, B.~Fuller, C.~Gao, V.~Goswami, N.~Goyal, A.~Hartshorn, S.~Hosseini, R.~Hou, H.~Inan, M.~Kardas, V.~Kerkez, M.~Khabsa, I.~Kloumann, A.~Korenev, P.~S. Koura, M.-A. Lachaux, T.~Lavril, J.~Lee, D.~Liskovich, Y.~Lu, Y.~Mao, X.~Martinet, T.~Mihaylov, P.~Mishra, I.~Molybog, Y.~Nie, A.~Poulton, J.~Reizenstein, R.~Rungta, K.~Saladi, A.~Schelten, R.~Silva, E.~M. Smith, R.~Subramanian, X.~E. Tan, B.~Tang, R.~Taylor, A.~Williams, J.~X. Kuan, P.~Xu, Z.~Yan, I.~Zarov, Y.~Zhang, A.~Fan, M.~Kambadur, S.~Narang, A.~Rodriguez, R.~Stojnic, S.~Edunov, and T.~Scialom.
\newblock Llama 2: Open foundation and fine-tuned chat models, 2023.
\newblock URL \url{https://arxiv.org/abs/2307.09288}.

\bibitem[Uesato et~al.(2022)Uesato, Kushman, Kumar, Song, Siegel, Wang, Creswell, Irving, and Higgins]{uesato2022solving}
J.~Uesato, N.~Kushman, R.~Kumar, F.~Song, N.~Siegel, L.~Wang, A.~Creswell, G.~Irving, and I.~Higgins.
\newblock Solving math word problems with process- and outcome-based feedback, 2022.

\bibitem[Valmeekam et~al.(2023)Valmeekam, Marquez, and Kambhampati]{valmeekam2023large}
K.~Valmeekam, M.~Marquez, and S.~Kambhampati.
\newblock Can large language models really improve by self-critiquing their own plans?, 2023.

\bibitem[Villalobos and Atkinson(2023)]{epoch2023tradingoffcomputeintrainingandinference}
P.~Villalobos and D.~Atkinson.
\newblock Trading off compute in training and inference, 2023.
\newblock URL \url{https://epochai.org/blog/trading-off-compute-in-training-and-inference}.
\newblock Accessed: 2024-07-03.

\bibitem[Wang et~al.(2023)Wang, Li, Shao, Xu, Dai, Li, Chen, Wu, and Sui]{wang2023mathshepherd}
P.~Wang, L.~Li, Z.~Shao, R.~X. Xu, D.~Dai, Y.~Li, D.~Chen, Y.~Wu, and Z.~Sui.
\newblock Math-shepherd: Verify and reinforce llms step-by-step without human annotations, 2023.

\bibitem[Wang et~al.(2024)Wang, Zelikman, Poesia, Pu, Haber, and Goodman]{wang2024hypothesissearchinductivereasoning}
R.~Wang, E.~Zelikman, G.~Poesia, Y.~Pu, N.~Haber, and N.~D. Goodman.
\newblock Hypothesis search: Inductive reasoning with language models, 2024.
\newblock URL \url{https://arxiv.org/abs/2309.05660}.

\bibitem[Wei et~al.(2023)Wei, Wang, Schuurmans, Bosma, Ichter, Xia, Chi, Le, and Zhou]{wei2023chainofthought}
J.~Wei, X.~Wang, D.~Schuurmans, M.~Bosma, B.~Ichter, F.~Xia, E.~Chi, Q.~Le, and D.~Zhou.
\newblock Chain-of-thought prompting elicits reasoning in large language models, 2023.

\bibitem[Yao et~al.(2023)Yao, Yu, Zhao, Shafran, Griffiths, Cao, and Narasimhan]{yao2023tree}
S.~Yao, D.~Yu, J.~Zhao, I.~Shafran, T.~L. Griffiths, Y.~Cao, and K.~Narasimhan.
\newblock Tree of thoughts: Deliberate problem solving with large language models, 2023.

\bibitem[Yuan et~al.(2023)Yuan, Yuan, Li, Dong, Lu, Tan, Zhou, and Zhou]{yuan2023scaling}
Z.~Yuan, H.~Yuan, C.~Li, G.~Dong, K.~Lu, C.~Tan, C.~Zhou, and J.~Zhou.
\newblock Scaling relationship on learning mathematical reasoning with large language models, 2023.

\bibitem[Zelikman et~al.(2022)Zelikman, Wu, Mu, and Goodman]{zelikman2022star}
E.~Zelikman, Y.~Wu, J.~Mu, and N.~D. Goodman.
\newblock Star: Bootstrapping reasoning with reasoning, 2022.

\bibitem[Zelikman et~al.(2024)Zelikman, Harik, Shao, Jayasiri, Haber, and Goodman]{zelikman2024quietstarlanguagemodelsteach}
E.~Zelikman, G.~Harik, Y.~Shao, V.~Jayasiri, N.~Haber, and N.~D. Goodman.
\newblock Quiet-star: Language models can teach themselves to think before speaking, 2024.
\newblock URL \url{https://arxiv.org/abs/2403.09629}.

\end{thebibliography}
