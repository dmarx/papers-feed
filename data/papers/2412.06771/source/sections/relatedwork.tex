\section{Related work}
\label{sec:related}

\nitkan{Maybe adding paragraph headers here could help with the readability. }
From the very outset of \textbf{artificial intelligence}, a core challenge has been to develop intelligent agents capable of representing knowledge and taking actions to acquire knowledge necessary for achieving their goals~\citep{McCHay69, minsky1974framework, moore1985formal, nilsson2009quest, russell2016artificial}. Our work is an attempt to address this challenge for intelligent T2I agents.%

In \textbf{machine learning and statistics}, efficient data acquisition has been extensively studied for many problems, including active learning~\citep{cohn1996active, settles.tr09, houlsby2011bayesian, gal2017deep, ren2021survey, wang2018active}, Bayesian optimization~\citep{garnett2023bayesian, kushner1964, mockus1974,auer2002b, srinivas2009gaussian, hennig2012, wang2017maxvalue,  wang2024pre}, reinforcement learning~\citep{kaelbling1996reinforcement, ghavamzadeh2015bayesian, sutton2018reinforcement} and experimental design~\citep{ chaloner1995bayesian, kirk2009experimental}. %
We reckon that T2I agents should also be capable of actively seeking important information from human users to quickly reduce uncertainty~\citep{wang2024gaussian} and generate satisfying images. In \S\ref{ssec:implementation}, we detail the implementation of action selection strategies for our T2I agents.



In \textbf{human-computer interaction}, researchers have been extensively studying how to best enable Human-AI interaction especially from user experience perspectives~\citep{norman1994might, hook2000steps, amershi2019guidelines, cai2019human, viegas2023system, chen2024designing, yang2020re, kim2023help}. Interface design for AI is becoming increasingly challenging due to the lack of transparency~\citep{viegas2023system, chen2024designing}, uncertainty about AI capability and complex outputs~\citep{yang2020re}. We aim to build user-friendly agents, and an indispensable component is their interface to enable them to effectively act and observe, as detailed in \S\ref{app:interface}.

\textbf{Interpretebaility.} Surfacing an agent's belief overlaps with interpretability as both aim to understand model or agent's internal. Some methods leverage LLM's natural language interface to surface their reasoning (e.g., chain of thought \citep{wei2023chainofthoughtpromptingelicitsreasoning}), sometime interactively \citep{wang2024llmcheckupconversationalexaminationlarge}. While these approaches make accessible explanations, whether the explanations represent truth has been questioned \citep{lanham2023measuringfaithfulnesschainofthoughtreasoning, wei2023largerlanguagemodelsincontext, chen2023modelsexplainthemselvescounterfactual}. Some studies indicate explanations generated by the LLMs may not entail the modelsâ€™ predictions nor be factually grounded in the input, even on simple tasks with extractive explanations \citep{ye2022unreliabilityexplanationsfewshotprompting}. In this work, the belief graph does not correspond to the distribution over outputs of the T2I \emph{model} itself conditioned on the underspecified prompt. Instead, the belief graph is designed to align with the distribution over images generated by the \emph{agent}, since the agent can construct detailed prompts according to its belief, and feed them into a high-quality T2I model.

\textbf{Text-to-Image (T2I) generation.} Text-to-image prompts can be ambiguous, subjective~\citep{hutchinson2022underspecificationscenedescriptiontodepictiontasks}, or challenging to represent visually \citep{wiles2024revisiting}. Different users often have distinct requirements for image generation, including personal preferences~\citep{wei2024powerful}, style constraints \citep{wang2023generative}, and individual interpretations \citep{yin2019semantics}. To create images that better align with users' specific needs and interpretations, it is essential to actively communicate and interact with the user to understand the user's intent.

\textbf{Multi-turn T2I.} Current multi-turn T2I systems typically focus on multi-turn user instructions. \cite{huang2024dialoggen, sun2023dsg} propose multi-modal interactive dialogue systems which passively respond to user's natural language instructions. %
Mini DALL$\cdot$E~3 \citep{lai2023minidalle3interactivetextimage} builds an interactive T2I framework that accepts user instructions and responds to user questions. %
\cite{vodrahalli2023artwhisperer} collected and analyzed a dataset of human-AI interactions where users iteratively refine prompts for T2I models to generate images similar to goal images (goal images are only visible to users). This may require users to actively try prompts to understand model behaviors. On the contrary, our work aims to reduce the burden on the user by actively asking questions to understand user intents. 

 A core challenge in multi-turn T2I is consistency~\citep{cheng2024autostudio, cheng2024theatergen, zeqiang2023mini}. \cite{hu2024instruct} introduce Instruct-Imagen, which is a model that follows complex multi-modal instructions. AudioStudio \citep{cheng2024autostudio} is a multi-turn T2I framework aimed at subject consistencies while generating diverse and coherent images. These consistency improvement methods can potentially be integrated into our T2I agents since they are highly modular. However, as an ablation, we only focus on the sequential decision making capability of agents to elicit user intents. 


\label{metrics_discuss}

Evaluating \textbf{image-prompt alignment} is important for T2I models. Relevant metrics can be embedding-based, such as CLIPScore \citep{hessel2022clipscore}, ALIGNScore \citep{zha2023alignscore}, VQA-based such as TIFA \citep{hu2023tifa}, DSG \citep{cho2023davidsonian} and VQAScore \citep{lin2024evaluatingtexttovisualgenerationimagetotext}, and captioning-based like LLMScore \citep{lu2023llmscore}. Approaches such as PickScore \citep{kirstain2023pickapic}, ImageReward \citep{xu2023imagereward} and HPS-v2 \citep{wu2023human} finetune models on human ratings to devise a metric that aligns with human preferences. Recently, diversity of generated images~\citep{naeem2020reliablefidelitydiversitymetrics} is also becoming an important metric of measurement to track progress, especially in the geo-cultural context \citep{kannen2024aestheticsculturalcompetencetexttoimage, hall2024diginevaluatingdisparities}. %

In this work, we develop an automatic approach to evaluate agent-user conversations. We adopt VQAScore~\citep{lin2024evaluatingtexttovisualgenerationimagetotext} to evaluate the alignment between a ground truth prompt and an image generated by an agent after interactions with a simulated user. Other T2I metrics can also be used.



 \textbf{Prompt expansion} is a widely known technique to improve image generation \citep{betker2023improving}. ImageinWords \citep{garg2024imageinwordsunlockinghyperdetailedimage} proposes to obtain high-quality hyper-detailed captions for images, which significantly improve quality of image generation.  \cite{datta-etal-2024-prompt} present a generic prompt expansion framework used along Text-to-Image generation and show an increase in user satisfaction through human study. While our work can be viewed as a method to adaptively expand a T2I prompt based on user feedback\footnote{Samples from the agent belief can be used to construct expanded prompts.}, evaluating our method as a prompt expansion tool is outside of our scope.
 






