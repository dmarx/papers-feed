




\section{Background}
\label{sec:background}
The belief graph in our work is closely related to symbolic world representations.
\vspace{-1em}
\paragraph{World states.}  In classical AI, researchers use symbolic representations to describe the world state~\citep{McCHay69, minsky1974framework, minsky1988society, pasula2007learning, kaelbling2011hierarchical}. For example, in the blocks world~\citep{ginsberg1988reasoning, gupta1992complexity, alkhazraji-et-al-zenodo2020}, a state can be $$is\_block(a) \wedge is\_red(a) \wedge on\_table(a) \wedge is\_block(b) \wedge is\_blue(b) \wedge on(b, a),$$ describing that there are a red block and a blue block, referred to as $a$ and $b$, block $a$ is on a table, and block $b$ is on $a$. Such world states must include \textbf{entities} (e.g., $a$ and $b$), their \textbf{attributes} (e.g., position $on\_table$, characteristics $is\_block$) and \textbf{relations} (e.g., $on(b, a)$) which are critical for enabling a robot to know and act in the world.

In linguistics, \cite{davidson2001theories,davidson2001logical,davidson1967truth} introduce logic-based formalisms of meanings of sentences. The semantics of a sentence is decomposed to a set of atomic propositions, such that no propositions can be added or removed from the set to represent the meaning of the sentence. \citep{cho2023davidsonian} propose Davidsonian Scene Graph (DSG) which represent an image description as a set of atomic propositions (and corresponding questions about each proposition) to evaluate T2I alignment. %



We borrow the same concept as symbolic world representations and scene graphs, except that the agent needs to represent an imaginary world. The image generation problem can be viewed as taking a picture of the imaginary world. The world state should include all entities that are in the picture, together with their attributes and relations.


\vspace{-1em}
\paragraph{Belief states.} Term ``belief state''~\citep{nilsson1986probabilistic, kaelbling1998planning} has been used to describe a distribution over states. %
E.g., for block $a$, we might have $p(on\_table(a)) = 0.5$ and $p(\neg on\_table(a)) = 0.5$, which means the agent is unsure whether the block is on a table. To represent the T2I agent's belief on which image to generate, we need to consider the distribution over all possible ``worlds'' in which the picture can be taken. This distribution can be described by the probabilities that an entity appears in the picture, an attribute gets assigned a certain value, etc.

A core difference between our belief graphs and classic belief states is that belief graphs do not need pre-defined  predicates (e.g., $on(b, a)$), but instead automatically produce useful predicates using LLMs. This makes belief graphs much more generalizable across domains. More details in \S\ref{app:novelty}.
