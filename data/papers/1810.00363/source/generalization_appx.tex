%!TEX root = main.tex

This section presents the proof of Proposition~\ref{prop:robust_margin_bound},
which relies on standard tools from statistical learning theory~\citep[\eg,][]{boucheron2005theory}.

\subsection{Proof of Proposition~\ref{prop:robust_margin_bound}}
\begin{proof}
Assume for now that~$\gamma$ is fixed in advance, and let $\mathcal F_\lambda := \{f \in \Hc : \|f\|_\Hc \leq \lambda\}$.
Note that for all~$f \in \mathcal F_\lambda$ we have
\begin{align*}
\text{err}_\mathcal{D}(f, \epsilon) = P(\exists \|\delta\| \leq \epsilon: y f(x + \delta) < 0) \leq P(yf(x) < \lambda \epsilon) =: L^{\lambda \epsilon}(f),
\end{align*}
since~$\|f\|_\Hc \leq \lambda$ is an upper bound on the Lipschitz constant of~$f$.
Consider the function
\begin{align*}
\phi(x) = \begin{cases}
	0, &\text{ if }x \leq -\gamma - \lambda \epsilon\\
	1, &\text{ if }x \geq - \lambda \epsilon\\
	1 + (x + \lambda \epsilon)/\gamma, &\text{ otherwise.}
\end{cases}
\end{align*}
Defining $A(f) = \E \phi(-y f(x)) \geq L^{\lambda \epsilon}(f)$ and $A_n(f) = \frac{1}{n} \sum_{i=1}^n \phi(- y_i f(x_i)) \leq L_n^{\lambda \epsilon + \gamma}(f)$,
and noting that $\phi$ is upper bounded by 1 and $1/\gamma$ Lipschitz,
we can apply similar arguments to~\citep[Theorem 4.1]{boucheron2005theory} to obtain,
with probability $1 - \delta$,
\begin{equation*}
L^\lambda \epsilon(f) \leq L_n^{\lambda \epsilon + \gamma}(f) + O \left(\frac{1}{\gamma} R_n(\mathcal{F}_\lambda) + \sqrt{\frac{\log 1/\delta}{n}} \right),
\end{equation*}
where~$R_n(\mathcal{F}_\lambda)$ denotes the empirical Rademacher complexity of~$\mathcal{F}_\lambda$ on the dataset $\{(x_i, y_i)\}_{i=1, \ldots, n}$.
Standard upper bounds on empirical Rademacher complexity of kernel classes with bounded RKHS norm yield the following bound
\begin{align*}
\text{err}_\mathcal{D}(f, \epsilon) \leq L_n^{\lambda \epsilon + \gamma}(f) + O \left( \frac{\lambda}{\gamma \sqrt{n}} \sqrt{\frac{1}{n}\sum_{i=1}^n K(x_i, x_i)} + \sqrt{\frac{\log 1/\delta}{n}} \right).
\end{align*}
Note that the bound is still valid with $\gamma' \geq \gamma$ instead of~$\gamma$ in the first term
of the r.h.s., since $L_n^{\gamma}(f)$ is non-decreasing as a function of~$\gamma$.

In order to establish the final bound, we instantiate the previous bound for values $\lambda_i = 2^i$ and $\gamma_j = 2^{-j}$.
Defining $\delta_{i,j} = \frac{\delta}{(1 + 4i^2) \cdot ( 1 + 4j^2)}$, we have that w.p. $1 - \delta_{i,j}$, for all $f \in \mathcal F_{\lambda_i}$ and all $\gamma \geq \gamma_j$,

\begin{align}
\label{eq:bound_single}
\text{err}_\mathcal{D}(f, \epsilon) \leq L_n^{\lambda_i \epsilon + \gamma}(f) + O \left( \frac{\lambda_i}{\gamma_j \sqrt{n}} \sqrt{\frac{1}{n}\sum_{i=1}^n K(x_i, x_i)} + \sqrt{\frac{\log 1/\delta_{i,j}}{n}} \right).
\end{align}
By a union bound, this event holds jointly for all integers $i, j$ w.p. greater than $1 - \delta$,
since $\sum_{i,j} \delta_{i,j} \leq \delta$.
Now consider an arbitrary $f \in \Hc$ and $\gamma > 0$ and let $i = \lceil \log_2 \|f\|_\Hc \rceil$
and $j = \lceil \log_2 (1/\gamma) \rceil$. We have
\begin{align*}
\lambda_i &\leq 2 \|f\|_\Hc \\
\frac{1}{\gamma_j} &\leq \frac{2}{\gamma} \\
\log(1/\delta_{i,j}) &\leq \log(C(\|f\|_\Hc, \gamma) / \delta),
\end{align*}
with $C(\|f\|_\Hc, \gamma) := (1 + 4(\log_2\|f\|_\Hc)^2) \cdot (1 + 4(\log_2 (1/\gamma))^2)$.
Applying this to the bound in~\eqref{eq:bound_single} yields the desired result.

\end{proof}