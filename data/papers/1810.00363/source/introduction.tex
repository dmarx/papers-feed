%!TEX root = main.tex

Learning predictive models for complex tasks often requires large amounts of
annotated data. For instance, convolutional neural networks are
huge-dimensional and typically involve more parameters than training samples,
which raises several challenges: achieving good generalization with small
datasets is indeed difficult, which limits the deployment of such deep models to
many tasks where labeled data is scarce, \eg, in biology~\citep{ching2018opportunities}.
Besides, imperceptible adversarial perturbations can
significantly degrade the prediction quality~\citep{szegedy2013intriguing,biggio2018wild}.
These issues raise the question of regularization as an essential
tool to control the complexity of deep models, as well as their stability
to small variations of their inputs.

In this paper, we present a new perspective on regularization of deep networks,
by viewing convolutional neural networks (CNNs) as elements of a
RKHS following the work
of~\citet{bietti2018group} on deep convolutional kernels. 
For such kernels, the RKHS contains indeed deep convolutional networks similar
to generic ones---up to smooth approximations of rectified linear units.
Such a point of view provides a
natural regularization function, the RKHS norm, which allows us to control the
variations of the predictive model and
to limit its complexity for better generalization.
Besides, the norm also acts as a Lipschitz constant, which provides a
direct control on the stability to adversarial perturbations.

In contrast to traditional kernel methods, the RKHS norm cannot be explicitly
computed in our setup. Yet, this norm admits numerous approximations---lower
bounds and upper bounds---which lead to many strategies for regularization
based on penalties, constraints, or combinations thereof.  Depending on the
chosen approximation, we recover then many existing principles such as spectral norm
regularization~\citep{cisse2017parseval,yoshida2017spectral,miyato2018spectral,sedghi2018singular},
gradient penalties and double backpropagation~\citep{drucker1991double,simon2018adversarial,gulrajani2017improved,roth2017stabilizing,roth2018adversarially,arbel2018gradient},
adversarial training~\citep{madry2018towards},
and we also draw links with tangent
propagation~\citep{simard1998transformation}.
For all these principles, we provide a unified viewpoint and
theoretical insights, and we also introduce new variants, which we show
are effective in practice when learning with few labeled data, or in 
the presence of adversarial perturbations.

Moreover, regularization and robustness are tightly linked in our kernel framework.
Specifically, some lower bounds on the RKHS norm lead to robust optimization objectives with worst-case $\ell_2$ perturbations;
further, we can extend margin-based generalization bounds in the spirit
of~\citet{bartlett2017spectrally,boucheron2005theory} to the setting of \emph{adversarially robust}
generalization~\citep[see][]{schmidt2018adversarially}, where an adversary can perturb test data.
We also discuss connections between recent regularization strategies for training generative adversarial networks
and approaches to generative modeling based on kernel two-sample tests (MMD)~\citep{dziugaite2015training,li2017mmd,binkowski2018demystifying}.

\vspace{-0.2cm}
\paragraph{Summary of the contributions.} ~ \\
~$\bullet$~ We introduce an RKHS perspective for regularizing deep neural networks models which provides
	a unified view on various practical regularization principles,
	together with theoretical insight and guarantees;\\
	~$\bullet$~ By considering lower bounds to the RKHS norm, we obtain new penalties based on adversarial perturbations,
	adversarial deformations, or gradient norms of prediction functions, which we show to be effective in practice; \\
	~$\bullet$~ Our RKHS point of view suggests combined strategies based on both upper and
	lower bounds, which we show often perform empirically best in the context of generalization from small image and biological datasets,
	by providing a tighter control of the RKHS norm.


\vspace{-0.2cm}
\paragraph{Related work.}
The construction of hierarchical kernels and the study of neural networks in the corresponding RKHS was studied
by~\citet{mairal2016end,zhang2016l1,zhang2016convexified,bietti2018group}.
Some of the regularization strategies we obtain from our kernel perspective are variants of previous
approaches to adversarial robustness~\citep{cisse2017parseval,madry2018towards,simon2018adversarial,roth2018adversarially},
to improving generalization~\citep{drucker1991double,miyato2018virtual,sedghi2018singular,simard1998transformation,yoshida2017spectral},
and stable training of generative adversarial networks~\citep{roth2017stabilizing,gulrajani2017improved,arbel2018gradient,miyato2018spectral}.
The link between robust optimization and regularization was studied by~\citet{xu2009robust,xu2009robustness},
focusing mainly on linear models with quadratic or hinge losses.
The notion of adversarial generalization was considered by~\citet{schmidt2018adversarially},
who provide lower bounds on a particular data distribution.
\citet{sinha2018certifying} provide generalization guarantees in the different setting of distributional robustness;
compared to our bound, they consider expected loss instead of classification error, and their bounds do not highlight the dependence on
the model complexity.

