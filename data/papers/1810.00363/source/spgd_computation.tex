%!TEX root = main.tex
%\subsection{Derivation of the proximal operator for solving %\eqref{eq:optimization_problem_penalized}}
%\label{sub:proximal_method}
%The proximal operator of \eqref{eq:optimization_problem_penalized} is, for $x \in \mathrm{R}^d$ :
%\begin{equation*}
%\label{prox_operator}
%\text{prox}_{\gamma\|.\|_{\infty}}(x) = x - \text{proj}_{\|.\|_1 \leq \gamma}(x),
%\end{equation*}
%with $\gamma>0$.
%\begin{proof}
%Using the generalized Moreau's decomposition and knowing that Fenchel's conjugate of the infinity norm %is the indicator function of the $l_1$-ball, we get :
%\begin{align*}
%x &= \text{prox}_{\gamma\|.\|_{\infty}}(x) + %\gamma\text{prox}_{\frac{\|.\|_{\infty}^*}{\gamma}}(\frac{x}{\gamma}) \\
%&= \text{prox}_{\gamma\|.\|_{\infty}}(x) + %\gamma\text{prox}_{\frac{{\mathbf{1}}_{\|.\|_{1}}}{\gamma}}(\frac{x}{\gamma}).
%\end{align*}
%As a consequence,
%\begin{align*}
%\text{prox}_{\gamma\|.\|_{\infty}}(x) &= x - %\gamma\text{prox}_{\frac{{\mathbf{1}}_{\|.\|_{1}}}{\gamma}}(\frac{x}{\gamma}) \\
%&= x - \gamma\text{argmin}_{u \in \mathrm{R}^d}\left(\frac{1}{2}\|u-\frac{x}{\gamma}\|_{2}^2 + %\frac{{\mathbf{1}}_{\|u\|_{1} \leq 1}}{\gamma}\right)\\
%&= x - \gamma\text{proj}_{\|.\|_1\leq1}(\frac{x}{\gamma}),
%\end{align*}
%since the argmin is both the definition of the proximal operator associated to ${\mathbf{1}}_{\|u\|_{1} \leq %1}$  and the projection of $x$ on the $l_1$-ball. We conclude :
%\begin{equation*}
%\text{prox}_{\gamma\|.\|_{\infty}}(x) = x - \text{proj}_{\|.\|_1\leq\gamma}(x).
%\end{equation*}
%\end{proof}

% \subsection{Algorithm for projected gradient with continuation}
\label{sub:projected_sgd}

This section details our optimization approach presented in Section~\ref{sub:upper_bounds}
for learning with spectral norm constraints.
In particular, we rely on a \emph{continuation} approach, decreasing the size of the ball constraints
during training, towards a final value~$\tau$. The method is presented in Algorithm~\ref{alg:psgd}.
We use an exponentially decreasing schedule for $\tau$,
and take $\kappa$ to be 2 epochs for regularization, and 50 epochs for robustness.
In the context of convolutional networks, we simply consider the SVD of a reshaped filter matrix,
but we note that alternative approaches based on the singular values of the full convolutional operation
may also be used~\citep{sedghi2018singular}.
% In our experiments, a fast decrease of $\tau$ yielded the best results. The algorithm could be accelerated in future works: more particularly, there may be a norm cheaper to compute than $\ell_\infty$ while producing similar results.


\begin{algorithm}[th]
	\caption{Stochastic projected gradient with continuation}
	\label{alg:psgd}
	\begin{algorithmic}
	\STATE Input: $\tau$, $\kappa$, step-sizes $\eta_t$
		\FOR{$t = 1, \ldots$}
		\STATE Sample mini-batch and compute gradients of the loss w.r.t. each $W^l$, denoted~$G_t^l$
		\STATE $\tau_{t}=\tau (1 + \exp{\left(\frac{-t}{\kappa}\right)})$
		\FOR{$l = 1, \ldots, L$}
		\STATE 	$\tilde W_t^l := W_t^l - \eta_t G_t^l$
		\STATE Compute SVD: $\tilde W_t^l = U \text{diag}(\sigma) V^T$
		\STATE  $ \widehat{\sigma} := \text{proj}_{\|.\|_{\infty} \leq \tau_t}\left(\sigma\right)$
		\STATE 	$ W_{t+1}^l := U\text{diag}(\widehat{\sigma})V^T$
		\ENDFOR
		\ENDFOR
	\end{algorithmic}
\end{algorithm}

% $\kappa$ may be cross-validated but values between $1$ and $5$ worked well in practice. SGD, stochastic proximal methods and stochastic projected gradient with continuation were compared, and the latter was found to be more suited for getting models whose layers have small spectral norms (see Annex \ref{sec:benchmark}). 