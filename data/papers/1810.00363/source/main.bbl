\begin{thebibliography}{52}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Alipanahi et~al.(2015)Alipanahi, Delong, Weirauch, and
  Frey]{alipanahi2015predicting}
Alipanahi, B., Delong, A., Weirauch, M.~T., and Frey, B.~J.
\newblock Predicting the sequence specificities of dna-and rna-binding proteins
  by deep learning.
\newblock \emph{Nature biotechnology}, 33\penalty0 (8):\penalty0 831, 2015.

\bibitem[Altschul et~al.(1997)Altschul, Madden, Sch{\"a}ffer, Zhang, Zhang,
  Miller, and Lipman]{altschul1997gapped}
Altschul, S.~F., Madden, T.~L., Sch{\"a}ffer, A.~A., Zhang, J., Zhang, Z.,
  Miller, W., and Lipman, D.~J.
\newblock Gapped blast and psi-blast: a new generation of protein database
  search programs.
\newblock \emph{Nucleic acids research}, 25\penalty0 (17):\penalty0 3389--3402,
  1997.

\bibitem[Arbel et~al.(2018)Arbel, Sutherland, Bi{\'n}kowski, and
  Gretton]{arbel2018gradient}
Arbel, M., Sutherland, D.~J., Bi{\'n}kowski, M., and Gretton, A.
\newblock On gradient regularizers for {MMD} {GAN}s.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2018.

\bibitem[Arjovsky et~al.(2017)Arjovsky, Chintala, and
  Bottou]{arjovsky2017wasserstein}
Arjovsky, M., Chintala, S., and Bottou, L.
\newblock Wasserstein {GAN}.
\newblock In \emph{Proceedings of the International Conference on Machine
  Learning (ICML)}, 2017.

\bibitem[Bartlett et~al.(2017)Bartlett, Foster, and
  Telgarsky]{bartlett2017spectrally}
Bartlett, P.~L., Foster, D.~J., and Telgarsky, M.~J.
\newblock Spectrally-normalized margin bounds for neural networks.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)},
  2017.

\bibitem[Belkin et~al.(2018{\natexlab{a}})Belkin, Hsu, and
  Mitra]{belkin2018overfitting}
Belkin, M., Hsu, D., and Mitra, P.
\newblock Overfitting or perfect fitting? risk bounds for classification and
  regression rules that interpolate.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2018{\natexlab{a}}.

\bibitem[Belkin et~al.(2018{\natexlab{b}})Belkin, Ma, and
  Mandal]{belkin2018understand}
Belkin, M., Ma, S., and Mandal, S.
\newblock To understand deep learning we need to understand kernel learning.
\newblock In \emph{Proceedings of the International Conference on Machine
  Learning (ICML)}, 2018{\natexlab{b}}.

\bibitem[Bietti \& Mairal(2019)Bietti and Mairal]{bietti2018group}
Bietti, A. and Mairal, J.
\newblock Group invariance, stability to deformations, and complexity of deep
  convolutional representations.
\newblock \emph{Journal of Machine Learning Research (JMLR)}, 20\penalty0
  (25):\penalty0 1--49, 2019.

\bibitem[Biggio \& Roli(2018)Biggio and Roli]{biggio2018wild}
Biggio, B. and Roli, F.
\newblock Wild patterns: Ten years after the rise of adversarial machine
  learning.
\newblock \emph{Pattern Recognition}, 84:\penalty0 317--331, 2018.

\bibitem[Bi{\'n}kowski et~al.(2018)Bi{\'n}kowski, Sutherland, Arbel, and
  Gretton]{binkowski2018demystifying}
Bi{\'n}kowski, M., Sutherland, D.~J., Arbel, M., and Gretton, A.
\newblock Demystifying {MMD} {GAN}s.
\newblock In \emph{Proceedings of the International Conference on Learning
  Representations (ICLR)}, 2018.

\bibitem[Boucheron et~al.(2005)Boucheron, Bousquet, and
  Lugosi]{boucheron2005theory}
Boucheron, S., Bousquet, O., and Lugosi, G.
\newblock Theory of classification: A survey of some recent advances.
\newblock \emph{ESAIM: probability and statistics}, 9:\penalty0 323--375, 2005.

\bibitem[Ching et~al.(2018)]{ching2018opportunities}
Ching, T. et~al.
\newblock Opportunities and obstacles for deep learning in biology and
  medicine.
\newblock \emph{Journal of The Royal Society Interface}, 15\penalty0 (141),
  2018.

\bibitem[Cisse et~al.(2017)Cisse, Bojanowski, Grave, Dauphin, and
  Usunier]{cisse2017parseval}
Cisse, M., Bojanowski, P., Grave, E., Dauphin, Y., and Usunier, N.
\newblock Parseval networks: Improving robustness to adversarial examples.
\newblock In \emph{Proceedings of the International Conference on Machine
  Learning (ICML)}, 2017.

\bibitem[Drucker \& Le~Cun(1991)Drucker and Le~Cun]{drucker1991double}
Drucker, H. and Le~Cun, Y.
\newblock Double backpropagation increasing generalization performance.
\newblock In \emph{International Joint Conference on Neural Networks (IJCNN)},
  1991.

\bibitem[Dziugaite et~al.(2015)Dziugaite, Roy, and
  Ghahramani]{dziugaite2015training}
Dziugaite, G.~K., Roy, D.~M., and Ghahramani, Z.
\newblock Training generative neural networks via maximum mean discrepancy
  optimization.
\newblock In \emph{Conference on Uncertainty in Artificial Intelligence (UAI)},
  2015.

\bibitem[Engstrom et~al.(2017)Engstrom, Tsipras, Schmidt, and
  Madry]{engstrom2017rotation}
Engstrom, L., Tsipras, D., Schmidt, L., and Madry, A.
\newblock A rotation and a translation suffice: Fooling cnns with simple
  transformations.
\newblock \emph{arXiv preprint arXiv:1712.02779}, 2017.

\bibitem[Gretton et~al.(2012)Gretton, Borgwardt, Rasch, Sch{\"o}lkopf, and
  Smola]{gretton2012kernel}
Gretton, A., Borgwardt, K.~M., Rasch, M.~J., Sch{\"o}lkopf, B., and Smola, A.
\newblock A kernel two-sample test.
\newblock \emph{Journal of Machine Learning Research (JMLR)}, 13\penalty0
  (Mar):\penalty0 723--773, 2012.

\bibitem[Gulrajani et~al.(2017)Gulrajani, Ahmed, Arjovsky, Dumoulin, and
  Courville]{gulrajani2017improved}
Gulrajani, I., Ahmed, F., Arjovsky, M., Dumoulin, V., and Courville, A.~C.
\newblock Improved training of {W}asserstein {GAN}s.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)},
  2017.

\bibitem[H{\aa}ndstad et~al.(2007)H{\aa}ndstad, Hestnes, and
  S{\ae}trom]{haandstad2007motif}
H{\aa}ndstad, T., Hestnes, A.~J., and S{\ae}trom, P.
\newblock Motif kernel generated by genetic programming improves remote
  homology and fold detection.
\newblock \emph{BMC bioinformatics}, 8\penalty0 (1):\penalty0 23, 2007.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deep}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition (CVPR)}, 2016.

\bibitem[Kakade et~al.(2009)Kakade, Sridharan, and
  Tewari]{kakade2009complexity}
Kakade, S.~M., Sridharan, K., and Tewari, A.
\newblock On the complexity of linear prediction: Risk bounds, margin bounds,
  and regularization.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)},
  2009.

\bibitem[Khim \& Loh(2018)Khim and Loh]{khim2018adversarial}
Khim, J. and Loh, P.-L.
\newblock Adversarial risk bounds via function transformation.
\newblock \emph{arXiv preprint arXiv:1810.09519}, 2018.

\bibitem[Koltchinskii \& Panchenko(2002)Koltchinskii and
  Panchenko]{koltchinskii2002empirical}
Koltchinskii, V. and Panchenko, D.
\newblock Empirical margin distributions and bounding the generalization error
  of combined classifiers.
\newblock \emph{The Annals of Statistics}, 30\penalty0 (1):\penalty0 1--50,
  2002.

\bibitem[Li et~al.(2017)Li, Chang, Cheng, Yang, and P{\'o}czos]{li2017mmd}
Li, C.-L., Chang, W.-C., Cheng, Y., Yang, Y., and P{\'o}czos, B.
\newblock Mmd gan: Towards deeper understanding of moment matching network.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)},
  2017.

\bibitem[Loosli et~al.(2007)Loosli, Canu, and Bottou]{loosli-canu-bottou-2006}
Loosli, G., Canu, S., and Bottou, L.
\newblock Training invariant support vector machines using selective sampling.
\newblock In Bottou, L., Chapelle, O., {DeCoste}, D., and Weston, J. (eds.),
  \emph{Large Scale Kernel Machines}, pp.\  301--320. MIT Press, Cambridge,
  MA., 2007.

\bibitem[Lyu et~al.(2015)Lyu, Huang, and Liang]{lyu2015unified}
Lyu, C., Huang, K., and Liang, H.-N.
\newblock A unified gradient regularization family for adversarial examples.
\newblock In \emph{IEEE International Conference on Data Mining (ICDM)}, 2015.

\bibitem[Madry et~al.(2018)Madry, Makelov, Schmidt, Tsipras, and
  Vladu]{madry2018towards}
Madry, A., Makelov, A., Schmidt, L., Tsipras, D., and Vladu, A.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock In \emph{Proceedings of the International Conference on Learning
  Representations (ICLR)}, 2018.

\bibitem[Mairal(2016)]{mairal2016end}
Mairal, J.
\newblock End-to-end kernel learning with supervised convolutional kernel
  networks.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)},
  2016.

\bibitem[Miyato et~al.(2018{\natexlab{a}})Miyato, Kataoka, Koyama, and
  Yoshida]{miyato2018spectral}
Miyato, T., Kataoka, T., Koyama, M., and Yoshida, Y.
\newblock Spectral normalization for generative adversarial networks.
\newblock In \emph{Proceedings of the International Conference on Learning
  Representations (ICLR)}, 2018{\natexlab{a}}.

\bibitem[Miyato et~al.(2018{\natexlab{b}})Miyato, Maeda, Ishii, and
  Koyama]{miyato2018virtual}
Miyato, T., Maeda, S.-i., Ishii, S., and Koyama, M.
\newblock Virtual adversarial training: a regularization method for supervised
  and semi-supervised learning.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine Intelligence
  (PAMI)}, 2018{\natexlab{b}}.

\bibitem[Murzin et~al.(1995)Murzin, Brenner, Hubbard, and
  Chothia]{murzin1995scop}
Murzin, A.~G., Brenner, S.~E., Hubbard, T., and Chothia, C.
\newblock Scop: a structural classification of proteins database for the
  investigation of sequences and structures.
\newblock \emph{Journal of molecular biology}, 247\penalty0 (4):\penalty0
  536--540, 1995.

\bibitem[Neyshabur et~al.(2018)Neyshabur, Bhojanapalli, McAllester, and
  Srebro]{neyshabur2017pac}
Neyshabur, B., Bhojanapalli, S., McAllester, D., and Srebro, N.
\newblock A {PAC}-{B}ayesian approach to spectrally-normalized margin bounds
  for neural networks.
\newblock In \emph{Proceedings of the International Conference on Learning
  Representations (ICLR)}, 2018.

\bibitem[Raghunathan et~al.(2018)Raghunathan, Steinhardt, and
  Liang]{raghunathan2018certified}
Raghunathan, A., Steinhardt, J., and Liang, P.
\newblock Certified defenses against adversarial examples.
\newblock In \emph{Proceedings of the International Conference on Learning
  Representations (ICLR)}, 2018.

\bibitem[Roth et~al.(2017)Roth, Lucchi, Nowozin, and
  Hofmann]{roth2017stabilizing}
Roth, K., Lucchi, A., Nowozin, S., and Hofmann, T.
\newblock Stabilizing training of generative adversarial networks through
  regularization.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)},
  2017.

\bibitem[Roth et~al.(2018)Roth, Lucchi, Nowozin, and
  Hofmann]{roth2018adversarially}
Roth, K., Lucchi, A., Nowozin, S., and Hofmann, T.
\newblock Adversarially robust training through structured gradient
  regularization.
\newblock \emph{arXiv preprint arXiv:1805.08736}, 2018.

\bibitem[Schmidt et~al.(2018)Schmidt, Santurkar, Tsipras, Talwar, and
  M{\k{a}}dry]{schmidt2018adversarially}
Schmidt, L., Santurkar, S., Tsipras, D., Talwar, K., and M{\k{a}}dry, A.
\newblock Adversarially robust generalization requires more data.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2018.

\bibitem[Sch\"olkopf \& Smola(2001)Sch\"olkopf and
  Smola]{scholkopf2001learning}
Sch\"olkopf, B. and Smola, A.~J.
\newblock \emph{Learning with kernels: support vector machines, regularization,
  optimization, and beyond}.
\newblock 2001.

\bibitem[Sedghi et~al.(2019)Sedghi, Gupta, and Long]{sedghi2018singular}
Sedghi, H., Gupta, V., and Long, P.~M.
\newblock The singular values of convolutional layers.
\newblock In \emph{Proceedings of the International Conference on Learning
  Representations (ICLR)}, 2019.

\bibitem[Simard et~al.(1998)Simard, LeCun, Denker, and
  Victorri]{simard1998transformation}
Simard, P.~Y., LeCun, Y.~A., Denker, J.~S., and Victorri, B.
\newblock Transformation invariance in pattern recognition--tangent distance
  and tangent propagation.
\newblock In \emph{Neural networks: tricks of the trade}, pp.\  239--274.
  Springer, 1998.

\bibitem[Simon-Gabriel et~al.(2019)Simon-Gabriel, Ollivier, Bottou,
  Sch{\"o}lkopf, and Lopez-Paz]{simon2018adversarial}
Simon-Gabriel, C.-J., Ollivier, Y., Bottou, L., Sch{\"o}lkopf, B., and
  Lopez-Paz, D.
\newblock First-order adversarial vulnerability of neural networks and input
  dimension.
\newblock In \emph{Proceedings of the International Conference on Machine
  Learning (ICML)}, 2019.

\bibitem[Simonyan \& Zisserman(2014)Simonyan and Zisserman]{simonyan2014very}
Simonyan, K. and Zisserman, A.
\newblock Very deep convolutional networks for large-scale image recognition.
\newblock In \emph{Proceedings of the International Conference on Learning
  Representations (ICLR)}, 2014.

\bibitem[Sinha et~al.(2018)Sinha, Namkoong, and Duchi]{sinha2018certifying}
Sinha, A., Namkoong, H., and Duchi, J.
\newblock Certifying some distributional robustness with principled adversarial
  training.
\newblock In \emph{Proceedings of the International Conference on Learning
  Representations (ICLR)}, 2018.

\bibitem[Sriperumbudur et~al.(2012)Sriperumbudur, Fukumizu, Gretton,
  Sch{\"o}lkopf, Lanckriet, et~al.]{sriperumbudur2012empirical}
Sriperumbudur, B.~K., Fukumizu, K., Gretton, A., Sch{\"o}lkopf, B., Lanckriet,
  G.~R., et~al.
\newblock On the empirical estimation of integral probability metrics.
\newblock \emph{Electronic Journal of Statistics}, 6:\penalty0 1550--1599,
  2012.

\bibitem[Szegedy et~al.(2013)Szegedy, Zaremba, Sutskever, Bruna, Erhan,
  Goodfellow, and Fergus]{szegedy2013intriguing}
Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I.,
  and Fergus, R.
\newblock Intriguing properties of neural networks.
\newblock \emph{arXiv preprint arXiv:1312.6199}, 2013.

\bibitem[Tsipras et~al.(2019)Tsipras, Santurkar, Engstrom, Turner, and
  Madry]{tsipras2018there}
Tsipras, D., Santurkar, S., Engstrom, L., Turner, A., and Madry, A.
\newblock Robustness may be at odds with accuracy.
\newblock In \emph{Proceedings of the International Conference on Learning
  Representations (ICLR)}, 2019.

\bibitem[Wong \& Kolter(2018)Wong and Kolter]{wong2018provable}
Wong, E. and Kolter, J.~Z.
\newblock Provable defenses against adversarial examples via the convex outer
  adversarial polytope.
\newblock In \emph{Proceedings of the International Conference on Machine
  Learning (ICML)}, 2018.

\bibitem[Xu et~al.(2009{\natexlab{a}})Xu, Caramanis, and Mannor]{xu2009robust}
Xu, H., Caramanis, C., and Mannor, S.
\newblock Robust regression and lasso.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)},
  2009{\natexlab{a}}.

\bibitem[Xu et~al.(2009{\natexlab{b}})Xu, Caramanis, and
  Mannor]{xu2009robustness}
Xu, H., Caramanis, C., and Mannor, S.
\newblock Robustness and regularization of support vector machines.
\newblock \emph{Journal of Machine Learning Research (JMLR)}, 10\penalty0
  (Jul):\penalty0 1485--1510, 2009{\natexlab{b}}.

\bibitem[Yin et~al.(2019)Yin, Ramchandran, and Bartlett]{yin2019rademacher}
Yin, D., Ramchandran, K., and Bartlett, P.
\newblock Rademacher complexity for adversarially robust generalization.
\newblock In \emph{Proceedings of the International Conference on Machine
  Learning (ICML)}, 2019.

\bibitem[Yoshida \& Miyato(2017)Yoshida and Miyato]{yoshida2017spectral}
Yoshida, Y. and Miyato, T.
\newblock Spectral norm regularization for improving the generalizability of
  deep learning.
\newblock \emph{arXiv preprint arXiv:1705.10941}, 2017.

\bibitem[Zhang et~al.(2016)Zhang, Lee, and Jordan]{zhang2016l1}
Zhang, Y., Lee, J.~D., and Jordan, M.~I.
\newblock $\ell_1$-regularized neural networks are improperly learnable in
  polynomial time.
\newblock In \emph{Proceedings of the International Conference on Machine
  Learning (ICML)}, 2016.

\bibitem[Zhang et~al.(2017)Zhang, Liang, and Wainwright]{zhang2016convexified}
Zhang, Y., Liang, P., and Wainwright, M.~J.
\newblock Convexified convolutional neural networks.
\newblock In \emph{Proceedings of the International Conference on Machine
  Learning (ICML)}, 2017.

\end{thebibliography}
