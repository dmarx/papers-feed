@misc{strubell2019energy,
      title={{Energy and Policy Considerations for Deep Learning in NLP}}, 
      author={Emma Strubell and Ananya Ganesh and Andrew McCallum},
      year={2019},
      eprint={1906.02243},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{jia2014caffe,
  Author = {Jia, Yangqing and Shelhamer, Evan and Donahue, Jeff and Karayev, Sergey and Long, Jonathan and Girshick, Ross and Guadarrama, Sergio and Darrell, Trevor},
  Journal = {arXiv preprint arXiv:1408.5093},
  Title = {{Caffe: Convolutional Architecture for Fast Feature Embedding}},
  Year = {2014}
}

@inproceedings{polymage-gpu,
author = {Jangda, Abhinav and Guha, Arjun},
title = {{Model-Based Warp Overlapped Tiling for Image Processing Programs on GPUs}},
year = {2020},
booktitle = {Proceedings of the ACM International Conference on Parallel Architectures and Compilation Techniques},
doi = {10.1145/3410463.3414649}
}

@inproceedings{sc20:pencil,
author = {Wang, Hengjie and Chandramowlishwaran, Aparna},
title={{Pencil: A Pipelined Algorithm for Distributed Stencils}},
year = {2020},
booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
doi={10.1109/SC41405.2020.00089}
}

@article{KOZIRIS20031138,
  title={{A pipelined schedule to minimize completion time for loop tiling with computation and communication overlapping}},
journal = {Journal of Parallel and Distributed Computing},
volume = "63",
number = "11",
year = "2003",
author ={N. Koziris and A. Sotiropoulos and G. Goumas},
doi = "https://doi.org/10.1016/S0743-7315(03)00102-3",
}

@inproceedings {osdi20:byteps,
author = {Yimin Jiang and Yibo Zhu and Chang Lan and Bairen Yi and Yong Cui and Chuanxiong Guo},
title = {{A Unified Architecture for Accelerating Distributed {DNN} Training in Heterogeneous GPU/CPU Clusters}},
booktitle = {14th {USENIX} Symposium on Operating Systems Design and Implementation},
year = {2020},
url={https://www.usenix.org/system/files/osdi20-jiang.pdf}
}

@Article{Barigou2017,
author={Barigou, Youcef
and Gabriel, Edgar},
  title={{Maximizing Communication--Computation Overlap Through Automatic Parallelization and Run-time Tuning of Non-blocking Collective Operations}},
journal={International Journal of Parallel Programming},
year={2017},
doi={10.1007/s10766-016-0477-7},
volume={45},
}
@ARTICLE{vpipe,
  author={Zhao, Shixiong and Li, Fanxin and Chen, Xusheng and Guan, Xiuxian and Jiang, Jianyu and Huang, Dong and Qing, Yuhao and Wang, Sen and Wang, Peng and Zhang, Gong and Li, Cheng and Luo, Ping and Cui, Heming},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={{vPipe: A Virtualized Acceleration System for Achieving Efficient and Scalable Pipeline Parallel DNN Training}}, 
  year={2022},
  doi={10.1109/TPDS.2021.3094364}
  }

@INPROCEEDINGS{isca21saeed,
  author={Rashidi, Saeed and Denton, Matthew and Sridharan, Srinivas and Srinivasan, Sudarshan and Suresh, Amoghavarsha and Nie, Jade and Krishna, Tushar},
  booktitle={2021 ACM/IEEE 48th Annual International Symposium on Computer Architecture (ISCA)}, 
  title={{Enabling Compute-Communication Overlap in Distributed Deep Learning Training Platforms}}, 
  year={2021},
  doi={10.1109/ISCA52012.2021.00049}
}

@InProceedings{mariannmt,
  title     = {{Marian: Fast Neural Machine Translation in {C++}}},
  author    = {Junczys-Dowmunt, Marcin and Grundkiewicz, Roman and
               Dwojak, Tomasz and Hoang, Hieu and Heafield, Kenneth and
               Neckermann, Tom and Seide, Frank and Germann, Ulrich and
               Fikri Aji, Alham and Bogoychev, Nikolay and
               Martins, Andr\'{e} F. T. and Birch, Alexandra},
  booktitle = {Proceedings of ACL 2018, System Demonstrations},
  publisher = {Association for Computational Linguistics},
  year      = {2018},
  doi = "10.18653/v1/P18-4020",
}

@inproceedings{10.1145/2503210.2503289,
author = {Bondhugula, Uday},
  title={{Compiling Affine Loop Nests for Distributed-Memory Parallel Architectures}},
year = {2013},
booktitle = {Proceedings of the International Conference on High Performance Computing, Networking, Storage and Analysis},
doi = {10.1145/2503210.2503289},
}



@article{8121995,
  author={I. Z. Reguly and G. R. Mudalige and M. B. Giles},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={{Loop Tiling in Large-Scale Stencil Codes at Run-Time with OPS}}, 
  year={2018},
     doi={10.1109/TPDS.2017.2778161}
}

@article{BESARD201929,
  title={{Rapid software prototyping for heterogeneous and distributed platforms}},
journal = {Advances in Engineering Software},
volume = "132",
year = "2019",
author = {Tim Besard and Valentin Churavy and Alan Edelman and Bjorn De Sutter},
doi = "https://doi.org/10.1016/j.advengsoft.2019.02.002",
}

@inproceedings{10.1145/3079079.3079099,
author = {Totoni, Ehsan and Anderson, Todd A. and Shpeisman, Tatiana},
  title={{HPAT: High Performance Analytics with Scripting Ease-of-Use}},
year = {2017},
booktitle = {Proceedings of the International Conference on Supercomputing},
doi = {10.1145/3079079.3079099},
}
@INPROCEEDINGS{6799131,
  author={P. {Basu} and A. {Venkat} and M. {Hall} and S. {Williams} and B. {Van Straalen} and L. {Oliker}},
  booktitle={20th Annual International Conference on High Performance Computing}, 
  title={{Compiler generation and autotuning of communication-avoiding operators for geometric multigrid}}, 
  year={2013},
  doi={10.1109/HiPC.2013.6799131}
}

@INPROCEEDINGS{7573826,
  author={A. {Denis} and F. {Trahay}},
  booktitle={2016 45th International Conference on Parallel Processing (ICPP)}, 
  title={{MPI Overlap: Benchmark and Analysis}}, 
  year={2016},
  doi={10.1109/ICPP.2016.37}
}


@InProceedings{10.1007/978-3-319-58667-0_18,
author="Subramoni, Hari
and Chakraborty, Sourav
and Panda, Dhabaleswar K.",
  title={{Designing Dynamic and Adaptive MPI Point-to-Point Communication Protocols for Efficient Overlap of Computation and Communication}},
booktitle="High Performance Computing",
year="2017",
}

@inproceedings{10.1145/1810085.1810091,
author = {Marjanovi\'{c}, Vladimir and Labarta, Jes\'{u}s and Ayguad\'{e}, Eduard and Valero, Mateo},
  title={{Overlapping Communication and Computation by Using a Hybrid MPI/SMPSs Approach}},
year = {2010},
booktitle = {Proceedings of the 24th ACM International Conference on Supercomputing},
doi = {10.1145/1810085.1810091},
}

@INPROCEEDINGS{7336201,
  author={H. {Lu} and S. {Seo} and P. {Balaji}},
  booktitle={2015 IEEE 17th International Conference on High Performance Computing and Communications, 2015 IEEE 7th International Symposium on Cyberspace Safety and Security, and 2015 IEEE 12th International Conference on Embedded Software and Systems}, 
  title={{MPI+ULT: Overlapping Communication and Computation with User-Level Threads}},
  year={2015},
  doi={10.1109/HPCC-CSS-ICESS.2015.82},
}

@inproceedings{lamb,
title={Large Batch Optimization for Deep Learning: Training BERT in 76 minutes},
author={Yang You and Jing Li and Sashank Reddi and Jonathan Hseu and Sanjiv Kumar and Srinadh Bhojanapalli and Xiaodan Song and James Demmel and Kurt Keutzer and Cho-Jui Hsieh},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=Syx4wnEtvH}
}



@inproceedings{adam,
  author    = {Diederik P. Kingma and
               Jimmy Ba},
  title     = {{Adam: A Method for Stochastic Optimization}},
  booktitle = {3rd International Conference on Learning Representations, {ICLR} 2015},
  year      = {2015},
  url       = {http://arxiv.org/abs/1412.6980},
}

@inproceedings{zero,
author = {Rajbhandari, Samyam and Rasley, Jeff and Ruwase, Olatunji and He, Yuxiong},
  title={{ZeRO: Memory Optimizations toward Training Trillion Parameter Models}},
year = {2020},
booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
}

@inproceedings{dcuda,
author = {Gysi, Tobias and B\"{a}r, Jeremia and Hoefler, Torsten},
  title={{dCUDA: Hardware Supported Overlap of Computation and Communication}},
year = {2016},
booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
doi={10.1109/SC.2016.51}
}

@INPROCEEDINGS{6687341,
  author={S. {Potluri} and K. {Hamidouche} and A. {Venkatesh} and D. {Bureddy} and D. K. {Panda}},
  booktitle={2013 42nd International Conference on Parallel Processing}, 
  title={{Efficient Inter-node MPI Communication Using GPUDirect RDMA for InfiniBand Clusters with NVIDIA GPUs}}, 
  year={2013},
  doi={10.1109/ICPP.2013.17}
}

@misc{sergeev2018horovod,
  title={{Horovod: fast and easy distributed deep learning in TensorFlow}},
  author={Alexander Sergeev and Mike Del Balso},
  year={2018},
  eprint={1802.05799},
  archivePrefix={arXiv},
  primaryClass={cs.LG}
}

@inproceedings{gpurdma,
author = {Daoud, Feras and Watad, Amir and Silberstein, Mark},
  title={{GPUrdma: GPU-Side Library for High Performance Networking from GPU Kernels}},
year = {2016},
booktitle = {Proceedings of the 6th International Workshop on Runtime and Operating Systems for Supercomputers},
doi = {10.1145/2931088.2931091},
}

@article{gpunet,
author = {Silberstein, Mark and Kim, Sangman and Huh, Seonggu and Zhang, Xinya and Hu, Yige and Wated, Amir and Witchel, Emmett},
  title={{GPUnet: Networking Abstractions for GPU Programs}},
year = {2016},
journal = {ACM Trans. Comput. Syst.},
doi = {10.1145/2963098},
}

@inproceedings{10.1145/3126908.3126950,
author = {LeBeane, Michael and Hamidouche, Khaled and Benton, Brad and Breternitz, Mauricio and Reinhardt, Steven K. and John, Lizy K.},
  title={{GPU Triggered Networking for Intra-Kernel Communications}},
year = {2017},
booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
doi = {10.1145/3126908.3126950},
}

@incollection{gpipe,
  title={{GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism}},
author = {Huang, Yanping and Cheng, Youlong and Bapna, Ankur and Firat, Orhan and Chen, Dehao and Chen, Mia and Lee, HyoukJoong and Ngiam, Jiquan and Le, Quoc V and Wu, Yonghui and Chen, Zhifeng},
booktitle = {Advances in Neural Information Processing Systems 32},
year = {2019},
}

@inproceedings{pipedream,
author = {Narayanan, Deepak and Harlap, Aaron and Phanishayee, Amar and Seshadri, Vivek and Devanur, Nikhil R. and Ganger, Gregory R. and Gibbons, Phillip B. and Zaharia, Matei},
  title={{PipeDream: Generalized Pipeline Parallelism for DNN Training}},
year = {2019},
booktitle = {Proceedings of the 27th ACM Symposium on Operating Systems Principles},
doi = {10.1145/3341301.3359646},
}

@inproceedings{flexflow,
 author = {Jia, Zhihao and Zaharia, Matei and Aiken, Alex},
 booktitle = {Proceedings of Machine Learning and Systems},
 title={{Beyond Data and Model Parallelism for Deep Neural Networks}},
  year = {2019}
}

@inproceedings{data-parallelism,
 author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {{ImageNet Classification with Deep Convolutional Neural Networks}},
 year = {2012}
}

@inproceedings{model-parallelism,
 author = {Dean, Jeffrey and Corrado, Greg and Monga, Rajat and Chen, Kai and Devin, Matthieu and Mao, Mark and Ranzato, Marc aurelio and Senior, Andrew and Tucker, Paul and Yang, Ke and Le, Quoc and Ng, Andrew},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {{Large Scale Distributed Deep Networks}},
 year = {2012}
}


@inproceedings{tensorflow,
  author = {Mart{\'\i}n Abadi and Paul Barham and Jianmin Chen and Zhifeng Chen and Andy Davis and Jeffrey Dean and Matthieu Devin and Sanjay Ghemawat and Geoffrey Irving and Michael Isard and Manjunath Kudlur and Josh Levenberg and Rajat Monga and Sherry Moore and Derek G. Murray and Benoit Steiner and Paul Tucker and Vijay Vasudevan and Pete Warden and Martin Wicke and Yuan Yu and Xiaoqiang Zheng},
  title = {{TensorFlow: A System for Large-Scale Machine Learning}},
  booktitle = {12th {USENIX} Symposium on Operating Systems Design and Implementation},
  year = {2016},
}

@inproceedings{gshard,
  title={{GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding}},
  author={Dmitry Lepikhin and HyoukJoong Lee and Yuanzhong Xu and Dehao Chen and Orhan Firat and Yanping Huang and Maxim Krikun and Noam Shazeer and Zhifeng Chen},
  booktitle={International Conference on Learning Representations},
  year={2021},
}

@misc{megatronlm,
  title={{Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism}}, 
  author={Mohammad Shoeybi and Mostofa Patwary and Raul Puri and Patrick LeGresley and Jared Casper and Bryan Catanzaro},
  year={2020},
  eprint={1909.08053},
  archivePrefix={arXiv},
  primaryClass={cs.CL}
}

@inproceedings{meshtensorflow,
  author = {Shazeer, Noam and Cheng, Youlong and Parmar, Niki and Tran, Dustin and Vaswani, Ashish and Koanantakool, Penporn and Hawkins, Peter and Lee, HyoukJoong and Hong, Mingsheng and Young, Cliff and Sepassi, Ryan and Hechtman, Blake},
  booktitle = {Advances in Neural Information Processing Systems},
  title = {{Mesh-TensorFlow: Deep Learning for Supercomputers}},
  year = {2018}
}

@inproceedings{gpt3,
 title={{Language Models are Few-Shot Learners}}, 
 author={Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
 booktitle = {Advances in Neural Information Processing Systems},
 year = {2020}
}


@article{10.5555/1239928.1239932,
  author = {Kaiser, Timothy H. and Baden, Scott B.},
  title={{Overlapping Communication and Computation with OpenMP and MPI}},
  year = {2001},
  publisher = {IOS Press},
  volume = {9},
  journal = {Sci. Program.}
}

@INPROCEEDINGS{8661197,
  author={R. {Baghdadi} and J. {Ray} and M. B. {Romdhane} and E. D. {Sozzo} and A. {Akkas} and Y. {Zhang} and P. {Suriana} and S. {Kamil} and S. {Amarasinghe}},
  booktitle={2019 IEEE/ACM International Symposium on Code Generation and Optimization (CGO)}, 
  title={{Tiramisu: A Polyhedral Compiler for Expressing Fast and Portable Code}}, 
  year={2019},
  doi={10.1109/CGO.2019.8661197}
}
@inproceedings{bert,
  author    = {Jacob Devlin and
               Ming{-}Wei Chang and
               Kenton Lee and
               Kristina Toutanova},
  title     = {{BERT:} Pre-training of Deep Bidirectional Transformers for Language Understanding},
  booktitle = {Proceedings of the 2019 Conference of the North American Chapter of
               the Association for Computational Linguistics: Human Language Technologies,
               {NAACL-HLT} 2019},
  publisher = {Association for Computational Linguistics},
  year      = {2019},
  doi       = {10.18653/v1/n19-1423},
}

@article{Rasch2020,
author={Rasch, Ari
and Bigge, Julian
and Wrodarczyk, Martin
and Schulze, Richard
and Gorlatch, Sergei},
  title={{dOCAL: high-level distributed programming with OpenCL and CUDA}},
journal={The Journal of Supercomputing},
year={2020},
volume={76},
doi={10.1007/s11227-019-02829-2},
}

@article{Raca2020,
author={Raca, Valon
and Mehofer, Eduard},
  title={{clusterCL: comprehensive support for multi-kernel data-parallel applications in heterogeneous asymmetric clusters}},
journal={The Journal of Supercomputing},
year={2020},
volume={76},
doi={10.1007/s11227-020-03234-w},
}

@inproceedings{distributed-halide,
author = {Denniston, Tyler and Kamil, Shoaib and Amarasinghe, Saman},
  title={{Distributed Halide}},
year = {2016},
booktitle = {Proceedings of the 21st ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming},
doi = {10.1145/2851141.2851157},
}

@article{gpt-2,
  title={{Language Models are Unsupervised Multitask Learners}},
  author={Radford, Alec and Wu, Jeff and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
  year={2019}
}

@misc{mlcommons,
  title={{ML Commons}},
  howpublished = {\url{https://mlcommons.org/en/}},
  year = {Accessed: 2022-01-12}
}

@misc{nccl,
  author={},
  title={{NVIDIA Collective Communication Library}},
  howpublished = {\url{https://github.com/NVIDIA/nccl}},
  year = {Accessed: 2022-01-12}
}

@misc{mxnet,
  title={{Apache mxnet}},
  howpublished = {\url{https://mxnet.apache.org/}},
  year = {Accessed: 2022-01-12}
}

@misc{gpt3cost,
  author={},
  title={{OpenAI's GPT-3 Language Model: A Technical Overview}},
  howpublished = {\url{https://lambdalabs.com/blog/demystifying-gpt-3/}},
  year = {Accessed: 2022-01-12}
}

@misc{apex,
  author={},
  title={{NVIDIA Apex}},
  howpublished = {\url{https://github.com/NVIDIA/apex}},
  year = {Accessed: 2022-01-12}
}

@misc{nvbert,
  author={},
  title={{NVIDIA BERT}},
  howpublished = {\url{https://github.com/NVIDIA/DeepLearningExamples}},
  year = {Accessed: 2022-01-12}
}

@misc{megatronlm-github,
  author={},
  title={{NVIDIA Megatron-LM}},
  howpublished = {\url{https://github.com/NVIDIA/Megatron-LM/}},
  year = {Accessed: 2022-01-12}
}

@misc{mpi,
  author={Message Passing Interface Forum},
  title={{MPI: A Message-Passing Interface Standard Version 3.0}},
  journal={},
  institution={},
  year={2012},
  month={},
  pages={},
  volume={},
  number={},
  booktitle={},
  location={},
  publisher={},
  issn={},
  isbn={},
}

@inproceedings{narayanan2021efficient,
author = {Narayanan, Deepak and Shoeybi, Mohammad and Casper, Jared and LeGresley, Patrick and Patwary, Mostofa and Korthikanti, Vijay and Vainbrand, Dmitri and Kashinkunti, Prethvi and Bernauer, Julie and Catanzaro, Bryan and Phanishayee, Amar and Zaharia, Matei},
title = {{Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM}},
year = {2021},
booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
doi={10.1145/3458817.3476209}
}

@article{pytorch-ddp,
author = {Li, Shen and Zhao, Yanli and Varma, Rohan and Salpekar, Omkar and Noordhuis, Pieter and Li, Teng and Paszke, Adam and Smith, Jeff and Vaughan, Brian and Damania, Pritam and Chintala, Soumith},
title = {{PyTorch Distributed: Experiences on Accelerating Data Parallel Training}},
year = {2020},
journal = {Proc. VLDB Endow.},
doi = {10.14778/3415478.3415530},
}

@incollection{pytorch,
title = {{PyTorch: An Imperative Style, High-Performance Deep Learning Library}},
author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
booktitle = {Advances in Neural Information Processing Systems 32},
year = {2019},
}

@inproceedings{halide,
author = {Ragan-Kelley, Jonathan and Barnes, Connelly and Adams, Andrew and Paris, Sylvain and Durand, Fr\'{e}do and Amarasinghe, Saman},
title = {{Halide: A Language and Compiler for Optimizing Parallelism, Locality, and Recomputation in Image Processing Pipelines}},
year = {2013},
booktitle = {Proceedings of the 34th ACM SIGPLAN Conference on Programming Language Design and Implementation},
doi = {10.1145/2491956.2462176},
}

@inproceedings{lift-cgo18,
author = {Hagedorn, Bastian and Stoltzfus, Larisa and Steuwer, Michel and Gorlatch, Sergei and Dubach, Christophe},
title = {{High Performance Stencil Code Generation with Lift}},
year = {2018},
booktitle = {Proceedings of the 2018 International Symposium on Code Generation and Optimization},
doi = {10.1145/3168824},
}

@INPROCEEDINGS{lift-cgo17,
  author={M. {Steuwer} and T. {Remmelg} and C. {Dubach}},
  booktitle={2017 IEEE/ACM International Symposium on Code Generation and Optimization (CGO)}, 
  title={{LIFT: A functional data-parallel IR for high-performance GPU code generation}}, 
  year={2017},
  doi={10.1109/CGO.2017.7863730}
}

@inproceedings{fireiron,
author = {Hagedorn, Bastian and Elliott, Archibald Samuel and Barthels, Henrik and Bodik, Rastislav and Grover, Vinod},
  title={{Fireiron: A Data-Movement-Aware Scheduling Language for GPUs}},
year = {2020},
booktitle = {Proceedings of the ACM International Conference on Parallel Architectures and Compilation Techniques},
doi = {10.1145/3410463.3414632},
}

@article{mlperf,
  author    = {Peter Mattson and
               Christine Cheng and
               Cody Coleman and
               Greg Diamos and
               Paulius Micikevicius and
               David A. Patterson and
               Hanlin Tang and
               Gu{-}Yeon Wei and
               Peter Bailis and
               Victor Bittorf and
               David Brooks and
               Dehao Chen and
               Debojyoti Dutta and
               Udit Gupta and
               Kim M. Hazelwood and
               Andrew Hock and
               Xinyuan Huang and
               Bill Jia and
               Daniel Kang and
               David Kanter and
               Naveen Kumar and
               Jeffery Liao and
               Guokai Ma and
               Deepak Narayanan and
               Tayo Oguntebi and
               Gennady Pekhimenko and
               Lillian Pentecost and
               Vijay Janapa Reddi and
               Taylor Robie and
               Tom St. John and
               Carole{-}Jean Wu and
               Lingjie Xu and
               Cliff Young and
               Matei Zaharia},
  title     = {{MLPerf Training Benchmark}},
  journal   = {CoRR},
  volume    = {abs/1910.01500},
  year      = {2019},
  url       = {http://arxiv.org/abs/1910.01500},
  archivePrefix = {arXiv},
  eprint    = {1910.01500},
}

@misc{mlperf-results,
  title={{MLPerf Training v0.7 Results}},
  url={https://mlperf.org/training-results-0-7/},
}
@misc{cublas,
  author={},
  title={{cuBLAS}},
  howpublished = {\url{https://docs.nvidia.com/cuda/cublas/index.html}},
  year = {Accessed: 2022-01-12}
}

@misc{coconet-artifact, 
  title={{CoCoNet: Co-Optimize Computation and Communication for Distributed Neural Networks}},
  howpublished = {\url{https://doi.org/10.6084/m9.figshare.18480953}},
  url={https://figshare.com/articles/software/CoCoNet_Co-Optimize_Computation_and_Communication_for_Distributed_Neural_Networks/18480953/3},
  DOI={10.6084/m9.figshare.18480953.v3}, 
  publisher={figshare}, 
  author={Jangda, Abhinav and Huang, Jun and Liu, Guodong and Sabet, Amir Hosseing Nodehi and Maleki, Saeed and Miao, Youshan and Musuvathi, Madanlal and Mytkowicz, Todd and Saarikivi, Olli}, 
  year={2022}, month={Jan}
}

@misc{gpudirect,
  author={},
  title={{GPUDirect RDMA}},
  howpublished = {\url{https://docs.nvidia.com/cuda/gpudirect-rdma/index.html}},
  year = {Accessed: 2022-01-12}
}
@misc{mixed-precision-training,
  author={},
  title={{Training with Mixed Precision}},
  howpublished = {\url{https://docs.nvidia.com/deeplearning/performance/mixed-precision-training/index.html}},
  year = {Accessed: 2022-01-12}
}

@misc{cudnn,
  author={},
  title={{cuDNN}},
  howpublished = {\url{https://docs.nvidia.com/cuda/cudnn/index.html}},
  year = {Accessed: 2022-01-12}
}

@misc{cutlass,
  author={},
  title={{CUTLASS}},
  howpublished = {\url{https://github.com/NVIDIA/cutlass}},
  year = {Accessed: 2022-01-12}
}

@misc{deepspeed490,
  author={},
  title={{Parameter fusion in optimizer partition makes LAMB behaves differently}},
  howpublished = {\url{https://github.com/microsoft/DeepSpeed/issues/490}},
  year = {Accessed: 2022-01-12}
}

@inproceedings{tvm18,
author = {Chen, Tianqi and Moreau, Thierry and Jiang, Ziheng and Zheng, Lianmin and Yan, Eddie and Cowan, Meghan and Shen, Haichen and Wang, Leyuan and Hu, Yuwei and Ceze, Luis and Guestrin, Carlos and Krishnamurthy, Arvind},
title = {{TVM: An Automated End-to-End Optimizing Compiler for Deep Learning}},
year = {2018},
booktitle = {Proceedings of the 13th USENIX Conference on Operating Systems Design and Implementation},
}