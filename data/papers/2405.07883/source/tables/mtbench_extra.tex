\begin{table}[!h]
\setlength{\aboverulesep}{0pt}
\setlength{\belowrulesep}{0pt}
\setlength{\extrarowheight}{.25ex}

\caption{Single model rating results on MT-Bench of transferring TinyLlama-1.1B-Chat-v1.0 to the GPT2 tokenizer, compare Table~\ref{table:mtbench_extra}.}
\centering
\small
\begin{tabular}{l>{\columncolor{gray!20}}r>{\columncolor{gray!20}}rrrrrrrr}
\toprule
& \multicolumn{2}{c}{\cellcolor{gray!20}\textbf{original}} & \multicolumn{2}{c}{\textbf{0-shot}} & \multicolumn{4}{c}{\textbf{n-shot}}\\
\textbf{Embeddings} & orig. & base & FOCUS & ours & \multicolumn{4}{c}{ours@800}\\
\cmidrule{2-3} \cmidrule(lr){4-5} \cmidrule(lr){6-9}
$\lambda$ & - & - & - & - & 0.0 & 0.3 & 0.5 & 0.7\\
\cmidrule{2-3} \cmidrule(lr){4-5} \cmidrule(lr){6-9}
\textbf{Score (1 to 10)} & 5.5 & 5.7 & 2.7 & \textbf{4.0} & 4.29 & 4.63 & \textbf{4.8} & 4.43\\
\bottomrule
\end{tabular}
\label{table:mtbench_extra}
\end{table}