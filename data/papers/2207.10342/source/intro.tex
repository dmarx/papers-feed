\section{Introduction}
\label{introduction}

Language models (LMs) have demonstrated impressive few-shot learning abilities \citep{gpt3,palm}. This has led
to a number of proposals to use LMs as the basis of informal reasoning,
including scratchpads \citep{scratchpads}, chain of thought prompting \citep{chainofthought,selfconsistency}, learned verifiers \citep{verifiers}, selection-inference \citep{selection_inference}, and bootstrapping \citep{zelikman2022star}. They have also been applied in formal mathematics settings to guide theorem provers \citep{gptf}. 
% chained % JSD: replaced ``chained'', since implies chain topology of interactions
These methods involve prompting to encourage step-by-step reasoning, repeated interactions with a single LM, or multiple LMs
linked together, with the models being fine-tuned or prompted in different ways. 

In this position paper, we argue that a useful unifying framework for understanding and extending this disparate body of work is in terms of probabilistic programming languages (PPL) extended to work with strings, instead of more atomic data types like integers and floats.
That is, we use a PPL to define a joint probability model on string-valued random variables, parameterized using LMs, and then condition this model on string-valued observations in order to compute a posterior over string-valued unknowns, which we can then infer.
We call such a probabilistic program a \emph{language model \cascade}.
%This kind of model has the advantage that the values that are being manipulated can represent complex phenomena, yet the process is fairly transparent to humans. 
We show that this framework captures many recent approaches, and also allows us to tackle more complex multi-step reasoning problems.
By implementing many disparate model structures and inference strategies in a single framework, we hope that language model cascades will enable
the development of generic procedures to perform inference, tune parameters, and choose prompts based on end-to-end objectives.\footnote{An implementation is available at \url{model-cascades.github.io}}