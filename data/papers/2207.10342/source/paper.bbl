\begin{thebibliography}{29}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[ELK(2022)]{ELK}
{ARC's} first technical report: Eliciting latent knowledge - {AI} alignment
  forum, 2022.
\newblock URL
  \url{https://www.alignmentforum.org/posts/qHCDysDnvhteW7kRd/arc-s-first-technical-report-eliciting-latent-knowledge}.

\bibitem[{BIG-bench collaboration}(2021)]{bigbench}
{BIG-bench collaboration}.
\newblock Beyond the imitation game: Measuring and extrapolating the
  capabilities of language models.
\newblock \emph{In preparation}, 2021.
\newblock URL \url{https://github.com/google/BIG-bench/}.

\bibitem[Bingham et~al.(2018)Bingham, Chen, Jankowiak, Obermeyer, Pradhan,
  Karaletsos, Singh, Szerlip, Horsfall, and Goodman]{pyro}
Bingham, E., Chen, J.~P., Jankowiak, M., Obermeyer, F., Pradhan, N.,
  Karaletsos, T., Singh, R., Szerlip, P., Horsfall, P., and Goodman, N.~D.
\newblock Pyro: Deep universal probabilistic programming.
\newblock October 2018.

\bibitem[Brown et~al.(2020)Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal,
  Neelakantan, Shyam, Sastry, Askell, and {Others}]{gpt3}
Brown, T.~B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P.,
  Neelakantan, A., Shyam, P., Sastry, G., Askell, A., and {Others}.
\newblock Language models are few-shot learners.
\newblock \emph{arXiv preprint arXiv:2005. 14165}, 2020.

\bibitem[Chen et~al.(2021)Chen, Lu, Rajeswaran, Lee, Grover, Laskin, Abbeel,
  Srinivas, and Mordatch]{decision_transformer}
Chen, L., Lu, K., Rajeswaran, A., Lee, K., Grover, A., Laskin, M., Abbeel, P.,
  Srinivas, A., and Mordatch, I.
\newblock Decision transformer: Reinforcement learning via sequence modeling.
\newblock June 2021.

\bibitem[Chowdhery et~al.(2022)Chowdhery, Narang, Devlin, Bosma, Mishra,
  Roberts, Barham, Chung, Sutton, Gehrmann, Schuh, Shi, Tsvyashchenko, Maynez,
  Rao, Barnes, Tay, Shazeer, Prabhakaran, Reif, Du, Hutchinson, Pope, Bradbury,
  Austin, Isard, Gur-Ari, Yin, Duke, Levskaya, Ghemawat, Dev, Michalewski,
  Garcia, Misra, Robinson, Fedus, Zhou, Ippolito, Luan, Lim, Zoph, Spiridonov,
  Sepassi, Dohan, Agrawal, Omernick, Dai, Pillai, Pellat, Lewkowycz, Moreira,
  Child, Polozov, Lee, Zhou, Wang, Saeta, Diaz, Firat, Catasta, Wei,
  Meier-Hellstern, Eck, Dean, Petrov, and Fiedel]{palm}
Chowdhery, A., Narang, S., Devlin, J., Bosma, M., Mishra, G., Roberts, A.,
  Barham, P., Chung, H.~W., Sutton, C., Gehrmann, S., Schuh, P., Shi, K.,
  Tsvyashchenko, S., Maynez, J., Rao, A., Barnes, P., Tay, Y., Shazeer, N.,
  Prabhakaran, V., Reif, E., Du, N., Hutchinson, B., Pope, R., Bradbury, J.,
  Austin, J., Isard, M., Gur-Ari, G., Yin, P., Duke, T., Levskaya, A.,
  Ghemawat, S., Dev, S., Michalewski, H., Garcia, X., Misra, V., Robinson, K.,
  Fedus, L., Zhou, D., Ippolito, D., Luan, D., Lim, H., Zoph, B., Spiridonov,
  A., Sepassi, R., Dohan, D., Agrawal, S., Omernick, M., Dai, A.~M., Pillai,
  T.~S., Pellat, M., Lewkowycz, A., Moreira, E., Child, R., Polozov, O., Lee,
  K., Zhou, Z., Wang, X., Saeta, B., Diaz, M., Firat, O., Catasta, M., Wei, J.,
  Meier-Hellstern, K., Eck, D., Dean, J., Petrov, S., and Fiedel, N.
\newblock {PaLM}: Scaling language modeling with pathways.
\newblock April 2022.

\bibitem[Cobbe et~al.(2021)Cobbe, Kosaraju, Bavarian, Chen, Jun, Kaiser,
  Plappert, Tworek, Hilton, Nakano, Hesse, and Schulman]{verifiers}
Cobbe, K., Kosaraju, V., Bavarian, M., Chen, M., Jun, H., Kaiser, L., Plappert,
  M., Tworek, J., Hilton, J., Nakano, R., Hesse, C., and Schulman, J.
\newblock Training verifiers to solve math word problems.
\newblock 2021.
\newblock \doi{10.48550/ARXIV.2110.14168}.
\newblock URL \url{https://arxiv.org/abs/2110.14168}.

\bibitem[Cranmer et~al.(2020)Cranmer, Brehmer, and
  Louppe]{simulation_inference}
Cranmer, K., Brehmer, J., and Louppe, G.
\newblock The frontier of simulation-based inference.
\newblock \emph{Proc. Natl. Acad. Sci. U. S. A.}, 117\penalty0 (48):\penalty0
  30055--30062, December 2020.

\bibitem[Creswell et~al.(2022)Creswell, Shanahan, and
  Higgins]{selection_inference}
Creswell, A., Shanahan, M., and Higgins, I.
\newblock {Selection-Inference}: Exploiting large language models for
  interpretable logical reasoning.
\newblock May 2022.

\bibitem[Goodman et~al.(2014)Goodman, Tenenbaum, and
  Gerstenberg]{language_of_thought}
Goodman, N.~D., Tenenbaum, J.~B., and Gerstenberg, T.
\newblock Concepts in a probabilistic language of thought.
\newblock \penalty0 (010), 06/2014 2014.

\bibitem[Kochurov et~al.(2019)Kochurov, Carroll, Wiecki, and Lao]{pymc4}
Kochurov, M., Carroll, C., Wiecki, T., and Lao, J.
\newblock {PyMC4}: Exploiting coroutines for implementing a probabilistic
  programming framework.
\newblock In \emph{{NeurIPS} 2019 Workshop Program Transformations}, 2019.

\bibitem[Lake et~al.(2015)Lake, Salakhutdinov, and Tenenbaum]{Lake2015}
Lake, B.~M., Salakhutdinov, R., and Tenenbaum, J.~B.
\newblock Human-level concept learning through probabilistic program induction.
\newblock \emph{Science}, 350\penalty0 (6266):\penalty0 1332--1338, December
  2015.

\bibitem[Levine(2018)]{rl_inference}
Levine, S.
\newblock Reinforcement learning and control as probabilistic inference:
  Tutorial and review.
\newblock May 2018.

\bibitem[Nakano et~al.(2021)Nakano, Hilton, Balaji, Wu, Ouyang, Kim, Hesse,
  Jain, Kosaraju, Saunders, Jiang, Cobbe, Eloundou, Krueger, Button, Knight,
  Chess, and Schulman]{webgpt}
Nakano, R., Hilton, J., Balaji, S., Wu, J., Ouyang, L., Kim, C., Hesse, C.,
  Jain, S., Kosaraju, V., Saunders, W., Jiang, X., Cobbe, K., Eloundou, T.,
  Krueger, G., Button, K., Knight, M., Chess, B., and Schulman, J.
\newblock {WebGPT}: Browser-assisted question-answering with human feedback.
\newblock December 2021.

\bibitem[Nye et~al.(2021)Nye, Andreassen, Gur-Ari, Michalewski, Austin, Bieber,
  Dohan, Lewkowycz, Bosma, Luan, Sutton, and Odena]{scratchpads}
Nye, M., Andreassen, A.~J., Gur-Ari, G., Michalewski, H., Austin, J., Bieber,
  D., Dohan, D., Lewkowycz, A., Bosma, M., Luan, D., Sutton, C., and Odena, A.
\newblock Show your work: Scratchpads for intermediate computation with
  language models.
\newblock November 2021.

\bibitem[Ortega et~al.(2021)Ortega, Kunesch, Del{\'e}tang, Genewein, Grau-Moya,
  Veness, Buchli, Degrave, Piot, Perolat, et~al.]{ortega2021shaking}
Ortega, P.~A., Kunesch, M., Del{\'e}tang, G., Genewein, T., Grau-Moya, J.,
  Veness, J., Buchli, J., Degrave, J., Piot, B., Perolat, J., et~al.
\newblock Shaking the foundations: delusions in sequence models for interaction
  and control.
\newblock \emph{arXiv preprint arXiv:2110.10819}, 2021.

\bibitem[Phan et~al.(2019)Phan, Pradhan, and Jankowiak]{numpyro}
Phan, D., Pradhan, N., and Jankowiak, M.
\newblock Composable effects for flexible and accelerated probabilistic
  programming in {NumPyro}.
\newblock December 2019.

\bibitem[Polu \& Sutskever(2020)Polu and Sutskever]{gptf}
Polu, S. and Sutskever, I.
\newblock Generative language modeling for automated theorem proving.
\newblock September 2020.

\bibitem[Saunders et~al.(2022)Saunders, Yeh, Wu, Bills, Ouyang, Ward, and
  Leike]{openai_critique}
Saunders, W., Yeh, C., Wu, J., Bills, S., Ouyang, L., Ward, J., and Leike, J.
\newblock Self-critiquing models for assisting human evaluators, 2022.
\newblock URL \url{https://arxiv.org/abs/2206.05802}.

\bibitem[Scheurer et~al.(2022)Scheurer, Campos, Chan, Chen, Cho, and
  Perez]{language_feedback}
Scheurer, J., Campos, J.~A., Chan, J.~S., Chen, A., Cho, K., and Perez, E.
\newblock Training language models with language feedback.
\newblock April 2022.

\bibitem[Thoppilan et~al.(2022)Thoppilan, De~Freitas, Hall, Shazeer,
  Kulshreshtha, Cheng, Jin, Bos, Baker, Du, Li, Lee, Zheng, Ghafouri, Menegali,
  Huang, Krikun, Lepikhin, Qin, Chen, Xu, Chen, Roberts, Bosma, Zhao, Zhou,
  Chang, Krivokon, Rusch, Pickett, Srinivasan, Man, Meier-Hellstern, Morris,
  Doshi, Santos, Duke, Soraker, Zevenbergen, Prabhakaran, Diaz, Hutchinson,
  Olson, Molina, Hoffman-John, Lee, Aroyo, Rajakumar, Butryna, Lamm, Kuzmina,
  Fenton, Cohen, Bernstein, Kurzweil, Aguera-Arcas, Cui, Croak, Chi, and
  Le]{lamda}
Thoppilan, R., De~Freitas, D., Hall, J., Shazeer, N., Kulshreshtha, A., Cheng,
  H.-T., Jin, A., Bos, T., Baker, L., Du, Y., Li, Y., Lee, H., Zheng, H.~S.,
  Ghafouri, A., Menegali, M., Huang, Y., Krikun, M., Lepikhin, D., Qin, J.,
  Chen, D., Xu, Y., Chen, Z., Roberts, A., Bosma, M., Zhao, V., Zhou, Y.,
  Chang, C.-C., Krivokon, I., Rusch, W., Pickett, M., Srinivasan, P., Man, L.,
  Meier-Hellstern, K., Morris, M.~R., Doshi, T., Santos, R.~D., Duke, T.,
  Soraker, J., Zevenbergen, B., Prabhakaran, V., Diaz, M., Hutchinson, B.,
  Olson, K., Molina, A., Hoffman-John, E., Lee, J., Aroyo, L., Rajakumar, R.,
  Butryna, A., Lamm, M., Kuzmina, V., Fenton, J., Cohen, A., Bernstein, R.,
  Kurzweil, R., Aguera-Arcas, B., Cui, C., Croak, M., Chi, E., and Le, Q.
\newblock {LaMDA}: Language models for dialog applications.
\newblock January 2022.
\newblock URL \url{https://arxiv.org/abs/2201.08239}.

\bibitem[Tolpin et~al.(2016)Tolpin, van~de Meent, Yang, and Wood]{anglican}
Tolpin, D., van~de Meent, J., Yang, H., and Wood, F.~D.
\newblock Design and implementation of probabilistic programming language
  anglican.
\newblock \emph{CoRR}, abs/1608.05263, 2016.
\newblock URL \url{http://arxiv.org/abs/1608.05263}.

\bibitem[van~de Meent et~al.(2018)van~de Meent, Paige, Yang, and
  Wood]{intro_ppl}
van~de Meent, J.-W., Paige, B., Yang, H., and Wood, F.
\newblock An introduction to probabilistic programming.
\newblock September 2018.

\bibitem[Wang et~al.(2022)Wang, Wei, Schuurmans, Le, Chi, Narang, Chowdhery,
  and Zhou]{selfconsistency}
Wang, X., Wei, J., Schuurmans, D., Le, Q., Chi, E., Narang, S., Chowdhery, A.,
  and Zhou, D.
\newblock {Self-Consistency} improves chain of thought reasoning in language
  models.
\newblock March 2022.

\bibitem[Wei et~al.(2022)Wei, Wang, Schuurmans, Bosma, Chi, Le, and
  Zhou]{chainofthought}
Wei, J., Wang, X., Schuurmans, D., Bosma, M., Chi, E., Le, Q., and Zhou, D.
\newblock Chain of thought prompting elicits reasoning in large language
  models.
\newblock January 2022.

\bibitem[Wu \& Goodman(2022)Wu and Goodman]{foundationposterior}
Wu, M. and Goodman, N.
\newblock Foundation posteriors for approximate probabilistic inference.
\newblock May 2022.

\bibitem[Wu et~al.(2022)Wu, Jiang, Donsbach, Gray, Molina, Terry, and
  Cai]{promptchainer}
Wu, T., Jiang, E., Donsbach, A., Gray, J., Molina, A., Terry, M., and Cai,
  C.~J.
\newblock Promptchainer: Chaining large language model prompts through visual
  programming, 2022.
\newblock URL \url{https://arxiv.org/abs/2203.06566}.

\bibitem[Zelikman et~al.(2022)Zelikman, Wu, and Goodman]{zelikman2022star}
Zelikman, E., Wu, Y., and Goodman, N.~D.
\newblock Star: Bootstrapping reasoning with reasoning.
\newblock \emph{arXiv preprint arXiv:2203.14465}, 2022.

\bibitem[Zeng et~al.(2022)Zeng, Wong, Welker, Choromanski, Tombari, Purohit,
  Ryoo, Sindhwani, Lee, Vanhoucke, and Florence]{socraticmodels}
Zeng, A., Wong, A., Welker, S., Choromanski, K., Tombari, F., Purohit, A.,
  Ryoo, M., Sindhwani, V., Lee, J., Vanhoucke, V., and Florence, P.
\newblock Socratic models: Composing {Zero-Shot} multimodal reasoning with
  language.
\newblock April 2022.

\end{thebibliography}
