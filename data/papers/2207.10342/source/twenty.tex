\subsection{Twenty questions}
\label{sec:twenty}

In this section, we discuss experimental results using \cascades\ to solve the
 ``Twenty Questions'' task from BigBench \citep{bigbench}.
This task  involves a conversation between two agents, Alice and Bob.
Both agents are presented with the rules of the game, and Alice is additionally presented with a concept (e.g. `apple') to describe.
Bob has to guess the concept by asking a series of  questions
$B_t$ of the form ``Is it X?'', to which Alice answers
$A_t \in \{ \text{`Yes.'}, \text{`No.'}\}$.
We repeat this process until Bob guesses correctly, or we hit the limit of $T$ rounds.
This can be thought of as a pair of interacting Markov chains, which exchange strings, until some final end state is reached,
 as illustrated in \cref{fig:twenty}.

\input{figures/twenty-fig}


% \begin{align*}
% \text{question}, \text{facts} \ &\sim \text{Tasks} \\
% \text{selection} &\sim S(\text{question}, \text{facts}) \\
% \text{inference} &\sim S(\text{question}, \text{selection}) \\
% \text{answer} &\sim S(\text{question}, \text{inference}) \\
% \text{reward} &\sim \text{Judge}(\text{answer}, \text{question})
% \end{align*}

The goal is to infer what questions Bob should ask to guess the concept as quickly as possible. This can be cast as a reinforcement learning problem with string-valued actions, or equivalently as an inference problem where we condition on the goal state that $A_T=\text{`yes'}$ for the soonest possible $T$ (c.f., planning as inference \cite{rl_inference}). %\todo{JSD: This is inaccurate -- Alice's answers can be yes or no for any question, regardless of whether Bob correctly guessed the concept.}.
%, goal-conditioned policies such as decision-transformer \cite{decision_transformer} and upside-down RL \cite{upsidedown_rl})

In our current preliminary experiments, we use a forward sampling
approach (aka ancestral sampling), in which 
we sample 50 conversations per concept with temperature $1.0$.
We consider a trial successful if the target concept appears in $B_t$.
(i.e., Bob guesses the right answer).
We reject a sampling chain early if it is ``malformed''
(e.g., Bob generates a response that is not a question).

%at least one of these samples has
% $A_t=\text{`yes'}$ for some $t \leq T$
%[JSD: I think this should rather be that we accept the chain if the concept being communicated appears in $B_t$? $A_t$ can be yes or no for any question.]

% TODO: Add this back in after deanonymized
%We use the pretrained "Lamda" LLM with 137B parameters \cite{lamda}.

Bob's turn starts with `Is the concept' which we complete with the LM. Then we let Alice generate an answer;
we post-process Alice's response
by replacing all mentions of the 
true concept with the generic  word ``concept", to prevent information leakage. 
%\rif{Why not use rejection sampling to constrain Alice to answer yes or no, which we said was the rule?} We repeat this for 10 rounds.
%\ddohan{We should have - no good reason.}
Using the LaMDA 137B large LM \citep{lamda},
we find that the model is able to solve $29\%$ of the tasks. %\rif{Is that good?}
See Appendix~\ref{app:20q-details} for more details.
