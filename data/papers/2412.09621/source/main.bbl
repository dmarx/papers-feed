\begin{thebibliography}{118}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Achiam et~al.(2023)Achiam, Adler, Agarwal, Ahmad, Akkaya, Aleman,
  Almeida, Altenschmidt, Altman, Anadkat, et~al.]{achiam2023gpt}
Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya,
  Florencia~Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman,
  Shyamal Anadkat, et~al.
\newblock Gpt-4 technical report.
\newblock \emph{arXiv preprint arXiv:2303.08774}, 2023.

\bibitem[Agarwal et~al.(2011)Agarwal, Furukawa, Snavely, Simon, Curless, Seitz,
  and Szeliski]{agarwal2011building}
Sameer Agarwal, Yasutaka Furukawa, Noah Snavely, Ian Simon, Brian Curless,
  Steven~M Seitz, and Richard Szeliski.
\newblock Building rome in a day.
\newblock \emph{Communications of the ACM}, 2011.

\bibitem[Birchfield and Tomasi(1999)]{birchfield1999depth}
Stan Birchfield and Carlo Tomasi.
\newblock Depth discontinuities by pixel-to-pixel stereo.
\newblock \emph{IJCV}, 1999.

\bibitem[Bloesch et~al.(2018)Bloesch, Czarnowski, Clark, Leutenegger, and
  Davison]{bloesch2018codeslam}
Michael Bloesch, Jan Czarnowski, Ronald Clark, Stefan Leutenegger, and Andrew~J
  Davison.
\newblock Codeslam—learning a compact, optimisable representation for dense
  visual slam.
\newblock In \emph{IEEE Conf. Comput. Vis. Pattern Recog.}, 2018.

\bibitem[Bochkovskii et~al.(2024)Bochkovskii, Delaunoy, Germain, Santos, Zhou,
  Richter, and Koltun]{bochkovskii2024depth}
Aleksei Bochkovskii, Ama{\"e}l Delaunoy, Hugo Germain, Marcel Santos, Yichao
  Zhou, Stephan~R Richter, and Vladlen Koltun.
\newblock Depth pro: Sharp monocular metric depth in less than a second.
\newblock \emph{arXiv preprint arXiv:2410.02073}, 2024.

\bibitem[Bozic et~al.(2020)Bozic, Zollhofer, Theobalt, and
  Nie{\ss}ner]{bozic2020deepdeform}
Aljaz Bozic, Michael Zollhofer, Christian Theobalt, and Matthias Nie{\ss}ner.
\newblock Deepdeform: Learning non-rigid rgb-d reconstruction with
  semi-supervised data.
\newblock In \emph{IEEE Conf. Comput. Vis. Pattern Recog.}, 2020.

\bibitem[Brachmann et~al.(2023)Brachmann, Cavallari, and
  Prisacariu]{brachmann2023ace}
Eric Brachmann, Tommaso Cavallari, and Victor~Adrian Prisacariu.
\newblock Accelerated coordinate encoding: Learning to relocalize in minutes
  using rgb and poses.
\newblock In \emph{IEEE Conf. Comput. Vis. Pattern Recog.}, 2023.

\bibitem[Brachmann et~al.(2024)Brachmann, Wynn, Chen, Cavallari, Monszpart,
  Turmukhambetov, and Prisacariu]{brachmann2024acezero}
Eric Brachmann, Jamie Wynn, Shuai Chen, Tommaso Cavallari, {\'{A}}ron
  Monszpart, Daniyar Turmukhambetov, and Victor~Adrian Prisacariu.
\newblock Scene coordinate reconstruction: Posing of image collections via
  incremental learning of a relocalizer.
\newblock In \emph{Eur. Conf. Comput. Vis.}, 2024.

\bibitem[Butler et~al.(2012)Butler, Wulff, Stanley, and
  Black]{butler2012naturalistic}
Daniel~J Butler, Jonas Wulff, Garrett~B Stanley, and Michael~J Black.
\newblock A naturalistic open source movie for optical flow evaluation.
\newblock In \emph{ECCV}, 2012.

\bibitem[Campbell et~al.(2008)Campbell, Vogiatzis, Hern{\'a}ndez, and
  Cipolla]{campbell2008using}
Neill~DF Campbell, George Vogiatzis, Carlos Hern{\'a}ndez, and Roberto Cipolla.
\newblock Using multiple hypotheses to improve depth-maps for multi-view
  stereo.
\newblock In \emph{Eur. Conf. Comput. Vis.}, 2008.

\bibitem[Campos et~al.(2021)Campos, Elvira, Rodr{\'\i}guez, Montiel, and
  Tard{\'o}s]{campos2021orb}
Carlos Campos, Richard Elvira, Juan J~G{\'o}mez Rodr{\'\i}guez, Jos{\'e}~MM
  Montiel, and Juan~D Tard{\'o}s.
\newblock Orb-slam3: An accurate open-source library for visual,
  visual--inertial, and multimap slam.
\newblock \emph{IEEE Transactions on Robotics}, 2021.

\bibitem[Chang and Chen(2018)]{chang2018pyramid}
Jia-Ren Chang and Yong-Sheng Chen.
\newblock Pyramid stereo matching network.
\newblock In \emph{IEEE Conf. Comput. Vis. Pattern Recog.}, 2018.

\bibitem[Chen(2017)]{chen2017rethinking}
Liang-Chieh Chen.
\newblock Rethinking atrous convolution for semantic image segmentation.
\newblock \emph{arXiv preprint arXiv:1706.05587}, 2017.

\bibitem[Curless and Levoy(1996)]{curless1996volumetric}
Brian Curless and Marc Levoy.
\newblock A volumetric method for building complex models from range images.
\newblock In \emph{SIGGRAPH}, 1996.

\bibitem[Davison et~al.(2007)Davison, Reid, Molton, and
  Stasse]{davison2007monoslam}
Andrew~J Davison, Ian~D Reid, Nicholas~D Molton, and Olivier Stasse.
\newblock Monoslam: Real-time single camera slam.
\newblock \emph{IEEE Trans. Pattern Anal. Mach. Intell.}, 2007.

\bibitem[Doersch et~al.(2022)Doersch, Gupta, Markeeva, Recasens, Smaira, Aytar,
  Carreira, Zisserman, and Yang]{doersch2022tap}
Carl Doersch, Ankush Gupta, Larisa Markeeva, Adria Recasens, Lucas Smaira,
  Yusuf Aytar, Joao Carreira, Andrew Zisserman, and Yi Yang.
\newblock Tap-vid: A benchmark for tracking any point in a video.
\newblock \emph{NeurIPS}, 2022.

\bibitem[Doersch et~al.(2024)Doersch, Luc, Yang, Gokay, Koppula, Gupta,
  Heyward, Rocco, Goroshin, Carreira, and Zisserman]{doersch2024bootstap}
Carl Doersch, Pauline Luc, Yi Yang, Dilara Gokay, Skanda Koppula, Ankush Gupta,
  Joseph Heyward, Ignacio Rocco, Ross Goroshin, João Carreira, and Andrew
  Zisserman.
\newblock {BootsTAP}: Bootstrapped training for tracking any point.
\newblock \emph{ICCV}, 2024.

\bibitem[Dosovitskiy(2021)]{dosovitskiy2020image}
Alexey Dosovitskiy.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock \emph{ICLR}, 2021.

\bibitem[Dosovitskiy et~al.(2015)Dosovitskiy, Fischer, Ilg, Hausser, Hazirbas,
  Golkov, Van Der~Smagt, Cremers, and Brox]{dosovitskiy2015flownet}
Alexey Dosovitskiy, Philipp Fischer, Eddy Ilg, Philip Hausser, Caner Hazirbas,
  Vladimir Golkov, Patrick Van Der~Smagt, Daniel Cremers, and Thomas Brox.
\newblock Flownet: Learning optical flow with convolutional networks.
\newblock In \emph{Int. Conf. Comput. Vis.}, 2015.

\bibitem[Engel et~al.(2017)Engel, Koltun, and Cremers]{engel2017direct}
Jakob Engel, Vladlen Koltun, and Daniel Cremers.
\newblock Direct sparse odometry.
\newblock \emph{IEEE Trans. Pattern Anal. Mach. Intell.}, 2017.

\bibitem[Fu et~al.(2024)Fu, Liu, Kulkarni, Kautz, Efros, and
  Wang]{Fu_2024_CVPR}
Yang Fu, Sifei Liu, Amey Kulkarni, Jan Kautz, Alexei~A. Efros, and Xiaolong
  Wang.
\newblock Colmap-free 3d gaussian splatting.
\newblock In \emph{IEEE Conf. Comput. Vis. Pattern Recog.}, 2024.

\bibitem[Furukawa and Ponce(2009)]{furukawa2009accurate}
Yasutaka Furukawa and Jean Ponce.
\newblock Accurate, dense, and robust multiview stereopsis.
\newblock \emph{IEEE Trans. Pattern Anal. Mach. Intell.}, 2009.

\bibitem[Furukawa et~al.(2010)Furukawa, Curless, Seitz, and
  Szeliski]{furukawa2010towards}
Yasutaka Furukawa, Brian Curless, Steven~M Seitz, and Richard Szeliski.
\newblock Towards internet-scale multi-view stereo.
\newblock In \emph{IEEE Conf. Comput. Vis. Pattern Recog.}, 2010.

\bibitem[Galliani et~al.(2015)Galliani, Lasinger, and
  Schindler]{galliani2015massively}
Silvano Galliani, Katrin Lasinger, and Konrad Schindler.
\newblock Massively parallel multiview stereopsis by surface normal diffusion.
\newblock In \emph{Int. Conf. Comput. Vis.}, 2015.

\bibitem[Gao et~al.(2022)Gao, Li, Tulsiani, Russell, and
  Kanazawa]{gao2022monocular}
Hang Gao, Ruilong Li, Shubham Tulsiani, Bryan Russell, and Angjoo Kanazawa.
\newblock Monocular dynamic view synthesis: A reality check.
\newblock \emph{NeurIPS}, 2022.

\bibitem[Gao et~al.(2024)Gao, Holynski, Henzler, Brussee, Martin-Brualla,
  Srinivasan, Barron, and Poole]{gao2024cat3d}
Ruiqi Gao, Aleksander Holynski, Philipp Henzler, Arthur Brussee, Ricardo
  Martin-Brualla, Pratul Srinivasan, Jonathan~T Barron, and Ben Poole.
\newblock Cat3d: Create anything in 3d with multi-view diffusion models.
\newblock \emph{NeurIPS}, 2024.

\bibitem[Geiger et~al.(2013)Geiger, Lenz, Stiller, and
  Urtasun]{geiger2013vision}
Andreas Geiger, Philip Lenz, Christoph Stiller, and Raquel Urtasun.
\newblock Vision meets robotics: The kitti dataset.
\newblock \emph{IJRR}, 2013.

\bibitem[Grauman et~al.(2024)Grauman, Westbury, Torresani, Kitani, Malik,
  Afouras, Ashutosh, Baiyya, Bansal, Boote, Byrne, Chavis, Chen, Cheng, Chu,
  Crane, Dasgupta, Dong, Escobar, Forigua, Gebreselasie, Haresh, Huang, Islam,
  Jain, Khirodkar, Kukreja, Liang, Liu, Majumder, Mao, Martin, Mavroudi,
  Nagarajan, Ragusa, Ramakrishnan, Seminara, Somayazulu, Song, Su, Xue, Zhang,
  Zhang, Castillo, Chen, Fu, Furuta, Gonzalez, Gupta, Hu, Huang, Huang, Khoo,
  Kumar, Kuo, Lakhavani, Liu, Luo, Luo, Meredith, Miller, Oguntola, Pan, Peng,
  Pramanick, Ramazanova, Ryan, Shan, Somasundaram, Song, Southerland, Tateno,
  Wang, Wang, Yagi, Yan, Yang, Yu, Zha, Zhao, Zhao, Zhu, Zhuo, Arbelaez,
  Bertasius, Damen, Engel, Farinella, Furnari, Ghanem, Hoffman, Jawahar,
  Newcombe, Park, Rehg, Sato, Savva, Shi, Shou, and Wray]{Grauman_2024_CVPR}
Kristen Grauman, Andrew Westbury, Lorenzo Torresani, Kris Kitani, Jitendra
  Malik, Triantafyllos Afouras, Kumar Ashutosh, Vijay Baiyya, Siddhant Bansal,
  Bikram Boote, Eugene Byrne, Zach Chavis, Joya Chen, Feng Cheng, Fu-Jen Chu,
  Sean Crane, Avijit Dasgupta, Jing Dong, Maria Escobar, Cristhian Forigua,
  Abrham Gebreselasie, Sanjay Haresh, Jing Huang, Md~Mohaiminul Islam, Suyog
  Jain, Rawal Khirodkar, Devansh Kukreja, Kevin~J Liang, Jia-Wei Liu, Sagnik
  Majumder, Yongsen Mao, Miguel Martin, Effrosyni Mavroudi, Tushar Nagarajan,
  Francesco Ragusa, Santhosh~Kumar Ramakrishnan, Luigi Seminara, Arjun
  Somayazulu, Yale Song, Shan Su, Zihui Xue, Edward Zhang, Jinxu Zhang, Angela
  Castillo, Changan Chen, Xinzhu Fu, Ryosuke Furuta, Cristina Gonzalez, Prince
  Gupta, Jiabo Hu, Yifei Huang, Yiming Huang, Weslie Khoo, Anush Kumar, Robert
  Kuo, Sach Lakhavani, Miao Liu, Mi Luo, Zhengyi Luo, Brighid Meredith, Austin
  Miller, Oluwatumininu Oguntola, Xiaqing Pan, Penny Peng, Shraman Pramanick,
  Merey Ramazanova, Fiona Ryan, Wei Shan, Kiran Somasundaram, Chenan Song,
  Audrey Southerland, Masatoshi Tateno, Huiyu Wang, Yuchen Wang, Takuma Yagi,
  Mingfei Yan, Xitong Yang, Zecheng Yu, Shengxin~Cindy Zha, Chen Zhao, Ziwei
  Zhao, Zhifan Zhu, Jeff Zhuo, Pablo Arbelaez, Gedas Bertasius, Dima Damen,
  Jakob Engel, Giovanni~Maria Farinella, Antonino Furnari, Bernard Ghanem, Judy
  Hoffman, C.V. Jawahar, Richard Newcombe, Hyun~Soo Park, James~M. Rehg, Yoichi
  Sato, Manolis Savva, Jianbo Shi, Mike~Zheng Shou, and Michael Wray.
\newblock Ego-exo4d: Understanding skilled human activity from first- and
  third-person perspectives.
\newblock In \emph{IEEE Conf. Comput. Vis. Pattern Recog.}, 2024.

\bibitem[Greff et~al.(2022)Greff, Belletti, Beyer, Doersch, Du, Duckworth,
  Fleet, Gnanapragasam, Golemo, Herrmann, Kipf, Kundu, Lagun, Laradji, Liu,
  Meyer, Miao, Nowrouzezahrai, Oztireli, Pot, Radwan, Rebain, Sabour, Sajjadi,
  Sela, Sitzmann, Stone, Sun, Vora, Wang, Wu, Yi, Zhong, and
  Tagliasacchi]{greff2021kubric}
Klaus Greff, Francois Belletti, Lucas Beyer, Carl Doersch, Yilun Du, Daniel
  Duckworth, David~J Fleet, Dan Gnanapragasam, Florian Golemo, Charles
  Herrmann, Thomas Kipf, Abhijit Kundu, Dmitry Lagun, Issam Laradji,
  Hsueh-Ti~(Derek) Liu, Henning Meyer, Yishu Miao, Derek Nowrouzezahrai, Cengiz
  Oztireli, Etienne Pot, Noha Radwan, Daniel Rebain, Sara Sabour, Mehdi S.~M.
  Sajjadi, Matan Sela, Vincent Sitzmann, Austin Stone, Deqing Sun, Suhani Vora,
  Ziyu Wang, Tianhao Wu, Kwang~Moo Yi, Fangcheng Zhong, and Andrea
  Tagliasacchi.
\newblock Kubric: a scalable dataset generator.
\newblock In \emph{IEEE Conf. Comput. Vis. Pattern Recog.}, 2022.

\bibitem[Harley et~al.(2022)Harley, Fang, and Fragkiadaki]{harley2022particle}
Adam~W Harley, Zhaoyuan Fang, and Katerina Fragkiadaki.
\newblock Particle video revisited: Tracking through occlusions using point
  trajectories.
\newblock In \emph{Eur. Conf. Comput. Vis.}, 2022.

\bibitem[Hirschm{\"u}ller et~al.(2002)Hirschm{\"u}ller, Innocent, and
  Garibaldi]{hirschmuller2002real}
Heiko Hirschm{\"u}ller, Peter~R Innocent, and Jon Garibaldi.
\newblock Real-time correlation-based stereo vision with reduced border errors.
\newblock \emph{IJCV}, 2002.

\bibitem[Holynski et~al.(2020)Holynski, Geraghty, Frahm, Sweeney, and
  Szeliski]{holynski2020reducing}
Aleksander Holynski, David Geraghty, Jan-Michael Frahm, Chris Sweeney, and
  Richard Szeliski.
\newblock Reducing drift in structure from motion using extended features.
\newblock In \emph{3DV}, 2020.

\bibitem[Hoppe et~al.(1992)Hoppe, DeRose, Duchamp, McDonald, and
  Stuetzle]{hoppe1992surface}
Hugues Hoppe, Tony DeRose, Tom Duchamp, John McDonald, and Werner Stuetzle.
\newblock Surface reconstruction from unorganized points.
\newblock In \emph{SIGGRAPH}, 1992.

\bibitem[Hu et~al.(2024)Hu, Gao, Li, Zhao, Cun, Zhang, Quan, and
  Shan]{hu2024depthcrafter}
Wenbo Hu, Xiangjun Gao, Xiaoyu Li, Sijie Zhao, Xiaodong Cun, Yong Zhang, Long
  Quan, and Ying Shan.
\newblock Depthcrafter: Generating consistent long depth sequences for
  open-world videos.
\newblock \emph{arXiv preprint arXiv:2409.02095}, 2024.

\bibitem[I\c{s}{\i}k et~al.(2023)I\c{s}{\i}k, Rünz, Georgopoulos, Khakhulin,
  Starck, Agapito, and Nießner]{isik2023humanrf}
Mustafa I\c{s}{\i}k, Martin Rünz, Markos Georgopoulos, Taras Khakhulin,
  Jonathan Starck, Lourdes Agapito, and Matthias Nießner.
\newblock Humanrf: High-fidelity neural radiance fields for humans in motion.
\newblock \emph{ACM Transactions on Graphics (TOG)}, 2023.

\bibitem[Jancosek and Pajdla(2011)]{jancosek2011multi}
Michal Jancosek and Tomas Pajdla.
\newblock Multi-view reconstruction preserving weakly-supported surfaces.
\newblock In \emph{IEEE Conf. Comput. Vis. Pattern Recog.}, 2011.

\bibitem[Jing et~al.(2025)Jing, Mao, and
  Mikolajczyk]{jing2024matchstereovideos}
Junpeng Jing, Ye Mao, and Krystian Mikolajczyk.
\newblock Match-stereo-videos: Bidirectional alignment for consistent dynamic
  stereo matching.
\newblock In \emph{ECCV}, 2025.

\bibitem[Joo et~al.(2015)Joo, Liu, Tan, Gui, Nabbe, Matthews, Kanade, Nobuhara,
  and Sheikh]{Joo_2015_ICCV}
Hanbyul Joo, Hao Liu, Lei Tan, Lin Gui, Bart Nabbe, Iain Matthews, Takeo
  Kanade, Shohei Nobuhara, and Yaser Sheikh.
\newblock Panoptic studio: A massively multiview system for social motion
  capture.
\newblock In \emph{Int. Conf. Comput. Vis.}, 2015.

\bibitem[Karaev et~al.(2023)Karaev, Rocco, Graham, Neverova, Vedaldi, and
  Rupprecht]{karaev2023dynamicstereo}
Nikita Karaev, Ignacio Rocco, Benjamin Graham, Natalia Neverova, Andrea
  Vedaldi, and Christian Rupprecht.
\newblock Dynamicstereo: Consistent dynamic depth from stereo videos.
\newblock In \emph{IEEE Conf. Comput. Vis. Pattern Recog.}, 2023.

\bibitem[Kazhdan et~al.(2006)Kazhdan, Bolitho, and Hoppe]{kazhdan2006poisson}
Michael Kazhdan, Matthew Bolitho, and Hugues Hoppe.
\newblock Poisson surface reconstruction.
\newblock In \emph{Proceedings of the fourth Eurographics symposium on Geometry
  processing}, 2006.

\bibitem[Ke et~al.(2024)Ke, Obukhov, Huang, Metzger, Daudt, and
  Schindler]{ke2024repurposing}
Bingxin Ke, Anton Obukhov, Shengyu Huang, Nando Metzger, Rodrigo~Caye Daudt,
  and Konrad Schindler.
\newblock Repurposing diffusion-based image generators for monocular depth
  estimation.
\newblock In \emph{IEEE Conf. Comput. Vis. Pattern Recog.}, 2024.

\bibitem[Kendall et~al.(2017)Kendall, Martirosyan, Dasgupta, Henry, Kennedy,
  Bachrach, and Bry]{kendall2017end}
Alex Kendall, Hayk Martirosyan, Saumitro Dasgupta, Peter Henry, Ryan Kennedy,
  Abraham Bachrach, and Adam Bry.
\newblock End-to-end learning of geometry and context for deep stereo
  regression.
\newblock In \emph{Int. Conf. Comput. Vis.}, 2017.

\bibitem[Kirschstein et~al.(2023)Kirschstein, Qian, Giebenhain, Walter, and
  Nie\ss{}ner]{kirschstein2023nersemble}
Tobias Kirschstein, Shenhan Qian, Simon Giebenhain, Tim Walter, and Matthias
  Nie\ss{}ner.
\newblock Nersemble: Multi-view radiance field reconstruction of human heads.
\newblock \emph{ACM Trans. Graph.}, 2023.

\bibitem[Klaus et~al.(2006)Klaus, Sormann, and Karner]{klaus2006segment}
Andreas Klaus, Mario Sormann, and Konrad Karner.
\newblock Segment-based stereo matching using belief propagation and a
  self-adapting dissimilarity measure.
\newblock In \emph{ICPR}, 2006.

\bibitem[Kopf et~al.(2021)Kopf, Rong, and Huang]{kopf2021rcvd}
Johannes Kopf, Xuejian Rong, and Jia-Bin Huang.
\newblock Robust consistent video depth estimation.
\newblock In \emph{IEEE Conf. Comput. Vis. Pattern Recog.}, 2021.

\bibitem[Koppula et~al.(2024)Koppula, Rocco, Yang, Heyward, Carreira,
  Zisserman, Brostow, and Doersch]{koppula2024tapvid3d}
Skanda Koppula, Ignacio Rocco, Yi Yang, Joe Heyward, João Carreira, Andrew
  Zisserman, Gabriel Brostow, and Carl Doersch.
\newblock Tapvid-3d: A benchmark for tracking any point in 3d.
\newblock In \emph{NeurIPS}, 2024.

\bibitem[Lei et~al.(2024)Lei, Weng, Harley, Guibas, and
  Daniilidis]{lei2024mosca}
Jiahui Lei, Yijia Weng, Adam Harley, Leonidas Guibas, and Kostas Daniilidis.
\newblock Mosca: Dynamic gaussian fusion from casual videos via 4d motion
  scaffolds.
\newblock \emph{arXiv preprint arXiv:2405.17421}, 2024.

\bibitem[Leroy et~al.(2024)Leroy, Cabon, and Revaud]{leroy2024grounding}
Vincent Leroy, Yohann Cabon, and J{\'e}r{\^o}me Revaud.
\newblock Grounding image matching in 3d with mast3r.
\newblock \emph{arXiv preprint arXiv:2406.09756}, 2024.

\bibitem[Li and Snavely(2018)]{li2018megadepth}
Zhengqi Li and Noah Snavely.
\newblock Megadepth: Learning single-view depth prediction from internet
  photos.
\newblock In \emph{IEEE Conf. Comput. Vis. Pattern Recog.}, 2018.

\bibitem[Li et~al.(2019)Li, Dekel, Cole, Tucker, Snavely, Liu, and
  Freeman]{li2019learning}
Zhengqi Li, Tali Dekel, Forrester Cole, Richard Tucker, Noah Snavely, Ce Liu,
  and William~T Freeman.
\newblock Learning the depths of moving people by watching frozen people.
\newblock In \emph{IEEE Conf. Comput. Vis. Pattern Recog.}, 2019.

\bibitem[Li et~al.(2021)Li, Niklaus, Snavely, and Wang]{li2021neural}
Zhengqi Li, Simon Niklaus, Noah Snavely, and Oliver Wang.
\newblock Neural scene flow fields for space-time view synthesis of dynamic
  scenes.
\newblock In \emph{IEEE Conf. Comput. Vis. Pattern Recog.}, 2021.

\bibitem[Li et~al.(2023{\natexlab{a}})Li, Wang, Cole, Tucker, and
  Snavely]{li2023dynibar}
Zhengqi Li, Qianqian Wang, Forrester Cole, Richard Tucker, and Noah Snavely.
\newblock Dynibar: Neural dynamic image-based rendering.
\newblock In \emph{IEEE Conf. Comput. Vis. Pattern Recog.}, 2023{\natexlab{a}}.

\bibitem[Li et~al.(2023{\natexlab{b}})Li, Ye, Wang, Creighton, Taylor,
  Venkatesh, and Unberath]{li2023temporally}
Zhaoshuo Li, Wei Ye, Dilin Wang, Francis~X Creighton, Russell~H Taylor, Ganesh
  Venkatesh, and Mathias Unberath.
\newblock Temporally consistent online depth estimation in dynamic scenes.
\newblock In \emph{IEEE Conf. Comput. Vis. Pattern Recog.}, 2023{\natexlab{b}}.

\bibitem[Li et~al.(2024)Li, Tucker, Cole, Wang, Jin, Ye, Kanazawa, Holynski,
  and Snavely]{li2024megasam}
Zhengqi Li, Richard Tucker, Forrester Cole, Qianqian Wang, Linyi Jin, Vickie
  Ye, Angjoo Kanazawa, Aleksander Holynski, and Noah Snavely.
\newblock Megasam: Accurate, fast, and robust structure and motion from casual
  dynamic videos.
\newblock \emph{arXiv preprint arXiv:2412.04463}, 2024.

\bibitem[Lin et~al.(2021)Lin, Ma, Torralba, and Lucey]{lin2021barf}
Chen-Hsuan Lin, Wei-Chiu Ma, Antonio Torralba, and Simon Lucey.
\newblock Barf: Bundle-adjusting neural radiance fields.
\newblock In \emph{IEEE Conf. Comput. Vis. Pattern Recog.}, 2021.

\bibitem[Liu et~al.(2023)Liu, Gao, Meuleman, Tseng, Saraf, Kim, Chuang, Kopf,
  and Huang]{liu2023robust}
Yu-Lun Liu, Chen Gao, Andreas Meuleman, Hung-Yu Tseng, Ayush Saraf, Changil
  Kim, Yung-Yu Chuang, Johannes Kopf, and Jia-Bin Huang.
\newblock Robust dynamic radiance fields.
\newblock In \emph{IEEE Conf. Comput. Vis. Pattern Recog.}, 2023.

\bibitem[Lowe(2004)]{lowe2004sift}
G Lowe.
\newblock Sift-the scale invariant feature transform.
\newblock \emph{Int. J}, 2004.

\bibitem[Luo et~al.(2020)Luo, Huang, Szeliski, Matzen, and
  Kopf]{luo2020consistent}
Xuan Luo, Jia-Bin Huang, Richard Szeliski, Kevin Matzen, and Johannes Kopf.
\newblock Consistent video depth estimation.
\newblock \emph{ACM Transactions on Graphics (ToG)}, 2020.

\bibitem[Mayer et~al.(2016)Mayer, Ilg, Hausser, Fischer, Cremers, Dosovitskiy,
  and Brox]{mayer2016large}
Nikolaus Mayer, Eddy Ilg, Philip Hausser, Philipp Fischer, Daniel Cremers,
  Alexey Dosovitskiy, and Thomas Brox.
\newblock A large dataset to train convolutional networks for disparity,
  optical flow, and scene flow estimation.
\newblock In \emph{IEEE Conf. Comput. Vis. Pattern Recog.}, 2016.

\bibitem[Mur-Artal et~al.(2015{\natexlab{a}})Mur-Artal, Montiel, and
  Tardos]{mur2015orb}
Raul Mur-Artal, Jose Maria~Martinez Montiel, and Juan~D Tardos.
\newblock Orb-slam: a versatile and accurate monocular slam system.
\newblock \emph{IEEE Transactions on Robotics}, 2015{\natexlab{a}}.

\bibitem[Mur-Artal et~al.(2015{\natexlab{b}})Mur-Artal, Montiel, and
  Tard\'os]{murartal2015orbslam}
Ra\'ul Mur-Artal, J.~M.~M. Montiel, and Juan~D. Tard\'os.
\newblock {ORB-SLAM}: a versatile and accurate monocular {SLAM} system.
\newblock \emph{IEEE Trans. on Robotics}, 2015{\natexlab{b}}.

\bibitem[Newcombe et~al.(2015)Newcombe, Fox, and
  Seitz]{newcombe2015dynamicfusion}
Richard~A Newcombe, Dieter Fox, and Steven~M Seitz.
\newblock Dynamicfusion: Reconstruction and tracking of non-rigid scenes in
  real-time.
\newblock In \emph{IEEE Conf. Comput. Vis. Pattern Recog.}, 2015.

\bibitem[Palazzolo et~al.(2019)Palazzolo, Behley, Lottes, Gigu\`ere, and
  Stachniss]{palazzolo2019iros}
E. Palazzolo, J. Behley, P. Lottes, P. Gigu\`ere, and C. Stachniss.
\newblock {ReFusion: 3D Reconstruction in Dynamic Environments for RGB-D
  Cameras Exploiting Residuals}.
\newblock In \emph{IROS}, 2019.

\bibitem[Pan et~al.(2023)Pan, Charron, Yang, Peters, Whelan, Kong, Parkhi,
  Newcombe, and Ren]{pan2023aria}
Xiaqing Pan, Nicholas Charron, Yongqian Yang, Scott Peters, Thomas Whelan, Chen
  Kong, Omkar Parkhi, Richard Newcombe, and Yuheng~Carl Ren.
\newblock Aria digital twin: A new benchmark dataset for egocentric 3d machine
  perception.
\newblock In \emph{ICCV}, 2023.

\bibitem[Pang et~al.(2017)Pang, Sun, Ren, Yang, and Yan]{pang2017cascade}
Jiahao Pang, Wenxiu Sun, Jimmy~SJ Ren, Chengxi Yang, and Qiong Yan.
\newblock Cascade residual learning: A two-stage convolutional neural network
  for stereo matching.
\newblock In \emph{Proc. CVPR Workshops}, 2017.

\bibitem[Park et~al.(2010)Park, Shiratori, Matthews, and Sheikh]{park20103d}
Hyun~Soo Park, Takaaki Shiratori, Iain Matthews, and Yaser Sheikh.
\newblock 3d reconstruction of a moving point from a series of 2d projections.
\newblock In \emph{Eur. Conf. Comput. Vis.}, 2010.

\bibitem[Park et~al.(2021{\natexlab{a}})Park, Sinha, Barron, Bouaziz, Goldman,
  Seitz, and Martin-Brualla]{park2021nerfies}
Keunhong Park, Utkarsh Sinha, Jonathan~T Barron, Sofien Bouaziz, Dan~B Goldman,
  Steven~M Seitz, and Ricardo Martin-Brualla.
\newblock Nerfies: Deformable neural radiance fields.
\newblock In \emph{IEEE Conf. Comput. Vis. Pattern Recog.}, 2021{\natexlab{a}}.

\bibitem[Park et~al.(2021{\natexlab{b}})Park, Sinha, Hedman, Barron, Bouaziz,
  Goldman, Martin-Brualla, and Seitz]{park2021hypernerf}
Keunhong Park, Utkarsh Sinha, Peter Hedman, Jonathan~T Barron, Sofien Bouaziz,
  Dan~B Goldman, Ricardo Martin-Brualla, and Steven~M Seitz.
\newblock Hypernerf: A higher-dimensional representation for topologically
  varying neural radiance fields.
\newblock \emph{arXiv preprint arXiv:2106.13228}, 2021{\natexlab{b}}.

\bibitem[Park et~al.(2023)Park, Henzler, Mildenhall, Barron, and
  Martin-Brualla]{park2023camp}
Keunhong Park, Philipp Henzler, Ben Mildenhall, Jonathan~T Barron, and Ricardo
  Martin-Brualla.
\newblock Camp: Camera preconditioning for neural radiance fields.
\newblock \emph{ACM Transactions on Graphics (TOG)}, 2023.

\bibitem[Piccinelli et~al.(2024)Piccinelli, Yang, Sakaridis, Segu, Li,
  Van~Gool, and Yu]{piccinelli2024unidepth}
Luigi Piccinelli, Yung-Hsu Yang, Christos Sakaridis, Mattia Segu, Siyuan Li,
  Luc Van~Gool, and Fisher Yu.
\newblock {U}ni{D}epth: Universal monocular metric depth estimation.
\newblock In \emph{IEEE Conf. Comput. Vis. Pattern Recog.}, 2024.

\bibitem[Pollefeys et~al.(2004)Pollefeys, Van~Gool, Vergauwen, Verbiest,
  Cornelis, Tops, and Koch]{pollefeys2004visual}
Marc Pollefeys, Luc Van~Gool, Maarten Vergauwen, Frank Verbiest, Kurt Cornelis,
  Jan Tops, and Reinhard Koch.
\newblock Visual modeling with a hand-held camera.
\newblock \emph{IJCV}, 2004.

\bibitem[Pollefeys et~al.(2008)Pollefeys, Nist{\'e}r, Frahm, Akbarzadeh,
  Mordohai, Clipp, Engels, Gallup, Kim, Merrell, et~al.]{pollefeys2008detailed}
Marc Pollefeys, David Nist{\'e}r, J-M Frahm, Amir Akbarzadeh, Philippos
  Mordohai, Brian Clipp, Chris Engels, David Gallup, S-J Kim, Paul Merrell,
  et~al.
\newblock Detailed real-time urban 3d reconstruction from video.
\newblock \emph{IJCV}, 2008.

\bibitem[Polyak et~al.(2024)Polyak, Zohar, Brown, Tjandra, Sinha, Lee, Vyas,
  Shi, Ma, Chuang, et~al.]{polyak2024movie}
Adam Polyak, Amit Zohar, Andrew Brown, Andros Tjandra, Animesh Sinha, Ann Lee,
  Apoorv Vyas, Bowen Shi, Chih-Yao Ma, Ching-Yao Chuang, et~al.
\newblock Movie gen: A cast of media foundation models.
\newblock \emph{arXiv preprint arXiv:2410.13720}, 2024.

\bibitem[Ranftl et~al.(2020)Ranftl, Lasinger, Hafner, Schindler, and
  Koltun]{ranftl2020towards}
Ren{\'e} Ranftl, Katrin Lasinger, David Hafner, Konrad Schindler, and Vladlen
  Koltun.
\newblock Towards robust monocular depth estimation: Mixing datasets for
  zero-shot cross-dataset transfer.
\newblock \emph{IEEE Trans. Pattern Anal. Mach. Intell.}, 2020.

\bibitem[Ranftl et~al.(2021)Ranftl, Bochkovskiy, and Koltun]{ranftl2021vision}
Ren{\'e} Ranftl, Alexey Bochkovskiy, and Vladlen Koltun.
\newblock Vision transformers for dense prediction.
\newblock In \emph{IEEE Conf. Comput. Vis. Pattern Recog.}, 2021.

\bibitem[Schonberger and Frahm(2016)]{schonberger2016structure}
Johannes~L Schonberger and Jan-Michael Frahm.
\newblock Structure-from-motion revisited.
\newblock In \emph{IEEE Conf. Comput. Vis. Pattern Recog.}, 2016.

\bibitem[Sch{\"o}nberger et~al.(2016)Sch{\"o}nberger, Zheng, Frahm, and
  Pollefeys]{schonberger2016pixelwise}
Johannes~L Sch{\"o}nberger, Enliang Zheng, Jan-Michael Frahm, and Marc
  Pollefeys.
\newblock Pixelwise view selection for unstructured multi-view stereo.
\newblock In \emph{ECCV}, 2016.

\bibitem[Shao et~al.(2024)Shao, Yang, Zhou, Zhang, Shen, Poggi, and
  Liao]{shao2024learning}
Jiahao Shao, Yuanbo Yang, Hongyu Zhou, Youmin Zhang, Yujun Shen, Matteo Poggi,
  and Yiyi Liao.
\newblock Learning temporally consistent video depth from video diffusion
  priors.
\newblock \emph{arXiv preprint arXiv:2406.01493}, 2024.

\bibitem[Shen et~al.(2023)Shen, Cai, Wang, and Scherer]{shen2023dytanvo}
Shihao Shen, Yilin Cai, Wenshan Wang, and Sebastian Scherer.
\newblock Dytanvo: Joint refinement of visual odometry and motion segmentation
  in dynamic environments.
\newblock In \emph{ICRA}, 2023.

\bibitem[Shih et~al.(2024)Shih, Ma, Boyice, Holynski, Cole, Curless, and
  Kontkanen]{shih2024extranerf}
Meng-Li Shih, Wei-Chiu Ma, Lorenzo Boyice, Aleksander Holynski, Forrester Cole,
  Brian Curless, and Janne Kontkanen.
\newblock Extranerf: Visibility-aware view extrapolation of neural radiance
  fields with diffusion models.
\newblock In \emph{CVPR}, 2024.

\bibitem[Simon et~al.(2016)Simon, Valmadre, Matthews, and
  Sheikh]{simon2016kronecker}
Tomas Simon, Jack Valmadre, Iain Matthews, and Yaser Sheikh.
\newblock Kronecker-markov prior for dynamic 3d reconstruction.
\newblock \emph{IEEE Trans. Pattern Anal. Mach. Intell.}, 2016.

\bibitem[Snavely et~al.(2006)Snavely, Seitz, and Szeliski]{snavely2006photo}
Noah Snavely, Steven~M Seitz, and Richard Szeliski.
\newblock Photo tourism: exploring photo collections in 3d.
\newblock In \emph{SIGGRAPH}, 2006.

\bibitem[Sun et~al.(2021)Sun, Vlasic, Herrmann, Jampani, Krainin, Chang, Zabih,
  Freeman, and Liu]{sun2021autoflow}
Deqing Sun, Daniel Vlasic, Charles Herrmann, Varun Jampani, Michael Krainin,
  Huiwen Chang, Ramin Zabih, William~T Freeman, and Ce Liu.
\newblock Autoflow: Learning a better training set for optical flow.
\newblock In \emph{IEEE Conf. Comput. Vis. Pattern Recog.}, 2021.

\bibitem[Sun et~al.(2022)Sun, Herrmann, Reda, Rubinstein, Fleet, and
  Freeman]{sun2022disentangling}
Deqing Sun, Charles Herrmann, Fitsum Reda, Michael Rubinstein, David~J Fleet,
  and William~T Freeman.
\newblock Disentangling architecture and training for optical flow.
\newblock In \emph{ECCV}, 2022.

\bibitem[Sun et~al.(2003)Sun, Zheng, and Shum]{sun2003stereo}
Jian Sun, Nan-Ning Zheng, and Heung-Yeung Shum.
\newblock Stereo matching using belief propagation.
\newblock \emph{IEEE Trans. Pattern Anal. Mach. Intell.}, 2003.

\bibitem[Sun et~al.(2020)Sun, Kretzschmar, Dotiwalla, Chouard, Patnaik, Tsui,
  Guo, Zhou, Chai, Caine, et~al.]{sun2020scalability}
Pei Sun, Henrik Kretzschmar, Xerxes Dotiwalla, Aurelien Chouard, Vijaysai
  Patnaik, Paul Tsui, James Guo, Yin Zhou, Yuning Chai, Benjamin Caine, et~al.
\newblock Scalability in perception for autonomous driving: Waymo open dataset.
\newblock In \emph{IEEE Conf. Comput. Vis. Pattern Recog.}, 2020.

\bibitem[Sweeney et~al.(2019)Sweeney, Holynski, Curless, and
  Seitz]{sweeney2019structure}
Chris Sweeney, Aleksander Holynski, Brian Curless, and Steve~M Seitz.
\newblock Structure from motion for panorama-style videos.
\newblock \emph{arXiv preprint arXiv:1906.03539}, 2019.

\bibitem[Tang and Tan(2018)]{tang2018ba}
Chengzhou Tang and Ping Tan.
\newblock Ba-net: Dense bundle adjustment network.
\newblock \emph{arXiv preprint arXiv:1806.04807}, 2018.

\bibitem[Team et~al.(2023)Team, Anil, Borgeaud, Alayrac, Yu, Soricut,
  Schalkwyk, Dai, Hauth, Millican, et~al.]{team2023gemini}
Gemini Team, Rohan Anil, Sebastian Borgeaud, Jean-Baptiste Alayrac, Jiahui Yu,
  Radu Soricut, Johan Schalkwyk, Andrew~M Dai, Anja Hauth, Katie Millican,
  et~al.
\newblock Gemini: a family of highly capable multimodal models.
\newblock \emph{arXiv preprint arXiv:2312.11805}, 2023.

\bibitem[Teed and Deng(2020)]{teed2020raft}
Zachary Teed and Jia Deng.
\newblock Raft: Recurrent all-pairs field transforms for optical flow.
\newblock In \emph{ECCV}, 2020.

\bibitem[Teed and Deng(2021{\natexlab{a}})]{teed2021droid}
Zachary Teed and Jia Deng.
\newblock Droid-slam: Deep visual slam for monocular, stereo, and rgb-d
  cameras.
\newblock \emph{NeurIPS}, 2021{\natexlab{a}}.

\bibitem[Teed and Deng(2021{\natexlab{b}})]{teed2021raft3d}
Zachary Teed and Jia Deng.
\newblock Raft-3d: Scene flow using rigid-motion embeddings.
\newblock In \emph{IEEE Conf. Comput. Vis. Pattern Recog.}, 2021{\natexlab{b}}.

\bibitem[Teed et~al.(2024)Teed, Lipson, and Deng]{teed2024deep}
Zachary Teed, Lahav Lipson, and Jia Deng.
\newblock Deep patch visual odometry.
\newblock \emph{NeurIPS}, 2024.

\bibitem[Van~Meerbergen et~al.(2002)Van~Meerbergen, Vergauwen, Pollefeys, and
  Van~Gool]{van2002hierarchical}
Geert Van~Meerbergen, Maarten Vergauwen, Marc Pollefeys, and Luc Van~Gool.
\newblock A hierarchical symmetric stereo algorithm using dynamic programming.
\newblock \emph{Int. J. Comput. Vis.}, 2002.

\bibitem[Vaswani(2017)]{vaswani2017attention}
A Vaswani.
\newblock Attention is all you need.
\newblock \emph{NeurIPS}, 2017.

\bibitem[Vo et~al.(2016)Vo, Narasimhan, and Sheikh]{vo2016spatiotemporal}
Minh Vo, Srinivasa~G Narasimhan, and Yaser Sheikh.
\newblock Spatiotemporal bundle adjustment for dynamic 3d reconstruction.
\newblock In \emph{IEEE Conf. Comput. Vis. Pattern Recog.}, 2016.

\bibitem[Wang et~al.(2023{\natexlab{a}})Wang, Lucey, Perazzi, and
  Wang]{wang2019web}
Chaoyang Wang, Simon Lucey, Federico Perazzi, and Oliver Wang.
\newblock Web stereo video supervision for depth prediction from dynamic
  scenes, 2023{\natexlab{a}}.

\bibitem[Wang et~al.(2024{\natexlab{a}})Wang, Ye, Gao, Austin, Li, and
  Kanazawa]{wang2024shape}
Qianqian Wang, Vickie Ye, Hang Gao, Jake Austin, Zhengqi Li, and Angjoo
  Kanazawa.
\newblock Shape of motion: 4d reconstruction from a single video.
\newblock \emph{arXiv preprint arXiv:2407.13764}, 2024{\natexlab{a}}.

\bibitem[Wang et~al.(2024{\natexlab{b}})Wang, Leroy, Cabon, Chidlovskii, and
  Revaud]{wang2024dust3r}
Shuzhe Wang, Vincent Leroy, Yohann Cabon, Boris Chidlovskii, and Jerome Revaud.
\newblock Dust3r: Geometric 3d vision made easy.
\newblock In \emph{IEEE Conf. Comput. Vis. Pattern Recog.}, 2024{\natexlab{b}}.

\bibitem[Wang et~al.(2023{\natexlab{b}})Wang, Shi, Li, Huang, Cao, Zhang, Xian,
  and Lin]{NVDS}
Yiran Wang, Min Shi, Jiaqi Li, Zihao Huang, Zhiguo Cao, Jianming Zhang, Ke
  Xian, and Guosheng Lin.
\newblock Neural video depth stabilizer.
\newblock In \emph{Int. Conf. Comput. Vis.}, 2023{\natexlab{b}}.

\bibitem[Wang et~al.(2025)Wang, Lipson, and Deng]{wang2025sea}
Yihan Wang, Lahav Lipson, and Jia Deng.
\newblock Sea-raft: Simple, efficient, accurate raft for optical flow.
\newblock In \emph{ECCV}, 2025.

\bibitem[Weber et~al.(2024)Weber, Holynski, Jampani, Saxena, Snavely, Kar, and
  Kanazawa]{weber2024nerfiller}
Ethan Weber, Aleksander Holynski, Varun Jampani, Saurabh Saxena, Noah Snavely,
  Abhishek Kar, and Angjoo Kanazawa.
\newblock Nerfiller: Completing scenes via generative 3d inpainting.
\newblock In \emph{CVPR}, 2024.

\bibitem[Wu et~al.(2024)Wu, Gao, Poole, Trevithick, Zheng, Barron, and
  Holynski]{wu2024cat4d}
Rundi Wu, Ruiqi Gao, Ben Poole, Alex Trevithick, Changxi Zheng, Jonathan~T
  Barron, and Aleksander Holynski.
\newblock Cat4d: Create anything in 4d with multi-view video diffusion models.
\newblock \emph{arXiv preprint arXiv:2411.18613}, 2024.

\bibitem[Yang et~al.(2024{\natexlab{a}})Yang, Kang, Huang, Xu, Feng, and
  Zhao]{depthanything}
Lihe Yang, Bingyi Kang, Zilong Huang, Xiaogang Xu, Jiashi Feng, and Hengshuang
  Zhao.
\newblock Depth anything: Unleashing the power of large-scale unlabeled data.
\newblock In \emph{IEEE Conf. Comput. Vis. Pattern Recog.}, 2024{\natexlab{a}}.

\bibitem[Yang et~al.(2024{\natexlab{b}})Yang, Kang, Huang, Zhao, Xu, Feng, and
  Zhao]{yang2024depth}
Lihe Yang, Bingyi Kang, Zilong Huang, Zhen Zhao, Xiaogang Xu, Jiashi Feng, and
  Hengshuang Zhao.
\newblock Depth anything v2.
\newblock \emph{arXiv preprint arXiv:2406.09414}, 2024{\natexlab{b}}.

\bibitem[Yao et~al.(2018)Yao, Luo, Li, Fang, and Quan]{yao2018mvsnet}
Yao Yao, Zixin Luo, Shiwei Li, Tian Fang, and Long Quan.
\newblock Mvsnet: Depth inference for unstructured multi-view stereo.
\newblock In \emph{Eur. Conf. Comput. Vis.}, 2018.

\bibitem[Yao et~al.(2019)Yao, Luo, Li, Shen, Fang, and Quan]{yao2019recurrent}
Yao Yao, Zixin Luo, Shiwei Li, Tianwei Shen, Tian Fang, and Long Quan.
\newblock Recurrent mvsnet for high-resolution multi-view stereo depth
  inference.
\newblock In \emph{IEEE Conf. Comput. Vis. Pattern Recog.}, 2019.

\bibitem[Yin et~al.(2021)Yin, Zhang, Wang, Niklaus, Mai, Chen, and
  Shen]{yin2021learning}
Wei Yin, Jianming Zhang, Oliver Wang, Simon Niklaus, Long Mai, Simon Chen, and
  Chunhua Shen.
\newblock Learning to recover 3d scene shape from a single image.
\newblock In \emph{IEEE Conf. Comput. Vis. Pattern Recog.}, 2021.

\bibitem[Yin et~al.(2023)Yin, Zhang, Chen, Cai, Yu, Wang, Chen, and
  Shen]{yin2023metric3d}
Wei Yin, Chi Zhang, Hao Chen, Zhipeng Cai, Gang Yu, Kaixuan Wang, Xiaozhi Chen,
  and Chunhua Shen.
\newblock Metric3d: Towards zero-shot metric 3d prediction from a single image.
\newblock In \emph{IEEE Conf. Comput. Vis. Pattern Recog.}, 2023.

\bibitem[Zhang et~al.(2019)Zhang, Prisacariu, Yang, and Torr]{zhang2019ga}
Feihu Zhang, Victor Prisacariu, Ruigang Yang, and Philip~HS Torr.
\newblock Ga-net: Guided aggregation net for end-to-end stereo matching.
\newblock In \emph{IEEE Conf. Comput. Vis. Pattern Recog.}, 2019.

\bibitem[Zhang et~al.(2024)Zhang, Herrmann, Hur, Jampani, Darrell, Cole, Sun,
  and Yang]{zhang2024monst3r}
Junyi Zhang, Charles Herrmann, Junhwa Hur, Varun Jampani, Trevor Darrell,
  Forrester Cole, Deqing Sun, and Ming-Hsuan Yang.
\newblock {MonST3R}: A simple approach for estimating geometry in the presence
  of motion.
\newblock \emph{arXiv preprint arXiv:2410.03825}, 2024.

\bibitem[Zhang et~al.(2023)Zhang, Poggi, and
  Mattoccia]{zhang2023temporalstereo}
Youmin Zhang, Matteo Poggi, and Stefano Mattoccia.
\newblock Temporalstereo: Efficient spatial-temporal stereo matching network.
\newblock In \emph{IROS}, 2023.

\bibitem[Zhang et~al.(2021)Zhang, Cole, Tucker, Freeman, and
  Dekel]{zhang2021consistent}
Zhoutong Zhang, Forrester Cole, Richard Tucker, William~T Freeman, and Tali
  Dekel.
\newblock Consistent depth of moving objects in video.
\newblock \emph{ACM Transactions on Graphics (ToG)}, 2021.

\bibitem[Zhang et~al.(2022)Zhang, Cole, Li, Rubinstein, Snavely, and
  Freeman]{zhang2022structure}
Zhoutong Zhang, Forrester Cole, Zhengqi Li, Michael Rubinstein, Noah Snavely,
  and William~T Freeman.
\newblock Structure and motion from casual videos.
\newblock In \emph{Eur. Conf. Comput. Vis.}, 2022.

\bibitem[Zheng et~al.(2023)Zheng, Harley, Shen, Wetzstein, and
  Guibas]{zheng2023point}
Yang Zheng, Adam~W. Harley, Bokui Shen, Gordon Wetzstein, and Leonidas~J.
  Guibas.
\newblock Pointodyssey: A large-scale synthetic dataset for long-term point
  tracking.
\newblock In \emph{Int. Conf. Comput. Vis.}, 2023.

\bibitem[Zhou et~al.(2017)Zhou, Zhao, Puig, Fidler, Barriuso, and
  Torralba]{zhou2017scene}
Bolei Zhou, Hang Zhao, Xavier Puig, Sanja Fidler, Adela Barriuso, and Antonio
  Torralba.
\newblock Scene parsing through ade20k dataset.
\newblock In \emph{CVPR}, 2017.

\bibitem[Zhou et~al.(2019)Zhou, Zhao, Puig, Xiao, Fidler, Barriuso, and
  Torralba]{zhou2019semantic}
Bolei Zhou, Hang Zhao, Xavier Puig, Tete Xiao, Sanja Fidler, Adela Barriuso,
  and Antonio Torralba.
\newblock Semantic understanding of scenes through the ade20k dataset.
\newblock \emph{IJCV}, 2019.

\bibitem[Zhou et~al.(2018)Zhou, Tucker, Flynn, Fyffe, and
  Snavely]{zhou2018stereo}
Tinghui Zhou, Richard Tucker, John Flynn, Graham Fyffe, and Noah Snavely.
\newblock Stereo magnification: Learning view synthesis using multiplane
  images.
\newblock In \emph{SIGGRAPH}, 2018.

\end{thebibliography}
