\section{Discussion and Conclusion}
\noindent \textbf{Limitations.} 
Our data curation pipeline and trained model have limitations. 
The quality of the long-range 3D motion tracks depends on the accuracy of optical flow and 2D point tracking and may degrade for distant background regions or objects occluded for long periods.
Additionally, \method is a non-generative model that only operates on two-frame inputs. 
Extending our model to video input by adopting an extra global optimization~\cite{zhang2024monst3r} or integrating generative priors for modeling ambiguous motion content is a promising future direction.

\bfpar{Conclusion.}
We presented a pipeline for mining high-quality 4D data from Internet stereoscopic videos. Our framework automatically annotates each real-world video sequence with camera parameters, 3D point clouds, and long-range 3D motion trajectories by consolidating different noisy structure and motion estimates derived from videos.  Furthermore, we show that training a variant of \duster on our real-world 4D data enables more accurate learning of 3D structure and motion in dynamic scenes, outperforming other baselines.

