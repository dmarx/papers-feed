\begin{thebibliography}{75}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[cog(2024)]{cogvideox5b}
Cogvideox-5b, 2024.
\newblock \url{https://huggingface.co/THUDM/CogVideoX-5b}.

\bibitem[Bain et~al.(2021)Bain, Nagrani, Varol, and Zisserman]{bain2021frozen}
Max Bain, Arsha Nagrani, G{\"u}l Varol, and Andrew Zisserman.
\newblock Frozen in time: A joint video and image encoder for end-to-end retrieval.
\newblock In \emph{ICCV}, pages 1728--1738, 2021.

\bibitem[Bao et~al.(2024)Bao, Xiang, Yue, He, Zhu, Zheng, Zhao, Liu, Wang, and Zhu]{bao2024vidu}
Fan Bao, Chendong Xiang, Gang Yue, Guande He, Hongzhou Zhu, Kaiwen Zheng, Min Zhao, Shilong Liu, Yaole Wang, and Jun Zhu.
\newblock Vidu: a highly consistent, dynamic and skilled text-to-video generator with diffusion models.
\newblock \emph{arXiv preprint arXiv:2405.04233}, 2024.

\bibitem[Blattmann et~al.(2023{\natexlab{a}})Blattmann, Dockhorn, Kulal, Mendelevitch, Kilian, Lorenz, Levi, English, Voleti, Letts, et~al.]{blattmann2023stable}
Andreas Blattmann, Tim Dockhorn, Sumith Kulal, Daniel Mendelevitch, Maciej Kilian, Dominik Lorenz, Yam Levi, Zion English, Vikram Voleti, Adam Letts, et~al.
\newblock Stable video diffusion: Scaling latent video diffusion models to large datasets.
\newblock \emph{arXiv preprint arXiv:2311.15127}, 2023{\natexlab{a}}.

\bibitem[Blattmann et~al.(2023{\natexlab{b}})Blattmann, Rombach, Ling, Dockhorn, Kim, Fidler, and Kreis]{blattmann2023align}
Andreas Blattmann, Robin Rombach, Huan Ling, Tim Dockhorn, Seung~Wook Kim, Sanja Fidler, and Karsten Kreis.
\newblock Align your latents: High-resolution video synthesis with latent diffusion models.
\newblock In \emph{CVPR}, pages 22563--22575, 2023{\natexlab{b}}.

\bibitem[Blau and Michaeli(2018)]{blau2018perception}
Yochai Blau and Tomer Michaeli.
\newblock The perception-distortion tradeoff.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and pattern recognition}, pages 6228--6237, 2018.

\bibitem[Brooks et~al.(2024)Brooks, Peebles, Holmes, DePue, Guo, Jing, Schnurr, Taylor, Luhman, Luhman, Ng, Wang, and Ramesh]{videoworldsimulators2024}
Tim Brooks, Bill Peebles, Connor Holmes, Will DePue, Yufei Guo, Li Jing, David Schnurr, Joe Taylor, Troy Luhman, Eric Luhman, Clarence Ng, Ricky Wang, and Aditya Ramesh.
\newblock Video generation models as world simulators.
\newblock 2024.

\bibitem[Caballero et~al.(2017)Caballero, Ledig, Aitken, Acosta, Totz, Wang, and Shi]{caballero2017real}
Jose Caballero, Christian Ledig, Andrew Aitken, Alejandro Acosta, Johannes Totz, Zehan Wang, and Wenzhe Shi.
\newblock Real-time video super-resolution with spatio-temporal networks and motion compensation.
\newblock In \emph{CVPR}, pages 4778--4787, 2017.

\bibitem[Chan et~al.(2021)Chan, Wang, Yu, Dong, and Loy]{chan2021basicvsr}
Kelvin~CK Chan, Xintao Wang, Ke Yu, Chao Dong, and Chen~Change Loy.
\newblock Basicvsr: The search for essential components in video super-resolution and beyond.
\newblock In \emph{CVPR}, pages 4947--4956, 2021.

\bibitem[Chan et~al.(2022{\natexlab{a}})Chan, Zhou, Xu, and Loy]{chan2022basicvsr++}
Kelvin~CK Chan, Shangchen Zhou, Xiangyu Xu, and Chen~Change Loy.
\newblock Basicvsr++: Improving video super-resolution with enhanced propagation and alignment.
\newblock In \emph{CVPR}, pages 5972--5981, 2022{\natexlab{a}}.

\bibitem[Chan et~al.(2022{\natexlab{b}})Chan, Zhou, Xu, and Loy]{chan2022investigating}
Kelvin~CK Chan, Shangchen Zhou, Xiangyu Xu, and Chen~Change Loy.
\newblock Investigating tradeoffs in real-world video super-resolution.
\newblock In \emph{CVPR}, pages 5962--5971, 2022{\natexlab{b}}.

\bibitem[Chen et~al.(2024{\natexlab{a}})Chen, Xu, Ren, Cong, He, Xie, Sinha, Luo, Xiang, and Perez-Rua]{chen2024gentron}
Shoufa Chen, Mengmeng Xu, Jiawei Ren, Yuren Cong, Sen He, Yanping Xie, Animesh Sinha, Ping Luo, Tao Xiang, and Juan-Manuel Perez-Rua.
\newblock Gentron: Diffusion transformers for image and video generation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 6441--6451, 2024{\natexlab{a}}.

\bibitem[Chen et~al.(2024{\natexlab{b}})Chen, Siarohin, Menapace, Deyneka, Chao, Jeon, Fang, Lee, Ren, Yang, et~al.]{chen2024panda}
Tsai-Shien Chen, Aliaksandr Siarohin, Willi Menapace, Ekaterina Deyneka, Hsiang-wei Chao, Byung~Eun Jeon, Yuwei Fang, Hsin-Ying Lee, Jian Ren, Ming-Hsuan Yang, et~al.
\newblock Panda-70m: Captioning 70m videos with multiple cross-modality teachers.
\newblock In \emph{CVPR}, pages 13320--13331, 2024{\natexlab{b}}.

\bibitem[Chen et~al.(2024{\natexlab{c}})Chen, Long, Qiu, Yao, Zhou, Luo, and Mei]{chen2024learning}
Zhikai Chen, Fuchen Long, Zhaofan Qiu, Ting Yao, Wengang Zhou, Jiebo Luo, and Tao Mei.
\newblock Learning spatial adaptation and temporal coherence in diffusion models for video super-resolution.
\newblock In \emph{CVPR}, pages 9232--9241, 2024{\natexlab{c}}.

\bibitem[Fuoli et~al.(2019)Fuoli, Gu, and Timofte]{fuoli2019efficient}
Dario Fuoli, Shuhang Gu, and Radu Timofte.
\newblock Efficient video super-resolution through recurrent latent space propagation.
\newblock In \emph{2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)}, pages 3476--3485. IEEE, 2019.

\bibitem[Haris et~al.(2019)Haris, Shakhnarovich, and Ukita]{haris2019recurrent}
Muhammad Haris, Gregory Shakhnarovich, and Norimichi Ukita.
\newblock Recurrent back-projection network for video super-resolution.
\newblock In \emph{CVPR}, pages 3897--3906, 2019.

\bibitem[He et~al.(2024)He, Xue, Liu, Lin, Gao, Lin, Qiao, Ouyang, and Liu]{he2024venhancer}
Jingwen He, Tianfan Xue, Dongyang Liu, Xinqi Lin, Peng Gao, Dahua Lin, Yu Qiao, Wanli Ouyang, and Ziwei Liu.
\newblock Venhancer: Generative space-time enhancement for video generation.
\newblock \emph{arXiv preprint arXiv:2407.07667}, 2024.

\bibitem[Henighan et~al.(2020)Henighan, Kaplan, Katz, Chen, Hesse, Jackson, Jun, Brown, Dhariwal, Gray, et~al.]{henighan2020scaling}
Tom Henighan, Jared Kaplan, Mor Katz, Mark Chen, Christopher Hesse, Jacob Jackson, Heewoo Jun, Tom~B Brown, Prafulla Dhariwal, Scott Gray, et~al.
\newblock Scaling laws for autoregressive generative modeling.
\newblock \emph{arXiv preprint arXiv:2010.14701}, 2020.

\bibitem[Ho et~al.(2022)Ho, Chan, Saharia, Whang, Gao, Gritsenko, Kingma, Poole, Norouzi, Fleet, et~al.]{ho2022imagen}
Jonathan Ho, William Chan, Chitwan Saharia, Jay Whang, Ruiqi Gao, Alexey Gritsenko, Diederik~P Kingma, Ben Poole, Mohammad Norouzi, David~J Fleet, et~al.
\newblock Imagen video: High definition video generation with diffusion models.
\newblock \emph{arXiv preprint arXiv:2210.02303}, 2022.

\bibitem[Huang et~al.(2017)Huang, Wang, and Wang]{huang2017video}
Yan Huang, Wei Wang, and Liang Wang.
\newblock Video super-resolution via bidirectional recurrent convolutional networks.
\newblock \emph{IEEE TPAMI}, 40\penalty0 (4):\penalty0 1015--1028, 2017.

\bibitem[Isobe et~al.(2020)Isobe, Jia, Gu, Li, Wang, and Tian]{isobe2020video}
Takashi Isobe, Xu Jia, Shuhang Gu, Songjiang Li, Shengjin Wang, and Qi Tian.
\newblock Video super-resolution with recurrent structure-detail network.
\newblock In \emph{ECCV}, pages 645--660. Springer, 2020.

\bibitem[Jo et~al.(2018)Jo, Oh, Kang, and Kim]{jo2018deep}
Younghyun Jo, Seoung~Wug Oh, Jaeyeon Kang, and Seon~Joo Kim.
\newblock Deep video super-resolution network using dynamic upsampling filters without explicit motion compensation.
\newblock In \emph{CVPR}, pages 3224--3232, 2018.

\bibitem[Kaplan et~al.(2020)Kaplan, McCandlish, Henighan, Brown, Chess, Child, Gray, Radford, Wu, and Amodei]{kaplan2020scaling}
Jared Kaplan, Sam McCandlish, Tom Henighan, Tom~B Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei.
\newblock Scaling laws for neural language models.
\newblock \emph{arXiv preprint arXiv:2001.08361}, 2020.

\bibitem[Kingma(2013)]{kingma2013auto}
Diederik~P Kingma.
\newblock Auto-encoding variational bayes.
\newblock \emph{arXiv preprint arXiv:1312.6114}, 2013.

\bibitem[Kong et~al.(2022)Kong, Li, Liu, Liu, He, Bai, Chen, and Fu]{kong2022residual}
Fangyuan Kong, Mingxi Li, Songwei Liu, Ding Liu, Jingwen He, Yang Bai, Fangmin Chen, and Lean Fu.
\newblock Residual local feature network for efficient super-resolution.
\newblock In \emph{CVPR}, pages 766--776, 2022.

\bibitem[Lai et~al.(2018)Lai, Huang, Wang, Shechtman, Yumer, and Yang]{Lai2018warping}
Wei-Sheng Lai, Jia-Bin Huang, Oliver Wang, Eli Shechtman, Ersin Yumer, and Ming-Hsuan Yang.
\newblock Learning blind video temporal consistency.
\newblock In \emph{ECCV}, 2018.

\bibitem[Li et~al.(2020)Li, Tao, Guo, Qi, Lu, and Jia]{li2020mucan}
Wenbo Li, Xin Tao, Taian Guo, Lu Qi, Jiangbo Lu, and Jiaya Jia.
\newblock Mucan: Multi-correspondence aggregation network for video super-resolution.
\newblock In \emph{ECCV}, pages 335--351. Springer, 2020.

\bibitem[Liang et~al.(2022)Liang, Fan, Xiang, Ranjan, Ilg, Green, Cao, Zhang, Timofte, and Gool]{liang2022recurrent}
Jingyun Liang, Yuchen Fan, Xiaoyu Xiang, Rakesh Ranjan, Eddy Ilg, Simon Green, Jiezhang Cao, Kai Zhang, Radu Timofte, and Luc~V Gool.
\newblock Recurrent video restoration transformer with guided deformable attention.
\newblock \emph{NeurIPS}, 35:\penalty0 378--393, 2022.

\bibitem[Liang et~al.(2024)Liang, Cao, Fan, Zhang, Ranjan, Li, Timofte, and Van~Gool]{liang2024vrt}
Jingyun Liang, Jiezhang Cao, Yuchen Fan, Kai Zhang, Rakesh Ranjan, Yawei Li, Radu Timofte, and Luc Van~Gool.
\newblock Vrt: A video restoration transformer.
\newblock \emph{IEEE TIP}, 2024.

\bibitem[Lin et~al.(2023)Lin, He, Chen, Lyu, Dai, Yu, Ouyang, Qiao, and Dong]{lin2023diffbir}
Xinqi Lin, Jingwen He, Ziyan Chen, Zhaoyang Lyu, Bo Dai, Fanghua Yu, Wanli Ouyang, Yu Qiao, and Chao Dong.
\newblock Diffbir: Towards blind image restoration with generative diffusion prior.
\newblock \emph{arXiv preprint arXiv:2308.15070}, 2023.

\bibitem[Liu et~al.(2021)Liu, Shao, and Hoffmann]{liu2021global}
Yichao Liu, Zongru Shao, and Nico Hoffmann.
\newblock Global attention mechanism: Retain information to enhance channel-spatial interactions.
\newblock \emph{arXiv preprint arXiv:2112.05561}, 2021.

\bibitem[Liu et~al.(2024)Liu, Cun, Liu, Wang, Zhang, Chen, Liu, Zeng, Chan, and Shan]{liu2024evalcrafter}
Yaofang Liu, Xiaodong Cun, Xuebo Liu, Xintao Wang, Yong Zhang, Haoxin Chen, Yang Liu, Tieyong Zeng, Raymond Chan, and Ying Shan.
\newblock Evalcrafter: Benchmarking and evaluating large video generation models.
\newblock In \emph{CVPR}, pages 22139--22149, 2024.

\bibitem[Loshchilov(2017)]{loshchilov2017decoupled}
I Loshchilov.
\newblock Decoupled weight decay regularization.
\newblock \emph{arXiv preprint arXiv:1711.05101}, 2017.

\bibitem[Mikolov et~al.(2010)Mikolov, Karafi{\'a}t, Burget, Cernock{\`y}, and Khudanpur]{mikolov2010recurrent}
Tomas Mikolov, Martin Karafi{\'a}t, Lukas Burget, Jan Cernock{\`y}, and Sanjeev Khudanpur.
\newblock Recurrent neural network based language model.
\newblock In \emph{Interspeech}, pages 1045--1048. Makuhari, 2010.

\bibitem[Nah et~al.(2019)Nah, Baik, Hong, Moon, Son, Timofte, and Mu~Lee]{nah2019ntire}
Seungjun Nah, Sungyong Baik, Seokil Hong, Gyeongsik Moon, Sanghyun Son, Radu Timofte, and Kyoung Mu~Lee.
\newblock Ntire 2019 challenge on video deblurring and super-resolution: Dataset and study.
\newblock In \emph{CVPRW}, pages 0--0, 2019.

\bibitem[Nan et~al.(2024)Nan, Xie, Zhou, Fan, Yang, Chen, Li, Yang, and Tai]{nan2024openvid}
Kepan Nan, Rui Xie, Penghao Zhou, Tiehan Fan, Zhenheng Yang, Zhijie Chen, Xiang Li, Jian Yang, and Ying Tai.
\newblock Openvid-1m: A large-scale high-quality dataset for text-to-video generation.
\newblock \emph{arXiv preprint arXiv:2407.02371}, 2024.

\bibitem[OpenAI(2024)]{sora}
OpenAI.
\newblock Sora, 2024.
\newblock \url{https://openai.com/index/sora}.

\bibitem[Pan et~al.(2021)Pan, Bai, Dong, Zhang, and Tang]{pan2021deep}
Jinshan Pan, Haoran Bai, Jiangxin Dong, Jiawei Zhang, and Jinhui Tang.
\newblock Deep blind video super-resolution.
\newblock In \emph{ICCV}, pages 4811--4820, 2021.

\bibitem[Peebles and Xie(2023)]{peebles2023scalable}
William Peebles and Saining Xie.
\newblock Scalable diffusion models with transformers.
\newblock In \emph{ICCV}, pages 4195--4205, 2023.

\bibitem[Polyak et~al.(2024)Polyak, Zohar, Brown, Tjandra, Sinha, Lee, Vyas, Shi, Ma, Chuang, et~al.]{polyak2024movie}
Adam Polyak, Amit Zohar, Andrew Brown, Andros Tjandra, Animesh Sinha, Ann Lee, Apoorv Vyas, Bowen Shi, Chih-Yao Ma, Ching-Yao Chuang, et~al.
\newblock Movie gen: A cast of media foundation models.
\newblock \emph{arXiv preprint arXiv:2410.13720}, 2024.

\bibitem[Radford et~al.(2021)Radford, Kim, Hallacy, Ramesh, Goh, Agarwal, Sastry, Askell, Mishkin, Clark, et~al.]{radford2021learning}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et~al.
\newblock Learning transferable visual models from natural language supervision.
\newblock In \emph{International conference on machine learning}, pages 8748--8763. PMLR, 2021.

\bibitem[Raffel et~al.(2020)Raffel, Shazeer, Roberts, Lee, Narang, Matena, Zhou, Li, and Liu]{raffel2020exploring}
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter~J Liu.
\newblock Exploring the limits of transfer learning with a unified text-to-text transformer.
\newblock \emph{Journal of machine learning research}, 21\penalty0 (140):\penalty0 1--67, 2020.

\bibitem[Rombach et~al.(2022)Rombach, Blattmann, Lorenz, Esser, and Ommer]{rombach2022high}
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj{\"o}rn Ommer.
\newblock High-resolution image synthesis with latent diffusion models.
\newblock In \emph{CVPR}, pages 10684--10695, 2022.

\bibitem[Sajjadi et~al.(2018)Sajjadi, Vemulapalli, and Brown]{sajjadi2018frame}
Mehdi~SM Sajjadi, Raviteja Vemulapalli, and Matthew Brown.
\newblock Frame-recurrent video super-resolution.
\newblock In \emph{CVPR}, pages 6626--6634, 2018.

\bibitem[Salimans and Ho(2022)]{salimans2022progressive}
Tim Salimans and Jonathan Ho.
\newblock Progressive distillation for fast sampling of diffusion models.
\newblock \emph{arXiv preprint arXiv:2202.00512}, 2022.

\bibitem[Shi et~al.(2022)Shi, Gu, Xie, Wang, Yang, and Dong]{shi2022rethinking}
Shuwei Shi, Jinjin Gu, Liangbin Xie, Xintao Wang, Yujiu Yang, and Chao Dong.
\newblock Rethinking alignment in video super-resolution transformers.
\newblock \emph{NeurIPS}, 35:\penalty0 36081--36093, 2022.

\bibitem[Singer et~al.(2022)Singer, Polyak, Hayes, Yin, An, Zhang, Hu, Yang, Ashual, Gafni, et~al.]{singer2022make}
Uriel Singer, Adam Polyak, Thomas Hayes, Xi Yin, Jie An, Songyang Zhang, Qiyuan Hu, Harry Yang, Oron Ashual, Oran Gafni, et~al.
\newblock Make-a-video: Text-to-video generation without text-video data.
\newblock \emph{arXiv preprint arXiv:2209.14792}, 2022.

\bibitem[Wang et~al.(2024)Wang, Yue, Zhou, Chan, and Loy]{wang2024exploiting}
Jianyi Wang, Zongsheng Yue, Shangchen Zhou, Kelvin~CK Chan, and Chen~Change Loy.
\newblock Exploiting diffusion prior for real-world image super-resolution.
\newblock \emph{IJCV}, pages 1--21, 2024.

\bibitem[Wang and Yang(2024)]{wang2024vidprom}
Wenhao Wang and Yi Yang.
\newblock Vidprom: A million-scale real prompt-gallery dataset for text-to-video diffusion models.
\newblock \emph{arXiv preprint arXiv:2403.06098}, 2024.

\bibitem[Wang et~al.(2019)Wang, Chan, Yu, Dong, and Change~Loy]{wang2019edvr}
Xintao Wang, Kelvin~CK Chan, Ke Yu, Chao Dong, and Chen Change~Loy.
\newblock Edvr: Video restoration with enhanced deformable convolutional networks.
\newblock In \emph{CVPRW}, pages 0--0, 2019.

\bibitem[Wang et~al.(2021)Wang, Xie, Dong, and Shan]{wang2021realesrgan}
Xintao Wang, Liangbin Xie, Chao Dong, and Ying Shan.
\newblock Real-esrgan: Training real-world blind super-resolution with pure synthetic data.
\newblock In \emph{ICCV}, pages 1905--1914, 2021.

\bibitem[Wang et~al.(2023{\natexlab{a}})Wang, Chen, Ma, Zhou, Huang, Wang, Yang, He, Yu, Yang, et~al.]{wang2023lavie}
Yaohui Wang, Xinyuan Chen, Xin Ma, Shangchen Zhou, Ziqi Huang, Yi Wang, Ceyuan Yang, Yinan He, Jiashuo Yu, Peiqing Yang, et~al.
\newblock Lavie: High-quality video generation with cascaded latent diffusion models.
\newblock \emph{arXiv preprint arXiv:2309.15103}, 2023{\natexlab{a}}.

\bibitem[Wang et~al.(2023{\natexlab{b}})Wang, He, Li, Li, Yu, Ma, Li, Chen, Chen, Wang, et~al.]{wang2023internvid}
Yi Wang, Yinan He, Yizhuo Li, Kunchang Li, Jiashuo Yu, Xin Ma, Xinhao Li, Guo Chen, Xinyuan Chen, Yaohui Wang, et~al.
\newblock Internvid: A large-scale video-text dataset for multimodal understanding and generation.
\newblock \emph{arXiv preprint arXiv:2307.06942}, 2023{\natexlab{b}}.

\bibitem[Wang et~al.(2004)Wang, Bovik, Sheikh, and Simoncelli]{wang2004image}
Zhou Wang, Alan~C Bovik, Hamid~R Sheikh, and Eero~P Simoncelli.
\newblock Image quality assessment: from error visibility to structural similarity.
\newblock \emph{IEEE TIP}, 13\penalty0 (4):\penalty0 600--612, 2004.

\bibitem[Woo et~al.(2018)Woo, Park, Lee, and Kweon]{woo2018cbam}
Sanghyun Woo, Jongchan Park, Joon-Young Lee, and In~So Kweon.
\newblock Cbam: Convolutional block attention module.
\newblock In \emph{ECCV}, pages 3--19, 2018.

\bibitem[Wu et~al.(2023)Wu, Zhang, Liao, Chen, Hou, Wang, Sun, Yan, and Lin]{wu2023dover}
Haoning Wu, Erli Zhang, Liang Liao, Chaofeng Chen, Jingwen~Hou Hou, Annan Wang, Wenxiu~Sun Sun, Qiong Yan, and Weisi Lin.
\newblock Exploring video quality assessment on user generated contents from aesthetic and technical perspectives.
\newblock In \emph{ICCV}, 2023.

\bibitem[Wu et~al.(2024)Wu, Yang, Sun, Zhang, Li, and Zhang]{wu2024seesr}
Rongyuan Wu, Tao Yang, Lingchen Sun, Zhengqiang Zhang, Shuai Li, and Lei Zhang.
\newblock Seesr: Towards semantics-aware real-world image super-resolution.
\newblock In \emph{CVPR}, pages 25456--25467, 2024.

\bibitem[Wu et~al.(2022)Wu, Wang, Li, and Shan]{wu2022animesr}
Yanze Wu, Xintao Wang, Gen Li, and Ying Shan.
\newblock Animesr: Learning real-world super-resolution models for animation videos.
\newblock \emph{NeurIPS}, 35:\penalty0 11241--11252, 2022.

\bibitem[Xu et~al.(2021)Xu, Xu, Li, Wang, Sun, and Cheng]{xu2021temporal}
Gang Xu, Jun Xu, Zhen Li, Liang Wang, Xing Sun, and Ming-Ming Cheng.
\newblock Temporal modulation network for controllable space-time video super-resolution.
\newblock In \emph{CVPR}, pages 6388--6397, 2021.

\bibitem[Xue et~al.(2019)Xue, Chen, Wu, Wei, and Freeman]{xue2019video}
Tianfan Xue, Baian Chen, Jiajun Wu, Donglai Wei, and William~T Freeman.
\newblock Video enhancement with task-oriented flow.
\newblock \emph{IJCV}, 127:\penalty0 1106--1125, 2019.

\bibitem[Yang et~al.(2023)Yang, Wu, Ren, Xie, and Zhang]{yang2023pixel}
Tao Yang, Rongyuan Wu, Peiran Ren, Xuansong Xie, and Lei Zhang.
\newblock Pixel-aware stable diffusion for realistic image super-resolution and personalized stylization.
\newblock \emph{arXiv preprint arXiv:2308.14469}, 2023.

\bibitem[Yang et~al.(2021)Yang, Xiang, Zeng, and Zhang]{yang2021realvsr}
Xi Yang, Wangmeng Xiang, Hui Zeng, and Lei Zhang.
\newblock Real-world video super-resolution: A benchmark dataset and a decomposition based learning scheme.
\newblock In \emph{ICCV}, pages 4781--4790, 2021.

\bibitem[Yang et~al.(2024{\natexlab{a}})Yang, He, Ma, and Zhang]{yang2023mgldvsr}
Xi Yang, Chenhang He, Jianqi Ma, and Lei Zhang.
\newblock Motion-guided latent diffusion for temporally consistent real-world video super-resolution.
\newblock 2024{\natexlab{a}}.

\bibitem[Yang et~al.(2024{\natexlab{b}})Yang, Teng, Zheng, Ding, Huang, Xu, Yang, Hong, Zhang, Feng, et~al.]{yang2024cogvideox}
Zhuoyi Yang, Jiayan Teng, Wendi Zheng, Ming Ding, Shiyu Huang, Jiazheng Xu, Yuanming Yang, Wenyi Hong, Xiaohan Zhang, Guanyu Feng, et~al.
\newblock Cogvideox: Text-to-video diffusion models with an expert transformer.
\newblock \emph{arXiv preprint arXiv:2408.06072}, 2024{\natexlab{b}}.

\bibitem[Yi et~al.(2019)Yi, Wang, Jiang, Jiang, and Ma]{yi2019progressive}
Peng Yi, Zhongyuan Wang, Kui Jiang, Junjun Jiang, and Jiayi Ma.
\newblock Progressive fusion video super-resolution network via exploiting non-local spatio-temporal correlations.
\newblock In \emph{ICCV}, pages 3106--3115, 2019.

\bibitem[Yu et~al.(2024)Yu, Gu, Li, Hu, Kong, Wang, He, Qiao, and Dong]{yu2024scaling}
Fanghua Yu, Jinjin Gu, Zheyuan Li, Jinfan Hu, Xiangtao Kong, Xintao Wang, Jingwen He, Yu Qiao, and Chao Dong.
\newblock Scaling up to excellence: Practicing model scaling for photo-realistic image restoration in the wild.
\newblock In \emph{CVPR}, pages 25669--25680, 2024.

\bibitem[Yuan et~al.(2024)Yuan, Baek, Xu, Tov, and Fei]{yuan2024inflation}
Xin Yuan, Jinoo Baek, Keyang Xu, Omer Tov, and Hongliang Fei.
\newblock Inflation with diffusion: Efficient temporal adaptation for text-to-video super-resolution.
\newblock In \emph{Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision}, pages 489--496, 2024.

\bibitem[Yue et~al.(2024)Yue, Wang, and Loy]{yue2024resshift}
Zongsheng Yue, Jianyi Wang, and Chen~Change Loy.
\newblock Resshift: Efficient diffusion model for image super-resolution by residual shifting.
\newblock \emph{NeurIPS}, 36, 2024.

\bibitem[Zhang et~al.(2015)Zhang, Zhang, and Bovik]{zhang2015ilniqe}
Lin Zhang, Lei Zhang, and Alan~C Bovik.
\newblock A feature-enriched completely blind image quality evaluator.
\newblock \emph{IEEE TIP}, 24\penalty0 (8):\penalty0 2579--2591, 2015.

\bibitem[Zhang et~al.(2023{\natexlab{a}})Zhang, Rao, and Agrawala]{zhang2023adding}
Lvmin Zhang, Anyi Rao, and Maneesh Agrawala.
\newblock Adding conditional control to text-to-image diffusion models.
\newblock In \emph{ICCV}, pages 3836--3847, 2023{\natexlab{a}}.

\bibitem[Zhang et~al.(2018)Zhang, Isola, Efros, Shechtman, and Wang]{zhang2018lpips}
Richard Zhang, Phillip Isola, Alexei~A Efros, Eli Shechtman, and Oliver Wang.
\newblock The unreasonable effectiveness of deep features as a perceptual metric.
\newblock In \emph{CVPR}, pages 586--595, 2018.

\bibitem[Zhang et~al.(2023{\natexlab{b}})Zhang, Wang, Zhang, Zhao, Yuan, Qin, Wang, Zhao, and Zhou]{zhang2023i2vgen}
Shiwei Zhang, Jiayu Wang, Yingya Zhang, Kang Zhao, Hangjie Yuan, Zhiwu Qin, Xiang Wang, Deli Zhao, and Jingren Zhou.
\newblock I2vgen-xl: High-quality image-to-video synthesis via cascaded diffusion models.
\newblock \emph{arXiv preprint arXiv:2311.04145}, 2023{\natexlab{b}}.

\bibitem[Zhang and Yao(2024)]{zhang2024realviformer}
Yuehan Zhang and Angela Yao.
\newblock Realviformer: Investigating attention for real-world video super-resolution.
\newblock \emph{ECCV}, 2024.

\bibitem[Zhao et~al.(2024)Zhao, Cai, Dong, and Hu]{zhao2024wavelet}
Chen Zhao, Weiling Cai, Chenyu Dong, and Chengwei Hu.
\newblock Wavelet-based fourier information interaction with frequency diffusion adjustment for underwater image restoration.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 8281--8291, 2024.

\bibitem[Zhou et~al.(2024)Zhou, Yang, Wang, Luo, and Loy]{zhou2024upscale}
Shangchen Zhou, Peiqing Yang, Jianyi Wang, Yihang Luo, and Chen~Change Loy.
\newblock Upscale-a-video: Temporal-consistent diffusion model for real-world video super-resolution.
\newblock In \emph{CVPR}, pages 2535--2545, 2024.

\end{thebibliography}
