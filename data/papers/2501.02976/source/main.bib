@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})


@inproceedings{zhou2024upscale,
  title={Upscale-A-Video: Temporal-Consistent Diffusion Model for Real-World Video Super-Resolution},
  author={Zhou, Shangchen and Yang, Peiqing and Wang, Jianyi and Luo, Yihang and Loy, Chen Change},
  booktitle=CVPR,
  pages={2535--2545},
  year={2024}
}

@article{ho2020denoising,
  title={Denoising diffusion probabilistic models},
  author={Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  journal=NIPS,
  volume={33},
  pages={6840--6851},
  year={2020}
}

@inproceedings{ronneberger2015u,
  title={U-net: Convolutional networks for biomedical image segmentation},
  author={Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  booktitle={Medical image computing and computer-assisted intervention--MICCAI 2015: 18th international conference, Munich, Germany, October 5-9, 2015, proceedings, part III 18},
  pages={234--241},
  year={2015},
  organization={Springer}
}

@inproceedings{rombach2022high,
  title={High-resolution image synthesis with latent diffusion models},
  author={Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\"o}rn},
  booktitle=CVPR,
  pages={10684--10695},
  year={2022}
}

@article{saharia2022photorealistic,
  title={Photorealistic text-to-image diffusion models with deep language understanding},
  author={Saharia, Chitwan and Chan, William and Saxena, Saurabh and Li, Lala and Whang, Jay and Denton, Emily L and Ghasemipour, Kamyar and Gontijo Lopes, Raphael and Karagol Ayan, Burcu and Salimans, Tim and others},
  journal=NIPS,
  volume={35},
  pages={36479--36494},
  year={2022}
}
@inproceedings{blattmann2023align,
  title={Align your latents: High-resolution video synthesis with latent diffusion models},
  author={Blattmann, Andreas and Rombach, Robin and Ling, Huan and Dockhorn, Tim and Kim, Seung Wook and Fidler, Sanja and Kreis, Karsten},
  booktitle=CVPR,
  pages={22563--22575},
  year={2023}
}

@article{zhang2023i2vgen,
  title={I2vgen-xl: High-quality image-to-video synthesis via cascaded diffusion models},
  author={Zhang, Shiwei and Wang, Jiayu and Zhang, Yingya and Zhao, Kang and Yuan, Hangjie and Qin, Zhiwu and Wang, Xiang and Zhao, Deli and Zhou, Jingren},
  journal={arXiv preprint arXiv:2311.04145},
  year={2023}
}

@article{yang2024cogvideox,
  title={Cogvideox: Text-to-video diffusion models with an expert transformer},
  author={Yang, Zhuoyi and Teng, Jiayan and Zheng, Wendi and Ding, Ming and Huang, Shiyu and Xu, Jiazheng and Yang, Yuanming and Hong, Wenyi and Zhang, Xiaohan and Feng, Guanyu and others},
  journal={arXiv preprint arXiv:2408.06072},
  year={2024}
}

@article{medsker2001recurrent,
  title={Recurrent neural networks},
  author={Medsker, Larry R and Jain, Lakhmi and others},
  journal={Design and Applications},
  volume={5},
  number={64-67},
  pages={2},
  year={2001}
}

@inproceedings{chan2022investigating,
  title={Investigating tradeoffs in real-world video super-resolution},
  author={Chan, Kelvin CK and Zhou, Shangchen and Xu, Xiangyu and Loy, Chen Change},
  booktitle=CVPR,
  pages={5962--5971},
  year={2022}
}

@inproceedings{chan2021basicvsr,
  title={Basicvsr: The search for essential components in video super-resolution and beyond},
  author={Chan, Kelvin CK and Wang, Xintao and Yu, Ke and Dong, Chao and Loy, Chen Change},
  booktitle=CVPR,
  pages={4947--4956},
  year={2021}
}

@article{zhang2024realviformer,
  title={RealViformer: Investigating Attention for Real-World Video Super-Resolution},
  author={Zhang, Yuehan and Yao, Angela},
  journal=ECCV,
  year={2024}
}

@article{videoworldsimulators2024,
  title={Video generation models as world simulators},
  author={Tim Brooks and Bill Peebles and Connor Holmes and Will DePue and Yufei Guo and Li Jing and David Schnurr and Joe Taylor and Troy Luhman and Eric Luhman and Clarence Ng and Ricky Wang and Aditya Ramesh},
  year={2024},
  url={https://openai.com/research/video-generation-models-as-world-simulators},
}

@article{ho2022imagen,
  title={Imagen video: High definition video generation with diffusion models},
  author={Ho, Jonathan and Chan, William and Saharia, Chitwan and Whang, Jay and Gao, Ruiqi and Gritsenko, Alexey and Kingma, Diederik P and Poole, Ben and Norouzi, Mohammad and Fleet, David J and others},
  journal={arXiv preprint arXiv:2210.02303},
  year={2022}
}

@article{singer2022make,
  title={Make-a-video: Text-to-video generation without text-video data},
  author={Singer, Uriel and Polyak, Adam and Hayes, Thomas and Yin, Xi and An, Jie and Zhang, Songyang and Hu, Qiyuan and Yang, Harry and Ashual, Oron and Gafni, Oran and others},
  journal={arXiv preprint arXiv:2209.14792},
  year={2022}
}

@article{blattmann2023stable,
  title={Stable video diffusion: Scaling latent video diffusion models to large datasets},
  author={Blattmann, Andreas and Dockhorn, Tim and Kulal, Sumith and Mendelevitch, Daniel and Kilian, Maciej and Lorenz, Dominik and Levi, Yam and English, Zion and Voleti, Vikram and Letts, Adam and others},
  journal={arXiv preprint arXiv:2311.15127},
  year={2023}
}

@inproceedings{peebles2023scalable,
  title={Scalable diffusion models with transformers},
  author={Peebles, William and Xie, Saining},
  booktitle=ICCV,
  pages={4195--4205},
  year={2023}
}

@article{wang2024exploiting,
  title={Exploiting diffusion prior for real-world image super-resolution},
  author={Wang, Jianyi and Yue, Zongsheng and Zhou, Shangchen and Chan, Kelvin CK and Loy, Chen Change},
  journal=IJCV,
  pages={1--21},
  year={2024},
  publisher={Springer}
}

@article{lin2023diffbir,
  title={Diffbir: Towards blind image restoration with generative diffusion prior},
  author={Lin, Xinqi and He, Jingwen and Chen, Ziyan and Lyu, Zhaoyang and Dai, Bo and Yu, Fanghua and Ouyang, Wanli and Qiao, Yu and Dong, Chao},
  journal={arXiv preprint arXiv:2308.15070},
  year={2023}
}

@article{yeh2024diffir2vr,
  title={DiffIR2VR-Zero: Zero-Shot Video Restoration with Diffusion-based Image Restoration Models},
  author={Yeh, Chang-Han and Lin, Chin-Yang and Wang, Zhixiang and Hsiao, Chi-Wei and Chen, Ting-Hsuan and Liu, Yu-Lun},
  journal={arXiv preprint arXiv:2407.01519},
  year={2024}
}

@article{yang2023pixel,
  title={Pixel-aware stable diffusion for realistic image super-resolution and personalized stylization},
  author={Yang, Tao and Wu, Rongyuan and Ren, Peiran and Xie, Xuansong and Zhang, Lei},
  journal={arXiv preprint arXiv:2308.14469},
  year={2023}
}

@inproceedings{wu2024seesr,
  title={Seesr: Towards semantics-aware real-world image super-resolution},
  author={Wu, Rongyuan and Yang, Tao and Sun, Lingchen and Zhang, Zhengqiang and Li, Shuai and Zhang, Lei},
  booktitle=CVPR,
  pages={25456--25467},
  year={2024}
}


@inproceedings{yuan2024inflation,
  title={Inflation with Diffusion: Efficient Temporal Adaptation for Text-to-Video Super-Resolution},
  author={Yuan, Xin and Baek, Jinoo and Xu, Keyang and Tov, Omer and Fei, Hongliang},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={489--496},
  year={2024}
}

@inproceedings{chen2024learning,
  title={Learning Spatial Adaptation and Temporal Coherence in Diffusion Models for Video Super-Resolution},
  author={Chen, Zhikai and Long, Fuchen and Qiu, Zhaofan and Yao, Ting and Zhou, Wengang and Luo, Jiebo and Mei, Tao},
  booktitle=CVPR,
  pages={9232--9241},
  year={2024}
}

@article{kingma2013auto,
  title={Auto-encoding variational bayes},
  author={Kingma, Diederik P},
  journal={arXiv preprint arXiv:1312.6114},
  year={2013}
}

@inproceedings{zhang2023adding,
  title={Adding conditional control to text-to-image diffusion models},
  author={Zhang, Lvmin and Rao, Anyi and Agrawala, Maneesh},
  booktitle=ICCV,
  pages={3836--3847},
  year={2023}
}

@article{liu2021global,
  title={Global attention mechanism: Retain information to enhance channel-spatial interactions},
  author={Liu, Yichao and Shao, Zongru and Hoffmann, Nico},
  journal={arXiv preprint arXiv:2112.05561},
  year={2021}
}

@article{nan2024openvid,
  title={Openvid-1m: A large-scale high-quality dataset for text-to-video generation},
  author={Nan, Kepan and Xie, Rui and Zhou, Penghao and Fan, Tiehan and Yang, Zhenheng and Chen, Zhijie and Li, Xiang and Yang, Jian and Tai, Ying},
  journal={arXiv preprint arXiv:2407.02371},
  year={2024}
}

@inproceedings{wang2021realesrgan,
  title={Real-esrgan: Training real-world blind super-resolution with pure synthetic data},
  author={Wang, Xintao and Xie, Liangbin and Dong, Chao and Shan, Ying},
  booktitle=ICCV,
  pages={1905--1914},
  year={2021}
}

@inproceedings{yi2019progressive,
  title={Progressive fusion video super-resolution network via exploiting non-local spatio-temporal correlations},
  author={Yi, Peng and Wang, Zhongyuan and Jiang, Kui and Jiang, Junjun and Ma, Jiayi},
  booktitle=ICCV,
  pages={3106--3115},
  year={2019}
}

@inproceedings{nah2019ntire,
  title={Ntire 2019 challenge on video deblurring and super-resolution: Dataset and study},
  author={Nah, Seungjun and Baik, Sungyong and Hong, Seokil and Moon, Gyeongsik and Son, Sanghyun and Timofte, Radu and Mu Lee, Kyoung},
  booktitle=CVPRW,
  pages={0--0},
  year={2019}
}

@article{wang2004image,
  title={Image quality assessment: from error visibility to structural similarity},
  author={Wang, Zhou and Bovik, Alan C and Sheikh, Hamid R and Simoncelli, Eero P},
  journal=TIP,
  volume={13},
  number={4},
  pages={600--612},
  year={2004},
  publisher={IEEE}
}

@inproceedings{zhang2018lpips,
  title={The unreasonable effectiveness of deep features as a perceptual metric},
  author={Zhang, Richard and Isola, Phillip and Efros, Alexei A and Shechtman, Eli and Wang, Oliver},
  booktitle=CVPR,
  pages={586--595},
  year={2018}
}

@inproceedings{Lai2018warping,
    author    = {Lai, Wei-Sheng and Huang, Jia-Bin and Wang, Oliver and Shechtman, Eli and Yumer, Ersin and Yang, Ming-Hsuan}, 
    title     = {Learning Blind Video Temporal Consistency}, 
    booktitle = ECCV,
    year      = {2018}
}

@inproceedings{liu2024evalcrafter,
  title={Evalcrafter: Benchmarking and evaluating large video generation models},
  author={Liu, Yaofang and Cun, Xiaodong and Liu, Xuebo and Wang, Xintao and Zhang, Yong and Chen, Haoxin and Liu, Yang and Zeng, Tieyong and Chan, Raymond and Shan, Ying},
  booktitle=CVPR,
  pages={22139--22149},
  year={2024}
}

@inproceedings{wu2023dover,
      title={Exploring Video Quality Assessment on User Generated Contents from Aesthetic and Technical Perspectives}, 
      author={Wu, Haoning and Zhang, Erli and Liao, Liang and Chen, Chaofeng and Hou, Jingwen Hou and Wang, Annan and Sun, Wenxiu Sun and Yan, Qiong and Lin, Weisi},
      year={2023},
      booktitle=ICCV
}

@article{zhang2015ilniqe,
  title={A feature-enriched completely blind image quality evaluator},
  author={Zhang, Lin and Zhang, Lei and Bovik, Alan C},
  journal=TIP,
  volume={24},
  number={8},
  pages={2579--2591},
  year={2015},
  publisher={IEEE}
}

@inproceedings{yang2021realvsr,
  title={Real-world video super-resolution: A benchmark dataset and a decomposition based learning scheme},
  author={Yang, Xi and Xiang, Wangmeng and Zeng, Hui and Zhang, Lei},
  booktitle=ICCV,
  pages={4781--4790},
  year={2021}
}

@inproceedings{pan2021deep,
  title={Deep blind video super-resolution},
  author={Pan, Jinshan and Bai, Haoran and Dong, Jiangxin and Zhang, Jiawei and Tang, Jinhui},
  booktitle=ICCV,
  pages={4811--4820},
  year={2021}
}

@article{yue2024resshift,
  title={Resshift: Efficient diffusion model for image super-resolution by residual shifting},
  author={Yue, Zongsheng and Wang, Jianyi and Loy, Chen Change},
  journal=NIPS,
  volume={36},
  year={2024}
}

@misc{sdx4,
  title     = {Stable Diffusion x4 Upscaler},
  year      = {2023},
  note = {\url{https://huggingface.co/stabilityai/stable-diffusion-x4-upscaler}}
}


@misc{cogvideox5b,
  title     = {CogVideoX-5b},
  year      = {2024},
  note = {\url{https://huggingface.co/THUDM/CogVideoX-5b}}
}

@misc{cogvideox2b,
  title     = {CogVideoX-2b},
  year      = {2024},
  note = {\url{https://huggingface.co/THUDM/CogVideoX-2b}}
}

@misc{sora,
    author={OpenAI},
    title={Sora},
    year={2024},
    note = {\url{https://openai.com/index/sora}}
}

@inproceedings{woo2018cbam,
  title={Cbam: Convolutional block attention module},
  author={Woo, Sanghyun and Park, Jongchan and Lee, Joon-Young and Kweon, In So},
  booktitle=ECCV,
  pages={3--19},
  year={2018}
}

@inproceedings{fuoli2019efficient,
  title={Efficient video super-resolution through recurrent latent space propagation},
  author={Fuoli, Dario and Gu, Shuhang and Timofte, Radu},
  booktitle={2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)},
  pages={3476--3485},
  year={2019},
  organization={IEEE}
}

@inproceedings{isobe2020video,
  title={Video super-resolution with recurrent structure-detail network},
  author={Isobe, Takashi and Jia, Xu and Gu, Shuhang and Li, Songjiang and Wang, Shengjin and Tian, Qi},
  booktitle=ECCV,
  pages={645--660},
  year={2020},
  organization={Springer}
}

@inproceedings{wang2019edvr,
  title={Edvr: Video restoration with enhanced deformable convolutional networks},
  author={Wang, Xintao and Chan, Kelvin CK and Yu, Ke and Dong, Chao and Change Loy, Chen},
  booktitle=CVPRW,
  pages={0--0},
  year={2019}
}

@inproceedings{chan2022basicvsr++,
  title={Basicvsr++: Improving video super-resolution with enhanced propagation and alignment},
  author={Chan, Kelvin CK and Zhou, Shangchen and Xu, Xiangyu and Loy, Chen Change},
  booktitle=CVPR,
  pages={5972--5981},
  year={2022}
}

@inproceedings{jo2018deep,
  title={Deep video super-resolution network using dynamic upsampling filters without explicit motion compensation},
  author={Jo, Younghyun and Oh, Seoung Wug and Kang, Jaeyeon and Kim, Seon Joo},
  booktitle=CVPR,
  pages={3224--3232},
  year={2018}
}

@article{xue2019video,
  title={Video enhancement with task-oriented flow},
  author={Xue, Tianfan and Chen, Baian and Wu, Jiajun and Wei, Donglai and Freeman, William T},
  journal=IJCV,
  volume={127},
  pages={1106--1125},
  year={2019},
  publisher={Springer}
}

@article{wu2022animesr,
  title={Animesr: Learning real-world super-resolution models for animation videos},
  author={Wu, Yanze and Wang, Xintao and Li, Gen and Shan, Ying},
  journal=NIPS,
  volume={35},
  pages={11241--11252},
  year={2022}
}



@inproceedings{chen2024panda,
  title={Panda-70m: Captioning 70m videos with multiple cross-modality teachers},
  author={Chen, Tsai-Shien and Siarohin, Aliaksandr and Menapace, Willi and Deyneka, Ekaterina and Chao, Hsiang-wei and Jeon, Byung Eun and Fang, Yuwei and Lee, Hsin-Ying and Ren, Jian and Yang, Ming-Hsuan and others},
  booktitle=CVPR,
  pages={13320--13331},
  year={2024}
}

@article{wang2023internvid,
  title={Internvid: A large-scale video-text dataset for multimodal understanding and generation},
  author={Wang, Yi and He, Yinan and Li, Yizhuo and Li, Kunchang and Yu, Jiashuo and Ma, Xin and Li, Xinhao and Chen, Guo and Chen, Xinyuan and Wang, Yaohui and others},
  journal={arXiv preprint arXiv:2307.06942},
  year={2023}
}

@article{wang2024vidprom,
  title={Vidprom: A million-scale real prompt-gallery dataset for text-to-video diffusion models},
  author={Wang, Wenhao and Yang, Yi},
  journal={arXiv preprint arXiv:2403.06098},
  year={2024}
}

@inproceedings{caballero2017real,
  title={Real-time video super-resolution with spatio-temporal networks and motion compensation},
  author={Caballero, Jose and Ledig, Christian and Aitken, Andrew and Acosta, Alejandro and Totz, Johannes and Wang, Zehan and Shi, Wenzhe},
  booktitle=CVPR,
  pages={4778--4787},
  year={2017}
}

@article{liang2024vrt,
  title={Vrt: A video restoration transformer},
  author={Liang, Jingyun and Cao, Jiezhang and Fan, Yuchen and Zhang, Kai and Ranjan, Rakesh and Li, Yawei and Timofte, Radu and Van Gool, Luc},
  journal=TIP,
  year={2024},
  publisher={IEEE}
}

@inproceedings{li2020mucan,
  title={Mucan: Multi-correspondence aggregation network for video super-resolution},
  author={Li, Wenbo and Tao, Xin and Guo, Taian and Qi, Lu and Lu, Jiangbo and Jia, Jiaya},
  booktitle=ECCV,
  pages={335--351},
  year={2020},
  organization={Springer}
}

@inproceedings{xu2021temporal,
  title={Temporal modulation network for controllable space-time video super-resolution},
  author={Xu, Gang and Xu, Jun and Li, Zhen and Wang, Liang and Sun, Xing and Cheng, Ming-Ming},
  booktitle=CVPR,
  pages={6388--6397},
  year={2021}
}

@inproceedings{haris2019recurrent,
  title={Recurrent back-projection network for video super-resolution},
  author={Haris, Muhammad and Shakhnarovich, Gregory and Ukita, Norimichi},
  booktitle=CVPR,
  pages={3897--3906},
  year={2019}
}

@article{huang2017video,
  title={Video super-resolution via bidirectional recurrent convolutional networks},
  author={Huang, Yan and Wang, Wei and Wang, Liang},
  journal=PAMI,
  volume={40},
  number={4},
  pages={1015--1028},
  year={2017},
  publisher={IEEE}
}

@article{liang2022recurrent,
  title={Recurrent video restoration transformer with guided deformable attention},
  author={Liang, Jingyun and Fan, Yuchen and Xiang, Xiaoyu and Ranjan, Rakesh and Ilg, Eddy and Green, Simon and Cao, Jiezhang and Zhang, Kai and Timofte, Radu and Gool, Luc V},
  journal=NIPS,
  volume={35},
  pages={378--393},
  year={2022}
}

@inproceedings{sajjadi2018frame,
  title={Frame-recurrent video super-resolution},
  author={Sajjadi, Mehdi SM and Vemulapalli, Raviteja and Brown, Matthew},
  booktitle=CVPR,
  pages={6626--6634},
  year={2018}
}

@article{shi2022rethinking,
  title={Rethinking alignment in video super-resolution transformers},
  author={Shi, Shuwei and Gu, Jinjin and Xie, Liangbin and Wang, Xintao and Yang, Yujiu and Dong, Chao},
  journal=NIPS,
  volume={35},
  pages={36081--36093},
  year={2022}
}

@article{bao2024vidu,
  title={Vidu: a highly consistent, dynamic and skilled text-to-video generator with diffusion models},
  author={Bao, Fan and Xiang, Chendong and Yue, Gang and He, Guande and Zhu, Hongzhou and Zheng, Kaiwen and Zhao, Min and Liu, Shilong and Wang, Yaole and Zhu, Jun},
  journal={arXiv preprint arXiv:2405.04233},
  year={2024}
}

@article{polyak2024movie,
  title={Movie gen: A cast of media foundation models},
  author={Polyak, Adam and Zohar, Amit and Brown, Andrew and Tjandra, Andros and Sinha, Animesh and Lee, Ann and Vyas, Apoorv and Shi, Bowen and Ma, Chih-Yao and Chuang, Ching-Yao and others},
  journal={arXiv preprint arXiv:2410.13720},
  year={2024}
}

@inproceedings{chen2024gentron,
  title={GenTron: Diffusion Transformers for Image and Video Generation},
  author={Chen, Shoufa and Xu, Mengmeng and Ren, Jiawei and Cong, Yuren and He, Sen and Xie, Yanping and Sinha, Animesh and Luo, Ping and Xiang, Tao and Perez-Rua, Juan-Manuel},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6441--6451},
  year={2024}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@article{raffel2020exploring,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={Journal of machine learning research},
  volume={21},
  number={140},
  pages={1--67},
  year={2020}
}

@article{salimans2022progressive,
  title={Progressive distillation for fast sampling of diffusion models},
  author={Salimans, Tim and Ho, Jonathan},
  journal={arXiv preprint arXiv:2202.00512},
  year={2022}
}

@inproceedings{kong2022residual,
  title={Residual local feature network for efficient super-resolution},
  author={Kong, Fangyuan and Li, Mingxi and Liu, Songwei and Liu, Ding and He, Jingwen and Bai, Yang and Chen, Fangmin and Fu, Lean},
  booktitle=CVPR,
  pages={766--776},
  year={2022}
}


@inproceedings{mikolov2010recurrent,
  title={Recurrent neural network based language model.},
  author={Mikolov, Tomas and Karafi{\'a}t, Martin and Burget, Lukas and Cernock{\`y}, Jan and Khudanpur, Sanjeev},
  booktitle={Interspeech},
  volume={2},
  number={3},
  pages={1045--1048},
  year={2010},
  organization={Makuhari}
}

@inproceedings{yu2024scaling,
  title={Scaling up to excellence: Practicing model scaling for photo-realistic image restoration in the wild},
  author={Yu, Fanghua and Gu, Jinjin and Li, Zheyuan and Hu, Jinfan and Kong, Xiangtao and Wang, Xintao and He, Jingwen and Qiao, Yu and Dong, Chao},
  booktitle=CVPR,
  pages={25669--25680},
  year={2024}
}

@article{he2024venhancer,
  title={VEnhancer: Generative Space-Time Enhancement for Video Generation},
  author={He, Jingwen and Xue, Tianfan and Liu, Dongyang and Lin, Xinqi and Gao, Peng and Lin, Dahua and Qiao, Yu and Ouyang, Wanli and Liu, Ziwei},
  journal={arXiv preprint arXiv:2407.07667},
  year={2024}
}

@article{loshchilov2017decoupled,
  title={Decoupled weight decay regularization},
  author={Loshchilov, I},
  journal={arXiv preprint arXiv:1711.05101},
  year={2017}
}

@article{yang2023mgldvsr,
  title={Motion-Guided Latent Diffusion for Temporally Consistent Real-world Video Super-resolution},
  author={Yang, Xi and He, Chenhang and Ma, Jianqi and Zhang, Lei},
  booktitle=ECCV,
  year={2024}
}

@article{wang2023lavie,
  title={Lavie: High-quality video generation with cascaded latent diffusion models},
  author={Wang, Yaohui and Chen, Xinyuan and Ma, Xin and Zhou, Shangchen and Huang, Ziqi and Wang, Yi and Yang, Ceyuan and He, Yinan and Yu, Jiashuo and Yang, Peiqing and others},
  journal={arXiv preprint arXiv:2309.15103},
  year={2023}
}

@inproceedings{bain2021frozen,
  title={Frozen in time: A joint video and image encoder for end-to-end retrieval},
  author={Bain, Max and Nagrani, Arsha and Varol, G{\"u}l and Zisserman, Andrew},
  booktitle=ICCV,
  pages={1728--1738},
  year={2021}
}

@article{kaplan2020scaling,
  title={Scaling laws for neural language models},
  author={Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  journal={arXiv preprint arXiv:2001.08361},
  year={2020}
}

@article{henighan2020scaling,
  title={Scaling laws for autoregressive generative modeling},
  author={Henighan, Tom and Kaplan, Jared and Katz, Mor and Chen, Mark and Hesse, Christopher and Jackson, Jacob and Jun, Heewoo and Brown, Tom B and Dhariwal, Prafulla and Gray, Scott and others},
  journal={arXiv preprint arXiv:2010.14701},
  year={2020}
}

@inproceedings{blau2018perception,
  title={The perception-distortion tradeoff},
  author={Blau, Yochai and Michaeli, Tomer},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={6228--6237},
  year={2018}
}

@inproceedings{zhao2024wavelet,
  title={Wavelet-based fourier information interaction with frequency diffusion adjustment for underwater image restoration},
  author={Zhao, Chen and Cai, Weiling and Dong, Chenyu and Hu, Chengwei},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={8281--8291},
  year={2024}
}