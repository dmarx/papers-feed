\begin{thebibliography}{38}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Esser et~al.(2024)Esser, Kulal, Blattmann, Entezari, M{\"u}ller, Saini, Levi, Lorenz, Sauer, Boesel, et~al.]{sd3}
Patrick Esser, Sumith Kulal, Andreas Blattmann, Rahim Entezari, Jonas M{\"u}ller, Harry Saini, Yam Levi, Dominik Lorenz, Axel Sauer, Frederic Boesel, et~al.
\newblock Scaling rectified flow transformers for high-resolution image synthesis.
\newblock \emph{arXiv preprint arXiv:2403.03206}, 2024.

\bibitem[Ye et~al.(2023)Ye, Zhang, Liu, Han, and Yang]{ye2023ip}
Hu~Ye, Jun Zhang, Sibo Liu, Xiao Han, and Wei Yang.
\newblock Ip-adapter: Text compatible image prompt adapter for text-to-image diffusion models.
\newblock \emph{arXiv preprint arXiv:2308.06721}, 2023.

\bibitem[Yan et~al.(2023)Yan, Zhang, Wang, Zhou, Zhang, Cheng, Yu, and Fu]{yan2023facestudio}
Yuxuan Yan, Chi Zhang, Rui Wang, Yichao Zhou, Gege Zhang, Pei Cheng, Gang Yu, and Bin Fu.
\newblock Facestudio: Put your face everywhere in seconds.
\newblock \emph{arXiv preprint arXiv:2312.02663}, 2023.

\bibitem[Pan et~al.(2023)Pan, Dong, Huang, Peng, Chen, and Wei]{pan2023kosmos}
Xichen Pan, Li~Dong, Shaohan Huang, Zhiliang Peng, Wenhu Chen, and Furu Wei.
\newblock Kosmos-g: Generating images in context with multimodal large language models.
\newblock \emph{arXiv preprint arXiv:2310.02992}, 2023.

\bibitem[Li et~al.(2024)Li, Li, and Hoi]{li2024blip}
Dongxu Li, Junnan Li, and Steven Hoi.
\newblock Blip-diffusion: Pre-trained subject representation for controllable text-to-image generation and editing.
\newblock \emph{Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem[Purushwalkam et~al.(2024)Purushwalkam, Gokul, Joty, and Naik]{purushwalkam2024bootpig}
Senthil Purushwalkam, Akash Gokul, Shafiq Joty, and Nikhil Naik.
\newblock Bootpig: Bootstrapping zero-shot personalized image generation capabilities in pretrained diffusion models.
\newblock \emph{arXiv preprint arXiv:2401.13974}, 2024.

\bibitem[Wang et~al.(2024)Wang, Bai, Wang, Qin, and Chen]{wang2024instantid}
Qixun Wang, Xu~Bai, Haofan Wang, Zekui Qin, and Anthony Chen.
\newblock Instantid: Zero-shot identity-preserving generation in seconds.
\newblock \emph{arXiv preprint arXiv:2401.07519}, 2024.

\bibitem[Zhang et~al.(2023)Zhang, Liu, Song, Wang, Tang, Yu, Li, Tang, Hu, Pan, et~al.]{zhang2023ssr}
Yuxuan Zhang, Jiaming Liu, Yiren Song, Rui Wang, Hao Tang, Jinpeng Yu, Huaxia Li, Xu~Tang, Yao Hu, Han Pan, et~al.
\newblock Ssr-encoder: Encoding selective subject representation for subject-driven generation.
\newblock \emph{arXiv preprint arXiv:2312.16272}, 2023.

\bibitem[Hu et~al.(2024)Hu, Wang, Fang, Fu, Cheng, and Yu]{hu2024ella}
Xiwei Hu, Rui Wang, Yixiao Fang, Bin Fu, Pei Cheng, and Gang Yu.
\newblock Ella: Equip diffusion models with llm for enhanced semantic alignment.
\newblock \emph{arXiv preprint arXiv:2403.05135}, 2024.

\bibitem[Alayrac et~al.(2022)Alayrac, Donahue, Luc, Miech, Barr, Hasson, Lenc, Mensch, Millican, Reynolds, et~al.]{alayrac2022flamingo}
Jean-Baptiste Alayrac, Jeff Donahue, Pauline Luc, Antoine Miech, Iain Barr, Yana Hasson, Karel Lenc, Arthur Mensch, Katherine Millican, Malcolm Reynolds, et~al.
\newblock Flamingo: a visual language model for few-shot learning.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 23716--23736, 2022.

\bibitem[Chen et~al.(2023)Chen, Yu, Ge, Yao, Xie, Wu, Wang, Kwok, Luo, Lu, et~al.]{chen2023pixart}
Junsong Chen, Jincheng Yu, Chongjian Ge, Lewei Yao, Enze Xie, Yue Wu, Zhongdao Wang, James Kwok, Ping Luo, Huchuan Lu, et~al.
\newblock Pixart-$\alpha$: Fast training of diffusion transformer for photorealistic text-to-image synthesis.
\newblock \emph{arXiv preprint arXiv:2310.00426}, 2023.

\bibitem[Peebles and Xie(2023)]{dit}
William Peebles and Saining Xie.
\newblock Scalable diffusion models with transformers.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 4195--4205, 2023.

\bibitem[Nichol et~al.(2021)Nichol, Dhariwal, Ramesh, Shyam, Mishkin, McGrew, Sutskever, and Chen]{nichol2021glide}
Alex Nichol, Prafulla Dhariwal, Aditya Ramesh, Pranav Shyam, Pamela Mishkin, Bob McGrew, Ilya Sutskever, and Mark Chen.
\newblock Glide: Towards photorealistic image generation and editing with text-guided diffusion models.
\newblock \emph{arXiv preprint arXiv:2112.10741}, 2021.

\bibitem[Rombach et~al.(2022)Rombach, Blattmann, Lorenz, Esser, and Ommer]{rombach2022high}
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj{\"o}rn Ommer.
\newblock High-resolution image synthesis with latent diffusion models.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 10684--10695, 2022.

\bibitem[Ramesh et~al.(2022)Ramesh, Dhariwal, Nichol, Chu, and Chen]{ramesh2022hierarchical}
Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen.
\newblock Hierarchical text-conditional image generation with clip latents.
\newblock \emph{arXiv preprint arXiv:2204.06125}, 1\penalty0 (2):\penalty0 3, 2022.

\bibitem[Podell et~al.(2023)Podell, English, Lacey, Blattmann, Dockhorn, M{\"u}ller, Penna, and Rombach]{podell2023sdxl}
Dustin Podell, Zion English, Kyle Lacey, Andreas Blattmann, Tim Dockhorn, Jonas M{\"u}ller, Joe Penna, and Robin Rombach.
\newblock Sdxl: Improving latent diffusion models for high-resolution image synthesis.
\newblock \emph{arXiv preprint arXiv:2307.01952}, 2023.

\bibitem[Radford et~al.(2021)Radford, Kim, Hallacy, Ramesh, Goh, Agarwal, Sastry, Askell, Mishkin, Clark, et~al.]{radford2021learning}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et~al.
\newblock Learning transferable visual models from natural language supervision.
\newblock In \emph{International conference on machine learning}, pages 8748--8763. PMLR, 2021.

\bibitem[Saharia et~al.(2022)Saharia, Chan, Saxena, Li, Whang, Denton, Ghasemipour, Gontijo~Lopes, Karagol~Ayan, Salimans, et~al.]{saharia2022photorealistic}
Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily~L Denton, Kamyar Ghasemipour, Raphael Gontijo~Lopes, Burcu Karagol~Ayan, Tim Salimans, et~al.
\newblock Photorealistic text-to-image diffusion models with deep language understanding.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 36479--36494, 2022.

\bibitem[Betker et~al.(2023)Betker, Goh, Jing, Brooks, Wang, Li, Ouyang, Zhuang, Lee, Guo, et~al.]{betker2023improving}
James Betker, Gabriel Goh, Li~Jing, Tim Brooks, Jianfeng Wang, Linjie Li, Long Ouyang, Juntang Zhuang, Joyce Lee, Yufei Guo, et~al.
\newblock Improving image generation with better captions.
\newblock \emph{Computer Science. https://cdn. openai. com/papers/dall-e-3. pdf}, 2\penalty0 (3):\penalty0 8, 2023.

\bibitem[Raffel et~al.(2020)Raffel, Shazeer, Roberts, Lee, Narang, Matena, Zhou, Li, and Liu]{raffel2020exploring}
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter~J Liu.
\newblock Exploring the limits of transfer learning with a unified text-to-text transformer.
\newblock \emph{The Journal of Machine Learning Research}, 21\penalty0 (1):\penalty0 5485--5551, 2020.

\bibitem[Balaji et~al.(2022)Balaji, Nah, Huang, Vahdat, Song, Kreis, Aittala, Aila, Laine, Catanzaro, et~al.]{balaji2022ediffi}
Yogesh Balaji, Seungjun Nah, Xun Huang, Arash Vahdat, Jiaming Song, Karsten Kreis, Miika Aittala, Timo Aila, Samuli Laine, Bryan Catanzaro, et~al.
\newblock ediffi: Text-to-image diffusion models with an ensemble of expert denoisers.
\newblock \emph{arXiv preprint arXiv:2211.01324}, 2022.

\bibitem[Dai et~al.(2023)Dai, Hou, Ma, Tsai, Wang, Wang, Zhang, Vandenhende, Wang, Dubey, et~al.]{dai2023emu}
Xiaoliang Dai, Ji~Hou, Chih-Yao Ma, Sam Tsai, Jialiang Wang, Rui Wang, Peizhao Zhang, Simon Vandenhende, Xiaofang Wang, Abhimanyu Dubey, et~al.
\newblock Emu: Enhancing image generation models using photogenic needles in a haystack.
\newblock \emph{arXiv preprint arXiv:2309.15807}, 2023.

\bibitem[Wu et~al.(2023)Wu, Li, He, Shou, Shen, Cheng, Li, Gao, Zhang, and Wang]{wu2023paradiffusion}
Weijia Wu, Zhuang Li, Yefei He, Mike~Zheng Shou, Chunhua Shen, Lele Cheng, Yan Li, Tingting Gao, Di~Zhang, and Zhongyuan Wang.
\newblock Paragraph-to-image generation with information-enriched diffusion model, 2023.

\bibitem[Touvron et~al.(2023)Touvron, Martin, Stone, Albert, Almahairi, Babaei, Bashlykov, Batra, Bhargava, Bhosale, et~al.]{touvron2023llama}
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et~al.
\newblock Llama 2: Open foundation and fine-tuned chat models.
\newblock \emph{arXiv preprint arXiv:2307.09288}, 2023.

\bibitem[Zhang et~al.(2024)Zhang, Zeng, Wang, and Lu]{zhang2024tinyllama}
Peiyuan Zhang, Guangtao Zeng, Tianduo Wang, and Wei Lu.
\newblock Tinyllama: An open-source small language model, 2024.

\bibitem[Ma et~al.(2023{\natexlab{a}})Ma, Liang, Chen, and Lu]{ma2023subject}
Jian Ma, Junhao Liang, Chen Chen, and Haonan Lu.
\newblock Subject-diffusion: Open domain personalized text-to-image generation without test-time fine-tuning.
\newblock \emph{arXiv preprint arXiv:2307.11410}, 2023{\natexlab{a}}.

\bibitem[Wei et~al.(2023)Wei, Zhang, Ji, Bai, Zhang, and Zuo]{wei2023elite}
Yuxiang Wei, Yabo Zhang, Zhilong Ji, Jinfeng Bai, Lei Zhang, and Wangmeng Zuo.
\newblock Elite: Encoding visual concepts into textual embeddings for customized text-to-image generation.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 15943--15953, 2023.

\bibitem[Xiao et~al.(2023)Xiao, Yin, Freeman, Durand, and Han]{xiao2023fastcomposer}
Guangxuan Xiao, Tianwei Yin, William~T Freeman, Fr{\'e}do Durand, and Song Han.
\newblock Fastcomposer: Tuning-free multi-subject image generation with localized attention.
\newblock \emph{arXiv preprint arXiv:2305.10431}, 2023.

\bibitem[Ma et~al.(2023{\natexlab{b}})Ma, Yang, Wang, Fu, and Liu]{ma2023unified}
Yiyang Ma, Huan Yang, Wenjing Wang, Jianlong Fu, and Jiaying Liu.
\newblock Unified multi-modal latent diffusion for joint subject and text conditional image generation.
\newblock \emph{arXiv preprint arXiv:2303.09319}, 2023{\natexlab{b}}.

\bibitem[Li et~al.(2023)Li, Cao, Wang, Qi, Cheng, and Shan]{li2023photomaker}
Zhen Li, Mingdeng Cao, Xintao Wang, Zhongang Qi, Ming-Ming Cheng, and Ying Shan.
\newblock Photomaker: Customizing realistic human photos via stacked id embedding.
\newblock \emph{arXiv preprint arXiv:2312.04461}, 2023.

\bibitem[Ostashev et~al.(2024)Ostashev, Fang, Tulyakov, Aberman, et~al.]{ostashev2024moa}
Daniil Ostashev, Yuwei Fang, Sergey Tulyakov, Kfir Aberman, et~al.
\newblock Moa: Mixture-of-attention for subject-context disentanglement in personalized image generation.
\newblock \emph{arXiv preprint arXiv:2404.11565}, 2024.

\bibitem[Gal et~al.(2022)Gal, Alaluf, Atzmon, Patashnik, Bermano, Chechik, and Cohen-Or]{gal2022image}
Rinon Gal, Yuval Alaluf, Yuval Atzmon, Or~Patashnik, Amit~H Bermano, Gal Chechik, and Daniel Cohen-Or.
\newblock An image is worth one word: Personalizing text-to-image generation using textual inversion.
\newblock \emph{arXiv preprint arXiv:2208.01618}, 2022.

\bibitem[Ruiz et~al.(2023)Ruiz, Li, Jampani, Pritch, Rubinstein, and Aberman]{ruiz2023dreambooth}
Nataniel Ruiz, Yuanzhen Li, Varun Jampani, Yael Pritch, Michael Rubinstein, and Kfir Aberman.
\newblock Dreambooth: Fine tuning text-to-image diffusion models for subject-driven generation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 22500--22510, 2023.

\bibitem[Liu et~al.(2023)Liu, Feng, Zhu, Zhang, Zheng, Liu, Zhao, Zhou, and Cao]{liu2023cones}
Zhiheng Liu, Ruili Feng, Kai Zhu, Yifei Zhang, Kecheng Zheng, Yu~Liu, Deli Zhao, Jingren Zhou, and Yang Cao.
\newblock Cones: Concept neurons in diffusion models for customized generation.
\newblock \emph{arXiv preprint arXiv:2303.05125}, 2023.

\bibitem[Chung et~al.(2024)Chung, Hou, Longpre, Zoph, Tay, Fedus, Li, Wang, Dehghani, Brahma, et~al.]{chung2024scaling}
Hyung~Won Chung, Le~Hou, Shayne Longpre, Barret Zoph, Yi~Tay, William Fedus, Yunxuan Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, et~al.
\newblock Scaling instruction-finetuned language models.
\newblock \emph{Journal of Machine Learning Research}, 25\penalty0 (70):\penalty0 1--53, 2024.

\bibitem[Schuhmann et~al.(2022)Schuhmann, Beaumont, Vencu, Gordon, Wightman, Cherti, Coombes, Katta, Mullis, Wortsman, et~al.]{schuhmann2022laion}
Christoph Schuhmann, Romain Beaumont, Richard Vencu, Cade Gordon, Ross Wightman, Mehdi Cherti, Theo Coombes, Aarush Katta, Clayton Mullis, Mitchell Wortsman, et~al.
\newblock Laion-5b: An open large-scale dataset for training next generation image-text models.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 25278--25294, 2022.

\bibitem[Byeon et~al.(2022)Byeon, Park, Kim, Lee, Baek, and Kim]{kakaobrain2022coyo-700m}
Minwoo Byeon, Beomhee Park, Haecheon Kim, Sungjun Lee, Woonhyuk Baek, and Saehoon Kim.
\newblock Coyo-700m: Image-text pair dataset.
\newblock \url{https://github.com/kakaobrain/coyo-dataset}, 2022.

\bibitem[Kim et~al.(2022)Kim, Jain, and Liu]{kim2022adaface}
Minchul Kim, Anil~K Jain, and Xiaoming Liu.
\newblock Adaface: Quality adaptive margin for face recognition.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 18750--18759, 2022.

\end{thebibliography}
